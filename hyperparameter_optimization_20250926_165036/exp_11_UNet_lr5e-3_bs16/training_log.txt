âœ“ GPU memory growth enabled for 1 GPUs
Loading dataset...
Loaded 144 images and 144 masks
Training set: (129, 256, 256, 3), Validation set: (15, 256, 256, 3)

============================================================
TRAINING: UNet
Learning Rate: 0.005, Batch Size: 16, Epochs: 30
============================================================
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 256, 256, 64)         640       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 256, 256, 64)         256       ['conv2d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 activation (Activation)     (None, 256, 256, 64)         0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['activation[0][0]']          
                                                                                                  
 batch_normalization_1 (Bat  (None, 256, 256, 64)         256       ['conv2d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_1 (Activation)   (None, 256, 256, 64)         0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['activation_1[0][0]']        
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       
                                                                                                  
 batch_normalization_2 (Bat  (None, 128, 128, 128)        512       ['conv2d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_2 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_3 (Conv2D)           (None, 128, 128, 128)        147584    ['activation_2[0][0]']        
                                                                                                  
 batch_normalization_3 (Bat  (None, 128, 128, 128)        512       ['conv2d_3[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_3 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_3[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_3[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 batch_normalization_4 (Bat  (None, 64, 64, 256)          1024      ['conv2d_4[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_4 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_4[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_5 (Conv2D)           (None, 64, 64, 256)          590080    ['activation_4[0][0]']        
                                                                                                  
 batch_normalization_5 (Bat  (None, 64, 64, 256)          1024      ['conv2d_5[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_5 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_5[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_5[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 512)          1180160   ['max_pooling2d_2[0][0]']     
                                                                                                  
 batch_normalization_6 (Bat  (None, 32, 32, 512)          2048      ['conv2d_6[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_6 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_6[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 32, 32, 512)          2359808   ['activation_6[0][0]']        
                                                                                                  
 batch_normalization_7 (Bat  (None, 32, 32, 512)          2048      ['conv2d_7[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_7 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_7[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_3 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_7[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 1024)         4719616   ['max_pooling2d_3[0][0]']     
                                                                                                  
 batch_normalization_8 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_8[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_8 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_8[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 1024)         9438208   ['activation_8[0][0]']        
                                                                                                  
 batch_normalization_9 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_9[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_9 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_9[0][0]'
                                                                    ]                             
                                                                                                  
 up_sampling2d (UpSampling2  (None, 32, 32, 1024)         0         ['activation_9[0][0]']        
 D)                                                                                               
                                                                                                  
 concatenate (Concatenate)   (None, 32, 32, 1536)         0         ['up_sampling2d[0][0]',       
                                                                     'activation_7[0][0]']        
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate[0][0]']         
                                                                                                  
 batch_normalization_10 (Ba  (None, 32, 32, 512)          2048      ['conv2d_10[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_10 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_10[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_10[0][0]']       
                                                                                                  
 batch_normalization_11 (Ba  (None, 32, 32, 512)          2048      ['conv2d_11[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_11 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_11[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 64, 64, 512)          0         ['activation_11[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_1 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_1[0][0]',     
 )                                                                   'activation_5[0][0]']        
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_1[0][0]']       
                                                                                                  
 batch_normalization_12 (Ba  (None, 64, 64, 256)          1024      ['conv2d_12[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_12 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_12[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_13 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_12[0][0]']       
                                                                                                  
 batch_normalization_13 (Ba  (None, 64, 64, 256)          1024      ['conv2d_13[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_13 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_13[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 128, 128, 256)        0         ['activation_13[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_2 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_2[0][0]',     
 )                                                                   'activation_3[0][0]']        
                                                                                                  
 conv2d_14 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_2[0][0]']       
                                                                                                  
 batch_normalization_14 (Ba  (None, 128, 128, 128)        512       ['conv2d_14[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_14 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_14[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_15 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_14[0][0]']       
                                                                                                  
 batch_normalization_15 (Ba  (None, 128, 128, 128)        512       ['conv2d_15[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_15 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_15[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 256, 256, 128)        0         ['activation_15[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_3 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_3[0][0]',     
 )                                                                   'activation_1[0][0]']        
                                                                                                  
 conv2d_16 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_3[0][0]']       
                                                                                                  
 batch_normalization_16 (Ba  (None, 256, 256, 64)         256       ['conv2d_16[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_16 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_16[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_16[0][0]']       
                                                                                                  
 batch_normalization_17 (Ba  (None, 256, 256, 64)         256       ['conv2d_17[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_17 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_17[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_18 (Conv2D)          (None, 256, 256, 1)          65        ['activation_17[0][0]']       
                                                                                                  
 batch_normalization_18 (Ba  (None, 256, 256, 1)          4         ['conv2d_18[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_18 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_18[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31401349 (119.79 MB)
Trainable params: 31389571 (119.74 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
None
âœ“ focal_loss imported successfully
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_2 (InputLayer)        [(None, 256, 256, 3)]        0         []                            
                                                                                                  
 conv2d_19 (Conv2D)          (None, 256, 256, 64)         1792      ['input_2[0][0]']             
                                                                                                  
 batch_normalization_19 (Ba  (None, 256, 256, 64)         256       ['conv2d_19[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_19 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_19[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_20 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_19[0][0]']       
                                                                                                  
 batch_normalization_20 (Ba  (None, 256, 256, 64)         256       ['conv2d_20[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_20 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_20[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_4 (MaxPoolin  (None, 128, 128, 64)         0         ['activation_20[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_21 (Conv2D)          (None, 128, 128, 128)        73856     ['max_pooling2d_4[0][0]']     
                                                                                                  
 batch_normalization_21 (Ba  (None, 128, 128, 128)        512       ['conv2d_21[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_21 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_21[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_22 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_21[0][0]']       
                                                                                                  
 batch_normalization_22 (Ba  (None, 128, 128, 128)        512       ['conv2d_22[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_22 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_22[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_5 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_22[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_23 (Conv2D)          (None, 64, 64, 256)          295168    ['max_pooling2d_5[0][0]']     
                                                                                                  
 batch_normalization_23 (Ba  (None, 64, 64, 256)          1024      ['conv2d_23[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_23 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_23[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_24 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_23[0][0]']       
                                                                                                  
 batch_normalization_24 (Ba  (None, 64, 64, 256)          1024      ['conv2d_24[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_24 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_24[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_6 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_24[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_25 (Conv2D)          (None, 32, 32, 512)          1180160   ['max_pooling2d_6[0][0]']     
                                                                                                  
 batch_normalization_25 (Ba  (None, 32, 32, 512)          2048      ['conv2d_25[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_25 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_25[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_26 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_25[0][0]']       
                                                                                                  
 batch_normalization_26 (Ba  (None, 32, 32, 512)          2048      ['conv2d_26[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_26 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_26[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_7 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_26[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_27 (Conv2D)          (None, 16, 16, 1024)         4719616   ['max_pooling2d_7[0][0]']     
                                                                                                  
 batch_normalization_27 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_27[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_27 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_27[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_28 (Conv2D)          (None, 16, 16, 1024)         9438208   ['activation_27[0][0]']       
                                                                                                  
 batch_normalization_28 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_28[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_28 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_28[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 1024)         0         ['activation_28[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_4 (Concatenate  (None, 32, 32, 1536)         0         ['up_sampling2d_4[0][0]',     
 )                                                                   'activation_26[0][0]']       
                                                                                                  
 conv2d_29 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate_4[0][0]']       
                                                                                                  
 batch_normalization_29 (Ba  (None, 32, 32, 512)          2048      ['conv2d_29[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_29 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_29[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_30 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_29[0][0]']       
                                                                                                  
 batch_normalization_30 (Ba  (None, 32, 32, 512)          2048      ['conv2d_30[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_30 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_30[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 512)          0         ['activation_30[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_5 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_5[0][0]',     
 )                                                                   'activation_24[0][0]']       
                                                                                                  
 conv2d_31 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_5[0][0]']       
                                                                                                  
 batch_normalization_31 (Ba  (None, 64, 64, 256)          1024      ['conv2d_31[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_31 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_31[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_32 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_31[0][0]']       
                                                                                                  
 batch_normalization_32 (Ba  (None, 64, 64, 256)          1024      ['conv2d_32[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_32 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_32[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_6 (UpSamplin  (None, 128, 128, 256)        0         ['activation_32[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_6 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_6[0][0]',     
 )                                                                   'activation_22[0][0]']       
                                                                                                  
 conv2d_33 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_6[0][0]']       
                                                                                                  
 batch_normalization_33 (Ba  (None, 128, 128, 128)        512       ['conv2d_33[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_33 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_33[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_34 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_33[0][0]']       
                                                                                                  
 batch_normalization_34 (Ba  (None, 128, 128, 128)        512       ['conv2d_34[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_34 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_34[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_7 (UpSamplin  (None, 256, 256, 128)        0         ['activation_34[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_7 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_7[0][0]',     
 )                                                                   'activation_20[0][0]']       
                                                                                                  
 conv2d_35 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_7[0][0]']       
                                                                                                  
 batch_normalization_35 (Ba  (None, 256, 256, 64)         256       ['conv2d_35[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_35 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_35[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_36 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_35[0][0]']       
                                                                                                  
 batch_normalization_36 (Ba  (None, 256, 256, 64)         256       ['conv2d_36[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_36 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_36[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_37 (Conv2D)          (None, 256, 256, 1)          65        ['activation_36[0][0]']       
                                                                                                  
 batch_normalization_37 (Ba  (None, 256, 256, 1)          4         ['conv2d_37[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_37 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_37[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31402501 (119.79 MB)
Trainable params: 31390723 (119.75 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
WARNING:absl:`lr` is deprecated in TF-Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
None
Epoch 1/30
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1758877773.706106 1064192 service.cc:145] XLA service 0x152849d28650 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1758877773.706128 1064192 service.cc:153]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6
I0000 00:00:1758877773.844512 1064192 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
1/9 [==>...........................] - ETA: 4:48 - loss: 0.3420 - accuracy: 0.5078 - jacard_coef: 0.09042/9 [=====>........................] - ETA: 54s - loss: 0.3283 - accuracy: 0.4893 - jacard_coef: 0.0788 3/9 [=========>....................] - ETA: 32s - loss: 0.3041 - accuracy: 0.4063 - jacard_coef: 0.07524/9 [============>.................] - ETA: 21s - loss: 0.2868 - accuracy: 0.3625 - jacard_coef: 0.07775/9 [===============>..............] - ETA: 13s - loss: 0.2701 - accuracy: 0.3296 - jacard_coef: 0.07706/9 [===================>..........] - ETA: 8s - loss: 0.2634 - accuracy: 0.3004 - jacard_coef: 0.0826 7/9 [======================>.......] - ETA: 5s - loss: 0.2552 - accuracy: 0.2758 - jacard_coef: 0.08188/9 [=========================>....] - ETA: 2s - loss: 0.2487 - accuracy: 0.2580 - jacard_coef: 0.08169/9 [==============================] - ETA: 0s - loss: 0.2484 - accuracy: 0.2577 - jacard_coef: 0.09059/9 [==============================] - 58s 3s/step - loss: 0.2484 - accuracy: 0.2577 - jacard_coef: 0.0905 - val_loss: 1.1218 - val_accuracy: 0.9304 - val_jacard_coef: 1.4616e-12 - lr: 0.0010
Epoch 2/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1890 - accuracy: 0.1583 - jacard_coef: 0.06842/9 [=====>........................] - ETA: 1s - loss: 0.1914 - accuracy: 0.1547 - jacard_coef: 0.07643/9 [=========>....................] - ETA: 1s - loss: 0.1917 - accuracy: 0.1809 - jacard_coef: 0.08854/9 [============>.................] - ETA: 1s - loss: 0.1960 - accuracy: 0.1948 - jacard_coef: 0.08085/9 [===============>..............] - ETA: 0s - loss: 0.1948 - accuracy: 0.2172 - jacard_coef: 0.08096/9 [===================>..........] - ETA: 0s - loss: 0.1927 - accuracy: 0.2506 - jacard_coef: 0.08327/9 [======================>.......] - ETA: 0s - loss: 0.1916 - accuracy: 0.2582 - jacard_coef: 0.08058/9 [=========================>....] - ETA: 0s - loss: 0.1907 - accuracy: 0.2622 - jacard_coef: 0.08089/9 [==============================] - 2s 229ms/step - loss: 0.1909 - accuracy: 0.2627 - jacard_coef: 0.0855 - val_loss: 1.1218 - val_accuracy: 0.9304 - val_jacard_coef: 1.4616e-12 - lr: 0.0010
Epoch 3/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1902 - accuracy: 0.1261 - jacard_coef: 0.08392/9 [=====>........................] - ETA: 1s - loss: 0.1914 - accuracy: 0.1355 - jacard_coef: 0.07313/9 [=========>....................] - ETA: 1s - loss: 0.1905 - accuracy: 0.1479 - jacard_coef: 0.07334/9 [============>.................] - ETA: 1s - loss: 0.1930 - accuracy: 0.1520 - jacard_coef: 0.07865/9 [===============>..............] - ETA: 0s - loss: 0.1951 - accuracy: 0.1507 - jacard_coef: 0.07946/9 [===================>..........] - ETA: 0s - loss: 0.1985 - accuracy: 0.1531 - jacard_coef: 0.08357/9 [======================>.......] - ETA: 0s - loss: 0.1980 - accuracy: 0.1547 - jacard_coef: 0.08648/9 [=========================>....] - ETA: 0s - loss: 0.1981 - accuracy: 0.1536 - jacard_coef: 0.08279/9 [==============================] - 2s 228ms/step - loss: 0.1982 - accuracy: 0.1530 - jacard_coef: 0.0743 - val_loss: 1.1218 - val_accuracy: 0.9304 - val_jacard_coef: 1.4616e-12 - lr: 0.0010
Epoch 4/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1961 - accuracy: 0.1818 - jacard_coef: 0.08602/9 [=====>........................] - ETA: 1s - loss: 0.2006 - accuracy: 0.1853 - jacard_coef: 0.08453/9 [=========>....................] - ETA: 1s - loss: 0.2009 - accuracy: 0.1895 - jacard_coef: 0.08104/9 [============>.................] - ETA: 1s - loss: 0.1975 - accuracy: 0.1859 - jacard_coef: 0.08165/9 [===============>..............] - ETA: 0s - loss: 0.1953 - accuracy: 0.1853 - jacard_coef: 0.08386/9 [===================>..........] - ETA: 0s - loss: 0.1938 - accuracy: 0.1884 - jacard_coef: 0.08497/9 [======================>.......] - ETA: 0s - loss: 0.1930 - accuracy: 0.1926 - jacard_coef: 0.08358/9 [=========================>....] - ETA: 0s - loss: 0.1919 - accuracy: 0.1989 - jacard_coef: 0.08339/9 [==============================] - 2s 228ms/step - loss: 0.1925 - accuracy: 0.1983 - jacard_coef: 0.0761 - val_loss: 1.1218 - val_accuracy: 0.9304 - val_jacard_coef: 1.4615e-12 - lr: 0.0010
Epoch 5/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1847 - accuracy: 0.2239 - jacard_coef: 0.07592/9 [=====>........................] - ETA: 1s - loss: 0.1822 - accuracy: 0.2747 - jacard_coef: 0.07973/9 [=========>....................] - ETA: 1s - loss: 0.1813 - accuracy: 0.2914 - jacard_coef: 0.07814/9 [============>.................] - ETA: 1s - loss: 0.1806 - accuracy: 0.3028 - jacard_coef: 0.07905/9 [===============>..............] - ETA: 0s - loss: 0.1803 - accuracy: 0.3026 - jacard_coef: 0.07566/9 [===================>..........] - ETA: 0s - loss: 0.1797 - accuracy: 0.3126 - jacard_coef: 0.07797/9 [======================>.......] - ETA: 0s - loss: 0.1817 - accuracy: 0.3201 - jacard_coef: 0.07948/9 [=========================>....] - ETA: 0s - loss: 0.1810 - accuracy: 0.3290 - jacard_coef: 0.08319/9 [==============================] - 2s 228ms/step - loss: 0.1814 - accuracy: 0.3291 - jacard_coef: 0.0816 - val_loss: 1.1199 - val_accuracy: 0.9304 - val_jacard_coef: 1.4614e-12 - lr: 0.0010
Epoch 6/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1809 - accuracy: 0.5316 - jacard_coef: 0.10062/9 [=====>........................] - ETA: 1s - loss: 0.1831 - accuracy: 0.5098 - jacard_coef: 0.09013/9 [=========>....................] - ETA: 1s - loss: 0.1867 - accuracy: 0.4955 - jacard_coef: 0.08724/9 [============>.................] - ETA: 1s - loss: 0.1851 - accuracy: 0.4924 - jacard_coef: 0.08395/9 [===============>..............] - ETA: 0s - loss: 0.1835 - accuracy: 0.4953 - jacard_coef: 0.08416/9 [===================>..........] - ETA: 0s - loss: 0.1823 - accuracy: 0.4939 - jacard_coef: 0.08407/9 [======================>.......] - ETA: 0s - loss: 0.1833 - accuracy: 0.4968 - jacard_coef: 0.08178/9 [=========================>....] - ETA: 0s - loss: 0.1823 - accuracy: 0.4974 - jacard_coef: 0.07799/9 [==============================] - 2s 228ms/step - loss: 0.1827 - accuracy: 0.4949 - jacard_coef: 0.0749 - val_loss: 1.0774 - val_accuracy: 0.9302 - val_jacard_coef: 1.4567e-12 - lr: 0.0010
Epoch 7/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1820 - accuracy: 0.2871 - jacard_coef: 0.07662/9 [=====>........................] - ETA: 1s - loss: 0.1988 - accuracy: 0.2244 - jacard_coef: 0.07453/9 [=========>....................] - ETA: 1s - loss: 0.1957 - accuracy: 0.2493 - jacard_coef: 0.06714/9 [============>.................] - ETA: 1s - loss: 0.1900 - accuracy: 0.3098 - jacard_coef: 0.06855/9 [===============>..............] - ETA: 0s - loss: 0.1894 - accuracy: 0.3287 - jacard_coef: 0.07136/9 [===================>..........] - ETA: 0s - loss: 0.1871 - accuracy: 0.3409 - jacard_coef: 0.07657/9 [======================>.......] - ETA: 0s - loss: 0.1857 - accuracy: 0.3458 - jacard_coef: 0.07788/9 [=========================>....] - ETA: 0s - loss: 0.1844 - accuracy: 0.3524 - jacard_coef: 0.07769/9 [==============================] - 2s 228ms/step - loss: 0.1844 - accuracy: 0.3509 - jacard_coef: 0.0716 - val_loss: 1.1218 - val_accuracy: 0.9304 - val_jacard_coef: 1.4614e-12 - lr: 5.0000e-04
Epoch 8/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1887 - accuracy: 0.4197 - jacard_coef: 0.08232/9 [=====>........................] - ETA: 1s - loss: 0.1828 - accuracy: 0.4129 - jacard_coef: 0.07193/9 [=========>....................] - ETA: 1s - loss: 0.1800 - accuracy: 0.4258 - jacard_coef: 0.07074/9 [============>.................] - ETA: 1s - loss: 0.1797 - accuracy: 0.4243 - jacard_coef: 0.07525/9 [===============>..............] - ETA: 0s - loss: 0.1831 - accuracy: 0.4254 - jacard_coef: 0.08096/9 [===================>..........] - ETA: 0s - loss: 0.1814 - accuracy: 0.4432 - jacard_coef: 0.08367/9 [======================>.......] - ETA: 0s - loss: 0.1801 - accuracy: 0.4615 - jacard_coef: 0.08168/9 [=========================>....] - ETA: 0s - loss: 0.1790 - accuracy: 0.4785 - jacard_coef: 0.07839/9 [==============================] - 2s 229ms/step - loss: 0.1790 - accuracy: 0.4774 - jacard_coef: 0.0776 - val_loss: 1.1195 - val_accuracy: 0.9302 - val_jacard_coef: 1.4576e-12 - lr: 5.0000e-04
Epoch 9/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1681 - accuracy: 0.6332 - jacard_coef: 0.06572/9 [=====>........................] - ETA: 1s - loss: 0.1690 - accuracy: 0.6188 - jacard_coef: 0.07873/9 [=========>....................] - ETA: 1s - loss: 0.1746 - accuracy: 0.6003 - jacard_coef: 0.08244/9 [============>.................] - ETA: 1s - loss: 0.1735 - accuracy: 0.5870 - jacard_coef: 0.07825/9 [===============>..............] - ETA: 0s - loss: 0.1727 - accuracy: 0.5854 - jacard_coef: 0.07816/9 [===================>..........] - ETA: 0s - loss: 0.1718 - accuracy: 0.5972 - jacard_coef: 0.07837/9 [======================>.......] - ETA: 0s - loss: 0.1714 - accuracy: 0.6021 - jacard_coef: 0.07568/9 [=========================>....] - ETA: 0s - loss: 0.1719 - accuracy: 0.5932 - jacard_coef: 0.07849/9 [==============================] - 2s 234ms/step - loss: 0.1719 - accuracy: 0.5916 - jacard_coef: 0.0701 - val_loss: 1.0243 - val_accuracy: 0.9291 - val_jacard_coef: 8.1661e-04 - lr: 5.0000e-04
Epoch 10/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1700 - accuracy: 0.6679 - jacard_coef: 0.06542/9 [=====>........................] - ETA: 1s - loss: 0.1689 - accuracy: 0.6963 - jacard_coef: 0.06203/9 [=========>....................] - ETA: 1s - loss: 0.1683 - accuracy: 0.6902 - jacard_coef: 0.06814/9 [============>.................] - ETA: 1s - loss: 0.1704 - accuracy: 0.6915 - jacard_coef: 0.06925/9 [===============>..............] - ETA: 0s - loss: 0.1704 - accuracy: 0.6539 - jacard_coef: 0.07056/9 [===================>..........] - ETA: 0s - loss: 0.1707 - accuracy: 0.6444 - jacard_coef: 0.07447/9 [======================>.......] - ETA: 0s - loss: 0.1698 - accuracy: 0.6609 - jacard_coef: 0.07008/9 [=========================>....] - ETA: 0s - loss: 0.1693 - accuracy: 0.6713 - jacard_coef: 0.07189/9 [==============================] - 2s 233ms/step - loss: 0.1696 - accuracy: 0.6703 - jacard_coef: 0.0703 - val_loss: 0.4039 - val_accuracy: 0.9221 - val_jacard_coef: 0.0034 - lr: 5.0000e-04
Epoch 11/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1636 - accuracy: 0.7599 - jacard_coef: 0.04982/9 [=====>........................] - ETA: 1s - loss: 0.1638 - accuracy: 0.7720 - jacard_coef: 0.06313/9 [=========>....................] - ETA: 1s - loss: 0.1634 - accuracy: 0.7768 - jacard_coef: 0.05814/9 [============>.................] - ETA: 1s - loss: 0.1632 - accuracy: 0.7642 - jacard_coef: 0.06555/9 [===============>..............] - ETA: 0s - loss: 0.1633 - accuracy: 0.7375 - jacard_coef: 0.07026/9 [===================>..........] - ETA: 0s - loss: 0.1632 - accuracy: 0.7215 - jacard_coef: 0.07157/9 [======================>.......] - ETA: 0s - loss: 0.1638 - accuracy: 0.7206 - jacard_coef: 0.07268/9 [=========================>....] - ETA: 0s - loss: 0.1636 - accuracy: 0.7289 - jacard_coef: 0.07029/9 [==============================] - 2s 233ms/step - loss: 0.1637 - accuracy: 0.7276 - jacard_coef: 0.0680 - val_loss: 0.2370 - val_accuracy: 0.9067 - val_jacard_coef: 0.0092 - lr: 5.0000e-04
Epoch 12/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1627 - accuracy: 0.8310 - jacard_coef: 0.05952/9 [=====>........................] - ETA: 1s - loss: 0.1621 - accuracy: 0.8532 - jacard_coef: 0.04263/9 [=========>....................] - ETA: 1s - loss: 0.1636 - accuracy: 0.8119 - jacard_coef: 0.06314/9 [============>.................] - ETA: 1s - loss: 0.1644 - accuracy: 0.7754 - jacard_coef: 0.06245/9 [===============>..............] - ETA: 0s - loss: 0.1641 - accuracy: 0.7670 - jacard_coef: 0.06296/9 [===================>..........] - ETA: 0s - loss: 0.1638 - accuracy: 0.7602 - jacard_coef: 0.07007/9 [======================>.......] - ETA: 0s - loss: 0.1638 - accuracy: 0.7401 - jacard_coef: 0.06988/9 [=========================>....] - ETA: 0s - loss: 0.1639 - accuracy: 0.7474 - jacard_coef: 0.06729/9 [==============================] - 2s 232ms/step - loss: 0.1639 - accuracy: 0.7454 - jacard_coef: 0.0722 - val_loss: 0.0919 - val_accuracy: 0.8489 - val_jacard_coef: 0.0268 - lr: 5.0000e-04
Epoch 13/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1605 - accuracy: 0.7889 - jacard_coef: 0.05772/9 [=====>........................] - ETA: 1s - loss: 0.1616 - accuracy: 0.7453 - jacard_coef: 0.05943/9 [=========>....................] - ETA: 1s - loss: 0.1619 - accuracy: 0.7404 - jacard_coef: 0.06064/9 [============>.................] - ETA: 1s - loss: 0.1624 - accuracy: 0.7347 - jacard_coef: 0.06005/9 [===============>..............] - ETA: 0s - loss: 0.1622 - accuracy: 0.7380 - jacard_coef: 0.06206/9 [===================>..........] - ETA: 0s - loss: 0.1624 - accuracy: 0.7326 - jacard_coef: 0.06117/9 [======================>.......] - ETA: 0s - loss: 0.1631 - accuracy: 0.7311 - jacard_coef: 0.06208/9 [=========================>....] - ETA: 0s - loss: 0.1631 - accuracy: 0.7291 - jacard_coef: 0.06429/9 [==============================] - 2s 233ms/step - loss: 0.1632 - accuracy: 0.7275 - jacard_coef: 0.0718 - val_loss: 0.1768 - val_accuracy: 0.4120 - val_jacard_coef: 0.0784 - lr: 5.0000e-04
Epoch 14/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1586 - accuracy: 0.8884 - jacard_coef: 0.03952/9 [=====>........................] - ETA: 1s - loss: 0.1609 - accuracy: 0.8639 - jacard_coef: 0.04783/9 [=========>....................] - ETA: 1s - loss: 0.1603 - accuracy: 0.8447 - jacard_coef: 0.04554/9 [============>.................] - ETA: 1s - loss: 0.1602 - accuracy: 0.8271 - jacard_coef: 0.04875/9 [===============>..............] - ETA: 0s - loss: 0.1604 - accuracy: 0.8117 - jacard_coef: 0.05496/9 [===================>..........] - ETA: 0s - loss: 0.1601 - accuracy: 0.8107 - jacard_coef: 0.05787/9 [======================>.......] - ETA: 0s - loss: 0.1599 - accuracy: 0.8098 - jacard_coef: 0.05738/9 [=========================>....] - ETA: 0s - loss: 0.1598 - accuracy: 0.8084 - jacard_coef: 0.05389/9 [==============================] - 2s 229ms/step - loss: 0.1599 - accuracy: 0.8074 - jacard_coef: 0.0579 - val_loss: 0.2022 - val_accuracy: 0.1427 - val_jacard_coef: 0.0696 - lr: 5.0000e-04
Epoch 15/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1586 - accuracy: 0.8836 - jacard_coef: 0.03352/9 [=====>........................] - ETA: 1s - loss: 0.1586 - accuracy: 0.8864 - jacard_coef: 0.03143/9 [=========>....................] - ETA: 1s - loss: 0.1601 - accuracy: 0.7975 - jacard_coef: 0.03894/9 [============>.................] - ETA: 1s - loss: 0.1607 - accuracy: 0.8177 - jacard_coef: 0.03115/9 [===============>..............] - ETA: 0s - loss: 0.1608 - accuracy: 0.8383 - jacard_coef: 0.02636/9 [===================>..........] - ETA: 0s - loss: 0.1605 - accuracy: 0.8499 - jacard_coef: 0.02217/9 [======================>.......] - ETA: 0s - loss: 0.1605 - accuracy: 0.8584 - jacard_coef: 0.02068/9 [=========================>....] - ETA: 0s - loss: 0.1605 - accuracy: 0.8640 - jacard_coef: 0.01929/9 [==============================] - 2s 229ms/step - loss: 0.1606 - accuracy: 0.8640 - jacard_coef: 0.0178 - val_loss: 0.1628 - val_accuracy: 0.8462 - val_jacard_coef: 0.0265 - lr: 5.0000e-04
Epoch 16/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1605 - accuracy: 0.8783 - jacard_coef: 0.02352/9 [=====>........................] - ETA: 1s - loss: 0.1598 - accuracy: 0.8883 - jacard_coef: 0.01913/9 [=========>....................] - ETA: 1s - loss: 0.1595 - accuracy: 0.8798 - jacard_coef: 0.02694/9 [============>.................] - ETA: 1s - loss: 0.1591 - accuracy: 0.8649 - jacard_coef: 0.03455/9 [===============>..............] - ETA: 0s - loss: 0.1598 - accuracy: 0.8428 - jacard_coef: 0.03876/9 [===================>..........] - ETA: 0s - loss: 0.1598 - accuracy: 0.8289 - jacard_coef: 0.04197/9 [======================>.......] - ETA: 0s - loss: 0.1594 - accuracy: 0.8314 - jacard_coef: 0.04468/9 [=========================>....] - ETA: 0s - loss: 0.1591 - accuracy: 0.8322 - jacard_coef: 0.04459/9 [==============================] - 2s 233ms/step - loss: 0.1592 - accuracy: 0.8304 - jacard_coef: 0.0557 - val_loss: 0.1719 - val_accuracy: 0.5880 - val_jacard_coef: 0.0808 - lr: 5.0000e-04
Epoch 17/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1582 - accuracy: 0.7660 - jacard_coef: 0.07422/9 [=====>........................] - ETA: 1s - loss: 0.1588 - accuracy: 0.7436 - jacard_coef: 0.06323/9 [=========>....................] - ETA: 1s - loss: 0.1585 - accuracy: 0.7253 - jacard_coef: 0.06984/9 [============>.................] - ETA: 1s - loss: 0.1584 - accuracy: 0.7280 - jacard_coef: 0.06855/9 [===============>..............] - ETA: 0s - loss: 0.1580 - accuracy: 0.7446 - jacard_coef: 0.06726/9 [===================>..........] - ETA: 0s - loss: 0.1577 - accuracy: 0.7702 - jacard_coef: 0.05777/9 [======================>.......] - ETA: 0s - loss: 0.1573 - accuracy: 0.7912 - jacard_coef: 0.05048/9 [=========================>....] - ETA: 0s - loss: 0.1572 - accuracy: 0.8068 - jacard_coef: 0.04499/9 [==============================] - 2s 229ms/step - loss: 0.1572 - accuracy: 0.8062 - jacard_coef: 0.0545 - val_loss: 0.1759 - val_accuracy: 0.3905 - val_jacard_coef: 0.0742 - lr: 5.0000e-04
Epoch 18/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1552 - accuracy: 0.9093 - jacard_coef: 0.00462/9 [=====>........................] - ETA: 1s - loss: 0.1550 - accuracy: 0.9145 - jacard_coef: 0.00323/9 [=========>....................] - ETA: 1s - loss: 0.1554 - accuracy: 0.9111 - jacard_coef: 0.00704/9 [============>.................] - ETA: 1s - loss: 0.1552 - accuracy: 0.9125 - jacard_coef: 0.00595/9 [===============>..............] - ETA: 0s - loss: 0.1549 - accuracy: 0.9131 - jacard_coef: 0.00566/9 [===================>..........] - ETA: 0s - loss: 0.1548 - accuracy: 0.9133 - jacard_coef: 0.00517/9 [======================>.......] - ETA: 0s - loss: 0.1546 - accuracy: 0.9146 - jacard_coef: 0.00528/9 [=========================>....] - ETA: 0s - loss: 0.1547 - accuracy: 0.9135 - jacard_coef: 0.00659/9 [==============================] - 2s 229ms/step - loss: 0.1548 - accuracy: 0.9105 - jacard_coef: 0.0113 - val_loss: 0.1820 - val_accuracy: 0.0699 - val_jacard_coef: 0.0696 - lr: 5.0000e-04
Epoch 19/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1574 - accuracy: 0.8959 - jacard_coef: 0.01252/9 [=====>........................] - ETA: 1s - loss: 0.1592 - accuracy: 0.8890 - jacard_coef: 0.01513/9 [=========>....................] - ETA: 1s - loss: 0.1599 - accuracy: 0.8890 - jacard_coef: 0.01244/9 [============>.................] - ETA: 1s - loss: 0.1604 - accuracy: 0.8886 - jacard_coef: 0.01565/9 [===============>..............] - ETA: 0s - loss: 0.1626 - accuracy: 0.8859 - jacard_coef: 0.01786/9 [===================>..........] - ETA: 0s - loss: 0.1627 - accuracy: 0.8848 - jacard_coef: 0.01837/9 [======================>.......] - ETA: 0s - loss: 0.1636 - accuracy: 0.8819 - jacard_coef: 0.02078/9 [=========================>....] - ETA: 0s - loss: 0.1634 - accuracy: 0.8827 - jacard_coef: 0.02259/9 [==============================] - 2s 229ms/step - loss: 0.1635 - accuracy: 0.8797 - jacard_coef: 0.0326 - val_loss: 0.1926 - val_accuracy: 0.0696 - val_jacard_coef: 0.0696 - lr: 5.0000e-04
Epoch 20/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1598 - accuracy: 0.9100 - jacard_coef: 0.02242/9 [=====>........................] - ETA: 1s - loss: 0.1613 - accuracy: 0.8923 - jacard_coef: 0.02663/9 [=========>....................] - ETA: 1s - loss: 0.1634 - accuracy: 0.8920 - jacard_coef: 0.02824/9 [============>.................] - ETA: 1s - loss: 0.1632 - accuracy: 0.8902 - jacard_coef: 0.02685/9 [===============>..............] - ETA: 0s - loss: 0.1623 - accuracy: 0.8914 - jacard_coef: 0.02316/9 [===================>..........] - ETA: 0s - loss: 0.1638 - accuracy: 0.8929 - jacard_coef: 0.02097/9 [======================>.......] - ETA: 0s - loss: 0.1630 - accuracy: 0.8929 - jacard_coef: 0.01938/9 [=========================>....] - ETA: 0s - loss: 0.1622 - accuracy: 0.8960 - jacard_coef: 0.01709/9 [==============================] - 2s 229ms/step - loss: 0.1623 - accuracy: 0.8956 - jacard_coef: 0.0188 - val_loss: 0.1860 - val_accuracy: 0.0696 - val_jacard_coef: 0.0696 - lr: 5.0000e-04
Epoch 21/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1571 - accuracy: 0.8800 - jacard_coef: 0.02592/9 [=====>........................] - ETA: 1s - loss: 0.1553 - accuracy: 0.9004 - jacard_coef: 0.03223/9 [=========>....................] - ETA: 1s - loss: 0.1551 - accuracy: 0.8964 - jacard_coef: 0.02394/9 [============>.................] - ETA: 1s - loss: 0.1560 - accuracy: 0.8976 - jacard_coef: 0.02475/9 [===============>..............] - ETA: 0s - loss: 0.1556 - accuracy: 0.9005 - jacard_coef: 0.02546/9 [===================>..........] - ETA: 0s - loss: 0.1555 - accuracy: 0.8981 - jacard_coef: 0.02497/9 [======================>.......] - ETA: 0s - loss: 0.1554 - accuracy: 0.8973 - jacard_coef: 0.02208/9 [=========================>....] - ETA: 0s - loss: 0.1558 - accuracy: 0.8993 - jacard_coef: 0.02269/9 [==============================] - 2s 229ms/step - loss: 0.1558 - accuracy: 0.8983 - jacard_coef: 0.0230 - val_loss: 0.1833 - val_accuracy: 0.0866 - val_jacard_coef: 0.0691 - lr: 5.0000e-04
Epoch 22/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1513 - accuracy: 0.9318 - jacard_coef: 0.00772/9 [=====>........................] - ETA: 1s - loss: 0.1531 - accuracy: 0.9243 - jacard_coef: 0.00403/9 [=========>....................] - ETA: 1s - loss: 0.1531 - accuracy: 0.9214 - jacard_coef: 0.00284/9 [============>.................] - ETA: 1s - loss: 0.1531 - accuracy: 0.9179 - jacard_coef: 0.00435/9 [===============>..............] - ETA: 0s - loss: 0.1544 - accuracy: 0.9162 - jacard_coef: 0.00496/9 [===================>..........] - ETA: 0s - loss: 0.1546 - accuracy: 0.9097 - jacard_coef: 0.00587/9 [======================>.......] - ETA: 0s - loss: 0.1544 - accuracy: 0.9090 - jacard_coef: 0.00508/9 [=========================>....] - ETA: 0s - loss: 0.1539 - accuracy: 0.9114 - jacard_coef: 0.00459/9 [==============================] - 2s 229ms/step - loss: 0.1540 - accuracy: 0.9116 - jacard_coef: 0.0082 - val_loss: 0.1819 - val_accuracy: 0.1126 - val_jacard_coef: 0.0689 - lr: 2.5000e-04
Epoch 23/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1528 - accuracy: 0.9082 - jacard_coef: 0.01032/9 [=====>........................] - ETA: 1s - loss: 0.1549 - accuracy: 0.9105 - jacard_coef: 0.01023/9 [=========>....................] - ETA: 1s - loss: 0.1540 - accuracy: 0.9045 - jacard_coef: 0.00724/9 [============>.................] - ETA: 1s - loss: 0.1534 - accuracy: 0.8991 - jacard_coef: 0.00835/9 [===============>..............] - ETA: 0s - loss: 0.1536 - accuracy: 0.8970 - jacard_coef: 0.00966/9 [===================>..........] - ETA: 0s - loss: 0.1535 - accuracy: 0.8993 - jacard_coef: 0.00867/9 [======================>.......] - ETA: 0s - loss: 0.1532 - accuracy: 0.9022 - jacard_coef: 0.00928/9 [=========================>....] - ETA: 0s - loss: 0.1528 - accuracy: 0.9071 - jacard_coef: 0.00859/9 [==============================] - 2s 229ms/step - loss: 0.1532 - accuracy: 0.9062 - jacard_coef: 0.0158 - val_loss: 0.1814 - val_accuracy: 0.1295 - val_jacard_coef: 0.0689 - lr: 2.5000e-04
Epoch 24/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1529 - accuracy: 0.9017 - jacard_coef: 0.00262/9 [=====>........................] - ETA: 1s - loss: 0.1521 - accuracy: 0.9131 - jacard_coef: 0.00173/9 [=========>....................] - ETA: 1s - loss: 0.1527 - accuracy: 0.9076 - jacard_coef: 0.00124/9 [============>.................] - ETA: 1s - loss: 0.1527 - accuracy: 0.9090 - jacard_coef: 0.00125/9 [===============>..............] - ETA: 0s - loss: 0.1522 - accuracy: 0.9144 - jacard_coef: 0.00356/9 [===================>..........] - ETA: 0s - loss: 0.1521 - accuracy: 0.9136 - jacard_coef: 0.00297/9 [======================>.......] - ETA: 0s - loss: 0.1527 - accuracy: 0.9141 - jacard_coef: 0.00418/9 [=========================>....] - ETA: 0s - loss: 0.1527 - accuracy: 0.9131 - jacard_coef: 0.00399/9 [==============================] - 2s 229ms/step - loss: 0.1527 - accuracy: 0.9131 - jacard_coef: 0.0081 - val_loss: 0.1804 - val_accuracy: 0.1631 - val_jacard_coef: 0.0689 - lr: 2.5000e-04
Epoch 25/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1513 - accuracy: 0.9035 - jacard_coef: 1.4814e-042/9 [=====>........................] - ETA: 1s - loss: 0.1508 - accuracy: 0.9105 - jacard_coef: 3.9202e-043/9 [=========>....................] - ETA: 1s - loss: 0.1508 - accuracy: 0.9186 - jacard_coef: 0.0012    4/9 [============>.................] - ETA: 1s - loss: 0.1508 - accuracy: 0.9200 - jacard_coef: 0.00255/9 [===============>..............] - ETA: 0s - loss: 0.1507 - accuracy: 0.9230 - jacard_coef: 0.00216/9 [===================>..........] - ETA: 0s - loss: 0.1511 - accuracy: 0.9188 - jacard_coef: 0.00187/9 [======================>.......] - ETA: 0s - loss: 0.1515 - accuracy: 0.9186 - jacard_coef: 0.00188/9 [=========================>....] - ETA: 0s - loss: 0.1514 - accuracy: 0.9161 - jacard_coef: 0.00199/9 [==============================] - 2s 229ms/step - loss: 0.1515 - accuracy: 0.9153 - jacard_coef: 0.0024 - val_loss: 0.1812 - val_accuracy: 0.1777 - val_jacard_coef: 0.0689 - lr: 2.5000e-04
Epoch 26/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1534 - accuracy: 0.8731 - jacard_coef: 0.00522/9 [=====>........................] - ETA: 1s - loss: 0.1513 - accuracy: 0.8950 - jacard_coef: 0.00773/9 [=========>....................] - ETA: 1s - loss: 0.1505 - accuracy: 0.9060 - jacard_coef: 0.00524/9 [============>.................] - ETA: 1s - loss: 0.1523 - accuracy: 0.8779 - jacard_coef: 0.01955/9 [===============>..............] - ETA: 0s - loss: 0.1516 - accuracy: 0.8860 - jacard_coef: 0.01626/9 [===================>..........] - ETA: 0s - loss: 0.1511 - accuracy: 0.8935 - jacard_coef: 0.01367/9 [======================>.......] - ETA: 0s - loss: 0.1514 - accuracy: 0.8968 - jacard_coef: 0.01298/9 [=========================>....] - ETA: 0s - loss: 0.1510 - accuracy: 0.9005 - jacard_coef: 0.01139/9 [==============================] - 2s 229ms/step - loss: 0.1513 - accuracy: 0.8998 - jacard_coef: 0.0129 - val_loss: 0.1795 - val_accuracy: 0.1953 - val_jacard_coef: 0.0690 - lr: 2.5000e-04
/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(

âœ“ Training completed successfully!
  Best Val Jaccard: 0.0808 (epoch 16)
  Final Val Loss: 0.1795
  Training Time: 0:01:50.102906
  Stability (std): 0.0042

Results saved to: hyperparameter_optimization_20250926_165036/exp_11_UNet_lr5e-3_bs16/UNet_lr0.005_bs16_results.json
