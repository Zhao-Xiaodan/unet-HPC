âœ“ GPU memory growth enabled for 1 GPUs
Loading dataset...
Loaded 144 images and 144 masks
Training set: (129, 256, 256, 3), Validation set: (15, 256, 256, 3)

============================================================
TRAINING: Attention_ResUNet
Learning Rate: 0.0001, Batch Size: 16, Epochs: 30
============================================================
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 256, 256, 64)         640       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 256, 256, 64)         256       ['conv2d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 activation (Activation)     (None, 256, 256, 64)         0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['activation[0][0]']          
                                                                                                  
 batch_normalization_1 (Bat  (None, 256, 256, 64)         256       ['conv2d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_1 (Activation)   (None, 256, 256, 64)         0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['activation_1[0][0]']        
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       
                                                                                                  
 batch_normalization_2 (Bat  (None, 128, 128, 128)        512       ['conv2d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_2 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_3 (Conv2D)           (None, 128, 128, 128)        147584    ['activation_2[0][0]']        
                                                                                                  
 batch_normalization_3 (Bat  (None, 128, 128, 128)        512       ['conv2d_3[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_3 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_3[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_3[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 batch_normalization_4 (Bat  (None, 64, 64, 256)          1024      ['conv2d_4[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_4 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_4[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_5 (Conv2D)           (None, 64, 64, 256)          590080    ['activation_4[0][0]']        
                                                                                                  
 batch_normalization_5 (Bat  (None, 64, 64, 256)          1024      ['conv2d_5[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_5 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_5[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_5[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 512)          1180160   ['max_pooling2d_2[0][0]']     
                                                                                                  
 batch_normalization_6 (Bat  (None, 32, 32, 512)          2048      ['conv2d_6[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_6 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_6[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 32, 32, 512)          2359808   ['activation_6[0][0]']        
                                                                                                  
 batch_normalization_7 (Bat  (None, 32, 32, 512)          2048      ['conv2d_7[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_7 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_7[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_3 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_7[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 1024)         4719616   ['max_pooling2d_3[0][0]']     
                                                                                                  
 batch_normalization_8 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_8[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_8 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_8[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 1024)         9438208   ['activation_8[0][0]']        
                                                                                                  
 batch_normalization_9 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_9[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_9 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_9[0][0]'
                                                                    ]                             
                                                                                                  
 up_sampling2d (UpSampling2  (None, 32, 32, 1024)         0         ['activation_9[0][0]']        
 D)                                                                                               
                                                                                                  
 concatenate (Concatenate)   (None, 32, 32, 1536)         0         ['up_sampling2d[0][0]',       
                                                                     'activation_7[0][0]']        
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate[0][0]']         
                                                                                                  
 batch_normalization_10 (Ba  (None, 32, 32, 512)          2048      ['conv2d_10[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_10 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_10[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_10[0][0]']       
                                                                                                  
 batch_normalization_11 (Ba  (None, 32, 32, 512)          2048      ['conv2d_11[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_11 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_11[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 64, 64, 512)          0         ['activation_11[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_1 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_1[0][0]',     
 )                                                                   'activation_5[0][0]']        
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_1[0][0]']       
                                                                                                  
 batch_normalization_12 (Ba  (None, 64, 64, 256)          1024      ['conv2d_12[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_12 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_12[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_13 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_12[0][0]']       
                                                                                                  
 batch_normalization_13 (Ba  (None, 64, 64, 256)          1024      ['conv2d_13[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_13 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_13[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 128, 128, 256)        0         ['activation_13[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_2 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_2[0][0]',     
 )                                                                   'activation_3[0][0]']        
                                                                                                  
 conv2d_14 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_2[0][0]']       
                                                                                                  
 batch_normalization_14 (Ba  (None, 128, 128, 128)        512       ['conv2d_14[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_14 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_14[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_15 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_14[0][0]']       
                                                                                                  
 batch_normalization_15 (Ba  (None, 128, 128, 128)        512       ['conv2d_15[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_15 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_15[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 256, 256, 128)        0         ['activation_15[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_3 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_3[0][0]',     
 )                                                                   'activation_1[0][0]']        
                                                                                                  
 conv2d_16 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_3[0][0]']       
                                                                                                  
 batch_normalization_16 (Ba  (None, 256, 256, 64)         256       ['conv2d_16[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_16 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_16[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_16[0][0]']       
                                                                                                  
 batch_normalization_17 (Ba  (None, 256, 256, 64)         256       ['conv2d_17[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_17 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_17[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_18 (Conv2D)          (None, 256, 256, 1)          65        ['activation_17[0][0]']       
                                                                                                  
 batch_normalization_18 (Ba  (None, 256, 256, 1)          4         ['conv2d_18[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_18 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_18[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31401349 (119.79 MB)
Trainable params: 31389571 (119.74 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
WARNING:absl:`lr` is deprecated in TF-Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
None
âœ“ focal_loss imported successfully
Epoch 1/30
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1758879831.767326 1158050 service.cc:145] XLA service 0x14ef9e9f8ac0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1758879831.767351 1158050 service.cc:153]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6
I0000 00:00:1758879831.903805 1158050 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
1/9 [==>...........................] - ETA: 7:43 - loss: 0.3457 - accuracy: 0.5271 - jacard_coef: 0.08122/9 [=====>........................] - ETA: 58s - loss: 0.3279 - accuracy: 0.4747 - jacard_coef: 0.0836 3/9 [=========>....................] - ETA: 26s - loss: 0.3052 - accuracy: 0.4014 - jacard_coef: 0.08544/9 [============>.................] - ETA: 15s - loss: 0.2851 - accuracy: 0.3458 - jacard_coef: 0.08605/9 [===============>..............] - ETA: 9s - loss: 0.2707 - accuracy: 0.3041 - jacard_coef: 0.0844 6/9 [===================>..........] - ETA: 5s - loss: 0.2602 - accuracy: 0.2775 - jacard_coef: 0.08437/9 [======================>.......] - ETA: 3s - loss: 0.2519 - accuracy: 0.2626 - jacard_coef: 0.08488/9 [=========================>....] - ETA: 1s - loss: 0.2462 - accuracy: 0.2659 - jacard_coef: 0.08359/9 [==============================] - ETA: 0s - loss: 0.2459 - accuracy: 0.2658 - jacard_coef: 0.08939/9 [==============================] - 78s 2s/step - loss: 0.2459 - accuracy: 0.2658 - jacard_coef: 0.0893 - val_loss: 1.1157 - val_accuracy: 0.9304 - val_jacard_coef: 1.4616e-12 - lr: 0.0010
Epoch 2/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1916 - accuracy: 0.4153 - jacard_coef: 0.06842/9 [=====>........................] - ETA: 2s - loss: 0.1909 - accuracy: 0.3840 - jacard_coef: 0.06313/9 [=========>....................] - ETA: 2s - loss: 0.1893 - accuracy: 0.3408 - jacard_coef: 0.06354/9 [============>.................] - ETA: 2s - loss: 0.1875 - accuracy: 0.3468 - jacard_coef: 0.06855/9 [===============>..............] - ETA: 1s - loss: 0.1856 - accuracy: 0.3650 - jacard_coef: 0.07666/9 [===================>..........] - ETA: 1s - loss: 0.1844 - accuracy: 0.3694 - jacard_coef: 0.07627/9 [======================>.......] - ETA: 0s - loss: 0.1831 - accuracy: 0.3767 - jacard_coef: 0.07818/9 [=========================>....] - ETA: 0s - loss: 0.1821 - accuracy: 0.3813 - jacard_coef: 0.07999/9 [==============================] - 3s 374ms/step - loss: 0.1821 - accuracy: 0.3811 - jacard_coef: 0.0829 - val_loss: 1.1107 - val_accuracy: 0.9304 - val_jacard_coef: 1.4616e-12 - lr: 0.0010
Epoch 3/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1743 - accuracy: 0.5123 - jacard_coef: 0.06162/9 [=====>........................] - ETA: 2s - loss: 0.1746 - accuracy: 0.5267 - jacard_coef: 0.07853/9 [=========>....................] - ETA: 2s - loss: 0.1750 - accuracy: 0.5261 - jacard_coef: 0.07684/9 [============>.................] - ETA: 2s - loss: 0.1750 - accuracy: 0.5293 - jacard_coef: 0.07655/9 [===============>..............] - ETA: 1s - loss: 0.1746 - accuracy: 0.5295 - jacard_coef: 0.08076/9 [===================>..........] - ETA: 1s - loss: 0.1740 - accuracy: 0.5349 - jacard_coef: 0.07897/9 [======================>.......] - ETA: 0s - loss: 0.1737 - accuracy: 0.5406 - jacard_coef: 0.08398/9 [=========================>....] - ETA: 0s - loss: 0.1734 - accuracy: 0.5431 - jacard_coef: 0.08229/9 [==============================] - 3s 381ms/step - loss: 0.1737 - accuracy: 0.5422 - jacard_coef: 0.0955 - val_loss: 1.0739 - val_accuracy: 0.9256 - val_jacard_coef: 0.0053 - lr: 0.0010
Epoch 4/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1763 - accuracy: 0.3847 - jacard_coef: 0.07262/9 [=====>........................] - ETA: 2s - loss: 0.1814 - accuracy: 0.2682 - jacard_coef: 0.07303/9 [=========>....................] - ETA: 2s - loss: 0.1817 - accuracy: 0.2808 - jacard_coef: 0.08814/9 [============>.................] - ETA: 2s - loss: 0.1810 - accuracy: 0.2789 - jacard_coef: 0.09095/9 [===============>..............] - ETA: 1s - loss: 0.1807 - accuracy: 0.2785 - jacard_coef: 0.08606/9 [===================>..........] - ETA: 1s - loss: 0.1814 - accuracy: 0.2739 - jacard_coef: 0.08187/9 [======================>.......] - ETA: 0s - loss: 0.1809 - accuracy: 0.2774 - jacard_coef: 0.08448/9 [=========================>....] - ETA: 0s - loss: 0.1805 - accuracy: 0.2857 - jacard_coef: 0.08189/9 [==============================] - 3s 380ms/step - loss: 0.1805 - accuracy: 0.2863 - jacard_coef: 0.0883 - val_loss: 1.1323 - val_accuracy: 0.9205 - val_jacard_coef: 0.0107 - lr: 0.0010
Epoch 5/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1755 - accuracy: 0.3899 - jacard_coef: 0.11102/9 [=====>........................] - ETA: 2s - loss: 0.1753 - accuracy: 0.3975 - jacard_coef: 0.10343/9 [=========>....................] - ETA: 2s - loss: 0.1748 - accuracy: 0.4082 - jacard_coef: 0.09374/9 [============>.................] - ETA: 2s - loss: 0.1744 - accuracy: 0.4223 - jacard_coef: 0.09005/9 [===============>..............] - ETA: 1s - loss: 0.1739 - accuracy: 0.4400 - jacard_coef: 0.08536/9 [===================>..........] - ETA: 1s - loss: 0.1734 - accuracy: 0.4591 - jacard_coef: 0.08657/9 [======================>.......] - ETA: 0s - loss: 0.1728 - accuracy: 0.4906 - jacard_coef: 0.08388/9 [=========================>....] - ETA: 0s - loss: 0.1726 - accuracy: 0.5059 - jacard_coef: 0.08079/9 [==============================] - 3s 380ms/step - loss: 0.1727 - accuracy: 0.5049 - jacard_coef: 0.0792 - val_loss: 0.7504 - val_accuracy: 0.8829 - val_jacard_coef: 0.0415 - lr: 0.0010
Epoch 6/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1708 - accuracy: 0.6029 - jacard_coef: 0.08212/9 [=====>........................] - ETA: 2s - loss: 0.1716 - accuracy: 0.5715 - jacard_coef: 0.07763/9 [=========>....................] - ETA: 2s - loss: 0.1718 - accuracy: 0.5560 - jacard_coef: 0.08094/9 [============>.................] - ETA: 2s - loss: 0.1722 - accuracy: 0.5484 - jacard_coef: 0.07905/9 [===============>..............] - ETA: 1s - loss: 0.1719 - accuracy: 0.5531 - jacard_coef: 0.08066/9 [===================>..........] - ETA: 1s - loss: 0.1720 - accuracy: 0.5620 - jacard_coef: 0.07667/9 [======================>.......] - ETA: 0s - loss: 0.1717 - accuracy: 0.5595 - jacard_coef: 0.08138/9 [=========================>....] - ETA: 0s - loss: 0.1718 - accuracy: 0.5510 - jacard_coef: 0.08159/9 [==============================] - 3s 373ms/step - loss: 0.1718 - accuracy: 0.5500 - jacard_coef: 0.0855 - val_loss: 0.9609 - val_accuracy: 0.9269 - val_jacard_coef: 0.0023 - lr: 0.0010
Epoch 7/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1720 - accuracy: 0.5744 - jacard_coef: 0.05302/9 [=====>........................] - ETA: 2s - loss: 0.1698 - accuracy: 0.6049 - jacard_coef: 0.06763/9 [=========>....................] - ETA: 2s - loss: 0.1693 - accuracy: 0.6203 - jacard_coef: 0.07114/9 [============>.................] - ETA: 2s - loss: 0.1686 - accuracy: 0.6452 - jacard_coef: 0.06775/9 [===============>..............] - ETA: 1s - loss: 0.1682 - accuracy: 0.6681 - jacard_coef: 0.06606/9 [===================>..........] - ETA: 1s - loss: 0.1677 - accuracy: 0.6871 - jacard_coef: 0.06677/9 [======================>.......] - ETA: 0s - loss: 0.1678 - accuracy: 0.6992 - jacard_coef: 0.06538/9 [=========================>....] - ETA: 0s - loss: 0.1673 - accuracy: 0.7149 - jacard_coef: 0.06409/9 [==============================] - 3s 374ms/step - loss: 0.1677 - accuracy: 0.7114 - jacard_coef: 0.0617 - val_loss: 0.2426 - val_accuracy: 0.8362 - val_jacard_coef: 0.0405 - lr: 0.0010
Epoch 8/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1641 - accuracy: 0.8544 - jacard_coef: 0.02702/9 [=====>........................] - ETA: 2s - loss: 0.1653 - accuracy: 0.8428 - jacard_coef: 0.02933/9 [=========>....................] - ETA: 2s - loss: 0.1657 - accuracy: 0.8182 - jacard_coef: 0.03854/9 [============>.................] - ETA: 2s - loss: 0.1655 - accuracy: 0.8286 - jacard_coef: 0.03165/9 [===============>..............] - ETA: 1s - loss: 0.1658 - accuracy: 0.8401 - jacard_coef: 0.02846/9 [===================>..........] - ETA: 1s - loss: 0.1657 - accuracy: 0.8384 - jacard_coef: 0.02737/9 [======================>.......] - ETA: 0s - loss: 0.1654 - accuracy: 0.8431 - jacard_coef: 0.02698/9 [=========================>....] - ETA: 0s - loss: 0.1652 - accuracy: 0.8505 - jacard_coef: 0.02809/9 [==============================] - 3s 374ms/step - loss: 0.1652 - accuracy: 0.8508 - jacard_coef: 0.0253 - val_loss: 0.1243 - val_accuracy: 0.9195 - val_jacard_coef: 0.0073 - lr: 0.0010
Epoch 9/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1619 - accuracy: 0.8916 - jacard_coef: 0.03392/9 [=====>........................] - ETA: 2s - loss: 0.1618 - accuracy: 0.8852 - jacard_coef: 0.03143/9 [=========>....................] - ETA: 2s - loss: 0.1620 - accuracy: 0.8740 - jacard_coef: 0.03404/9 [============>.................] - ETA: 2s - loss: 0.1618 - accuracy: 0.8817 - jacard_coef: 0.03065/9 [===============>..............] - ETA: 1s - loss: 0.1615 - accuracy: 0.8831 - jacard_coef: 0.03106/9 [===================>..........] - ETA: 1s - loss: 0.1614 - accuracy: 0.8830 - jacard_coef: 0.02807/9 [======================>.......] - ETA: 0s - loss: 0.1615 - accuracy: 0.8864 - jacard_coef: 0.02618/9 [=========================>....] - ETA: 0s - loss: 0.1615 - accuracy: 0.8837 - jacard_coef: 0.02369/9 [==============================] - 3s 374ms/step - loss: 0.1615 - accuracy: 0.8833 - jacard_coef: 0.0278 - val_loss: 0.1356 - val_accuracy: 0.9292 - val_jacard_coef: 8.0445e-04 - lr: 0.0010
Epoch 10/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1585 - accuracy: 0.8918 - jacard_coef: 0.00672/9 [=====>........................] - ETA: 2s - loss: 0.1598 - accuracy: 0.8828 - jacard_coef: 0.01563/9 [=========>....................] - ETA: 2s - loss: 0.1588 - accuracy: 0.8953 - jacard_coef: 0.01634/9 [============>.................] - ETA: 2s - loss: 0.1587 - accuracy: 0.8993 - jacard_coef: 0.01795/9 [===============>..............] - ETA: 1s - loss: 0.1586 - accuracy: 0.8985 - jacard_coef: 0.01826/9 [===================>..........] - ETA: 1s - loss: 0.1584 - accuracy: 0.8960 - jacard_coef: 0.02027/9 [======================>.......] - ETA: 0s - loss: 0.1583 - accuracy: 0.8954 - jacard_coef: 0.02108/9 [=========================>....] - ETA: 0s - loss: 0.1581 - accuracy: 0.8962 - jacard_coef: 0.01899/9 [==============================] - 3s 374ms/step - loss: 0.1583 - accuracy: 0.8923 - jacard_coef: 0.0209 - val_loss: 0.1523 - val_accuracy: 0.9137 - val_jacard_coef: 0.0245 - lr: 0.0010
Epoch 11/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1581 - accuracy: 0.9146 - jacard_coef: 0.01942/9 [=====>........................] - ETA: 2s - loss: 0.1591 - accuracy: 0.9090 - jacard_coef: 0.01913/9 [=========>....................] - ETA: 2s - loss: 0.1597 - accuracy: 0.8962 - jacard_coef: 0.02274/9 [============>.................] - ETA: 2s - loss: 0.1601 - accuracy: 0.8869 - jacard_coef: 0.02525/9 [===============>..............] - ETA: 1s - loss: 0.1599 - accuracy: 0.8855 - jacard_coef: 0.02396/9 [===================>..........] - ETA: 1s - loss: 0.1600 - accuracy: 0.8830 - jacard_coef: 0.02527/9 [======================>.......] - ETA: 0s - loss: 0.1610 - accuracy: 0.8652 - jacard_coef: 0.03068/9 [=========================>....] - ETA: 0s - loss: 0.1609 - accuracy: 0.8630 - jacard_coef: 0.03209/9 [==============================] - 3s 374ms/step - loss: 0.1609 - accuracy: 0.8638 - jacard_coef: 0.0294 - val_loss: 0.1551 - val_accuracy: 0.9134 - val_jacard_coef: 0.0161 - lr: 5.0000e-04
Epoch 12/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1637 - accuracy: 0.8287 - jacard_coef: 0.04522/9 [=====>........................] - ETA: 2s - loss: 0.1640 - accuracy: 0.8252 - jacard_coef: 0.05163/9 [=========>....................] - ETA: 2s - loss: 0.1623 - accuracy: 0.8429 - jacard_coef: 0.04294/9 [============>.................] - ETA: 2s - loss: 0.1610 - accuracy: 0.8553 - jacard_coef: 0.04105/9 [===============>..............] - ETA: 1s - loss: 0.1609 - accuracy: 0.8531 - jacard_coef: 0.04336/9 [===================>..........] - ETA: 1s - loss: 0.1605 - accuracy: 0.8503 - jacard_coef: 0.04547/9 [======================>.......] - ETA: 0s - loss: 0.1602 - accuracy: 0.8507 - jacard_coef: 0.04738/9 [=========================>....] - ETA: 0s - loss: 0.1598 - accuracy: 0.8533 - jacard_coef: 0.04549/9 [==============================] - 3s 374ms/step - loss: 0.1599 - accuracy: 0.8517 - jacard_coef: 0.0406 - val_loss: 0.1450 - val_accuracy: 0.9242 - val_jacard_coef: 0.0031 - lr: 5.0000e-04
Epoch 13/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1570 - accuracy: 0.8798 - jacard_coef: 0.02742/9 [=====>........................] - ETA: 2s - loss: 0.1581 - accuracy: 0.8773 - jacard_coef: 0.03003/9 [=========>....................] - ETA: 2s - loss: 0.1586 - accuracy: 0.8825 - jacard_coef: 0.02454/9 [============>.................] - ETA: 2s - loss: 0.1581 - accuracy: 0.8908 - jacard_coef: 0.02095/9 [===============>..............] - ETA: 1s - loss: 0.1580 - accuracy: 0.8890 - jacard_coef: 0.01946/9 [===================>..........] - ETA: 1s - loss: 0.1581 - accuracy: 0.8921 - jacard_coef: 0.01817/9 [======================>.......] - ETA: 0s - loss: 0.1576 - accuracy: 0.8974 - jacard_coef: 0.01618/9 [=========================>....] - ETA: 0s - loss: 0.1573 - accuracy: 0.9018 - jacard_coef: 0.01469/9 [==============================] - 3s 374ms/step - loss: 0.1573 - accuracy: 0.9011 - jacard_coef: 0.0193 - val_loss: 0.1463 - val_accuracy: 0.9078 - val_jacard_coef: 0.0157 - lr: 5.0000e-04
Epoch 14/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1560 - accuracy: 0.9303 - jacard_coef: 0.00422/9 [=====>........................] - ETA: 2s - loss: 0.1560 - accuracy: 0.9109 - jacard_coef: 0.00423/9 [=========>....................] - ETA: 2s - loss: 0.1561 - accuracy: 0.9044 - jacard_coef: 0.00494/9 [============>.................] - ETA: 2s - loss: 0.1557 - accuracy: 0.9097 - jacard_coef: 0.00465/9 [===============>..............] - ETA: 1s - loss: 0.1556 - accuracy: 0.9108 - jacard_coef: 0.00506/9 [===================>..........] - ETA: 1s - loss: 0.1555 - accuracy: 0.9121 - jacard_coef: 0.00587/9 [======================>.......] - ETA: 0s - loss: 0.1554 - accuracy: 0.9136 - jacard_coef: 0.00628/9 [=========================>....] - ETA: 0s - loss: 0.1551 - accuracy: 0.9137 - jacard_coef: 0.00709/9 [==============================] - 3s 374ms/step - loss: 0.1551 - accuracy: 0.9123 - jacard_coef: 0.0256 - val_loss: 0.1459 - val_accuracy: 0.9181 - val_jacard_coef: 0.0098 - lr: 5.0000e-04
Epoch 15/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1534 - accuracy: 0.9086 - jacard_coef: 0.02062/9 [=====>........................] - ETA: 2s - loss: 0.1543 - accuracy: 0.8854 - jacard_coef: 0.03043/9 [=========>....................] - ETA: 2s - loss: 0.1542 - accuracy: 0.8849 - jacard_coef: 0.03364/9 [============>.................] - ETA: 2s - loss: 0.1543 - accuracy: 0.8798 - jacard_coef: 0.03685/9 [===============>..............] - ETA: 1s - loss: 0.1540 - accuracy: 0.8837 - jacard_coef: 0.03896/9 [===================>..........] - ETA: 1s - loss: 0.1537 - accuracy: 0.8845 - jacard_coef: 0.03817/9 [======================>.......] - ETA: 0s - loss: 0.1534 - accuracy: 0.8902 - jacard_coef: 0.03528/9 [=========================>....] - ETA: 0s - loss: 0.1535 - accuracy: 0.8876 - jacard_coef: 0.03269/9 [==============================] - 3s 374ms/step - loss: 0.1535 - accuracy: 0.8858 - jacard_coef: 0.0421 - val_loss: 0.1512 - val_accuracy: 0.9290 - val_jacard_coef: 0.0017 - lr: 5.0000e-04
/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(

âœ“ Training completed successfully!
  Best Val Jaccard: 0.0415 (epoch 5)
  Final Val Loss: 0.1512
  Training Time: 0:02:06.044353
  Stability (std): 0.2436

Results saved to: hyperparameter_optimization_20250926_165036/exp_26_Attention_ResUNet_lr1e-4_bs16/Attention_ResUNet_lr0.0001_bs16_results.json
