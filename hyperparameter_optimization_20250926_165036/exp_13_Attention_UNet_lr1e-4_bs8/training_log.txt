✓ GPU memory growth enabled for 1 GPUs
Loading dataset...
Loaded 144 images and 144 masks
Training set: (129, 256, 256, 3), Validation set: (15, 256, 256, 3)

============================================================
TRAINING: Attention_UNet
Learning Rate: 0.0001, Batch Size: 8, Epochs: 30
============================================================
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 256, 256, 64)         640       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 256, 256, 64)         256       ['conv2d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 activation (Activation)     (None, 256, 256, 64)         0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['activation[0][0]']          
                                                                                                  
 batch_normalization_1 (Bat  (None, 256, 256, 64)         256       ['conv2d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_1 (Activation)   (None, 256, 256, 64)         0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['activation_1[0][0]']        
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       
                                                                                                  
 batch_normalization_2 (Bat  (None, 128, 128, 128)        512       ['conv2d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_2 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_3 (Conv2D)           (None, 128, 128, 128)        147584    ['activation_2[0][0]']        
                                                                                                  
 batch_normalization_3 (Bat  (None, 128, 128, 128)        512       ['conv2d_3[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_3 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_3[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_3[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 batch_normalization_4 (Bat  (None, 64, 64, 256)          1024      ['conv2d_4[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_4 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_4[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_5 (Conv2D)           (None, 64, 64, 256)          590080    ['activation_4[0][0]']        
                                                                                                  
 batch_normalization_5 (Bat  (None, 64, 64, 256)          1024      ['conv2d_5[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_5 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_5[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_5[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 512)          1180160   ['max_pooling2d_2[0][0]']     
                                                                                                  
 batch_normalization_6 (Bat  (None, 32, 32, 512)          2048      ['conv2d_6[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_6 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_6[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 32, 32, 512)          2359808   ['activation_6[0][0]']        
                                                                                                  
 batch_normalization_7 (Bat  (None, 32, 32, 512)          2048      ['conv2d_7[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_7 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_7[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_3 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_7[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 1024)         4719616   ['max_pooling2d_3[0][0]']     
                                                                                                  
 batch_normalization_8 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_8[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_8 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_8[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 1024)         9438208   ['activation_8[0][0]']        
                                                                                                  
 batch_normalization_9 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_9[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_9 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_9[0][0]'
                                                                    ]                             
                                                                                                  
 up_sampling2d (UpSampling2  (None, 32, 32, 1024)         0         ['activation_9[0][0]']        
 D)                                                                                               
                                                                                                  
 concatenate (Concatenate)   (None, 32, 32, 1536)         0         ['up_sampling2d[0][0]',       
                                                                     'activation_7[0][0]']        
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate[0][0]']         
                                                                                                  
 batch_normalization_10 (Ba  (None, 32, 32, 512)          2048      ['conv2d_10[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_10 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_10[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_10[0][0]']       
                                                                                                  
 batch_normalization_11 (Ba  (None, 32, 32, 512)          2048      ['conv2d_11[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_11 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_11[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 64, 64, 512)          0         ['activation_11[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_1 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_1[0][0]',     
 )                                                                   'activation_5[0][0]']        
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_1[0][0]']       
                                                                                                  
 batch_normalization_12 (Ba  (None, 64, 64, 256)          1024      ['conv2d_12[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_12 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_12[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_13 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_12[0][0]']       
                                                                                                  
 batch_normalization_13 (Ba  (None, 64, 64, 256)          1024      ['conv2d_13[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_13 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_13[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 128, 128, 256)        0         ['activation_13[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_2 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_2[0][0]',     
 )                                                                   'activation_3[0][0]']        
                                                                                                  
 conv2d_14 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_2[0][0]']       
                                                                                                  
 batch_normalization_14 (Ba  (None, 128, 128, 128)        512       ['conv2d_14[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_14 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_14[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_15 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_14[0][0]']       
                                                                                                  
 batch_normalization_15 (Ba  (None, 128, 128, 128)        512       ['conv2d_15[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_15 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_15[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 256, 256, 128)        0         ['activation_15[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_3 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_3[0][0]',     
 )                                                                   'activation_1[0][0]']        
                                                                                                  
 conv2d_16 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_3[0][0]']       
                                                                                                  
 batch_normalization_16 (Ba  (None, 256, 256, 64)         256       ['conv2d_16[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_16 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_16[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_16[0][0]']       
                                                                                                  
 batch_normalization_17 (Ba  (None, 256, 256, 64)         256       ['conv2d_17[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_17 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_17[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_18 (Conv2D)          (None, 256, 256, 1)          65        ['activation_17[0][0]']       
                                                                                                  
 batch_normalization_18 (Ba  (None, 256, 256, 1)          4         ['conv2d_18[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_18 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_18[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31401349 (119.79 MB)
Trainable params: 31389571 (119.74 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
WARNING:absl:`lr` is deprecated in TF-Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
None
✓ focal_loss imported successfully
Epoch 1/30
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1758878012.879644 1072361 service.cc:145] XLA service 0x14eedd592c50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1758878012.879667 1072361 service.cc:153]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6
I0000 00:00:1758878013.017323 1072361 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
 1/17 [>.............................] - ETA: 12:03 - loss: 0.3407 - accuracy: 0.5017 - jacard_coef: 0.0878 2/17 [==>...........................] - ETA: 1:11 - loss: 0.3009 - accuracy: 0.3998 - jacard_coef: 0.0656  3/17 [====>.........................] - ETA: 34s - loss: 0.2748 - accuracy: 0.3785 - jacard_coef: 0.0751  4/17 [======>.......................] - ETA: 22s - loss: 0.2567 - accuracy: 0.3739 - jacard_coef: 0.0742 5/17 [=======>......................] - ETA: 15s - loss: 0.2442 - accuracy: 0.3478 - jacard_coef: 0.0802 6/17 [=========>....................] - ETA: 12s - loss: 0.2354 - accuracy: 0.3082 - jacard_coef: 0.0738 7/17 [===========>..................] - ETA: 9s - loss: 0.2306 - accuracy: 0.3018 - jacard_coef: 0.0714  8/17 [=============>................] - ETA: 7s - loss: 0.2266 - accuracy: 0.2887 - jacard_coef: 0.0705 9/17 [==============>...............] - ETA: 6s - loss: 0.2227 - accuracy: 0.2741 - jacard_coef: 0.072310/17 [================>.............] - ETA: 4s - loss: 0.2199 - accuracy: 0.2581 - jacard_coef: 0.072411/17 [==================>...........] - ETA: 3s - loss: 0.2171 - accuracy: 0.2444 - jacard_coef: 0.073712/17 [====================>.........] - ETA: 2s - loss: 0.2147 - accuracy: 0.2352 - jacard_coef: 0.077013/17 [=====================>........] - ETA: 2s - loss: 0.2126 - accuracy: 0.2291 - jacard_coef: 0.079414/17 [=======================>......] - ETA: 1s - loss: 0.2103 - accuracy: 0.2261 - jacard_coef: 0.080915/17 [=========================>....] - ETA: 1s - loss: 0.2084 - accuracy: 0.2310 - jacard_coef: 0.083916/17 [===========================>..] - ETA: 0s - loss: 0.2066 - accuracy: 0.2369 - jacard_coef: 0.080817/17 [==============================] - ETA: 0s - loss: 0.2064 - accuracy: 0.2376 - jacard_coef: 0.076517/17 [==============================] - 59s 871ms/step - loss: 0.2064 - accuracy: 0.2376 - jacard_coef: 0.0765 - val_loss: 0.2493 - val_accuracy: 0.9046 - val_jacard_coef: 0.0162 - lr: 0.0010
Epoch 2/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1781 - accuracy: 0.4230 - jacard_coef: 0.1143 2/17 [==>...........................] - ETA: 2s - loss: 0.1772 - accuracy: 0.4277 - jacard_coef: 0.1087 3/17 [====>.........................] - ETA: 2s - loss: 0.1759 - accuracy: 0.4535 - jacard_coef: 0.0959 4/17 [======>.......................] - ETA: 2s - loss: 0.1769 - accuracy: 0.4392 - jacard_coef: 0.0855 5/17 [=======>......................] - ETA: 2s - loss: 0.1765 - accuracy: 0.4528 - jacard_coef: 0.0873 6/17 [=========>....................] - ETA: 1s - loss: 0.1764 - accuracy: 0.4612 - jacard_coef: 0.0772 7/17 [===========>..................] - ETA: 1s - loss: 0.1763 - accuracy: 0.4715 - jacard_coef: 0.0760 8/17 [=============>................] - ETA: 1s - loss: 0.1763 - accuracy: 0.4674 - jacard_coef: 0.0761 9/17 [==============>...............] - ETA: 1s - loss: 0.1764 - accuracy: 0.4612 - jacard_coef: 0.076910/17 [================>.............] - ETA: 1s - loss: 0.1764 - accuracy: 0.4510 - jacard_coef: 0.077511/17 [==================>...........] - ETA: 1s - loss: 0.1762 - accuracy: 0.4485 - jacard_coef: 0.076812/17 [====================>.........] - ETA: 0s - loss: 0.1761 - accuracy: 0.4308 - jacard_coef: 0.079713/17 [=====================>........] - ETA: 0s - loss: 0.1761 - accuracy: 0.4127 - jacard_coef: 0.077814/17 [=======================>......] - ETA: 0s - loss: 0.1760 - accuracy: 0.4009 - jacard_coef: 0.078415/17 [=========================>....] - ETA: 0s - loss: 0.1758 - accuracy: 0.4056 - jacard_coef: 0.076416/17 [===========================>..] - ETA: 0s - loss: 0.1755 - accuracy: 0.4202 - jacard_coef: 0.078817/17 [==============================] - 3s 180ms/step - loss: 0.1755 - accuracy: 0.4201 - jacard_coef: 0.0764 - val_loss: 0.7565 - val_accuracy: 0.9302 - val_jacard_coef: 2.3436e-05 - lr: 0.0010
Epoch 3/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1730 - accuracy: 0.7287 - jacard_coef: 0.0504 2/17 [==>...........................] - ETA: 2s - loss: 0.1740 - accuracy: 0.7351 - jacard_coef: 0.0758 3/17 [====>.........................] - ETA: 2s - loss: 0.1743 - accuracy: 0.7153 - jacard_coef: 0.0747 4/17 [======>.......................] - ETA: 2s - loss: 0.1735 - accuracy: 0.7403 - jacard_coef: 0.0651 5/17 [=======>......................] - ETA: 2s - loss: 0.1732 - accuracy: 0.7429 - jacard_coef: 0.0632 6/17 [=========>....................] - ETA: 1s - loss: 0.1734 - accuracy: 0.7410 - jacard_coef: 0.0650 7/17 [===========>..................] - ETA: 1s - loss: 0.1733 - accuracy: 0.7388 - jacard_coef: 0.0716 8/17 [=============>................] - ETA: 1s - loss: 0.1729 - accuracy: 0.7429 - jacard_coef: 0.0694 9/17 [==============>...............] - ETA: 1s - loss: 0.1727 - accuracy: 0.7504 - jacard_coef: 0.072310/17 [================>.............] - ETA: 1s - loss: 0.1726 - accuracy: 0.7512 - jacard_coef: 0.075511/17 [==================>...........] - ETA: 1s - loss: 0.1723 - accuracy: 0.7557 - jacard_coef: 0.073212/17 [====================>.........] - ETA: 0s - loss: 0.1720 - accuracy: 0.7578 - jacard_coef: 0.070813/17 [=====================>........] - ETA: 0s - loss: 0.1717 - accuracy: 0.7605 - jacard_coef: 0.066914/17 [=======================>......] - ETA: 0s - loss: 0.1714 - accuracy: 0.7601 - jacard_coef: 0.064415/17 [=========================>....] - ETA: 0s - loss: 0.1712 - accuracy: 0.7577 - jacard_coef: 0.066916/17 [===========================>..] - ETA: 0s - loss: 0.1709 - accuracy: 0.7547 - jacard_coef: 0.068017/17 [==============================] - 3s 179ms/step - loss: 0.1709 - accuracy: 0.7539 - jacard_coef: 0.0640 - val_loss: 0.2367 - val_accuracy: 0.9263 - val_jacard_coef: 0.0016 - lr: 0.0010
Epoch 4/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1645 - accuracy: 0.7257 - jacard_coef: 0.0962 2/17 [==>...........................] - ETA: 2s - loss: 0.1665 - accuracy: 0.6705 - jacard_coef: 0.0772 3/17 [====>.........................] - ETA: 2s - loss: 0.1654 - accuracy: 0.6947 - jacard_coef: 0.0688 4/17 [======>.......................] - ETA: 2s - loss: 0.1652 - accuracy: 0.7359 - jacard_coef: 0.0562 5/17 [=======>......................] - ETA: 2s - loss: 0.1649 - accuracy: 0.7713 - jacard_coef: 0.0473 6/17 [=========>....................] - ETA: 1s - loss: 0.1649 - accuracy: 0.7905 - jacard_coef: 0.0421 7/17 [===========>..................] - ETA: 1s - loss: 0.1648 - accuracy: 0.8050 - jacard_coef: 0.0376 8/17 [=============>................] - ETA: 1s - loss: 0.1648 - accuracy: 0.8014 - jacard_coef: 0.0365 9/17 [==============>...............] - ETA: 1s - loss: 0.1646 - accuracy: 0.8101 - jacard_coef: 0.039310/17 [================>.............] - ETA: 1s - loss: 0.1644 - accuracy: 0.8142 - jacard_coef: 0.038411/17 [==================>...........] - ETA: 1s - loss: 0.1642 - accuracy: 0.8203 - jacard_coef: 0.036612/17 [====================>.........] - ETA: 0s - loss: 0.1640 - accuracy: 0.8237 - jacard_coef: 0.037613/17 [=====================>........] - ETA: 0s - loss: 0.1639 - accuracy: 0.8244 - jacard_coef: 0.039914/17 [=======================>......] - ETA: 0s - loss: 0.1637 - accuracy: 0.8275 - jacard_coef: 0.039115/17 [=========================>....] - ETA: 0s - loss: 0.1636 - accuracy: 0.8295 - jacard_coef: 0.037716/17 [===========================>..] - ETA: 0s - loss: 0.1635 - accuracy: 0.8218 - jacard_coef: 0.039817/17 [==============================] - 3s 180ms/step - loss: 0.1644 - accuracy: 0.8190 - jacard_coef: 0.0376 - val_loss: 0.1340 - val_accuracy: 0.9252 - val_jacard_coef: 0.0058 - lr: 0.0010
Epoch 5/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1825 - accuracy: 0.1600 - jacard_coef: 0.0478 2/17 [==>...........................] - ETA: 2s - loss: 0.1764 - accuracy: 0.1989 - jacard_coef: 0.0514 3/17 [====>.........................] - ETA: 2s - loss: 0.1744 - accuracy: 0.3288 - jacard_coef: 0.0700 4/17 [======>.......................] - ETA: 2s - loss: 0.1729 - accuracy: 0.4701 - jacard_coef: 0.0591 5/17 [=======>......................] - ETA: 2s - loss: 0.1714 - accuracy: 0.5607 - jacard_coef: 0.0494 6/17 [=========>....................] - ETA: 1s - loss: 0.1713 - accuracy: 0.6121 - jacard_coef: 0.0461 7/17 [===========>..................] - ETA: 1s - loss: 0.1705 - accuracy: 0.6533 - jacard_coef: 0.0424 8/17 [=============>................] - ETA: 1s - loss: 0.1698 - accuracy: 0.6828 - jacard_coef: 0.0416 9/17 [==============>...............] - ETA: 1s - loss: 0.1697 - accuracy: 0.7022 - jacard_coef: 0.041410/17 [================>.............] - ETA: 1s - loss: 0.1698 - accuracy: 0.7146 - jacard_coef: 0.044911/17 [==================>...........] - ETA: 1s - loss: 0.1692 - accuracy: 0.7301 - jacard_coef: 0.045312/17 [====================>.........] - ETA: 0s - loss: 0.1690 - accuracy: 0.7368 - jacard_coef: 0.048113/17 [=====================>........] - ETA: 0s - loss: 0.1687 - accuracy: 0.7438 - jacard_coef: 0.049214/17 [=======================>......] - ETA: 0s - loss: 0.1686 - accuracy: 0.7492 - jacard_coef: 0.049515/17 [=========================>....] - ETA: 0s - loss: 0.1683 - accuracy: 0.7565 - jacard_coef: 0.049816/17 [===========================>..] - ETA: 0s - loss: 0.1679 - accuracy: 0.7657 - jacard_coef: 0.053617/17 [==============================] - 3s 179ms/step - loss: 0.1679 - accuracy: 0.7659 - jacard_coef: 0.0605 - val_loss: 1.0627 - val_accuracy: 0.9234 - val_jacard_coef: 0.0064 - lr: 0.0010
Epoch 6/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1607 - accuracy: 0.8470 - jacard_coef: 0.0726 2/17 [==>...........................] - ETA: 2s - loss: 0.1615 - accuracy: 0.8339 - jacard_coef: 0.0645 3/17 [====>.........................] - ETA: 2s - loss: 0.1610 - accuracy: 0.8407 - jacard_coef: 0.0779 4/17 [======>.......................] - ETA: 2s - loss: 0.1613 - accuracy: 0.8367 - jacard_coef: 0.0789 5/17 [=======>......................] - ETA: 2s - loss: 0.1610 - accuracy: 0.8379 - jacard_coef: 0.0822 6/17 [=========>....................] - ETA: 1s - loss: 0.1613 - accuracy: 0.8372 - jacard_coef: 0.0739 7/17 [===========>..................] - ETA: 1s - loss: 0.1615 - accuracy: 0.8354 - jacard_coef: 0.0750 8/17 [=============>................] - ETA: 1s - loss: 0.1613 - accuracy: 0.8383 - jacard_coef: 0.0682 9/17 [==============>...............] - ETA: 1s - loss: 0.1607 - accuracy: 0.8445 - jacard_coef: 0.071510/17 [================>.............] - ETA: 1s - loss: 0.1604 - accuracy: 0.8474 - jacard_coef: 0.066911/17 [==================>...........] - ETA: 1s - loss: 0.1602 - accuracy: 0.8482 - jacard_coef: 0.065412/17 [====================>.........] - ETA: 0s - loss: 0.1608 - accuracy: 0.8252 - jacard_coef: 0.069113/17 [=====================>........] - ETA: 0s - loss: 0.1606 - accuracy: 0.8312 - jacard_coef: 0.064414/17 [=======================>......] - ETA: 0s - loss: 0.1605 - accuracy: 0.8333 - jacard_coef: 0.064315/17 [=========================>....] - ETA: 0s - loss: 0.1604 - accuracy: 0.8343 - jacard_coef: 0.062316/17 [===========================>..] - ETA: 0s - loss: 0.1604 - accuracy: 0.8349 - jacard_coef: 0.060017/17 [==============================] - 3s 180ms/step - loss: 0.1604 - accuracy: 0.8347 - jacard_coef: 0.0619 - val_loss: 0.4208 - val_accuracy: 0.9231 - val_jacard_coef: 0.0064 - lr: 0.0010
Epoch 7/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1583 - accuracy: 0.8380 - jacard_coef: 0.0353 2/17 [==>...........................] - ETA: 2s - loss: 0.1588 - accuracy: 0.8477 - jacard_coef: 0.0375 3/17 [====>.........................] - ETA: 2s - loss: 0.1582 - accuracy: 0.8570 - jacard_coef: 0.0380 4/17 [======>.......................] - ETA: 2s - loss: 0.1584 - accuracy: 0.8597 - jacard_coef: 0.0361 5/17 [=======>......................] - ETA: 2s - loss: 0.1580 - accuracy: 0.8670 - jacard_coef: 0.0332 6/17 [=========>....................] - ETA: 1s - loss: 0.1581 - accuracy: 0.8694 - jacard_coef: 0.0364 7/17 [===========>..................] - ETA: 1s - loss: 0.1577 - accuracy: 0.8750 - jacard_coef: 0.0357 8/17 [=============>................] - ETA: 1s - loss: 0.1576 - accuracy: 0.8791 - jacard_coef: 0.0356 9/17 [==============>...............] - ETA: 1s - loss: 0.1571 - accuracy: 0.8852 - jacard_coef: 0.060110/17 [================>.............] - ETA: 1s - loss: 0.1569 - accuracy: 0.8876 - jacard_coef: 0.061911/17 [==================>...........] - ETA: 1s - loss: 0.1570 - accuracy: 0.8858 - jacard_coef: 0.056712/17 [====================>.........] - ETA: 0s - loss: 0.1570 - accuracy: 0.8833 - jacard_coef: 0.055713/17 [=====================>........] - ETA: 0s - loss: 0.1572 - accuracy: 0.8804 - jacard_coef: 0.053614/17 [=======================>......] - ETA: 0s - loss: 0.1570 - accuracy: 0.8809 - jacard_coef: 0.052915/17 [=========================>....] - ETA: 0s - loss: 0.1568 - accuracy: 0.8814 - jacard_coef: 0.052516/17 [===========================>..] - ETA: 0s - loss: 0.1568 - accuracy: 0.8812 - jacard_coef: 0.052817/17 [==============================] - 3s 180ms/step - loss: 0.1568 - accuracy: 0.8813 - jacard_coef: 0.0665 - val_loss: 0.1415 - val_accuracy: 0.9262 - val_jacard_coef: 0.0032 - lr: 5.0000e-04
Epoch 8/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1543 - accuracy: 0.8965 - jacard_coef: 0.0656 2/17 [==>...........................] - ETA: 2s - loss: 0.1544 - accuracy: 0.8953 - jacard_coef: 0.0385 3/17 [====>.........................] - ETA: 2s - loss: 0.1560 - accuracy: 0.8743 - jacard_coef: 0.0319 4/17 [======>.......................] - ETA: 2s - loss: 0.1561 - accuracy: 0.8661 - jacard_coef: 0.0342 5/17 [=======>......................] - ETA: 2s - loss: 0.1553 - accuracy: 0.8674 - jacard_coef: 0.0419 6/17 [=========>....................] - ETA: 1s - loss: 0.1552 - accuracy: 0.8688 - jacard_coef: 0.0627 7/17 [===========>..................] - ETA: 1s - loss: 0.1549 - accuracy: 0.8701 - jacard_coef: 0.0652 8/17 [=============>................] - ETA: 1s - loss: 0.1545 - accuracy: 0.8734 - jacard_coef: 0.0766 9/17 [==============>...............] - ETA: 1s - loss: 0.1544 - accuracy: 0.8747 - jacard_coef: 0.082010/17 [================>.............] - ETA: 1s - loss: 0.1542 - accuracy: 0.8732 - jacard_coef: 0.081411/17 [==================>...........] - ETA: 1s - loss: 0.1542 - accuracy: 0.8721 - jacard_coef: 0.078312/17 [====================>.........] - ETA: 0s - loss: 0.1540 - accuracy: 0.8736 - jacard_coef: 0.080713/17 [=====================>........] - ETA: 0s - loss: 0.1540 - accuracy: 0.8708 - jacard_coef: 0.076514/17 [=======================>......] - ETA: 0s - loss: 0.1541 - accuracy: 0.8689 - jacard_coef: 0.073315/17 [=========================>....] - ETA: 0s - loss: 0.1542 - accuracy: 0.8658 - jacard_coef: 0.071016/17 [===========================>..] - ETA: 0s - loss: 0.1540 - accuracy: 0.8669 - jacard_coef: 0.070917/17 [==============================] - 3s 180ms/step - loss: 0.1540 - accuracy: 0.8670 - jacard_coef: 0.0667 - val_loss: 0.0835 - val_accuracy: 0.9240 - val_jacard_coef: 0.0062 - lr: 5.0000e-04
Epoch 9/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1526 - accuracy: 0.8610 - jacard_coef: 0.0817 2/17 [==>...........................] - ETA: 2s - loss: 0.1533 - accuracy: 0.8631 - jacard_coef: 0.0460 3/17 [====>.........................] - ETA: 2s - loss: 0.1525 - accuracy: 0.8725 - jacard_coef: 0.0427 4/17 [======>.......................] - ETA: 2s - loss: 0.1518 - accuracy: 0.8839 - jacard_coef: 0.0454 5/17 [=======>......................] - ETA: 2s - loss: 0.1522 - accuracy: 0.8815 - jacard_coef: 0.0460 6/17 [=========>....................] - ETA: 1s - loss: 0.1520 - accuracy: 0.8857 - jacard_coef: 0.0431 7/17 [===========>..................] - ETA: 1s - loss: 0.1516 - accuracy: 0.8918 - jacard_coef: 0.0402 8/17 [=============>................] - ETA: 1s - loss: 0.1519 - accuracy: 0.8874 - jacard_coef: 0.0365 9/17 [==============>...............] - ETA: 1s - loss: 0.1518 - accuracy: 0.8876 - jacard_coef: 0.037610/17 [================>.............] - ETA: 1s - loss: 0.1515 - accuracy: 0.8927 - jacard_coef: 0.033811/17 [==================>...........] - ETA: 1s - loss: 0.1516 - accuracy: 0.8923 - jacard_coef: 0.031512/17 [====================>.........] - ETA: 0s - loss: 0.1513 - accuracy: 0.8969 - jacard_coef: 0.030313/17 [=====================>........] - ETA: 0s - loss: 0.1512 - accuracy: 0.8976 - jacard_coef: 0.028714/17 [=======================>......] - ETA: 0s - loss: 0.1510 - accuracy: 0.8991 - jacard_coef: 0.027415/17 [=========================>....] - ETA: 0s - loss: 0.1510 - accuracy: 0.8991 - jacard_coef: 0.026116/17 [===========================>..] - ETA: 0s - loss: 0.1509 - accuracy: 0.8998 - jacard_coef: 0.024517/17 [==============================] - 3s 180ms/step - loss: 0.1509 - accuracy: 0.8991 - jacard_coef: 0.0301 - val_loss: 0.0966 - val_accuracy: 0.9292 - val_jacard_coef: 0.0019 - lr: 5.0000e-04
Epoch 10/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1501 - accuracy: 0.8281 - jacard_coef: 0.0607 2/17 [==>...........................] - ETA: 2s - loss: 0.1494 - accuracy: 0.8737 - jacard_coef: 0.0337 3/17 [====>.........................] - ETA: 2s - loss: 0.1502 - accuracy: 0.8789 - jacard_coef: 0.0257 4/17 [======>.......................] - ETA: 2s - loss: 0.1502 - accuracy: 0.8917 - jacard_coef: 0.0216 5/17 [=======>......................] - ETA: 2s - loss: 0.1505 - accuracy: 0.8918 - jacard_coef: 0.0192 6/17 [=========>....................] - ETA: 1s - loss: 0.1502 - accuracy: 0.8988 - jacard_coef: 0.0161 7/17 [===========>..................] - ETA: 1s - loss: 0.1500 - accuracy: 0.9036 - jacard_coef: 0.0141 8/17 [=============>................] - ETA: 1s - loss: 0.1500 - accuracy: 0.9034 - jacard_coef: 0.0131 9/17 [==============>...............] - ETA: 1s - loss: 0.1497 - accuracy: 0.9071 - jacard_coef: 0.011610/17 [================>.............] - ETA: 1s - loss: 0.1504 - accuracy: 0.9004 - jacard_coef: 0.011911/17 [==================>...........] - ETA: 1s - loss: 0.1503 - accuracy: 0.9021 - jacard_coef: 0.011312/17 [====================>.........] - ETA: 0s - loss: 0.1504 - accuracy: 0.9028 - jacard_coef: 0.010913/17 [=====================>........] - ETA: 0s - loss: 0.1502 - accuracy: 0.9050 - jacard_coef: 0.010214/17 [=======================>......] - ETA: 0s - loss: 0.1502 - accuracy: 0.9054 - jacard_coef: 0.009615/17 [=========================>....] - ETA: 0s - loss: 0.1502 - accuracy: 0.9048 - jacard_coef: 0.009116/17 [===========================>..] - ETA: 0s - loss: 0.1499 - accuracy: 0.9069 - jacard_coef: 0.008617/17 [==============================] - 3s 180ms/step - loss: 0.1499 - accuracy: 0.9074 - jacard_coef: 0.0081 - val_loss: 0.0890 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 5.0000e-04
Epoch 11/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1502 - accuracy: 0.8862 - jacard_coef: 2.1779e-04 2/17 [==>...........................] - ETA: 2s - loss: 0.1482 - accuracy: 0.9207 - jacard_coef: 1.7271e-04 3/17 [====>.........................] - ETA: 2s - loss: 0.1487 - accuracy: 0.9106 - jacard_coef: 1.6738e-04 4/17 [======>.......................] - ETA: 2s - loss: 0.1480 - accuracy: 0.9220 - jacard_coef: 3.3179e-04 5/17 [=======>......................] - ETA: 2s - loss: 0.1482 - accuracy: 0.9196 - jacard_coef: 3.9681e-04 6/17 [=========>....................] - ETA: 1s - loss: 0.1484 - accuracy: 0.9147 - jacard_coef: 4.4086e-04 7/17 [===========>..................] - ETA: 1s - loss: 0.1481 - accuracy: 0.9167 - jacard_coef: 3.7788e-04 8/17 [=============>................] - ETA: 1s - loss: 0.1483 - accuracy: 0.9168 - jacard_coef: 4.7309e-04 9/17 [==============>...............] - ETA: 1s - loss: 0.1484 - accuracy: 0.9134 - jacard_coef: 5.9236e-0410/17 [================>.............] - ETA: 1s - loss: 0.1486 - accuracy: 0.9120 - jacard_coef: 6.7935e-0411/17 [==================>...........] - ETA: 1s - loss: 0.1486 - accuracy: 0.9114 - jacard_coef: 0.0011    12/17 [====================>.........] - ETA: 0s - loss: 0.1483 - accuracy: 0.9135 - jacard_coef: 0.001113/17 [=====================>........] - ETA: 0s - loss: 0.1483 - accuracy: 0.9134 - jacard_coef: 0.002014/17 [=======================>......] - ETA: 0s - loss: 0.1481 - accuracy: 0.9147 - jacard_coef: 0.002015/17 [=========================>....] - ETA: 0s - loss: 0.1482 - accuracy: 0.9136 - jacard_coef: 0.002816/17 [===========================>..] - ETA: 0s - loss: 0.1479 - accuracy: 0.9156 - jacard_coef: 0.002717/17 [==============================] - 3s 180ms/step - loss: 0.1481 - accuracy: 0.9136 - jacard_coef: 0.0027 - val_loss: 0.1454 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 5.0000e-04
/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(

✓ Training completed successfully!
  Best Val Jaccard: 0.0162 (epoch 1)
  Final Val Loss: 0.1454
  Training Time: 0:01:30.178351
  Stability (std): 0.3186

Results saved to: hyperparameter_optimization_20250926_165036/exp_13_Attention_UNet_lr1e-4_bs8/Attention_UNet_lr0.0001_bs8_results.json
