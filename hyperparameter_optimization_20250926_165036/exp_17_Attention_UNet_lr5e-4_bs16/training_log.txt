âœ“ GPU memory growth enabled for 1 GPUs
Loading dataset...
Loaded 144 images and 144 masks
Training set: (129, 256, 256, 3), Validation set: (15, 256, 256, 3)

============================================================
TRAINING: Attention_UNet
Learning Rate: 0.0005, Batch Size: 16, Epochs: 30
============================================================
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 256, 256, 64)         640       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 256, 256, 64)         256       ['conv2d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 activation (Activation)     (None, 256, 256, 64)         0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['activation[0][0]']          
                                                                                                  
 batch_normalization_1 (Bat  (None, 256, 256, 64)         256       ['conv2d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_1 (Activation)   (None, 256, 256, 64)         0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['activation_1[0][0]']        
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       
                                                                                                  
 batch_normalization_2 (Bat  (None, 128, 128, 128)        512       ['conv2d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_2 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_3 (Conv2D)           (None, 128, 128, 128)        147584    ['activation_2[0][0]']        
                                                                                                  
 batch_normalization_3 (Bat  (None, 128, 128, 128)        512       ['conv2d_3[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_3 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_3[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_3[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 batch_normalization_4 (Bat  (None, 64, 64, 256)          1024      ['conv2d_4[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_4 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_4[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_5 (Conv2D)           (None, 64, 64, 256)          590080    ['activation_4[0][0]']        
                                                                                                  
 batch_normalization_5 (Bat  (None, 64, 64, 256)          1024      ['conv2d_5[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_5 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_5[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_5[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 512)          1180160   ['max_pooling2d_2[0][0]']     
                                                                                                  
 batch_normalization_6 (Bat  (None, 32, 32, 512)          2048      ['conv2d_6[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_6 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_6[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 32, 32, 512)          2359808   ['activation_6[0][0]']        
                                                                                                  
 batch_normalization_7 (Bat  (None, 32, 32, 512)          2048      ['conv2d_7[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_7 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_7[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_3 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_7[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 1024)         4719616   ['max_pooling2d_3[0][0]']     
                                                                                                  
 batch_normalization_8 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_8[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_8 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_8[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 1024)         9438208   ['activation_8[0][0]']        
                                                                                                  
 batch_normalization_9 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_9[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_9 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_9[0][0]'
                                                                    ]                             
                                                                                                  
 up_sampling2d (UpSampling2  (None, 32, 32, 1024)         0         ['activation_9[0][0]']        
 D)                                                                                               
                                                                                                  
 concatenate (Concatenate)   (None, 32, 32, 1536)         0         ['up_sampling2d[0][0]',       
                                                                     'activation_7[0][0]']        
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate[0][0]']         
                                                                                                  
 batch_normalization_10 (Ba  (None, 32, 32, 512)          2048      ['conv2d_10[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_10 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_10[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_10[0][0]']       
                                                                                                  
 batch_normalization_11 (Ba  (None, 32, 32, 512)          2048      ['conv2d_11[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_11 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_11[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 64, 64, 512)          0         ['activation_11[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_1 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_1[0][0]',     
 )                                                                   'activation_5[0][0]']        
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_1[0][0]']       
                                                                                                  
 batch_normalization_12 (Ba  (None, 64, 64, 256)          1024      ['conv2d_12[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_12 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_12[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_13 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_12[0][0]']       
                                                                                                  
 batch_normalization_13 (Ba  (None, 64, 64, 256)          1024      ['conv2d_13[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_13 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_13[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 128, 128, 256)        0         ['activation_13[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_2 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_2[0][0]',     
 )                                                                   'activation_3[0][0]']        
                                                                                                  
 conv2d_14 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_2[0][0]']       
                                                                                                  
 batch_normalization_14 (Ba  (None, 128, 128, 128)        512       ['conv2d_14[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_14 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_14[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_15 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_14[0][0]']       
                                                                                                  
 batch_normalization_15 (Ba  (None, 128, 128, 128)        512       ['conv2d_15[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_15 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_15[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 256, 256, 128)        0         ['activation_15[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_3 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_3[0][0]',     
 )                                                                   'activation_1[0][0]']        
                                                                                                  
 conv2d_16 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_3[0][0]']       
                                                                                                  
 batch_normalization_16 (Ba  (None, 256, 256, 64)         256       ['conv2d_16[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_16 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_16[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_16[0][0]']       
                                                                                                  
 batch_normalization_17 (Ba  (None, 256, 256, 64)         256       ['conv2d_17[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_17 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_17[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_18 (Conv2D)          (None, 256, 256, 1)          65        ['activation_17[0][0]']       
                                                                                                  
 batch_normalization_18 (Ba  (None, 256, 256, 1)          4         ['conv2d_18[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_18 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_18[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31401349 (119.79 MB)
Trainable params: 31389571 (119.74 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
WARNING:absl:`lr` is deprecated in TF-Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
None
âœ“ focal_loss imported successfully
Epoch 1/30
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1758878559.228619 1097935 service.cc:145] XLA service 0x14cf9d2946f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1758878559.228643 1097935 service.cc:153]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6
I0000 00:00:1758878559.366436 1097935 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
1/9 [==>...........................] - ETA: 6:44 - loss: 0.3313 - accuracy: 0.4637 - jacard_coef: 0.07842/9 [=====>........................] - ETA: 59s - loss: 0.3012 - accuracy: 0.3743 - jacard_coef: 0.0842 3/9 [=========>....................] - ETA: 26s - loss: 0.2751 - accuracy: 0.3195 - jacard_coef: 0.07544/9 [============>.................] - ETA: 15s - loss: 0.2617 - accuracy: 0.2997 - jacard_coef: 0.08515/9 [===============>..............] - ETA: 9s - loss: 0.2563 - accuracy: 0.2770 - jacard_coef: 0.0853 6/9 [===================>..........] - ETA: 5s - loss: 0.2474 - accuracy: 0.2583 - jacard_coef: 0.08417/9 [======================>.......] - ETA: 3s - loss: 0.2407 - accuracy: 0.2394 - jacard_coef: 0.08178/9 [=========================>....] - ETA: 1s - loss: 0.2357 - accuracy: 0.2287 - jacard_coef: 0.08259/9 [==============================] - ETA: 0s - loss: 0.2355 - accuracy: 0.2275 - jacard_coef: 0.07389/9 [==============================] - 69s 2s/step - loss: 0.2355 - accuracy: 0.2275 - jacard_coef: 0.0738 - val_loss: 1.1113 - val_accuracy: 0.9304 - val_jacard_coef: 1.4616e-12 - lr: 0.0010
Epoch 2/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1887 - accuracy: 0.2532 - jacard_coef: 0.08752/9 [=====>........................] - ETA: 2s - loss: 0.1870 - accuracy: 0.2477 - jacard_coef: 0.08433/9 [=========>....................] - ETA: 2s - loss: 0.1877 - accuracy: 0.2596 - jacard_coef: 0.08024/9 [============>.................] - ETA: 1s - loss: 0.1864 - accuracy: 0.2639 - jacard_coef: 0.08095/9 [===============>..............] - ETA: 1s - loss: 0.1854 - accuracy: 0.2706 - jacard_coef: 0.08436/9 [===================>..........] - ETA: 1s - loss: 0.1849 - accuracy: 0.2920 - jacard_coef: 0.08137/9 [======================>.......] - ETA: 0s - loss: 0.1839 - accuracy: 0.3044 - jacard_coef: 0.08038/9 [=========================>....] - ETA: 0s - loss: 0.1944 - accuracy: 0.3114 - jacard_coef: 0.08199/9 [==============================] - 3s 333ms/step - loss: 0.1947 - accuracy: 0.3101 - jacard_coef: 0.0733 - val_loss: 1.1194 - val_accuracy: 0.9270 - val_jacard_coef: 0.0029 - lr: 0.0010
Epoch 3/30
1/9 [==>...........................] - ETA: 2s - loss: 0.2101 - accuracy: 0.1764 - jacard_coef: 0.10782/9 [=====>........................] - ETA: 2s - loss: 0.2154 - accuracy: 0.2251 - jacard_coef: 0.09883/9 [=========>....................] - ETA: 2s - loss: 0.2177 - accuracy: 0.1905 - jacard_coef: 0.09484/9 [============>.................] - ETA: 1s - loss: 0.2165 - accuracy: 0.1703 - jacard_coef: 0.08905/9 [===============>..............] - ETA: 1s - loss: 0.2130 - accuracy: 0.1735 - jacard_coef: 0.08756/9 [===================>..........] - ETA: 1s - loss: 0.2098 - accuracy: 0.2280 - jacard_coef: 0.08117/9 [======================>.......] - ETA: 0s - loss: 0.2063 - accuracy: 0.2494 - jacard_coef: 0.08248/9 [=========================>....] - ETA: 0s - loss: 0.2081 - accuracy: 0.2449 - jacard_coef: 0.08319/9 [==============================] - 3s 332ms/step - loss: 0.2081 - accuracy: 0.2437 - jacard_coef: 0.0796 - val_loss: 1.1243 - val_accuracy: 0.9170 - val_jacard_coef: 0.0141 - lr: 0.0010
Epoch 4/30
1/9 [==>...........................] - ETA: 2s - loss: 0.2382 - accuracy: 0.1484 - jacard_coef: 0.10552/9 [=====>........................] - ETA: 2s - loss: 0.2291 - accuracy: 0.1284 - jacard_coef: 0.08553/9 [=========>....................] - ETA: 2s - loss: 0.2236 - accuracy: 0.1295 - jacard_coef: 0.08784/9 [============>.................] - ETA: 1s - loss: 0.2199 - accuracy: 0.1246 - jacard_coef: 0.08055/9 [===============>..............] - ETA: 1s - loss: 0.2166 - accuracy: 0.1886 - jacard_coef: 0.07776/9 [===================>..........] - ETA: 1s - loss: 0.2126 - accuracy: 0.2678 - jacard_coef: 0.07717/9 [======================>.......] - ETA: 0s - loss: 0.2094 - accuracy: 0.3287 - jacard_coef: 0.07708/9 [=========================>....] - ETA: 0s - loss: 0.2060 - accuracy: 0.3524 - jacard_coef: 0.07519/9 [==============================] - 3s 326ms/step - loss: 0.2059 - accuracy: 0.3512 - jacard_coef: 0.0769 - val_loss: 1.1189 - val_accuracy: 0.9300 - val_jacard_coef: 6.6793e-04 - lr: 0.0010
Epoch 5/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1788 - accuracy: 0.3396 - jacard_coef: 0.08492/9 [=====>........................] - ETA: 2s - loss: 0.1794 - accuracy: 0.3490 - jacard_coef: 0.08183/9 [=========>....................] - ETA: 2s - loss: 0.1769 - accuracy: 0.3848 - jacard_coef: 0.08354/9 [============>.................] - ETA: 1s - loss: 0.1752 - accuracy: 0.4209 - jacard_coef: 0.07965/9 [===============>..............] - ETA: 1s - loss: 0.1878 - accuracy: 0.3806 - jacard_coef: 0.07556/9 [===================>..........] - ETA: 1s - loss: 0.1899 - accuracy: 0.3424 - jacard_coef: 0.07257/9 [======================>.......] - ETA: 0s - loss: 0.1924 - accuracy: 0.3204 - jacard_coef: 0.07448/9 [=========================>....] - ETA: 0s - loss: 0.1923 - accuracy: 0.3240 - jacard_coef: 0.07549/9 [==============================] - 3s 332ms/step - loss: 0.1922 - accuracy: 0.3249 - jacard_coef: 0.0786 - val_loss: 13.1525 - val_accuracy: 0.1362 - val_jacard_coef: 0.0704 - lr: 0.0010
Epoch 6/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1974 - accuracy: 0.1498 - jacard_coef: 0.07362/9 [=====>........................] - ETA: 2s - loss: 0.2000 - accuracy: 0.1760 - jacard_coef: 0.07633/9 [=========>....................] - ETA: 2s - loss: 0.1920 - accuracy: 0.2501 - jacard_coef: 0.07574/9 [============>.................] - ETA: 1s - loss: 0.1895 - accuracy: 0.3111 - jacard_coef: 0.07375/9 [===============>..............] - ETA: 1s - loss: 0.1860 - accuracy: 0.3650 - jacard_coef: 0.07556/9 [===================>..........] - ETA: 1s - loss: 0.1853 - accuracy: 0.3600 - jacard_coef: 0.07867/9 [======================>.......] - ETA: 0s - loss: 0.1858 - accuracy: 0.3427 - jacard_coef: 0.07838/9 [=========================>....] - ETA: 0s - loss: 0.1866 - accuracy: 0.3386 - jacard_coef: 0.07739/9 [==============================] - 3s 327ms/step - loss: 0.1869 - accuracy: 0.3400 - jacard_coef: 0.0887 - val_loss: 1.1206 - val_accuracy: 0.9304 - val_jacard_coef: 1.4610e-12 - lr: 0.0010
Epoch 7/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1842 - accuracy: 0.6242 - jacard_coef: 0.08932/9 [=====>........................] - ETA: 2s - loss: 0.1839 - accuracy: 0.5818 - jacard_coef: 0.09213/9 [=========>....................] - ETA: 2s - loss: 0.1820 - accuracy: 0.5349 - jacard_coef: 0.07924/9 [============>.................] - ETA: 1s - loss: 0.1830 - accuracy: 0.4766 - jacard_coef: 0.08015/9 [===============>..............] - ETA: 1s - loss: 0.1825 - accuracy: 0.4484 - jacard_coef: 0.08086/9 [===================>..........] - ETA: 1s - loss: 0.1817 - accuracy: 0.4308 - jacard_coef: 0.07827/9 [======================>.......] - ETA: 0s - loss: 0.1809 - accuracy: 0.4192 - jacard_coef: 0.08178/9 [=========================>....] - ETA: 0s - loss: 0.1817 - accuracy: 0.4073 - jacard_coef: 0.08229/9 [==============================] - 3s 327ms/step - loss: 0.1817 - accuracy: 0.4062 - jacard_coef: 0.0819 - val_loss: 1.1218 - val_accuracy: 0.9304 - val_jacard_coef: 1.4616e-12 - lr: 0.0010
Epoch 8/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1713 - accuracy: 0.6623 - jacard_coef: 0.06642/9 [=====>........................] - ETA: 2s - loss: 0.1736 - accuracy: 0.6733 - jacard_coef: 0.05403/9 [=========>....................] - ETA: 2s - loss: 0.1727 - accuracy: 0.6761 - jacard_coef: 0.06184/9 [============>.................] - ETA: 1s - loss: 0.1727 - accuracy: 0.6816 - jacard_coef: 0.06425/9 [===============>..............] - ETA: 1s - loss: 0.1720 - accuracy: 0.6841 - jacard_coef: 0.06696/9 [===================>..........] - ETA: 1s - loss: 0.1714 - accuracy: 0.6795 - jacard_coef: 0.06867/9 [======================>.......] - ETA: 0s - loss: 0.1706 - accuracy: 0.6844 - jacard_coef: 0.06748/9 [=========================>....] - ETA: 0s - loss: 0.1702 - accuracy: 0.6723 - jacard_coef: 0.07069/9 [==============================] - 3s 327ms/step - loss: 0.1706 - accuracy: 0.6709 - jacard_coef: 0.0770 - val_loss: 1.0678 - val_accuracy: 0.9187 - val_jacard_coef: 0.0054 - lr: 0.0010
Epoch 9/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1728 - accuracy: 0.3271 - jacard_coef: 0.06762/9 [=====>........................] - ETA: 2s - loss: 0.1799 - accuracy: 0.2773 - jacard_coef: 0.07563/9 [=========>....................] - ETA: 2s - loss: 0.1787 - accuracy: 0.2704 - jacard_coef: 0.08154/9 [============>.................] - ETA: 1s - loss: 0.1806 - accuracy: 0.2597 - jacard_coef: 0.08145/9 [===============>..............] - ETA: 1s - loss: 0.1804 - accuracy: 0.2553 - jacard_coef: 0.08266/9 [===================>..........] - ETA: 1s - loss: 0.1798 - accuracy: 0.2556 - jacard_coef: 0.08507/9 [======================>.......] - ETA: 0s - loss: 0.1802 - accuracy: 0.2487 - jacard_coef: 0.08768/9 [=========================>....] - ETA: 0s - loss: 0.1813 - accuracy: 0.2399 - jacard_coef: 0.08409/9 [==============================] - 3s 327ms/step - loss: 0.1813 - accuracy: 0.2389 - jacard_coef: 0.0751 - val_loss: 1.1218 - val_accuracy: 0.9304 - val_jacard_coef: 1.4616e-12 - lr: 0.0010
Epoch 10/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1786 - accuracy: 0.1931 - jacard_coef: 0.08192/9 [=====>........................] - ETA: 2s - loss: 0.1799 - accuracy: 0.1835 - jacard_coef: 0.07123/9 [=========>....................] - ETA: 2s - loss: 0.1813 - accuracy: 0.1771 - jacard_coef: 0.07244/9 [============>.................] - ETA: 1s - loss: 0.1853 - accuracy: 0.1843 - jacard_coef: 0.08345/9 [===============>..............] - ETA: 1s - loss: 0.1838 - accuracy: 0.1868 - jacard_coef: 0.08356/9 [===================>..........] - ETA: 1s - loss: 0.1818 - accuracy: 0.1975 - jacard_coef: 0.08487/9 [======================>.......] - ETA: 0s - loss: 0.1811 - accuracy: 0.2095 - jacard_coef: 0.08218/9 [=========================>....] - ETA: 0s - loss: 0.1795 - accuracy: 0.2951 - jacard_coef: 0.07339/9 [==============================] - 3s 326ms/step - loss: 0.1794 - accuracy: 0.2946 - jacard_coef: 0.0804 - val_loss: 1.1218 - val_accuracy: 0.9304 - val_jacard_coef: 1.4616e-12 - lr: 0.0010
Epoch 11/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1705 - accuracy: 0.8360 - jacard_coef: 0.04242/9 [=====>........................] - ETA: 2s - loss: 0.1692 - accuracy: 0.8665 - jacard_coef: 0.02263/9 [=========>....................] - ETA: 2s - loss: 0.1684 - accuracy: 0.8860 - jacard_coef: 0.01834/9 [============>.................] - ETA: 1s - loss: 0.1679 - accuracy: 0.8904 - jacard_coef: 0.01735/9 [===============>..............] - ETA: 1s - loss: 0.1709 - accuracy: 0.8965 - jacard_coef: 0.01926/9 [===================>..........] - ETA: 1s - loss: 0.1699 - accuracy: 0.8977 - jacard_coef: 0.01677/9 [======================>.......] - ETA: 0s - loss: 0.1694 - accuracy: 0.8989 - jacard_coef: 0.01448/9 [=========================>....] - ETA: 0s - loss: 0.1689 - accuracy: 0.8957 - jacard_coef: 0.01509/9 [==============================] - 3s 327ms/step - loss: 0.1690 - accuracy: 0.8905 - jacard_coef: 0.0142 - val_loss: 1.1211 - val_accuracy: 0.9300 - val_jacard_coef: 1.4529e-12 - lr: 5.0000e-04
Epoch 12/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1673 - accuracy: 0.8764 - jacard_coef: 0.01912/9 [=====>........................] - ETA: 2s - loss: 0.1729 - accuracy: 0.9013 - jacard_coef: 0.01933/9 [=========>....................] - ETA: 2s - loss: 0.1705 - accuracy: 0.9029 - jacard_coef: 0.02034/9 [============>.................] - ETA: 1s - loss: 0.1685 - accuracy: 0.9004 - jacard_coef: 0.02195/9 [===============>..............] - ETA: 1s - loss: 0.1672 - accuracy: 0.8952 - jacard_coef: 0.02016/9 [===================>..........] - ETA: 1s - loss: 0.1660 - accuracy: 0.8975 - jacard_coef: 0.01727/9 [======================>.......] - ETA: 0s - loss: 0.1657 - accuracy: 0.8929 - jacard_coef: 0.01738/9 [=========================>....] - ETA: 0s - loss: 0.1650 - accuracy: 0.8984 - jacard_coef: 0.01649/9 [==============================] - 3s 327ms/step - loss: 0.1650 - accuracy: 0.8962 - jacard_coef: 0.0146 - val_loss: 1.0575 - val_accuracy: 0.8506 - val_jacard_coef: 0.0207 - lr: 5.0000e-04
Epoch 13/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1602 - accuracy: 0.9129 - jacard_coef: 0.02392/9 [=====>........................] - ETA: 2s - loss: 0.1615 - accuracy: 0.8943 - jacard_coef: 0.01933/9 [=========>....................] - ETA: 2s - loss: 0.1618 - accuracy: 0.8980 - jacard_coef: 0.01534/9 [============>.................] - ETA: 1s - loss: 0.1645 - accuracy: 0.9000 - jacard_coef: 0.02245/9 [===============>..............] - ETA: 1s - loss: 0.1638 - accuracy: 0.9034 - jacard_coef: 0.02106/9 [===================>..........] - ETA: 1s - loss: 0.1641 - accuracy: 0.8988 - jacard_coef: 0.02117/9 [======================>.......] - ETA: 0s - loss: 0.1633 - accuracy: 0.9017 - jacard_coef: 0.01818/9 [=========================>....] - ETA: 0s - loss: 0.1625 - accuracy: 0.9048 - jacard_coef: 0.01649/9 [==============================] - 3s 327ms/step - loss: 0.1626 - accuracy: 0.9010 - jacard_coef: 0.0279 - val_loss: 0.4806 - val_accuracy: 0.8337 - val_jacard_coef: 0.0247 - lr: 5.0000e-04
Epoch 14/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1595 - accuracy: 0.8858 - jacard_coef: 8.3488e-132/9 [=====>........................] - ETA: 2s - loss: 0.1586 - accuracy: 0.9056 - jacard_coef: 0.0036    3/9 [=========>....................] - ETA: 2s - loss: 0.1588 - accuracy: 0.9045 - jacard_coef: 0.00354/9 [============>.................] - ETA: 1s - loss: 0.1585 - accuracy: 0.9095 - jacard_coef: 0.00275/9 [===============>..............] - ETA: 1s - loss: 0.1588 - accuracy: 0.9070 - jacard_coef: 0.00216/9 [===================>..........] - ETA: 1s - loss: 0.1591 - accuracy: 0.9099 - jacard_coef: 0.00247/9 [======================>.......] - ETA: 0s - loss: 0.1606 - accuracy: 0.9124 - jacard_coef: 0.00258/9 [=========================>....] - ETA: 0s - loss: 0.1605 - accuracy: 0.9134 - jacard_coef: 0.00239/9 [==============================] - 3s 326ms/step - loss: 0.1606 - accuracy: 0.9082 - jacard_coef: 0.0073 - val_loss: 0.1418 - val_accuracy: 0.8031 - val_jacard_coef: 0.0229 - lr: 5.0000e-04
Epoch 15/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1612 - accuracy: 0.9118 - jacard_coef: 1.0812e-122/9 [=====>........................] - ETA: 2s - loss: 0.1604 - accuracy: 0.9177 - jacard_coef: 6.7330e-043/9 [=========>....................] - ETA: 2s - loss: 0.1591 - accuracy: 0.9138 - jacard_coef: 4.6238e-044/9 [============>.................] - ETA: 1s - loss: 0.1610 - accuracy: 0.9165 - jacard_coef: 0.0020    5/9 [===============>..............] - ETA: 1s - loss: 0.1608 - accuracy: 0.9150 - jacard_coef: 0.00176/9 [===================>..........] - ETA: 1s - loss: 0.1604 - accuracy: 0.9113 - jacard_coef: 0.00197/9 [======================>.......] - ETA: 0s - loss: 0.1594 - accuracy: 0.9153 - jacard_coef: 0.00168/9 [=========================>....] - ETA: 0s - loss: 0.1589 - accuracy: 0.9153 - jacard_coef: 0.00199/9 [==============================] - 3s 326ms/step - loss: 0.1590 - accuracy: 0.9145 - jacard_coef: 0.0023 - val_loss: 0.1555 - val_accuracy: 0.6726 - val_jacard_coef: 0.0497 - lr: 5.0000e-04
/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(

âœ“ Training completed successfully!
  Best Val Jaccard: 0.0704 (epoch 5)
  Final Val Loss: 0.1555
  Training Time: 0:01:51.465932
  Stability (std): 0.3974

Results saved to: hyperparameter_optimization_20250926_165036/exp_17_Attention_UNet_lr5e-4_bs16/Attention_UNet_lr0.0005_bs16_results.json
