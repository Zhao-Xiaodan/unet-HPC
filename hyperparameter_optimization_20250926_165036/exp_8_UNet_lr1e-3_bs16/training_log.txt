âœ“ GPU memory growth enabled for 1 GPUs
Loading dataset...
Loaded 144 images and 144 masks
Training set: (129, 256, 256, 3), Validation set: (15, 256, 256, 3)

============================================================
TRAINING: UNet
Learning Rate: 0.001, Batch Size: 16, Epochs: 30
============================================================
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 256, 256, 64)         640       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 256, 256, 64)         256       ['conv2d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 activation (Activation)     (None, 256, 256, 64)         0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['activation[0][0]']          
                                                                                                  
 batch_normalization_1 (Bat  (None, 256, 256, 64)         256       ['conv2d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_1 (Activation)   (None, 256, 256, 64)         0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['activation_1[0][0]']        
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       
                                                                                                  
 batch_normalization_2 (Bat  (None, 128, 128, 128)        512       ['conv2d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_2 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_3 (Conv2D)           (None, 128, 128, 128)        147584    ['activation_2[0][0]']        
                                                                                                  
 batch_normalization_3 (Bat  (None, 128, 128, 128)        512       ['conv2d_3[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_3 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_3[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_3[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 batch_normalization_4 (Bat  (None, 64, 64, 256)          1024      ['conv2d_4[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_4 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_4[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_5 (Conv2D)           (None, 64, 64, 256)          590080    ['activation_4[0][0]']        
                                                                                                  
 batch_normalization_5 (Bat  (None, 64, 64, 256)          1024      ['conv2d_5[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_5 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_5[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_5[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 512)          1180160   ['max_pooling2d_2[0][0]']     
                                                                                                  
 batch_normalization_6 (Bat  (None, 32, 32, 512)          2048      ['conv2d_6[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_6 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_6[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 32, 32, 512)          2359808   ['activation_6[0][0]']        
                                                                                                  
 batch_normalization_7 (Bat  (None, 32, 32, 512)          2048      ['conv2d_7[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_7 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_7[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_3 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_7[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 1024)         4719616   ['max_pooling2d_3[0][0]']     
                                                                                                  
 batch_normalization_8 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_8[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_8 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_8[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 1024)         9438208   ['activation_8[0][0]']        
                                                                                                  
 batch_normalization_9 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_9[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_9 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_9[0][0]'
                                                                    ]                             
                                                                                                  
 up_sampling2d (UpSampling2  (None, 32, 32, 1024)         0         ['activation_9[0][0]']        
 D)                                                                                               
                                                                                                  
 concatenate (Concatenate)   (None, 32, 32, 1536)         0         ['up_sampling2d[0][0]',       
                                                                     'activation_7[0][0]']        
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate[0][0]']         
                                                                                                  
 batch_normalization_10 (Ba  (None, 32, 32, 512)          2048      ['conv2d_10[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_10 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_10[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_10[0][0]']       
                                                                                                  
 batch_normalization_11 (Ba  (None, 32, 32, 512)          2048      ['conv2d_11[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_11 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_11[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 64, 64, 512)          0         ['activation_11[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_1 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_1[0][0]',     
 )                                                                   'activation_5[0][0]']        
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_1[0][0]']       
                                                                                                  
 batch_normalization_12 (Ba  (None, 64, 64, 256)          1024      ['conv2d_12[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_12 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_12[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_13 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_12[0][0]']       
                                                                                                  
 batch_normalization_13 (Ba  (None, 64, 64, 256)          1024      ['conv2d_13[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_13 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_13[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 128, 128, 256)        0         ['activation_13[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_2 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_2[0][0]',     
 )                                                                   'activation_3[0][0]']        
                                                                                                  
 conv2d_14 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_2[0][0]']       
                                                                                                  
 batch_normalization_14 (Ba  (None, 128, 128, 128)        512       ['conv2d_14[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_14 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_14[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_15 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_14[0][0]']       
                                                                                                  
 batch_normalization_15 (Ba  (None, 128, 128, 128)        512       ['conv2d_15[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_15 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_15[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 256, 256, 128)        0         ['activation_15[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_3 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_3[0][0]',     
 )                                                                   'activation_1[0][0]']        
                                                                                                  
 conv2d_16 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_3[0][0]']       
                                                                                                  
 batch_normalization_16 (Ba  (None, 256, 256, 64)         256       ['conv2d_16[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_16 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_16[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_16[0][0]']       
                                                                                                  
 batch_normalization_17 (Ba  (None, 256, 256, 64)         256       ['conv2d_17[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_17 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_17[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_18 (Conv2D)          (None, 256, 256, 1)          65        ['activation_17[0][0]']       
                                                                                                  
 batch_normalization_18 (Ba  (None, 256, 256, 1)          4         ['conv2d_18[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_18 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_18[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31401349 (119.79 MB)
Trainable params: 31389571 (119.74 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
None
âœ“ focal_loss imported successfully
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_2 (InputLayer)        [(None, 256, 256, 3)]        0         []                            
                                                                                                  
 conv2d_19 (Conv2D)          (None, 256, 256, 64)         1792      ['input_2[0][0]']             
                                                                                                  
 batch_normalization_19 (Ba  (None, 256, 256, 64)         256       ['conv2d_19[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_19 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_19[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_20 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_19[0][0]']       
                                                                                                  
 batch_normalization_20 (Ba  (None, 256, 256, 64)         256       ['conv2d_20[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_20 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_20[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_4 (MaxPoolin  (None, 128, 128, 64)         0         ['activation_20[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_21 (Conv2D)          (None, 128, 128, 128)        73856     ['max_pooling2d_4[0][0]']     
                                                                                                  
 batch_normalization_21 (Ba  (None, 128, 128, 128)        512       ['conv2d_21[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_21 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_21[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_22 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_21[0][0]']       
                                                                                                  
 batch_normalization_22 (Ba  (None, 128, 128, 128)        512       ['conv2d_22[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_22 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_22[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_5 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_22[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_23 (Conv2D)          (None, 64, 64, 256)          295168    ['max_pooling2d_5[0][0]']     
                                                                                                  
 batch_normalization_23 (Ba  (None, 64, 64, 256)          1024      ['conv2d_23[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_23 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_23[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_24 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_23[0][0]']       
                                                                                                  
 batch_normalization_24 (Ba  (None, 64, 64, 256)          1024      ['conv2d_24[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_24 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_24[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_6 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_24[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_25 (Conv2D)          (None, 32, 32, 512)          1180160   ['max_pooling2d_6[0][0]']     
                                                                                                  
 batch_normalization_25 (Ba  (None, 32, 32, 512)          2048      ['conv2d_25[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_25 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_25[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_26 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_25[0][0]']       
                                                                                                  
 batch_normalization_26 (Ba  (None, 32, 32, 512)          2048      ['conv2d_26[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_26 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_26[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_7 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_26[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_27 (Conv2D)          (None, 16, 16, 1024)         4719616   ['max_pooling2d_7[0][0]']     
                                                                                                  
 batch_normalization_27 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_27[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_27 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_27[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_28 (Conv2D)          (None, 16, 16, 1024)         9438208   ['activation_27[0][0]']       
                                                                                                  
 batch_normalization_28 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_28[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_28 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_28[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 1024)         0         ['activation_28[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_4 (Concatenate  (None, 32, 32, 1536)         0         ['up_sampling2d_4[0][0]',     
 )                                                                   'activation_26[0][0]']       
                                                                                                  
 conv2d_29 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate_4[0][0]']       
                                                                                                  
 batch_normalization_29 (Ba  (None, 32, 32, 512)          2048      ['conv2d_29[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_29 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_29[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_30 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_29[0][0]']       
                                                                                                  
 batch_normalization_30 (Ba  (None, 32, 32, 512)          2048      ['conv2d_30[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_30 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_30[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 512)          0         ['activation_30[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_5 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_5[0][0]',     
 )                                                                   'activation_24[0][0]']       
                                                                                                  
 conv2d_31 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_5[0][0]']       
                                                                                                  
 batch_normalization_31 (Ba  (None, 64, 64, 256)          1024      ['conv2d_31[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_31 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_31[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_32 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_31[0][0]']       
                                                                                                  
 batch_normalization_32 (Ba  (None, 64, 64, 256)          1024      ['conv2d_32[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_32 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_32[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_6 (UpSamplin  (None, 128, 128, 256)        0         ['activation_32[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_6 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_6[0][0]',     
 )                                                                   'activation_22[0][0]']       
                                                                                                  
 conv2d_33 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_6[0][0]']       
                                                                                                  
 batch_normalization_33 (Ba  (None, 128, 128, 128)        512       ['conv2d_33[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_33 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_33[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_34 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_33[0][0]']       
                                                                                                  
 batch_normalization_34 (Ba  (None, 128, 128, 128)        512       ['conv2d_34[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_34 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_34[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_7 (UpSamplin  (None, 256, 256, 128)        0         ['activation_34[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_7 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_7[0][0]',     
 )                                                                   'activation_20[0][0]']       
                                                                                                  
 conv2d_35 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_7[0][0]']       
                                                                                                  
 batch_normalization_35 (Ba  (None, 256, 256, 64)         256       ['conv2d_35[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_35 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_35[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_36 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_35[0][0]']       
                                                                                                  
 batch_normalization_36 (Ba  (None, 256, 256, 64)         256       ['conv2d_36[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_36 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_36[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_37 (Conv2D)          (None, 256, 256, 1)          65        ['activation_36[0][0]']       
                                                                                                  
 batch_normalization_37 (Ba  (None, 256, 256, 1)          4         ['conv2d_37[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_37 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_37[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31402501 (119.79 MB)
Trainable params: 31390723 (119.75 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
WARNING:absl:`lr` is deprecated in TF-Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
None
Epoch 1/30
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1758877448.074332 1051952 service.cc:145] XLA service 0x15496db9ab70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1758877448.074361 1051952 service.cc:153]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6
I0000 00:00:1758877448.210771 1051952 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
1/9 [==>...........................] - ETA: 4:49 - loss: 0.3448 - accuracy: 0.5123 - jacard_coef: 0.07582/9 [=====>........................] - ETA: 50s - loss: 0.3120 - accuracy: 0.4809 - jacard_coef: 0.0788 3/9 [=========>....................] - ETA: 28s - loss: 0.2888 - accuracy: 0.4550 - jacard_coef: 0.08064/9 [============>.................] - ETA: 19s - loss: 0.2729 - accuracy: 0.4562 - jacard_coef: 0.08235/9 [===============>..............] - ETA: 12s - loss: 0.2623 - accuracy: 0.4908 - jacard_coef: 0.08236/9 [===================>..........] - ETA: 7s - loss: 0.2544 - accuracy: 0.5310 - jacard_coef: 0.0779 7/9 [======================>.......] - ETA: 4s - loss: 0.2484 - accuracy: 0.5673 - jacard_coef: 0.07528/9 [=========================>....] - ETA: 1s - loss: 0.2432 - accuracy: 0.5968 - jacard_coef: 0.07109/9 [==============================] - ETA: 0s - loss: 0.2429 - accuracy: 0.5982 - jacard_coef: 0.07669/9 [==============================] - 56s 2s/step - loss: 0.2429 - accuracy: 0.5982 - jacard_coef: 0.0766 - val_loss: 3.0357 - val_accuracy: 0.1218 - val_jacard_coef: 0.0715 - lr: 0.0010
Epoch 2/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1995 - accuracy: 0.7973 - jacard_coef: 0.03272/9 [=====>........................] - ETA: 1s - loss: 0.1972 - accuracy: 0.7971 - jacard_coef: 0.04093/9 [=========>....................] - ETA: 1s - loss: 0.1944 - accuracy: 0.8054 - jacard_coef: 0.04674/9 [============>.................] - ETA: 1s - loss: 0.1928 - accuracy: 0.8191 - jacard_coef: 0.04265/9 [===============>..............] - ETA: 0s - loss: 0.1908 - accuracy: 0.8095 - jacard_coef: 0.04616/9 [===================>..........] - ETA: 0s - loss: 0.1886 - accuracy: 0.7961 - jacard_coef: 0.04977/9 [======================>.......] - ETA: 0s - loss: 0.1863 - accuracy: 0.7814 - jacard_coef: 0.05118/9 [=========================>....] - ETA: 0s - loss: 0.1845 - accuracy: 0.7744 - jacard_coef: 0.05349/9 [==============================] - 2s 229ms/step - loss: 0.1850 - accuracy: 0.7741 - jacard_coef: 0.0551 - val_loss: 1.9189 - val_accuracy: 0.8793 - val_jacard_coef: 0.0338 - lr: 0.0010
Epoch 3/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1917 - accuracy: 0.8119 - jacard_coef: 0.05052/9 [=====>........................] - ETA: 1s - loss: 0.1866 - accuracy: 0.7301 - jacard_coef: 0.05133/9 [=========>....................] - ETA: 1s - loss: 0.1857 - accuracy: 0.6798 - jacard_coef: 0.06084/9 [============>.................] - ETA: 1s - loss: 0.1834 - accuracy: 0.6522 - jacard_coef: 0.06725/9 [===============>..............] - ETA: 0s - loss: 0.1818 - accuracy: 0.6487 - jacard_coef: 0.06826/9 [===================>..........] - ETA: 0s - loss: 0.1807 - accuracy: 0.6639 - jacard_coef: 0.06837/9 [======================>.......] - ETA: 0s - loss: 0.1798 - accuracy: 0.6838 - jacard_coef: 0.06548/9 [=========================>....] - ETA: 0s - loss: 0.1796 - accuracy: 0.7049 - jacard_coef: 0.06139/9 [==============================] - 2s 229ms/step - loss: 0.1796 - accuracy: 0.7049 - jacard_coef: 0.0556 - val_loss: 14.9366 - val_accuracy: 0.0732 - val_jacard_coef: 0.0696 - lr: 0.0010
Epoch 4/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1748 - accuracy: 0.8449 - jacard_coef: 0.04322/9 [=====>........................] - ETA: 1s - loss: 0.1754 - accuracy: 0.8287 - jacard_coef: 0.05513/9 [=========>....................] - ETA: 1s - loss: 0.1757 - accuracy: 0.7932 - jacard_coef: 0.05414/9 [============>.................] - ETA: 1s - loss: 0.1751 - accuracy: 0.7588 - jacard_coef: 0.05455/9 [===============>..............] - ETA: 0s - loss: 0.1747 - accuracy: 0.7566 - jacard_coef: 0.05666/9 [===================>..........] - ETA: 0s - loss: 0.1743 - accuracy: 0.7713 - jacard_coef: 0.05487/9 [======================>.......] - ETA: 0s - loss: 0.1737 - accuracy: 0.7781 - jacard_coef: 0.05488/9 [=========================>....] - ETA: 0s - loss: 0.1730 - accuracy: 0.7706 - jacard_coef: 0.05599/9 [==============================] - 2s 229ms/step - loss: 0.1730 - accuracy: 0.7709 - jacard_coef: 0.0560 - val_loss: 14.9402 - val_accuracy: 0.0731 - val_jacard_coef: 0.0696 - lr: 0.0010
Epoch 5/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1671 - accuracy: 0.7007 - jacard_coef: 0.06222/9 [=====>........................] - ETA: 1s - loss: 0.1667 - accuracy: 0.7117 - jacard_coef: 0.07093/9 [=========>....................] - ETA: 1s - loss: 0.1661 - accuracy: 0.7543 - jacard_coef: 0.06144/9 [============>.................] - ETA: 1s - loss: 0.1656 - accuracy: 0.7444 - jacard_coef: 0.06695/9 [===============>..............] - ETA: 0s - loss: 0.1656 - accuracy: 0.7669 - jacard_coef: 0.06246/9 [===================>..........] - ETA: 0s - loss: 0.1654 - accuracy: 0.7794 - jacard_coef: 0.06367/9 [======================>.......] - ETA: 0s - loss: 0.1654 - accuracy: 0.7895 - jacard_coef: 0.06148/9 [=========================>....] - ETA: 0s - loss: 0.1653 - accuracy: 0.7966 - jacard_coef: 0.06189/9 [==============================] - 2s 229ms/step - loss: 0.1665 - accuracy: 0.7947 - jacard_coef: 0.0550 - val_loss: 14.8118 - val_accuracy: 0.0799 - val_jacard_coef: 0.0697 - lr: 0.0010
Epoch 6/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1647 - accuracy: 0.6743 - jacard_coef: 0.07982/9 [=====>........................] - ETA: 1s - loss: 0.1681 - accuracy: 0.6539 - jacard_coef: 0.07813/9 [=========>....................] - ETA: 1s - loss: 0.1689 - accuracy: 0.6512 - jacard_coef: 0.07694/9 [============>.................] - ETA: 1s - loss: 0.1696 - accuracy: 0.6426 - jacard_coef: 0.07625/9 [===============>..............] - ETA: 0s - loss: 0.1695 - accuracy: 0.6451 - jacard_coef: 0.07126/9 [===================>..........] - ETA: 0s - loss: 0.1694 - accuracy: 0.6643 - jacard_coef: 0.06927/9 [======================>.......] - ETA: 0s - loss: 0.1690 - accuracy: 0.6781 - jacard_coef: 0.07068/9 [=========================>....] - ETA: 0s - loss: 0.1689 - accuracy: 0.6867 - jacard_coef: 0.06999/9 [==============================] - 2s 229ms/step - loss: 0.1689 - accuracy: 0.6876 - jacard_coef: 0.0914 - val_loss: 13.3378 - val_accuracy: 0.0757 - val_jacard_coef: 0.0697 - lr: 0.0010
Epoch 7/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1646 - accuracy: 0.6323 - jacard_coef: 0.10612/9 [=====>........................] - ETA: 1s - loss: 0.1660 - accuracy: 0.6306 - jacard_coef: 0.09463/9 [=========>....................] - ETA: 1s - loss: 0.1663 - accuracy: 0.6242 - jacard_coef: 0.08604/9 [============>.................] - ETA: 1s - loss: 0.1670 - accuracy: 0.6124 - jacard_coef: 0.07805/9 [===============>..............] - ETA: 0s - loss: 0.1663 - accuracy: 0.6135 - jacard_coef: 0.08106/9 [===================>..........] - ETA: 0s - loss: 0.1657 - accuracy: 0.6239 - jacard_coef: 0.08617/9 [======================>.......] - ETA: 0s - loss: 0.1654 - accuracy: 0.6395 - jacard_coef: 0.08318/9 [=========================>....] - ETA: 0s - loss: 0.1653 - accuracy: 0.6625 - jacard_coef: 0.07859/9 [==============================] - 2s 235ms/step - loss: 0.1658 - accuracy: 0.6616 - jacard_coef: 0.0856 - val_loss: 0.8949 - val_accuracy: 0.2750 - val_jacard_coef: 0.0735 - lr: 5.0000e-04
Epoch 8/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1666 - accuracy: 0.8787 - jacard_coef: 0.01502/9 [=====>........................] - ETA: 1s - loss: 0.1662 - accuracy: 0.9089 - jacard_coef: 0.00853/9 [=========>....................] - ETA: 1s - loss: 0.1676 - accuracy: 0.9041 - jacard_coef: 0.00704/9 [============>.................] - ETA: 1s - loss: 0.1671 - accuracy: 0.9102 - jacard_coef: 0.00675/9 [===============>..............] - ETA: 0s - loss: 0.1676 - accuracy: 0.9106 - jacard_coef: 0.00716/9 [===================>..........] - ETA: 0s - loss: 0.1681 - accuracy: 0.9143 - jacard_coef: 0.00727/9 [======================>.......] - ETA: 0s - loss: 0.1687 - accuracy: 0.9126 - jacard_coef: 0.00708/9 [=========================>....] - ETA: 0s - loss: 0.1692 - accuracy: 0.9099 - jacard_coef: 0.00729/9 [==============================] - 2s 229ms/step - loss: 0.1693 - accuracy: 0.9099 - jacard_coef: 0.0097 - val_loss: 0.2894 - val_accuracy: 0.8884 - val_jacard_coef: 0.0215 - lr: 5.0000e-04
Epoch 9/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1694 - accuracy: 0.9089 - jacard_coef: 0.00892/9 [=====>........................] - ETA: 1s - loss: 0.1712 - accuracy: 0.9027 - jacard_coef: 0.00873/9 [=========>....................] - ETA: 1s - loss: 0.1714 - accuracy: 0.9131 - jacard_coef: 0.00844/9 [============>.................] - ETA: 1s - loss: 0.1715 - accuracy: 0.9074 - jacard_coef: 0.01005/9 [===============>..............] - ETA: 0s - loss: 0.1719 - accuracy: 0.9044 - jacard_coef: 0.01016/9 [===================>..........] - ETA: 0s - loss: 0.1721 - accuracy: 0.9026 - jacard_coef: 0.00997/9 [======================>.......] - ETA: 0s - loss: 0.1716 - accuracy: 0.9044 - jacard_coef: 0.01028/9 [=========================>....] - ETA: 0s - loss: 0.1713 - accuracy: 0.9044 - jacard_coef: 0.01119/9 [==============================] - 2s 229ms/step - loss: 0.1713 - accuracy: 0.9048 - jacard_coef: 0.0108 - val_loss: 0.2260 - val_accuracy: 0.8912 - val_jacard_coef: 0.0238 - lr: 5.0000e-04
Epoch 10/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1682 - accuracy: 0.9125 - jacard_coef: 0.00882/9 [=====>........................] - ETA: 1s - loss: 0.1673 - accuracy: 0.9129 - jacard_coef: 0.01103/9 [=========>....................] - ETA: 1s - loss: 0.1686 - accuracy: 0.9087 - jacard_coef: 0.01004/9 [============>.................] - ETA: 1s - loss: 0.1685 - accuracy: 0.9104 - jacard_coef: 0.01005/9 [===============>..............] - ETA: 0s - loss: 0.1680 - accuracy: 0.9047 - jacard_coef: 0.01056/9 [===================>..........] - ETA: 0s - loss: 0.1675 - accuracy: 0.9044 - jacard_coef: 0.01147/9 [======================>.......] - ETA: 0s - loss: 0.1675 - accuracy: 0.9020 - jacard_coef: 0.01118/9 [=========================>....] - ETA: 0s - loss: 0.1673 - accuracy: 0.9043 - jacard_coef: 0.01029/9 [==============================] - 2s 229ms/step - loss: 0.1674 - accuracy: 0.9049 - jacard_coef: 0.0090 - val_loss: 0.1976 - val_accuracy: 0.9058 - val_jacard_coef: 0.0171 - lr: 5.0000e-04
Epoch 11/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1638 - accuracy: 0.8948 - jacard_coef: 0.00712/9 [=====>........................] - ETA: 1s - loss: 0.1648 - accuracy: 0.9027 - jacard_coef: 0.00703/9 [=========>....................] - ETA: 1s - loss: 0.1646 - accuracy: 0.9033 - jacard_coef: 0.00654/9 [============>.................] - ETA: 1s - loss: 0.1646 - accuracy: 0.9039 - jacard_coef: 0.00675/9 [===============>..............] - ETA: 0s - loss: 0.1643 - accuracy: 0.9057 - jacard_coef: 0.00676/9 [===================>..........] - ETA: 0s - loss: 0.1641 - accuracy: 0.9079 - jacard_coef: 0.00657/9 [======================>.......] - ETA: 0s - loss: 0.1638 - accuracy: 0.9106 - jacard_coef: 0.00658/9 [=========================>....] - ETA: 0s - loss: 0.1634 - accuracy: 0.9110 - jacard_coef: 0.00639/9 [==============================] - 2s 229ms/step - loss: 0.1635 - accuracy: 0.9106 - jacard_coef: 0.0068 - val_loss: 0.1677 - val_accuracy: 0.9232 - val_jacard_coef: 0.0058 - lr: 5.0000e-04
Epoch 12/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1588 - accuracy: 0.9502 - jacard_coef: 0.00532/9 [=====>........................] - ETA: 1s - loss: 0.1597 - accuracy: 0.9433 - jacard_coef: 0.00343/9 [=========>....................] - ETA: 1s - loss: 0.1606 - accuracy: 0.9349 - jacard_coef: 0.00364/9 [============>.................] - ETA: 1s - loss: 0.1607 - accuracy: 0.9242 - jacard_coef: 0.00365/9 [===============>..............] - ETA: 0s - loss: 0.1615 - accuracy: 0.9176 - jacard_coef: 0.00376/9 [===================>..........] - ETA: 0s - loss: 0.1610 - accuracy: 0.9180 - jacard_coef: 0.00387/9 [======================>.......] - ETA: 0s - loss: 0.1610 - accuracy: 0.9130 - jacard_coef: 0.00388/9 [=========================>....] - ETA: 0s - loss: 0.1609 - accuracy: 0.9126 - jacard_coef: 0.00409/9 [==============================] - 2s 229ms/step - loss: 0.1609 - accuracy: 0.9129 - jacard_coef: 0.0057 - val_loss: 0.1533 - val_accuracy: 0.9269 - val_jacard_coef: 0.0029 - lr: 5.0000e-04
Epoch 13/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1615 - accuracy: 0.8923 - jacard_coef: 0.00332/9 [=====>........................] - ETA: 1s - loss: 0.1610 - accuracy: 0.8941 - jacard_coef: 0.00483/9 [=========>....................] - ETA: 1s - loss: 0.1606 - accuracy: 0.8948 - jacard_coef: 0.00534/9 [============>.................] - ETA: 1s - loss: 0.1600 - accuracy: 0.8967 - jacard_coef: 0.00605/9 [===============>..............] - ETA: 0s - loss: 0.1599 - accuracy: 0.9055 - jacard_coef: 0.00586/9 [===================>..........] - ETA: 0s - loss: 0.1599 - accuracy: 0.9048 - jacard_coef: 0.00567/9 [======================>.......] - ETA: 0s - loss: 0.1594 - accuracy: 0.9096 - jacard_coef: 0.00568/9 [=========================>....] - ETA: 0s - loss: 0.1591 - accuracy: 0.9113 - jacard_coef: 0.00599/9 [==============================] - 2s 229ms/step - loss: 0.1591 - accuracy: 0.9116 - jacard_coef: 0.0086 - val_loss: 0.1513 - val_accuracy: 0.9270 - val_jacard_coef: 0.0029 - lr: 2.5000e-04
Epoch 14/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1566 - accuracy: 0.9052 - jacard_coef: 0.00722/9 [=====>........................] - ETA: 1s - loss: 0.1566 - accuracy: 0.9170 - jacard_coef: 0.00693/9 [=========>....................] - ETA: 1s - loss: 0.1566 - accuracy: 0.9130 - jacard_coef: 0.00634/9 [============>.................] - ETA: 1s - loss: 0.1573 - accuracy: 0.9088 - jacard_coef: 0.00585/9 [===============>..............] - ETA: 0s - loss: 0.1572 - accuracy: 0.9119 - jacard_coef: 0.00566/9 [===================>..........] - ETA: 0s - loss: 0.1576 - accuracy: 0.9099 - jacard_coef: 0.00527/9 [======================>.......] - ETA: 0s - loss: 0.1576 - accuracy: 0.9112 - jacard_coef: 0.00498/9 [=========================>....] - ETA: 0s - loss: 0.1574 - accuracy: 0.9118 - jacard_coef: 0.00499/9 [==============================] - 2s 229ms/step - loss: 0.1580 - accuracy: 0.9101 - jacard_coef: 0.0045 - val_loss: 0.1477 - val_accuracy: 0.9270 - val_jacard_coef: 0.0029 - lr: 2.5000e-04
Epoch 15/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1569 - accuracy: 0.9144 - jacard_coef: 0.00132/9 [=====>........................] - ETA: 1s - loss: 0.1570 - accuracy: 0.9111 - jacard_coef: 0.00243/9 [=========>....................] - ETA: 1s - loss: 0.1572 - accuracy: 0.9038 - jacard_coef: 0.00264/9 [============>.................] - ETA: 1s - loss: 0.1580 - accuracy: 0.9055 - jacard_coef: 0.00285/9 [===============>..............] - ETA: 0s - loss: 0.1582 - accuracy: 0.9100 - jacard_coef: 0.00326/9 [===================>..........] - ETA: 0s - loss: 0.1580 - accuracy: 0.9085 - jacard_coef: 0.00457/9 [======================>.......] - ETA: 0s - loss: 0.1579 - accuracy: 0.9124 - jacard_coef: 0.00428/9 [=========================>....] - ETA: 0s - loss: 0.1578 - accuracy: 0.9142 - jacard_coef: 0.00459/9 [==============================] - 2s 229ms/step - loss: 0.1580 - accuracy: 0.9130 - jacard_coef: 0.0149 - val_loss: 0.1372 - val_accuracy: 0.9272 - val_jacard_coef: 0.0027 - lr: 2.5000e-04
Epoch 16/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1581 - accuracy: 0.9171 - jacard_coef: 0.00332/9 [=====>........................] - ETA: 1s - loss: 0.1589 - accuracy: 0.9112 - jacard_coef: 0.00753/9 [=========>....................] - ETA: 1s - loss: 0.1584 - accuracy: 0.9144 - jacard_coef: 0.00844/9 [============>.................] - ETA: 1s - loss: 0.1589 - accuracy: 0.9093 - jacard_coef: 0.00865/9 [===============>..............] - ETA: 0s - loss: 0.1587 - accuracy: 0.9077 - jacard_coef: 0.00776/9 [===================>..........] - ETA: 0s - loss: 0.1584 - accuracy: 0.9072 - jacard_coef: 0.00677/9 [======================>.......] - ETA: 0s - loss: 0.1579 - accuracy: 0.9116 - jacard_coef: 0.00648/9 [=========================>....] - ETA: 0s - loss: 0.1579 - accuracy: 0.9119 - jacard_coef: 0.00609/9 [==============================] - 2s 229ms/step - loss: 0.1581 - accuracy: 0.9122 - jacard_coef: 0.0053 - val_loss: 0.1349 - val_accuracy: 0.9279 - val_jacard_coef: 0.0017 - lr: 2.5000e-04
Epoch 17/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1580 - accuracy: 0.9043 - jacard_coef: 0.00162/9 [=====>........................] - ETA: 1s - loss: 0.1560 - accuracy: 0.9164 - jacard_coef: 0.00213/9 [=========>....................] - ETA: 1s - loss: 0.1559 - accuracy: 0.9208 - jacard_coef: 0.00204/9 [============>.................] - ETA: 1s - loss: 0.1559 - accuracy: 0.9172 - jacard_coef: 0.00205/9 [===============>..............] - ETA: 0s - loss: 0.1559 - accuracy: 0.9151 - jacard_coef: 0.00216/9 [===================>..........] - ETA: 0s - loss: 0.1555 - accuracy: 0.9175 - jacard_coef: 0.00217/9 [======================>.......] - ETA: 0s - loss: 0.1552 - accuracy: 0.9188 - jacard_coef: 0.00238/9 [=========================>....] - ETA: 0s - loss: 0.1555 - accuracy: 0.9140 - jacard_coef: 0.00239/9 [==============================] - 2s 230ms/step - loss: 0.1556 - accuracy: 0.9143 - jacard_coef: 0.0028 - val_loss: 0.1360 - val_accuracy: 0.9303 - val_jacard_coef: 1.4596e-12 - lr: 2.5000e-04
/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(

âœ“ Training completed successfully!
  Best Val Jaccard: 0.0735 (epoch 7)
  Final Val Loss: 0.1360
  Training Time: 0:01:29.553995
  Stability (std): 0.0475

Results saved to: hyperparameter_optimization_20250926_165036/exp_8_UNet_lr1e-3_bs16/UNet_lr0.001_bs16_results.json
