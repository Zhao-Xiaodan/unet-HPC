✓ GPU memory growth enabled for 1 GPUs
Loading dataset...
Loaded 144 images and 144 masks
Training set: (129, 256, 256, 3), Validation set: (15, 256, 256, 3)

============================================================
TRAINING: Attention_ResUNet
Learning Rate: 0.005, Batch Size: 16, Epochs: 30
============================================================
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 256, 256, 64)         640       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 256, 256, 64)         256       ['conv2d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 activation (Activation)     (None, 256, 256, 64)         0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['activation[0][0]']          
                                                                                                  
 batch_normalization_1 (Bat  (None, 256, 256, 64)         256       ['conv2d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_1 (Activation)   (None, 256, 256, 64)         0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['activation_1[0][0]']        
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       
                                                                                                  
 batch_normalization_2 (Bat  (None, 128, 128, 128)        512       ['conv2d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_2 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_3 (Conv2D)           (None, 128, 128, 128)        147584    ['activation_2[0][0]']        
                                                                                                  
 batch_normalization_3 (Bat  (None, 128, 128, 128)        512       ['conv2d_3[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_3 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_3[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_3[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 batch_normalization_4 (Bat  (None, 64, 64, 256)          1024      ['conv2d_4[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_4 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_4[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_5 (Conv2D)           (None, 64, 64, 256)          590080    ['activation_4[0][0]']        
                                                                                                  
 batch_normalization_5 (Bat  (None, 64, 64, 256)          1024      ['conv2d_5[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_5 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_5[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_5[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 512)          1180160   ['max_pooling2d_2[0][0]']     
                                                                                                  
 batch_normalization_6 (Bat  (None, 32, 32, 512)          2048      ['conv2d_6[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_6 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_6[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 32, 32, 512)          2359808   ['activation_6[0][0]']        
                                                                                                  
 batch_normalization_7 (Bat  (None, 32, 32, 512)          2048      ['conv2d_7[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_7 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_7[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_3 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_7[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 1024)         4719616   ['max_pooling2d_3[0][0]']     
                                                                                                  
 batch_normalization_8 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_8[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_8 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_8[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 1024)         9438208   ['activation_8[0][0]']        
                                                                                                  
 batch_normalization_9 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_9[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_9 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_9[0][0]'
                                                                    ]                             
                                                                                                  
 up_sampling2d (UpSampling2  (None, 32, 32, 1024)         0         ['activation_9[0][0]']        
 D)                                                                                               
                                                                                                  
 concatenate (Concatenate)   (None, 32, 32, 1536)         0         ['up_sampling2d[0][0]',       
                                                                     'activation_7[0][0]']        
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate[0][0]']         
                                                                                                  
 batch_normalization_10 (Ba  (None, 32, 32, 512)          2048      ['conv2d_10[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_10 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_10[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_10[0][0]']       
                                                                                                  
 batch_normalization_11 (Ba  (None, 32, 32, 512)          2048      ['conv2d_11[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_11 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_11[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 64, 64, 512)          0         ['activation_11[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_1 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_1[0][0]',     
 )                                                                   'activation_5[0][0]']        
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_1[0][0]']       
                                                                                                  
 batch_normalization_12 (Ba  (None, 64, 64, 256)          1024      ['conv2d_12[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_12 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_12[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_13 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_12[0][0]']       
                                                                                                  
 batch_normalization_13 (Ba  (None, 64, 64, 256)          1024      ['conv2d_13[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_13 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_13[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 128, 128, 256)        0         ['activation_13[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_2 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_2[0][0]',     
 )                                                                   'activation_3[0][0]']        
                                                                                                  
 conv2d_14 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_2[0][0]']       
                                                                                                  
 batch_normalization_14 (Ba  (None, 128, 128, 128)        512       ['conv2d_14[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_14 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_14[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_15 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_14[0][0]']       
                                                                                                  
 batch_normalization_15 (Ba  (None, 128, 128, 128)        512       ['conv2d_15[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_15 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_15[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 256, 256, 128)        0         ['activation_15[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_3 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_3[0][0]',     
 )                                                                   'activation_1[0][0]']        
                                                                                                  
 conv2d_16 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_3[0][0]']       
                                                                                                  
 batch_normalization_16 (Ba  (None, 256, 256, 64)         256       ['conv2d_16[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_16 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_16[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_16[0][0]']       
                                                                                                  
 batch_normalization_17 (Ba  (None, 256, 256, 64)         256       ['conv2d_17[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_17 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_17[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_18 (Conv2D)          (None, 256, 256, 1)          65        ['activation_17[0][0]']       
                                                                                                  
 batch_normalization_18 (Ba  (None, 256, 256, 1)          4         ['conv2d_18[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_18 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_18[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31401349 (119.79 MB)
Trainable params: 31389571 (119.74 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
WARNING:absl:`lr` is deprecated in TF-Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
None
✓ focal_loss imported successfully
Epoch 1/30
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1758881214.787462 1228086 service.cc:145] XLA service 0x149c3957f9d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1758881214.787482 1228086 service.cc:153]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6
I0000 00:00:1758881214.924131 1228086 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
1/9 [==>...........................] - ETA: 7:44 - loss: 0.3403 - accuracy: 0.5023 - jacard_coef: 0.08942/9 [=====>........................] - ETA: 56s - loss: 0.3036 - accuracy: 0.4126 - jacard_coef: 0.0864 3/9 [=========>....................] - ETA: 25s - loss: 0.2773 - accuracy: 0.3271 - jacard_coef: 0.07994/9 [============>.................] - ETA: 14s - loss: 0.2614 - accuracy: 0.2994 - jacard_coef: 0.07675/9 [===============>..............] - ETA: 9s - loss: 0.2487 - accuracy: 0.3235 - jacard_coef: 0.0825 6/9 [===================>..........] - ETA: 5s - loss: 0.2392 - accuracy: 0.3003 - jacard_coef: 0.08267/9 [======================>.......] - ETA: 3s - loss: 0.2320 - accuracy: 0.2847 - jacard_coef: 0.08138/9 [=========================>....] - ETA: 1s - loss: 0.2264 - accuracy: 0.2776 - jacard_coef: 0.08309/9 [==============================] - ETA: 0s - loss: 0.2261 - accuracy: 0.2770 - jacard_coef: 0.07779/9 [==============================] - 78s 2s/step - loss: 0.2261 - accuracy: 0.2770 - jacard_coef: 0.0777 - val_loss: 1.1218 - val_accuracy: 0.9304 - val_jacard_coef: 1.4616e-12 - lr: 0.0010
Epoch 2/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1847 - accuracy: 0.2358 - jacard_coef: 0.10782/9 [=====>........................] - ETA: 2s - loss: 0.1848 - accuracy: 0.2310 - jacard_coef: 0.10433/9 [=========>....................] - ETA: 2s - loss: 0.1834 - accuracy: 0.2440 - jacard_coef: 0.09364/9 [============>.................] - ETA: 2s - loss: 0.1854 - accuracy: 0.2695 - jacard_coef: 0.09205/9 [===============>..............] - ETA: 1s - loss: 0.1855 - accuracy: 0.2759 - jacard_coef: 0.08916/9 [===================>..........] - ETA: 1s - loss: 0.1858 - accuracy: 0.2782 - jacard_coef: 0.08437/9 [======================>.......] - ETA: 0s - loss: 0.1860 - accuracy: 0.2875 - jacard_coef: 0.08108/9 [=========================>....] - ETA: 0s - loss: 0.1857 - accuracy: 0.3038 - jacard_coef: 0.08129/9 [==============================] - 3s 381ms/step - loss: 0.1856 - accuracy: 0.3048 - jacard_coef: 0.0773 - val_loss: 14.9378 - val_accuracy: 0.0730 - val_jacard_coef: 0.0696 - lr: 0.0010
Epoch 3/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1807 - accuracy: 0.5746 - jacard_coef: 0.08852/9 [=====>........................] - ETA: 2s - loss: 0.1782 - accuracy: 0.5730 - jacard_coef: 0.08723/9 [=========>....................] - ETA: 2s - loss: 0.1777 - accuracy: 0.5067 - jacard_coef: 0.08304/9 [============>.................] - ETA: 2s - loss: 0.1774 - accuracy: 0.4635 - jacard_coef: 0.08455/9 [===============>..............] - ETA: 1s - loss: 0.1772 - accuracy: 0.4468 - jacard_coef: 0.08776/9 [===================>..........] - ETA: 1s - loss: 0.1768 - accuracy: 0.4512 - jacard_coef: 0.08607/9 [======================>.......] - ETA: 0s - loss: 0.1764 - accuracy: 0.4614 - jacard_coef: 0.08538/9 [=========================>....] - ETA: 0s - loss: 0.1759 - accuracy: 0.4808 - jacard_coef: 0.08869/9 [==============================] - 3s 380ms/step - loss: 0.1760 - accuracy: 0.4811 - jacard_coef: 0.0875 - val_loss: 14.5147 - val_accuracy: 0.0731 - val_jacard_coef: 0.0696 - lr: 0.0010
Epoch 4/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1745 - accuracy: 0.6144 - jacard_coef: 0.06082/9 [=====>........................] - ETA: 2s - loss: 0.1754 - accuracy: 0.5454 - jacard_coef: 0.06503/9 [=========>....................] - ETA: 2s - loss: 0.1758 - accuracy: 0.4873 - jacard_coef: 0.06824/9 [============>.................] - ETA: 2s - loss: 0.1758 - accuracy: 0.4563 - jacard_coef: 0.07465/9 [===============>..............] - ETA: 1s - loss: 0.1761 - accuracy: 0.4374 - jacard_coef: 0.08216/9 [===================>..........] - ETA: 1s - loss: 0.1765 - accuracy: 0.4217 - jacard_coef: 0.08037/9 [======================>.......] - ETA: 0s - loss: 0.1765 - accuracy: 0.4136 - jacard_coef: 0.08148/9 [=========================>....] - ETA: 0s - loss: 0.1764 - accuracy: 0.4044 - jacard_coef: 0.08359/9 [==============================] - 3s 380ms/step - loss: 0.1765 - accuracy: 0.4036 - jacard_coef: 0.0802 - val_loss: 0.4173 - val_accuracy: 0.1350 - val_jacard_coef: 0.0721 - lr: 0.0010
Epoch 5/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1768 - accuracy: 0.5954 - jacard_coef: 0.07652/9 [=====>........................] - ETA: 2s - loss: 0.1762 - accuracy: 0.6108 - jacard_coef: 0.06983/9 [=========>....................] - ETA: 2s - loss: 0.1764 - accuracy: 0.6107 - jacard_coef: 0.06754/9 [============>.................] - ETA: 2s - loss: 0.1763 - accuracy: 0.6165 - jacard_coef: 0.06425/9 [===============>..............] - ETA: 1s - loss: 0.1758 - accuracy: 0.6204 - jacard_coef: 0.06716/9 [===================>..........] - ETA: 1s - loss: 0.1753 - accuracy: 0.6251 - jacard_coef: 0.06977/9 [======================>.......] - ETA: 0s - loss: 0.1750 - accuracy: 0.6203 - jacard_coef: 0.07208/9 [=========================>....] - ETA: 0s - loss: 0.1746 - accuracy: 0.6204 - jacard_coef: 0.07649/9 [==============================] - 3s 373ms/step - loss: 0.1746 - accuracy: 0.6209 - jacard_coef: 0.0682 - val_loss: 0.0878 - val_accuracy: 0.9287 - val_jacard_coef: 9.8321e-04 - lr: 0.0010
Epoch 6/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1697 - accuracy: 0.6080 - jacard_coef: 0.09872/9 [=====>........................] - ETA: 2s - loss: 0.1688 - accuracy: 0.6276 - jacard_coef: 0.08623/9 [=========>....................] - ETA: 2s - loss: 0.1992 - accuracy: 0.5461 - jacard_coef: 0.09384/9 [============>.................] - ETA: 2s - loss: 0.2029 - accuracy: 0.4791 - jacard_coef: 0.08835/9 [===============>..............] - ETA: 1s - loss: 0.2056 - accuracy: 0.4421 - jacard_coef: 0.08716/9 [===================>..........] - ETA: 1s - loss: 0.2036 - accuracy: 0.4158 - jacard_coef: 0.08517/9 [======================>.......] - ETA: 0s - loss: 0.2013 - accuracy: 0.3932 - jacard_coef: 0.08328/9 [=========================>....] - ETA: 0s - loss: 0.1984 - accuracy: 0.3901 - jacard_coef: 0.08469/9 [==============================] - 3s 373ms/step - loss: 0.1983 - accuracy: 0.3901 - jacard_coef: 0.0988 - val_loss: 1.1035 - val_accuracy: 0.9304 - val_jacard_coef: 1.4609e-12 - lr: 0.0010
Epoch 7/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1741 - accuracy: 0.5213 - jacard_coef: 0.10502/9 [=====>........................] - ETA: 2s - loss: 0.1775 - accuracy: 0.4131 - jacard_coef: 0.08623/9 [=========>....................] - ETA: 2s - loss: 0.1782 - accuracy: 0.3997 - jacard_coef: 0.07664/9 [============>.................] - ETA: 2s - loss: 0.1828 - accuracy: 0.3425 - jacard_coef: 0.06995/9 [===============>..............] - ETA: 1s - loss: 0.1827 - accuracy: 0.3301 - jacard_coef: 0.07576/9 [===================>..........] - ETA: 1s - loss: 0.1848 - accuracy: 0.3130 - jacard_coef: 0.08067/9 [======================>.......] - ETA: 0s - loss: 0.1847 - accuracy: 0.3189 - jacard_coef: 0.07968/9 [=========================>....] - ETA: 0s - loss: 0.1840 - accuracy: 0.3378 - jacard_coef: 0.08009/9 [==============================] - 3s 373ms/step - loss: 0.1840 - accuracy: 0.3376 - jacard_coef: 0.0720 - val_loss: 1.1218 - val_accuracy: 0.9304 - val_jacard_coef: 1.4616e-12 - lr: 0.0010
Epoch 8/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1755 - accuracy: 0.5236 - jacard_coef: 0.10142/9 [=====>........................] - ETA: 2s - loss: 0.1751 - accuracy: 0.5073 - jacard_coef: 0.08963/9 [=========>....................] - ETA: 2s - loss: 0.1729 - accuracy: 0.5446 - jacard_coef: 0.08354/9 [============>.................] - ETA: 2s - loss: 0.1738 - accuracy: 0.5169 - jacard_coef: 0.07805/9 [===============>..............] - ETA: 1s - loss: 0.1725 - accuracy: 0.5726 - jacard_coef: 0.07226/9 [===================>..........] - ETA: 1s - loss: 0.1738 - accuracy: 0.5990 - jacard_coef: 0.07267/9 [======================>.......] - ETA: 0s - loss: 0.1728 - accuracy: 0.6114 - jacard_coef: 0.07498/9 [=========================>....] - ETA: 0s - loss: 0.1731 - accuracy: 0.5885 - jacard_coef: 0.07769/9 [==============================] - 3s 374ms/step - loss: 0.1733 - accuracy: 0.5869 - jacard_coef: 0.0727 - val_loss: 1.0798 - val_accuracy: 0.9294 - val_jacard_coef: 5.1853e-04 - lr: 0.0010
Epoch 9/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1881 - accuracy: 0.6284 - jacard_coef: 0.05832/9 [=====>........................] - ETA: 2s - loss: 0.1847 - accuracy: 0.4977 - jacard_coef: 0.06253/9 [=========>....................] - ETA: 2s - loss: 0.1841 - accuracy: 0.4133 - jacard_coef: 0.07104/9 [============>.................] - ETA: 2s - loss: 0.1818 - accuracy: 0.3877 - jacard_coef: 0.07455/9 [===============>..............] - ETA: 1s - loss: 0.1808 - accuracy: 0.3812 - jacard_coef: 0.07796/9 [===================>..........] - ETA: 1s - loss: 0.1829 - accuracy: 0.3760 - jacard_coef: 0.08267/9 [======================>.......] - ETA: 0s - loss: 0.1847 - accuracy: 0.3828 - jacard_coef: 0.08048/9 [=========================>....] - ETA: 0s - loss: 0.1842 - accuracy: 0.4022 - jacard_coef: 0.08239/9 [==============================] - 3s 373ms/step - loss: 0.1841 - accuracy: 0.4035 - jacard_coef: 0.0869 - val_loss: 1.1126 - val_accuracy: 0.9304 - val_jacard_coef: 1.4612e-12 - lr: 0.0010
Epoch 10/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1749 - accuracy: 0.6407 - jacard_coef: 0.08532/9 [=====>........................] - ETA: 2s - loss: 0.1716 - accuracy: 0.6627 - jacard_coef: 0.06893/9 [=========>....................] - ETA: 2s - loss: 0.1706 - accuracy: 0.6678 - jacard_coef: 0.06814/9 [============>.................] - ETA: 2s - loss: 0.1717 - accuracy: 0.6679 - jacard_coef: 0.07355/9 [===============>..............] - ETA: 1s - loss: 0.1717 - accuracy: 0.6909 - jacard_coef: 0.07066/9 [===================>..........] - ETA: 1s - loss: 0.1705 - accuracy: 0.7136 - jacard_coef: 0.06817/9 [======================>.......] - ETA: 0s - loss: 0.1692 - accuracy: 0.7276 - jacard_coef: 0.06718/9 [=========================>....] - ETA: 0s - loss: 0.1688 - accuracy: 0.7233 - jacard_coef: 0.06709/9 [==============================] - 3s 373ms/step - loss: 0.1688 - accuracy: 0.7215 - jacard_coef: 0.0669 - val_loss: 0.6287 - val_accuracy: 0.9274 - val_jacard_coef: 0.0117 - lr: 5.0000e-04
Epoch 11/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1748 - accuracy: 0.8869 - jacard_coef: 0.08782/9 [=====>........................] - ETA: 2s - loss: 0.1697 - accuracy: 0.8702 - jacard_coef: 0.06313/9 [=========>....................] - ETA: 2s - loss: 0.1695 - accuracy: 0.8727 - jacard_coef: 0.05344/9 [============>.................] - ETA: 2s - loss: 0.1675 - accuracy: 0.8761 - jacard_coef: 0.04875/9 [===============>..............] - ETA: 1s - loss: 0.1674 - accuracy: 0.8622 - jacard_coef: 0.05086/9 [===================>..........] - ETA: 1s - loss: 0.1683 - accuracy: 0.8545 - jacard_coef: 0.04997/9 [======================>.......] - ETA: 0s - loss: 0.1676 - accuracy: 0.8525 - jacard_coef: 0.05208/9 [=========================>....] - ETA: 0s - loss: 0.1674 - accuracy: 0.8499 - jacard_coef: 0.05119/9 [==============================] - 3s 374ms/step - loss: 0.1674 - accuracy: 0.8494 - jacard_coef: 0.0463 - val_loss: 0.3601 - val_accuracy: 0.9286 - val_jacard_coef: 8.6881e-04 - lr: 5.0000e-04
Epoch 12/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1600 - accuracy: 0.8921 - jacard_coef: 0.04832/9 [=====>........................] - ETA: 2s - loss: 0.1656 - accuracy: 0.8733 - jacard_coef: 0.05563/9 [=========>....................] - ETA: 2s - loss: 0.1659 - accuracy: 0.8698 - jacard_coef: 0.05094/9 [============>.................] - ETA: 2s - loss: 0.1664 - accuracy: 0.8701 - jacard_coef: 0.05545/9 [===============>..............] - ETA: 1s - loss: 0.1655 - accuracy: 0.8692 - jacard_coef: 0.04806/9 [===================>..........] - ETA: 1s - loss: 0.1643 - accuracy: 0.8721 - jacard_coef: 0.04447/9 [======================>.......] - ETA: 0s - loss: 0.1638 - accuracy: 0.8642 - jacard_coef: 0.05188/9 [=========================>....] - ETA: 0s - loss: 0.1629 - accuracy: 0.8689 - jacard_coef: 0.04899/9 [==============================] - 3s 374ms/step - loss: 0.1629 - accuracy: 0.8661 - jacard_coef: 0.0466 - val_loss: 0.2213 - val_accuracy: 0.9263 - val_jacard_coef: 0.0041 - lr: 5.0000e-04
Epoch 13/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1566 - accuracy: 0.9012 - jacard_coef: 0.04222/9 [=====>........................] - ETA: 2s - loss: 0.1617 - accuracy: 0.8953 - jacard_coef: 0.03883/9 [=========>....................] - ETA: 2s - loss: 0.1604 - accuracy: 0.8868 - jacard_coef: 0.03354/9 [============>.................] - ETA: 2s - loss: 0.1592 - accuracy: 0.8960 - jacard_coef: 0.02735/9 [===============>..............] - ETA: 1s - loss: 0.1587 - accuracy: 0.8973 - jacard_coef: 0.02816/9 [===================>..........] - ETA: 1s - loss: 0.1584 - accuracy: 0.8920 - jacard_coef: 0.02747/9 [======================>.......] - ETA: 0s - loss: 0.1579 - accuracy: 0.8914 - jacard_coef: 0.02828/9 [=========================>....] - ETA: 0s - loss: 0.1586 - accuracy: 0.8856 - jacard_coef: 0.03159/9 [==============================] - 3s 374ms/step - loss: 0.1586 - accuracy: 0.8834 - jacard_coef: 0.0281 - val_loss: 0.1203 - val_accuracy: 0.9302 - val_jacard_coef: 4.0787e-04 - lr: 5.0000e-04
Epoch 14/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1592 - accuracy: 0.8853 - jacard_coef: 0.04702/9 [=====>........................] - ETA: 2s - loss: 0.1570 - accuracy: 0.8971 - jacard_coef: 0.03283/9 [=========>....................] - ETA: 2s - loss: 0.1560 - accuracy: 0.9045 - jacard_coef: 0.03124/9 [============>.................] - ETA: 2s - loss: 0.1558 - accuracy: 0.9061 - jacard_coef: 0.02925/9 [===============>..............] - ETA: 1s - loss: 0.1558 - accuracy: 0.9059 - jacard_coef: 0.02466/9 [===================>..........] - ETA: 1s - loss: 0.1557 - accuracy: 0.9039 - jacard_coef: 0.02327/9 [======================>.......] - ETA: 0s - loss: 0.1557 - accuracy: 0.9060 - jacard_coef: 0.02068/9 [=========================>....] - ETA: 0s - loss: 0.1560 - accuracy: 0.9050 - jacard_coef: 0.02029/9 [==============================] - 3s 374ms/step - loss: 0.1561 - accuracy: 0.9023 - jacard_coef: 0.0225 - val_loss: 0.1573 - val_accuracy: 0.9304 - val_jacard_coef: 1.4616e-12 - lr: 5.0000e-04
/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(

✓ Training completed successfully!
  Best Val Jaccard: 0.0721 (epoch 4)
  Final Val Loss: 0.1573
  Training Time: 0:02:02.548692
  Stability (std): 0.4369

Results saved to: hyperparameter_optimization_20250926_165036/exp_35_Attention_ResUNet_lr5e-3_bs16/Attention_ResUNet_lr0.005_bs16_results.json
