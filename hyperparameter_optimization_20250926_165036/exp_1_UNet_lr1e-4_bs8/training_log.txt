âœ“ GPU memory growth enabled for 1 GPUs
Loading dataset...
Loaded 144 images and 144 masks
Training set: (129, 256, 256, 3), Validation set: (15, 256, 256, 3)

============================================================
TRAINING: UNet
Learning Rate: 0.0001, Batch Size: 8, Epochs: 30
============================================================
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 256, 256, 64)         640       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 256, 256, 64)         256       ['conv2d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 activation (Activation)     (None, 256, 256, 64)         0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['activation[0][0]']          
                                                                                                  
 batch_normalization_1 (Bat  (None, 256, 256, 64)         256       ['conv2d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_1 (Activation)   (None, 256, 256, 64)         0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['activation_1[0][0]']        
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       
                                                                                                  
 batch_normalization_2 (Bat  (None, 128, 128, 128)        512       ['conv2d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_2 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_3 (Conv2D)           (None, 128, 128, 128)        147584    ['activation_2[0][0]']        
                                                                                                  
 batch_normalization_3 (Bat  (None, 128, 128, 128)        512       ['conv2d_3[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_3 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_3[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_3[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 batch_normalization_4 (Bat  (None, 64, 64, 256)          1024      ['conv2d_4[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_4 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_4[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_5 (Conv2D)           (None, 64, 64, 256)          590080    ['activation_4[0][0]']        
                                                                                                  
 batch_normalization_5 (Bat  (None, 64, 64, 256)          1024      ['conv2d_5[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_5 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_5[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_5[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 512)          1180160   ['max_pooling2d_2[0][0]']     
                                                                                                  
 batch_normalization_6 (Bat  (None, 32, 32, 512)          2048      ['conv2d_6[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_6 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_6[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 32, 32, 512)          2359808   ['activation_6[0][0]']        
                                                                                                  
 batch_normalization_7 (Bat  (None, 32, 32, 512)          2048      ['conv2d_7[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_7 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_7[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_3 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_7[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 1024)         4719616   ['max_pooling2d_3[0][0]']     
                                                                                                  
 batch_normalization_8 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_8[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_8 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_8[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 1024)         9438208   ['activation_8[0][0]']        
                                                                                                  
 batch_normalization_9 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_9[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_9 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_9[0][0]'
                                                                    ]                             
                                                                                                  
 up_sampling2d (UpSampling2  (None, 32, 32, 1024)         0         ['activation_9[0][0]']        
 D)                                                                                               
                                                                                                  
 concatenate (Concatenate)   (None, 32, 32, 1536)         0         ['up_sampling2d[0][0]',       
                                                                     'activation_7[0][0]']        
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate[0][0]']         
                                                                                                  
 batch_normalization_10 (Ba  (None, 32, 32, 512)          2048      ['conv2d_10[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_10 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_10[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_10[0][0]']       
                                                                                                  
 batch_normalization_11 (Ba  (None, 32, 32, 512)          2048      ['conv2d_11[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_11 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_11[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 64, 64, 512)          0         ['activation_11[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_1 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_1[0][0]',     
 )                                                                   'activation_5[0][0]']        
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_1[0][0]']       
                                                                                                  
 batch_normalization_12 (Ba  (None, 64, 64, 256)          1024      ['conv2d_12[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_12 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_12[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_13 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_12[0][0]']       
                                                                                                  
 batch_normalization_13 (Ba  (None, 64, 64, 256)          1024      ['conv2d_13[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_13 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_13[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 128, 128, 256)        0         ['activation_13[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_2 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_2[0][0]',     
 )                                                                   'activation_3[0][0]']        
                                                                                                  
 conv2d_14 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_2[0][0]']       
                                                                                                  
 batch_normalization_14 (Ba  (None, 128, 128, 128)        512       ['conv2d_14[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_14 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_14[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_15 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_14[0][0]']       
                                                                                                  
 batch_normalization_15 (Ba  (None, 128, 128, 128)        512       ['conv2d_15[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_15 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_15[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 256, 256, 128)        0         ['activation_15[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_3 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_3[0][0]',     
 )                                                                   'activation_1[0][0]']        
                                                                                                  
 conv2d_16 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_3[0][0]']       
                                                                                                  
 batch_normalization_16 (Ba  (None, 256, 256, 64)         256       ['conv2d_16[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_16 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_16[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_16[0][0]']       
                                                                                                  
 batch_normalization_17 (Ba  (None, 256, 256, 64)         256       ['conv2d_17[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_17 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_17[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_18 (Conv2D)          (None, 256, 256, 1)          65        ['activation_17[0][0]']       
                                                                                                  
 batch_normalization_18 (Ba  (None, 256, 256, 1)          4         ['conv2d_18[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_18 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_18[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31401349 (119.79 MB)
Trainable params: 31389571 (119.74 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
None
âœ“ focal_loss imported successfully
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_2 (InputLayer)        [(None, 256, 256, 3)]        0         []                            
                                                                                                  
 conv2d_19 (Conv2D)          (None, 256, 256, 64)         1792      ['input_2[0][0]']             
                                                                                                  
 batch_normalization_19 (Ba  (None, 256, 256, 64)         256       ['conv2d_19[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_19 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_19[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_20 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_19[0][0]']       
                                                                                                  
 batch_normalization_20 (Ba  (None, 256, 256, 64)         256       ['conv2d_20[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_20 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_20[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_4 (MaxPoolin  (None, 128, 128, 64)         0         ['activation_20[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_21 (Conv2D)          (None, 128, 128, 128)        73856     ['max_pooling2d_4[0][0]']     
                                                                                                  
 batch_normalization_21 (Ba  (None, 128, 128, 128)        512       ['conv2d_21[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_21 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_21[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_22 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_21[0][0]']       
                                                                                                  
 batch_normalization_22 (Ba  (None, 128, 128, 128)        512       ['conv2d_22[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_22 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_22[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_5 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_22[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_23 (Conv2D)          (None, 64, 64, 256)          295168    ['max_pooling2d_5[0][0]']     
                                                                                                  
 batch_normalization_23 (Ba  (None, 64, 64, 256)          1024      ['conv2d_23[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_23 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_23[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_24 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_23[0][0]']       
                                                                                                  
 batch_normalization_24 (Ba  (None, 64, 64, 256)          1024      ['conv2d_24[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_24 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_24[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_6 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_24[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_25 (Conv2D)          (None, 32, 32, 512)          1180160   ['max_pooling2d_6[0][0]']     
                                                                                                  
 batch_normalization_25 (Ba  (None, 32, 32, 512)          2048      ['conv2d_25[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_25 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_25[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_26 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_25[0][0]']       
                                                                                                  
 batch_normalization_26 (Ba  (None, 32, 32, 512)          2048      ['conv2d_26[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_26 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_26[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_7 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_26[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_27 (Conv2D)          (None, 16, 16, 1024)         4719616   ['max_pooling2d_7[0][0]']     
                                                                                                  
 batch_normalization_27 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_27[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_27 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_27[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_28 (Conv2D)          (None, 16, 16, 1024)         9438208   ['activation_27[0][0]']       
                                                                                                  
 batch_normalization_28 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_28[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_28 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_28[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 1024)         0         ['activation_28[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_4 (Concatenate  (None, 32, 32, 1536)         0         ['up_sampling2d_4[0][0]',     
 )                                                                   'activation_26[0][0]']       
                                                                                                  
 conv2d_29 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate_4[0][0]']       
                                                                                                  
 batch_normalization_29 (Ba  (None, 32, 32, 512)          2048      ['conv2d_29[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_29 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_29[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_30 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_29[0][0]']       
                                                                                                  
 batch_normalization_30 (Ba  (None, 32, 32, 512)          2048      ['conv2d_30[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_30 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_30[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 512)          0         ['activation_30[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_5 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_5[0][0]',     
 )                                                                   'activation_24[0][0]']       
                                                                                                  
 conv2d_31 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_5[0][0]']       
                                                                                                  
 batch_normalization_31 (Ba  (None, 64, 64, 256)          1024      ['conv2d_31[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_31 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_31[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_32 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_31[0][0]']       
                                                                                                  
 batch_normalization_32 (Ba  (None, 64, 64, 256)          1024      ['conv2d_32[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_32 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_32[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_6 (UpSamplin  (None, 128, 128, 256)        0         ['activation_32[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_6 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_6[0][0]',     
 )                                                                   'activation_22[0][0]']       
                                                                                                  
 conv2d_33 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_6[0][0]']       
                                                                                                  
 batch_normalization_33 (Ba  (None, 128, 128, 128)        512       ['conv2d_33[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_33 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_33[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_34 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_33[0][0]']       
                                                                                                  
 batch_normalization_34 (Ba  (None, 128, 128, 128)        512       ['conv2d_34[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_34 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_34[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_7 (UpSamplin  (None, 256, 256, 128)        0         ['activation_34[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_7 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_7[0][0]',     
 )                                                                   'activation_20[0][0]']       
                                                                                                  
 conv2d_35 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_7[0][0]']       
                                                                                                  
 batch_normalization_35 (Ba  (None, 256, 256, 64)         256       ['conv2d_35[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_35 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_35[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_36 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_35[0][0]']       
                                                                                                  
 batch_normalization_36 (Ba  (None, 256, 256, 64)         256       ['conv2d_36[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_36 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_36[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_37 (Conv2D)          (None, 256, 256, 1)          65        ['activation_36[0][0]']       
                                                                                                  
 batch_normalization_37 (Ba  (None, 256, 256, 1)          4         ['conv2d_37[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_37 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_37[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31402501 (119.79 MB)
Trainable params: 31390723 (119.75 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
WARNING:absl:`lr` is deprecated in TF-Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
None
Epoch 1/30
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1758876677.519503 1006088 service.cc:145] XLA service 0x145f6a11bdb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1758876677.519530 1006088 service.cc:153]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6
I0000 00:00:1758876677.656728 1006088 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
 1/17 [>.............................] - ETA: 8:55 - loss: 0.3266 - accuracy: 0.4468 - jacard_coef: 0.0944 2/17 [==>...........................] - ETA: 53s - loss: 0.3095 - accuracy: 0.3496 - jacard_coef: 0.0674  3/17 [====>.........................] - ETA: 32s - loss: 0.2836 - accuracy: 0.3035 - jacard_coef: 0.0806 4/17 [======>.......................] - ETA: 24s - loss: 0.2679 - accuracy: 0.2670 - jacard_coef: 0.0808 5/17 [=======>......................] - ETA: 18s - loss: 0.2576 - accuracy: 0.2369 - jacard_coef: 0.0778 6/17 [=========>....................] - ETA: 13s - loss: 0.2505 - accuracy: 0.2197 - jacard_coef: 0.0766 7/17 [===========>..................] - ETA: 10s - loss: 0.2430 - accuracy: 0.2231 - jacard_coef: 0.0738 8/17 [=============>................] - ETA: 8s - loss: 0.2377 - accuracy: 0.2140 - jacard_coef: 0.0721  9/17 [==============>...............] - ETA: 6s - loss: 0.2327 - accuracy: 0.2229 - jacard_coef: 0.075010/17 [================>.............] - ETA: 5s - loss: 0.2283 - accuracy: 0.2213 - jacard_coef: 0.072211/17 [==================>...........] - ETA: 4s - loss: 0.2248 - accuracy: 0.2289 - jacard_coef: 0.078712/17 [====================>.........] - ETA: 3s - loss: 0.2215 - accuracy: 0.2344 - jacard_coef: 0.080613/17 [=====================>........] - ETA: 2s - loss: 0.2185 - accuracy: 0.2409 - jacard_coef: 0.081214/17 [=======================>......] - ETA: 1s - loss: 0.2165 - accuracy: 0.2424 - jacard_coef: 0.081215/17 [=========================>....] - ETA: 1s - loss: 0.2191 - accuracy: 0.2483 - jacard_coef: 0.080916/17 [===========================>..] - ETA: 0s - loss: 0.2177 - accuracy: 0.2440 - jacard_coef: 0.080617/17 [==============================] - ETA: 0s - loss: 0.2175 - accuracy: 0.2438 - jacard_coef: 0.086117/17 [==============================] - 47s 846ms/step - loss: 0.2175 - accuracy: 0.2438 - jacard_coef: 0.0861 - val_loss: 1.1218 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 0.0010
Epoch 2/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1985 - accuracy: 0.1142 - jacard_coef: 0.0289 2/17 [==>...........................] - ETA: 1s - loss: 0.1949 - accuracy: 0.1458 - jacard_coef: 0.0703 3/17 [====>.........................] - ETA: 1s - loss: 0.1941 - accuracy: 0.1422 - jacard_coef: 0.0802 4/17 [======>.......................] - ETA: 1s - loss: 0.1949 - accuracy: 0.1409 - jacard_coef: 0.0793 5/17 [=======>......................] - ETA: 1s - loss: 0.1933 - accuracy: 0.1423 - jacard_coef: 0.0791 6/17 [=========>....................] - ETA: 1s - loss: 0.1954 - accuracy: 0.1432 - jacard_coef: 0.0801 7/17 [===========>..................] - ETA: 1s - loss: 0.1945 - accuracy: 0.1411 - jacard_coef: 0.0792 8/17 [=============>................] - ETA: 1s - loss: 0.1939 - accuracy: 0.1450 - jacard_coef: 0.0823 9/17 [==============>...............] - ETA: 1s - loss: 0.1926 - accuracy: 0.1505 - jacard_coef: 0.080110/17 [================>.............] - ETA: 0s - loss: 0.1919 - accuracy: 0.1631 - jacard_coef: 0.083311/17 [==================>...........] - ETA: 0s - loss: 0.1943 - accuracy: 0.1705 - jacard_coef: 0.081312/17 [====================>.........] - ETA: 0s - loss: 0.1944 - accuracy: 0.1718 - jacard_coef: 0.081313/17 [=====================>........] - ETA: 0s - loss: 0.1957 - accuracy: 0.1699 - jacard_coef: 0.079614/17 [=======================>......] - ETA: 0s - loss: 0.1978 - accuracy: 0.1682 - jacard_coef: 0.078915/17 [=========================>....] - ETA: 0s - loss: 0.1988 - accuracy: 0.1714 - jacard_coef: 0.078216/17 [===========================>..] - ETA: 0s - loss: 0.1988 - accuracy: 0.1844 - jacard_coef: 0.079117/17 [==============================] - ETA: 0s - loss: 0.1990 - accuracy: 0.1857 - jacard_coef: 0.079917/17 [==============================] - 2s 133ms/step - loss: 0.1990 - accuracy: 0.1857 - jacard_coef: 0.0799 - val_loss: 1.1014 - val_accuracy: 0.9222 - val_jacard_coef: 0.0034 - lr: 0.0010
Epoch 3/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1880 - accuracy: 0.5201 - jacard_coef: 0.0890 2/17 [==>...........................] - ETA: 1s - loss: 0.1943 - accuracy: 0.5138 - jacard_coef: 0.0745 3/17 [====>.........................] - ETA: 1s - loss: 0.1929 - accuracy: 0.5010 - jacard_coef: 0.0847 4/17 [======>.......................] - ETA: 1s - loss: 0.1905 - accuracy: 0.4831 - jacard_coef: 0.0824 5/17 [=======>......................] - ETA: 1s - loss: 0.1903 - accuracy: 0.4603 - jacard_coef: 0.0876 6/17 [=========>....................] - ETA: 1s - loss: 0.1884 - accuracy: 0.4436 - jacard_coef: 0.0905 7/17 [===========>..................] - ETA: 1s - loss: 0.1876 - accuracy: 0.4252 - jacard_coef: 0.0881 8/17 [=============>................] - ETA: 1s - loss: 0.1862 - accuracy: 0.4209 - jacard_coef: 0.0839 9/17 [==============>...............] - ETA: 1s - loss: 0.1855 - accuracy: 0.4027 - jacard_coef: 0.082310/17 [================>.............] - ETA: 0s - loss: 0.1847 - accuracy: 0.3898 - jacard_coef: 0.080711/17 [==================>...........] - ETA: 0s - loss: 0.1839 - accuracy: 0.3939 - jacard_coef: 0.078912/17 [====================>.........] - ETA: 0s - loss: 0.1833 - accuracy: 0.3937 - jacard_coef: 0.078213/17 [=====================>........] - ETA: 0s - loss: 0.1826 - accuracy: 0.3994 - jacard_coef: 0.076714/17 [=======================>......] - ETA: 0s - loss: 0.1821 - accuracy: 0.4009 - jacard_coef: 0.076115/17 [=========================>....] - ETA: 0s - loss: 0.1815 - accuracy: 0.4134 - jacard_coef: 0.076016/17 [===========================>..] - ETA: 0s - loss: 0.1810 - accuracy: 0.4122 - jacard_coef: 0.076717/17 [==============================] - 2s 130ms/step - loss: 0.1810 - accuracy: 0.4115 - jacard_coef: 0.0759 - val_loss: 1.0180 - val_accuracy: 0.9269 - val_jacard_coef: 0.0064 - lr: 0.0010
Epoch 4/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1746 - accuracy: 0.5272 - jacard_coef: 0.0680 2/17 [==>...........................] - ETA: 1s - loss: 0.1746 - accuracy: 0.5770 - jacard_coef: 0.0605 3/17 [====>.........................] - ETA: 1s - loss: 0.1744 - accuracy: 0.5800 - jacard_coef: 0.0752 4/17 [======>.......................] - ETA: 1s - loss: 0.1772 - accuracy: 0.5363 - jacard_coef: 0.0793 5/17 [=======>......................] - ETA: 1s - loss: 0.1764 - accuracy: 0.5190 - jacard_coef: 0.0795 6/17 [=========>....................] - ETA: 1s - loss: 0.1756 - accuracy: 0.5115 - jacard_coef: 0.0782 7/17 [===========>..................] - ETA: 1s - loss: 0.1757 - accuracy: 0.5069 - jacard_coef: 0.0769 8/17 [=============>................] - ETA: 1s - loss: 0.1756 - accuracy: 0.4928 - jacard_coef: 0.0778 9/17 [==============>...............] - ETA: 1s - loss: 0.1750 - accuracy: 0.4838 - jacard_coef: 0.073210/17 [================>.............] - ETA: 0s - loss: 0.1746 - accuracy: 0.5055 - jacard_coef: 0.073911/17 [==================>...........] - ETA: 0s - loss: 0.1741 - accuracy: 0.5311 - jacard_coef: 0.071912/17 [====================>.........] - ETA: 0s - loss: 0.1735 - accuracy: 0.5579 - jacard_coef: 0.069113/17 [=====================>........] - ETA: 0s - loss: 0.1732 - accuracy: 0.5661 - jacard_coef: 0.071314/17 [=======================>......] - ETA: 0s - loss: 0.1727 - accuracy: 0.5797 - jacard_coef: 0.071915/17 [=========================>....] - ETA: 0s - loss: 0.1722 - accuracy: 0.5954 - jacard_coef: 0.067816/17 [===========================>..] - ETA: 0s - loss: 0.1724 - accuracy: 0.6076 - jacard_coef: 0.065817/17 [==============================] - 2s 130ms/step - loss: 0.1725 - accuracy: 0.6063 - jacard_coef: 0.0716 - val_loss: 1.0617 - val_accuracy: 0.8968 - val_jacard_coef: 0.0359 - lr: 0.0010
Epoch 5/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1649 - accuracy: 0.8688 - jacard_coef: 0.0241 2/17 [==>...........................] - ETA: 1s - loss: 0.1683 - accuracy: 0.8737 - jacard_coef: 0.0266 3/17 [====>.........................] - ETA: 1s - loss: 0.1704 - accuracy: 0.8612 - jacard_coef: 0.0358 4/17 [======>.......................] - ETA: 1s - loss: 0.1696 - accuracy: 0.8541 - jacard_coef: 0.0385 5/17 [=======>......................] - ETA: 1s - loss: 0.1714 - accuracy: 0.8319 - jacard_coef: 0.0417 6/17 [=========>....................] - ETA: 1s - loss: 0.1718 - accuracy: 0.8244 - jacard_coef: 0.0478 7/17 [===========>..................] - ETA: 1s - loss: 0.1711 - accuracy: 0.7823 - jacard_coef: 0.0498 8/17 [=============>................] - ETA: 1s - loss: 0.1712 - accuracy: 0.7693 - jacard_coef: 0.0520 9/17 [==============>...............] - ETA: 1s - loss: 0.1702 - accuracy: 0.7772 - jacard_coef: 0.050410/17 [================>.............] - ETA: 0s - loss: 0.1696 - accuracy: 0.7725 - jacard_coef: 0.048311/17 [==================>...........] - ETA: 0s - loss: 0.1689 - accuracy: 0.7690 - jacard_coef: 0.051012/17 [====================>.........] - ETA: 0s - loss: 0.1685 - accuracy: 0.7617 - jacard_coef: 0.055313/17 [=====================>........] - ETA: 0s - loss: 0.1681 - accuracy: 0.7550 - jacard_coef: 0.054814/17 [=======================>......] - ETA: 0s - loss: 0.1677 - accuracy: 0.7516 - jacard_coef: 0.057115/17 [=========================>....] - ETA: 0s - loss: 0.1687 - accuracy: 0.7311 - jacard_coef: 0.061116/17 [===========================>..] - ETA: 0s - loss: 0.1683 - accuracy: 0.7363 - jacard_coef: 0.060517/17 [==============================] - 2s 130ms/step - loss: 0.1686 - accuracy: 0.7371 - jacard_coef: 0.0600 - val_loss: 0.1817 - val_accuracy: 0.4574 - val_jacard_coef: 0.0531 - lr: 0.0010
Epoch 6/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1678 - accuracy: 0.8735 - jacard_coef: 0.0221 2/17 [==>...........................] - ETA: 1s - loss: 0.1665 - accuracy: 0.8527 - jacard_coef: 0.0490 3/17 [====>.........................] - ETA: 1s - loss: 0.1669 - accuracy: 0.8363 - jacard_coef: 0.0463 4/17 [======>.......................] - ETA: 1s - loss: 0.1673 - accuracy: 0.8457 - jacard_coef: 0.0411 5/17 [=======>......................] - ETA: 1s - loss: 0.1670 - accuracy: 0.8303 - jacard_coef: 0.0429 6/17 [=========>....................] - ETA: 1s - loss: 0.1657 - accuracy: 0.8242 - jacard_coef: 0.0484 7/17 [===========>..................] - ETA: 1s - loss: 0.1660 - accuracy: 0.7972 - jacard_coef: 0.0523 8/17 [=============>................] - ETA: 1s - loss: 0.1656 - accuracy: 0.7902 - jacard_coef: 0.0601 9/17 [==============>...............] - ETA: 1s - loss: 0.1649 - accuracy: 0.7842 - jacard_coef: 0.062510/17 [================>.............] - ETA: 0s - loss: 0.1645 - accuracy: 0.7744 - jacard_coef: 0.062611/17 [==================>...........] - ETA: 0s - loss: 0.1645 - accuracy: 0.7699 - jacard_coef: 0.063212/17 [====================>.........] - ETA: 0s - loss: 0.1639 - accuracy: 0.7744 - jacard_coef: 0.064813/17 [=====================>........] - ETA: 0s - loss: 0.1637 - accuracy: 0.7766 - jacard_coef: 0.062214/17 [=======================>......] - ETA: 0s - loss: 0.1633 - accuracy: 0.7782 - jacard_coef: 0.062715/17 [=========================>....] - ETA: 0s - loss: 0.1630 - accuracy: 0.7774 - jacard_coef: 0.062216/17 [===========================>..] - ETA: 0s - loss: 0.1626 - accuracy: 0.7791 - jacard_coef: 0.061517/17 [==============================] - 2s 130ms/step - loss: 0.1627 - accuracy: 0.7776 - jacard_coef: 0.0632 - val_loss: 0.1751 - val_accuracy: 0.4348 - val_jacard_coef: 0.0599 - lr: 0.0010
Epoch 7/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1590 - accuracy: 0.9169 - jacard_coef: 0.0193 2/17 [==>...........................] - ETA: 1s - loss: 0.1580 - accuracy: 0.8951 - jacard_coef: 0.0266 3/17 [====>.........................] - ETA: 1s - loss: 0.1597 - accuracy: 0.8584 - jacard_coef: 0.0474 4/17 [======>.......................] - ETA: 1s - loss: 0.1600 - accuracy: 0.8527 - jacard_coef: 0.0441 5/17 [=======>......................] - ETA: 1s - loss: 0.1600 - accuracy: 0.8460 - jacard_coef: 0.0486 6/17 [=========>....................] - ETA: 1s - loss: 0.1598 - accuracy: 0.8461 - jacard_coef: 0.0479 7/17 [===========>..................] - ETA: 1s - loss: 0.1599 - accuracy: 0.8367 - jacard_coef: 0.0611 8/17 [=============>................] - ETA: 1s - loss: 0.1597 - accuracy: 0.8318 - jacard_coef: 0.0611 9/17 [==============>...............] - ETA: 1s - loss: 0.1597 - accuracy: 0.8251 - jacard_coef: 0.064010/17 [================>.............] - ETA: 0s - loss: 0.1597 - accuracy: 0.8248 - jacard_coef: 0.062011/17 [==================>...........] - ETA: 0s - loss: 0.1594 - accuracy: 0.8236 - jacard_coef: 0.062212/17 [====================>.........] - ETA: 0s - loss: 0.1592 - accuracy: 0.8243 - jacard_coef: 0.062713/17 [=====================>........] - ETA: 0s - loss: 0.1588 - accuracy: 0.8259 - jacard_coef: 0.061914/17 [=======================>......] - ETA: 0s - loss: 0.1585 - accuracy: 0.8263 - jacard_coef: 0.060815/17 [=========================>....] - ETA: 0s - loss: 0.1583 - accuracy: 0.8266 - jacard_coef: 0.060016/17 [===========================>..] - ETA: 0s - loss: 0.1584 - accuracy: 0.8252 - jacard_coef: 0.060817/17 [==============================] - 2s 130ms/step - loss: 0.1584 - accuracy: 0.8252 - jacard_coef: 0.0579 - val_loss: 0.2021 - val_accuracy: 0.2289 - val_jacard_coef: 0.0649 - lr: 0.0010
Epoch 8/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1554 - accuracy: 0.8220 - jacard_coef: 0.0613 2/17 [==>...........................] - ETA: 1s - loss: 0.1555 - accuracy: 0.8185 - jacard_coef: 0.0525 3/17 [====>.........................] - ETA: 1s - loss: 0.1549 - accuracy: 0.8342 - jacard_coef: 0.0447 4/17 [======>.......................] - ETA: 1s - loss: 0.1544 - accuracy: 0.8543 - jacard_coef: 0.0379 5/17 [=======>......................] - ETA: 1s - loss: 0.1540 - accuracy: 0.8665 - jacard_coef: 0.0327 6/17 [=========>....................] - ETA: 1s - loss: 0.1538 - accuracy: 0.8740 - jacard_coef: 0.0279 7/17 [===========>..................] - ETA: 1s - loss: 0.1540 - accuracy: 0.8807 - jacard_coef: 0.0243 8/17 [=============>................] - ETA: 1s - loss: 0.1539 - accuracy: 0.8818 - jacard_coef: 0.0220 9/17 [==============>...............] - ETA: 1s - loss: 0.1537 - accuracy: 0.8862 - jacard_coef: 0.019810/17 [================>.............] - ETA: 0s - loss: 0.1534 - accuracy: 0.8905 - jacard_coef: 0.018111/17 [==================>...........] - ETA: 0s - loss: 0.1533 - accuracy: 0.8907 - jacard_coef: 0.017312/17 [====================>.........] - ETA: 0s - loss: 0.1534 - accuracy: 0.8878 - jacard_coef: 0.017013/17 [=====================>........] - ETA: 0s - loss: 0.1533 - accuracy: 0.8883 - jacard_coef: 0.017014/17 [=======================>......] - ETA: 0s - loss: 0.1532 - accuracy: 0.8892 - jacard_coef: 0.016515/17 [=========================>....] - ETA: 0s - loss: 0.1530 - accuracy: 0.8902 - jacard_coef: 0.017716/17 [===========================>..] - ETA: 0s - loss: 0.1528 - accuracy: 0.8924 - jacard_coef: 0.017617/17 [==============================] - 2s 130ms/step - loss: 0.1528 - accuracy: 0.8905 - jacard_coef: 0.0251 - val_loss: 0.2428 - val_accuracy: 0.1590 - val_jacard_coef: 0.0698 - lr: 0.0010
Epoch 9/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1489 - accuracy: 0.9274 - jacard_coef: 0.0133 2/17 [==>...........................] - ETA: 1s - loss: 0.1504 - accuracy: 0.9077 - jacard_coef: 0.0102 3/17 [====>.........................] - ETA: 1s - loss: 0.1511 - accuracy: 0.8969 - jacard_coef: 0.0072 4/17 [======>.......................] - ETA: 1s - loss: 0.1509 - accuracy: 0.8985 - jacard_coef: 0.0063 5/17 [=======>......................] - ETA: 1s - loss: 0.1506 - accuracy: 0.9046 - jacard_coef: 0.0060 6/17 [=========>....................] - ETA: 1s - loss: 0.1502 - accuracy: 0.9094 - jacard_coef: 0.0055 7/17 [===========>..................] - ETA: 1s - loss: 0.1507 - accuracy: 0.9066 - jacard_coef: 0.0050 8/17 [=============>................] - ETA: 1s - loss: 0.1507 - accuracy: 0.9102 - jacard_coef: 0.0044 9/17 [==============>...............] - ETA: 1s - loss: 0.1506 - accuracy: 0.9084 - jacard_coef: 0.003910/17 [================>.............] - ETA: 0s - loss: 0.1503 - accuracy: 0.9103 - jacard_coef: 0.003611/17 [==================>...........] - ETA: 0s - loss: 0.1501 - accuracy: 0.9119 - jacard_coef: 0.003412/17 [====================>.........] - ETA: 0s - loss: 0.1500 - accuracy: 0.9115 - jacard_coef: 0.003313/17 [=====================>........] - ETA: 0s - loss: 0.1497 - accuracy: 0.9141 - jacard_coef: 0.003214/17 [=======================>......] - ETA: 0s - loss: 0.1495 - accuracy: 0.9144 - jacard_coef: 0.003315/17 [=========================>....] - ETA: 0s - loss: 0.1493 - accuracy: 0.9153 - jacard_coef: 0.003416/17 [===========================>..] - ETA: 0s - loss: 0.1492 - accuracy: 0.9137 - jacard_coef: 0.003417/17 [==============================] - 2s 128ms/step - loss: 0.1492 - accuracy: 0.9132 - jacard_coef: 0.0032 - val_loss: 0.1615 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 0.0010
Epoch 10/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1507 - accuracy: 0.8754 - jacard_coef: 0.0081 2/17 [==>...........................] - ETA: 1s - loss: 0.1476 - accuracy: 0.9105 - jacard_coef: 0.0092 3/17 [====>.........................] - ETA: 1s - loss: 0.1468 - accuracy: 0.9169 - jacard_coef: 0.0070 4/17 [======>.......................] - ETA: 1s - loss: 0.1465 - accuracy: 0.9190 - jacard_coef: 0.0056 5/17 [=======>......................] - ETA: 1s - loss: 0.1465 - accuracy: 0.9187 - jacard_coef: 0.0050 6/17 [=========>....................] - ETA: 1s - loss: 0.1467 - accuracy: 0.9114 - jacard_coef: 0.0043 7/17 [===========>..................] - ETA: 1s - loss: 0.1464 - accuracy: 0.9144 - jacard_coef: 0.0040 8/17 [=============>................] - ETA: 1s - loss: 0.1462 - accuracy: 0.9166 - jacard_coef: 0.0038 9/17 [==============>...............] - ETA: 1s - loss: 0.1459 - accuracy: 0.9179 - jacard_coef: 0.003510/17 [================>.............] - ETA: 0s - loss: 0.1457 - accuracy: 0.9168 - jacard_coef: 0.003311/17 [==================>...........] - ETA: 0s - loss: 0.1457 - accuracy: 0.9147 - jacard_coef: 0.003112/17 [====================>.........] - ETA: 0s - loss: 0.1454 - accuracy: 0.9162 - jacard_coef: 0.003013/17 [=====================>........] - ETA: 0s - loss: 0.1451 - accuracy: 0.9177 - jacard_coef: 0.002714/17 [=======================>......] - ETA: 0s - loss: 0.1450 - accuracy: 0.9169 - jacard_coef: 0.002815/17 [=========================>....] - ETA: 0s - loss: 0.1449 - accuracy: 0.9161 - jacard_coef: 0.002816/17 [===========================>..] - ETA: 0s - loss: 0.1448 - accuracy: 0.9156 - jacard_coef: 0.002717/17 [==============================] - 2s 128ms/step - loss: 0.1449 - accuracy: 0.9149 - jacard_coef: 0.0026 - val_loss: 0.1618 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 0.0010
Epoch 11/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1440 - accuracy: 0.9039 - jacard_coef: 0.0020 2/17 [==>...........................] - ETA: 1s - loss: 0.1443 - accuracy: 0.8906 - jacard_coef: 0.0011 3/17 [====>.........................] - ETA: 1s - loss: 0.1427 - accuracy: 0.9108 - jacard_coef: 7.3425e-04 4/17 [======>.......................] - ETA: 1s - loss: 0.1418 - accuracy: 0.9219 - jacard_coef: 6.0372e-04 5/17 [=======>......................] - ETA: 1s - loss: 0.1417 - accuracy: 0.9208 - jacard_coef: 0.0043     6/17 [=========>....................] - ETA: 1s - loss: 0.1411 - accuracy: 0.9259 - jacard_coef: 0.0097 7/17 [===========>..................] - ETA: 1s - loss: 0.1410 - accuracy: 0.9251 - jacard_coef: 0.0126 8/17 [=============>................] - ETA: 1s - loss: 0.1410 - accuracy: 0.9234 - jacard_coef: 0.0118 9/17 [==============>...............] - ETA: 1s - loss: 0.1412 - accuracy: 0.9190 - jacard_coef: 0.011210/17 [================>.............] - ETA: 0s - loss: 0.1409 - accuracy: 0.9211 - jacard_coef: 0.010111/17 [==================>...........] - ETA: 0s - loss: 0.1408 - accuracy: 0.9221 - jacard_coef: 0.009212/17 [====================>.........] - ETA: 0s - loss: 0.1410 - accuracy: 0.9193 - jacard_coef: 0.008713/17 [=====================>........] - ETA: 0s - loss: 0.1412 - accuracy: 0.9160 - jacard_coef: 0.008014/17 [=======================>......] - ETA: 0s - loss: 0.1412 - accuracy: 0.9145 - jacard_coef: 0.007515/17 [=========================>....] - ETA: 0s - loss: 0.1411 - accuracy: 0.9149 - jacard_coef: 0.007016/17 [===========================>..] - ETA: 0s - loss: 0.1412 - accuracy: 0.9134 - jacard_coef: 0.006517/17 [==============================] - 2s 128ms/step - loss: 0.1412 - accuracy: 0.9133 - jacard_coef: 0.0061 - val_loss: 0.1571 - val_accuracy: 0.9294 - val_jacard_coef: 0.0018 - lr: 0.0010
Epoch 12/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1381 - accuracy: 0.9230 - jacard_coef: 2.4775e-12 2/17 [==>...........................] - ETA: 1s - loss: 0.1359 - accuracy: 0.9449 - jacard_coef: 4.1138e-12 3/17 [====>.........................] - ETA: 1s - loss: 0.1383 - accuracy: 0.9224 - jacard_coef: 7.7752e-05 4/17 [======>.......................] - ETA: 1s - loss: 0.1384 - accuracy: 0.9203 - jacard_coef: 5.8314e-05 5/17 [=======>......................] - ETA: 1s - loss: 0.1379 - accuracy: 0.9249 - jacard_coef: 4.6651e-05 6/17 [=========>....................] - ETA: 1s - loss: 0.1383 - accuracy: 0.9194 - jacard_coef: 3.8876e-05 7/17 [===========>..................] - ETA: 1s - loss: 0.1386 - accuracy: 0.9166 - jacard_coef: 3.3322e-05 8/17 [=============>................] - ETA: 1s - loss: 0.1385 - accuracy: 0.9187 - jacard_coef: 2.9157e-05 9/17 [==============>...............] - ETA: 1s - loss: 0.1399 - accuracy: 0.8956 - jacard_coef: 0.0062    10/17 [================>.............] - ETA: 0s - loss: 0.1398 - accuracy: 0.8966 - jacard_coef: 0.005611/17 [==================>...........] - ETA: 0s - loss: 0.1400 - accuracy: 0.8957 - jacard_coef: 0.005112/17 [====================>.........] - ETA: 0s - loss: 0.1401 - accuracy: 0.8973 - jacard_coef: 0.004913/17 [=====================>........] - ETA: 0s - loss: 0.1401 - accuracy: 0.8972 - jacard_coef: 0.004714/17 [=======================>......] - ETA: 0s - loss: 0.1400 - accuracy: 0.8983 - jacard_coef: 0.005115/17 [=========================>....] - ETA: 0s - loss: 0.1403 - accuracy: 0.8962 - jacard_coef: 0.005716/17 [===========================>..] - ETA: 0s - loss: 0.1400 - accuracy: 0.8995 - jacard_coef: 0.005817/17 [==============================] - 2s 128ms/step - loss: 0.1400 - accuracy: 0.8989 - jacard_coef: 0.0087 - val_loss: 0.1541 - val_accuracy: 0.7392 - val_jacard_coef: 0.0685 - lr: 0.0010
Epoch 13/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1403 - accuracy: 0.9166 - jacard_coef: 0.0206 2/17 [==>...........................] - ETA: 1s - loss: 0.1408 - accuracy: 0.8985 - jacard_coef: 0.0121 3/17 [====>.........................] - ETA: 1s - loss: 0.1409 - accuracy: 0.8933 - jacard_coef: 0.0119 4/17 [======>.......................] - ETA: 1s - loss: 0.1409 - accuracy: 0.8932 - jacard_coef: 0.0152 5/17 [=======>......................] - ETA: 1s - loss: 0.1402 - accuracy: 0.9054 - jacard_coef: 0.0157 6/17 [=========>....................] - ETA: 1s - loss: 0.1402 - accuracy: 0.9082 - jacard_coef: 0.0145 7/17 [===========>..................] - ETA: 1s - loss: 0.1400 - accuracy: 0.9087 - jacard_coef: 0.0132 8/17 [=============>................] - ETA: 1s - loss: 0.1400 - accuracy: 0.9066 - jacard_coef: 0.0122 9/17 [==============>...............] - ETA: 1s - loss: 0.1401 - accuracy: 0.9053 - jacard_coef: 0.011010/17 [================>.............] - ETA: 0s - loss: 0.1402 - accuracy: 0.9031 - jacard_coef: 0.010711/17 [==================>...........] - ETA: 0s - loss: 0.1401 - accuracy: 0.9028 - jacard_coef: 0.009812/17 [====================>.........] - ETA: 0s - loss: 0.1399 - accuracy: 0.9031 - jacard_coef: 0.009313/17 [=====================>........] - ETA: 0s - loss: 0.1399 - accuracy: 0.9022 - jacard_coef: 0.008914/17 [=======================>......] - ETA: 0s - loss: 0.1397 - accuracy: 0.9035 - jacard_coef: 0.008415/17 [=========================>....] - ETA: 0s - loss: 0.1393 - accuracy: 0.9062 - jacard_coef: 0.008016/17 [===========================>..] - ETA: 0s - loss: 0.1394 - accuracy: 0.9053 - jacard_coef: 0.007717/17 [==============================] - 2s 128ms/step - loss: 0.1394 - accuracy: 0.9052 - jacard_coef: 0.0072 - val_loss: 0.1496 - val_accuracy: 0.9302 - val_jacard_coef: 5.2965e-05 - lr: 0.0010
Epoch 14/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1331 - accuracy: 0.9421 - jacard_coef: 9.8645e-04 2/17 [==>...........................] - ETA: 1s - loss: 0.1342 - accuracy: 0.9317 - jacard_coef: 0.0050     3/17 [====>.........................] - ETA: 1s - loss: 0.1340 - accuracy: 0.9289 - jacard_coef: 0.0047 4/17 [======>.......................] - ETA: 1s - loss: 0.1340 - accuracy: 0.9280 - jacard_coef: 0.0040 5/17 [=======>......................] - ETA: 1s - loss: 0.1336 - accuracy: 0.9300 - jacard_coef: 0.0035 6/17 [=========>....................] - ETA: 1s - loss: 0.1343 - accuracy: 0.9221 - jacard_coef: 0.0032 7/17 [===========>..................] - ETA: 1s - loss: 0.1347 - accuracy: 0.9187 - jacard_coef: 0.0028 8/17 [=============>................] - ETA: 1s - loss: 0.1347 - accuracy: 0.9184 - jacard_coef: 0.0026 9/17 [==============>...............] - ETA: 1s - loss: 0.1346 - accuracy: 0.9200 - jacard_coef: 0.002310/17 [================>.............] - ETA: 0s - loss: 0.1344 - accuracy: 0.9215 - jacard_coef: 0.002211/17 [==================>...........] - ETA: 0s - loss: 0.1346 - accuracy: 0.9189 - jacard_coef: 0.002012/17 [====================>.........] - ETA: 0s - loss: 0.1344 - accuracy: 0.9201 - jacard_coef: 0.001813/17 [=====================>........] - ETA: 0s - loss: 0.1348 - accuracy: 0.9171 - jacard_coef: 0.001714/17 [=======================>......] - ETA: 0s - loss: 0.1346 - accuracy: 0.9180 - jacard_coef: 0.001615/17 [=========================>....] - ETA: 0s - loss: 0.1344 - accuracy: 0.9194 - jacard_coef: 0.001516/17 [===========================>..] - ETA: 0s - loss: 0.1348 - accuracy: 0.9148 - jacard_coef: 0.001417/17 [==============================] - 2s 128ms/step - loss: 0.1348 - accuracy: 0.9137 - jacard_coef: 0.0016 - val_loss: 0.1460 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 5.0000e-04
Epoch 15/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1336 - accuracy: 0.9232 - jacard_coef: 3.4770e-04 2/17 [==>...........................] - ETA: 1s - loss: 0.1345 - accuracy: 0.9163 - jacard_coef: 5.3134e-04 3/17 [====>.........................] - ETA: 1s - loss: 0.1369 - accuracy: 0.8978 - jacard_coef: 3.5423e-04 4/17 [======>.......................] - ETA: 1s - loss: 0.1364 - accuracy: 0.9012 - jacard_coef: 3.2488e-04 5/17 [=======>......................] - ETA: 1s - loss: 0.1359 - accuracy: 0.9117 - jacard_coef: 0.0018     6/17 [=========>....................] - ETA: 1s - loss: 0.1361 - accuracy: 0.9083 - jacard_coef: 0.0015 7/17 [===========>..................] - ETA: 1s - loss: 0.1358 - accuracy: 0.9129 - jacard_coef: 0.0017 8/17 [=============>................] - ETA: 1s - loss: 0.1358 - accuracy: 0.9117 - jacard_coef: 0.0015 9/17 [==============>...............] - ETA: 1s - loss: 0.1356 - accuracy: 0.9131 - jacard_coef: 0.001410/17 [================>.............] - ETA: 0s - loss: 0.1351 - accuracy: 0.9172 - jacard_coef: 0.001311/17 [==================>...........] - ETA: 0s - loss: 0.1350 - accuracy: 0.9178 - jacard_coef: 0.001212/17 [====================>.........] - ETA: 0s - loss: 0.1352 - accuracy: 0.9165 - jacard_coef: 0.001213/17 [=====================>........] - ETA: 0s - loss: 0.1352 - accuracy: 0.9161 - jacard_coef: 0.001114/17 [=======================>......] - ETA: 0s - loss: 0.1356 - accuracy: 0.9131 - jacard_coef: 9.9805e-0415/17 [=========================>....] - ETA: 0s - loss: 0.1357 - accuracy: 0.9131 - jacard_coef: 9.3151e-0416/17 [===========================>..] - ETA: 0s - loss: 0.1353 - accuracy: 0.9162 - jacard_coef: 8.7329e-0417/17 [==============================] - 2s 128ms/step - loss: 0.1353 - accuracy: 0.9164 - jacard_coef: 8.2192e-04 - val_loss: 0.1427 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 5.0000e-04
Epoch 16/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1373 - accuracy: 0.9041 - jacard_coef: 1.9894e-05 2/17 [==>...........................] - ETA: 1s - loss: 0.1363 - accuracy: 0.9069 - jacard_coef: 4.1650e-05 3/17 [====>.........................] - ETA: 1s - loss: 0.1346 - accuracy: 0.9168 - jacard_coef: 2.7767e-05 4/17 [======>.......................] - ETA: 1s - loss: 0.1340 - accuracy: 0.9224 - jacard_coef: 3.6504e-04 5/17 [=======>......................] - ETA: 1s - loss: 0.1337 - accuracy: 0.9216 - jacard_coef: 2.9203e-04 6/17 [=========>....................] - ETA: 1s - loss: 0.1336 - accuracy: 0.9198 - jacard_coef: 2.4692e-04 7/17 [===========>..................] - ETA: 1s - loss: 0.1336 - accuracy: 0.9179 - jacard_coef: 6.4515e-04 8/17 [=============>................] - ETA: 1s - loss: 0.1337 - accuracy: 0.9168 - jacard_coef: 5.9348e-04 9/17 [==============>...............] - ETA: 1s - loss: 0.1336 - accuracy: 0.9184 - jacard_coef: 9.2945e-0410/17 [================>.............] - ETA: 0s - loss: 0.1336 - accuracy: 0.9175 - jacard_coef: 0.0010    11/17 [==================>...........] - ETA: 0s - loss: 0.1335 - accuracy: 0.9175 - jacard_coef: 9.2787e-0412/17 [====================>.........] - ETA: 0s - loss: 0.1334 - accuracy: 0.9185 - jacard_coef: 0.0010    13/17 [=====================>........] - ETA: 0s - loss: 0.1335 - accuracy: 0.9178 - jacard_coef: 0.001114/17 [=======================>......] - ETA: 0s - loss: 0.1332 - accuracy: 0.9199 - jacard_coef: 0.001615/17 [=========================>....] - ETA: 0s - loss: 0.1332 - accuracy: 0.9185 - jacard_coef: 0.001516/17 [===========================>..] - ETA: 0s - loss: 0.1333 - accuracy: 0.9166 - jacard_coef: 0.001417/17 [==============================] - 2s 128ms/step - loss: 0.1333 - accuracy: 0.9162 - jacard_coef: 0.0013 - val_loss: 0.1433 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 5.0000e-04
Epoch 17/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1289 - accuracy: 0.9345 - jacard_coef: 2.9121e-05 2/17 [==>...........................] - ETA: 1s - loss: 0.1291 - accuracy: 0.9336 - jacard_coef: 1.4560e-05 3/17 [====>.........................] - ETA: 1s - loss: 0.1297 - accuracy: 0.9314 - jacard_coef: 1.4883e-04 4/17 [======>.......................] - ETA: 1s - loss: 0.1300 - accuracy: 0.9298 - jacard_coef: 1.6244e-04 5/17 [=======>......................] - ETA: 1s - loss: 0.1298 - accuracy: 0.9310 - jacard_coef: 1.4183e-04 6/17 [=========>....................] - ETA: 1s - loss: 0.1301 - accuracy: 0.9281 - jacard_coef: 1.1819e-04 7/17 [===========>..................] - ETA: 1s - loss: 0.1306 - accuracy: 0.9228 - jacard_coef: 1.0131e-04 8/17 [=============>................] - ETA: 1s - loss: 0.1309 - accuracy: 0.9210 - jacard_coef: 9.1240e-05 9/17 [==============>...............] - ETA: 1s - loss: 0.1309 - accuracy: 0.9194 - jacard_coef: 2.4262e-0410/17 [================>.............] - ETA: 0s - loss: 0.1306 - accuracy: 0.9219 - jacard_coef: 3.2452e-0411/17 [==================>...........] - ETA: 0s - loss: 0.1311 - accuracy: 0.9181 - jacard_coef: 2.9935e-0412/17 [====================>.........] - ETA: 0s - loss: 0.1308 - accuracy: 0.9208 - jacard_coef: 8.1206e-0413/17 [=====================>........] - ETA: 0s - loss: 0.1311 - accuracy: 0.9171 - jacard_coef: 8.5150e-0414/17 [=======================>......] - ETA: 0s - loss: 0.1310 - accuracy: 0.9176 - jacard_coef: 8.2624e-0415/17 [=========================>....] - ETA: 0s - loss: 0.1310 - accuracy: 0.9180 - jacard_coef: 0.0013    16/17 [===========================>..] - ETA: 0s - loss: 0.1310 - accuracy: 0.9166 - jacard_coef: 0.001417/17 [==============================] - 2s 128ms/step - loss: 0.1311 - accuracy: 0.9162 - jacard_coef: 0.0014 - val_loss: 0.1397 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 5.0000e-04
Epoch 18/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1288 - accuracy: 0.9209 - jacard_coef: 5.7810e-04 2/17 [==>...........................] - ETA: 1s - loss: 0.1282 - accuracy: 0.9231 - jacard_coef: 9.1464e-04 3/17 [====>.........................] - ETA: 1s - loss: 0.1290 - accuracy: 0.9205 - jacard_coef: 7.8999e-04 4/17 [======>.......................] - ETA: 1s - loss: 0.1298 - accuracy: 0.9141 - jacard_coef: 7.9617e-04 5/17 [=======>......................] - ETA: 1s - loss: 0.1294 - accuracy: 0.9155 - jacard_coef: 6.3693e-04 6/17 [=========>....................] - ETA: 1s - loss: 0.1290 - accuracy: 0.9179 - jacard_coef: 0.0015     7/17 [===========>..................] - ETA: 1s - loss: 0.1292 - accuracy: 0.9155 - jacard_coef: 0.0017 8/17 [=============>................] - ETA: 1s - loss: 0.1291 - accuracy: 0.9173 - jacard_coef: 0.0017 9/17 [==============>...............] - ETA: 1s - loss: 0.1289 - accuracy: 0.9185 - jacard_coef: 0.001610/17 [================>.............] - ETA: 0s - loss: 0.1287 - accuracy: 0.9189 - jacard_coef: 0.002511/17 [==================>...........] - ETA: 0s - loss: 0.1289 - accuracy: 0.9172 - jacard_coef: 0.002612/17 [====================>.........] - ETA: 0s - loss: 0.1289 - accuracy: 0.9167 - jacard_coef: 0.002413/17 [=====================>........] - ETA: 0s - loss: 0.1288 - accuracy: 0.9165 - jacard_coef: 0.002414/17 [=======================>......] - ETA: 0s - loss: 0.1288 - accuracy: 0.9171 - jacard_coef: 0.002415/17 [=========================>....] - ETA: 0s - loss: 0.1291 - accuracy: 0.9148 - jacard_coef: 0.002216/17 [===========================>..] - ETA: 0s - loss: 0.1289 - accuracy: 0.9160 - jacard_coef: 0.002217/17 [==============================] - 2s 128ms/step - loss: 0.1289 - accuracy: 0.9154 - jacard_coef: 0.0031 - val_loss: 0.1364 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 5.0000e-04
/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(

âœ“ Training completed successfully!
  Best Val Jaccard: 0.0698 (epoch 8)
  Final Val Loss: 0.1364
  Training Time: 0:01:24.751752
  Stability (std): 0.0086

Results saved to: hyperparameter_optimization_20250926_165036/exp_1_UNet_lr1e-4_bs8/UNet_lr0.0001_bs8_results.json
