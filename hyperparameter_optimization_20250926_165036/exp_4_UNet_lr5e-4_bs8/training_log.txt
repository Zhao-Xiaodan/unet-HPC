✓ GPU memory growth enabled for 1 GPUs
Loading dataset...
Loaded 144 images and 144 masks
Training set: (129, 256, 256, 3), Validation set: (15, 256, 256, 3)

============================================================
TRAINING: UNet
Learning Rate: 0.0005, Batch Size: 8, Epochs: 30
============================================================
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 256, 256, 64)         640       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 256, 256, 64)         256       ['conv2d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 activation (Activation)     (None, 256, 256, 64)         0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['activation[0][0]']          
                                                                                                  
 batch_normalization_1 (Bat  (None, 256, 256, 64)         256       ['conv2d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_1 (Activation)   (None, 256, 256, 64)         0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['activation_1[0][0]']        
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       
                                                                                                  
 batch_normalization_2 (Bat  (None, 128, 128, 128)        512       ['conv2d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_2 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_3 (Conv2D)           (None, 128, 128, 128)        147584    ['activation_2[0][0]']        
                                                                                                  
 batch_normalization_3 (Bat  (None, 128, 128, 128)        512       ['conv2d_3[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_3 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_3[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_3[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 batch_normalization_4 (Bat  (None, 64, 64, 256)          1024      ['conv2d_4[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_4 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_4[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_5 (Conv2D)           (None, 64, 64, 256)          590080    ['activation_4[0][0]']        
                                                                                                  
 batch_normalization_5 (Bat  (None, 64, 64, 256)          1024      ['conv2d_5[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_5 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_5[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_5[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 512)          1180160   ['max_pooling2d_2[0][0]']     
                                                                                                  
 batch_normalization_6 (Bat  (None, 32, 32, 512)          2048      ['conv2d_6[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_6 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_6[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 32, 32, 512)          2359808   ['activation_6[0][0]']        
                                                                                                  
 batch_normalization_7 (Bat  (None, 32, 32, 512)          2048      ['conv2d_7[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_7 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_7[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_3 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_7[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 1024)         4719616   ['max_pooling2d_3[0][0]']     
                                                                                                  
 batch_normalization_8 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_8[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_8 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_8[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 1024)         9438208   ['activation_8[0][0]']        
                                                                                                  
 batch_normalization_9 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_9[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_9 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_9[0][0]'
                                                                    ]                             
                                                                                                  
 up_sampling2d (UpSampling2  (None, 32, 32, 1024)         0         ['activation_9[0][0]']        
 D)                                                                                               
                                                                                                  
 concatenate (Concatenate)   (None, 32, 32, 1536)         0         ['up_sampling2d[0][0]',       
                                                                     'activation_7[0][0]']        
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate[0][0]']         
                                                                                                  
 batch_normalization_10 (Ba  (None, 32, 32, 512)          2048      ['conv2d_10[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_10 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_10[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_10[0][0]']       
                                                                                                  
 batch_normalization_11 (Ba  (None, 32, 32, 512)          2048      ['conv2d_11[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_11 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_11[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 64, 64, 512)          0         ['activation_11[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_1 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_1[0][0]',     
 )                                                                   'activation_5[0][0]']        
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_1[0][0]']       
                                                                                                  
 batch_normalization_12 (Ba  (None, 64, 64, 256)          1024      ['conv2d_12[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_12 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_12[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_13 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_12[0][0]']       
                                                                                                  
 batch_normalization_13 (Ba  (None, 64, 64, 256)          1024      ['conv2d_13[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_13 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_13[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 128, 128, 256)        0         ['activation_13[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_2 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_2[0][0]',     
 )                                                                   'activation_3[0][0]']        
                                                                                                  
 conv2d_14 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_2[0][0]']       
                                                                                                  
 batch_normalization_14 (Ba  (None, 128, 128, 128)        512       ['conv2d_14[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_14 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_14[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_15 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_14[0][0]']       
                                                                                                  
 batch_normalization_15 (Ba  (None, 128, 128, 128)        512       ['conv2d_15[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_15 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_15[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 256, 256, 128)        0         ['activation_15[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_3 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_3[0][0]',     
 )                                                                   'activation_1[0][0]']        
                                                                                                  
 conv2d_16 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_3[0][0]']       
                                                                                                  
 batch_normalization_16 (Ba  (None, 256, 256, 64)         256       ['conv2d_16[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_16 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_16[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_16[0][0]']       
                                                                                                  
 batch_normalization_17 (Ba  (None, 256, 256, 64)         256       ['conv2d_17[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_17 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_17[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_18 (Conv2D)          (None, 256, 256, 1)          65        ['activation_17[0][0]']       
                                                                                                  
 batch_normalization_18 (Ba  (None, 256, 256, 1)          4         ['conv2d_18[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_18 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_18[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31401349 (119.79 MB)
Trainable params: 31389571 (119.74 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
None
✓ focal_loss imported successfully
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_2 (InputLayer)        [(None, 256, 256, 3)]        0         []                            
                                                                                                  
 conv2d_19 (Conv2D)          (None, 256, 256, 64)         1792      ['input_2[0][0]']             
                                                                                                  
 batch_normalization_19 (Ba  (None, 256, 256, 64)         256       ['conv2d_19[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_19 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_19[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_20 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_19[0][0]']       
                                                                                                  
 batch_normalization_20 (Ba  (None, 256, 256, 64)         256       ['conv2d_20[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_20 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_20[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_4 (MaxPoolin  (None, 128, 128, 64)         0         ['activation_20[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_21 (Conv2D)          (None, 128, 128, 128)        73856     ['max_pooling2d_4[0][0]']     
                                                                                                  
 batch_normalization_21 (Ba  (None, 128, 128, 128)        512       ['conv2d_21[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_21 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_21[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_22 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_21[0][0]']       
                                                                                                  
 batch_normalization_22 (Ba  (None, 128, 128, 128)        512       ['conv2d_22[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_22 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_22[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_5 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_22[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_23 (Conv2D)          (None, 64, 64, 256)          295168    ['max_pooling2d_5[0][0]']     
                                                                                                  
 batch_normalization_23 (Ba  (None, 64, 64, 256)          1024      ['conv2d_23[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_23 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_23[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_24 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_23[0][0]']       
                                                                                                  
 batch_normalization_24 (Ba  (None, 64, 64, 256)          1024      ['conv2d_24[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_24 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_24[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_6 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_24[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_25 (Conv2D)          (None, 32, 32, 512)          1180160   ['max_pooling2d_6[0][0]']     
                                                                                                  
 batch_normalization_25 (Ba  (None, 32, 32, 512)          2048      ['conv2d_25[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_25 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_25[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_26 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_25[0][0]']       
                                                                                                  
 batch_normalization_26 (Ba  (None, 32, 32, 512)          2048      ['conv2d_26[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_26 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_26[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_7 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_26[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_27 (Conv2D)          (None, 16, 16, 1024)         4719616   ['max_pooling2d_7[0][0]']     
                                                                                                  
 batch_normalization_27 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_27[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_27 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_27[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_28 (Conv2D)          (None, 16, 16, 1024)         9438208   ['activation_27[0][0]']       
                                                                                                  
 batch_normalization_28 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_28[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_28 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_28[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 1024)         0         ['activation_28[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_4 (Concatenate  (None, 32, 32, 1536)         0         ['up_sampling2d_4[0][0]',     
 )                                                                   'activation_26[0][0]']       
                                                                                                  
 conv2d_29 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate_4[0][0]']       
                                                                                                  
 batch_normalization_29 (Ba  (None, 32, 32, 512)          2048      ['conv2d_29[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_29 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_29[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_30 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_29[0][0]']       
                                                                                                  
 batch_normalization_30 (Ba  (None, 32, 32, 512)          2048      ['conv2d_30[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_30 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_30[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 512)          0         ['activation_30[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_5 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_5[0][0]',     
 )                                                                   'activation_24[0][0]']       
                                                                                                  
 conv2d_31 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_5[0][0]']       
                                                                                                  
 batch_normalization_31 (Ba  (None, 64, 64, 256)          1024      ['conv2d_31[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_31 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_31[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_32 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_31[0][0]']       
                                                                                                  
 batch_normalization_32 (Ba  (None, 64, 64, 256)          1024      ['conv2d_32[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_32 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_32[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_6 (UpSamplin  (None, 128, 128, 256)        0         ['activation_32[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_6 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_6[0][0]',     
 )                                                                   'activation_22[0][0]']       
                                                                                                  
 conv2d_33 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_6[0][0]']       
                                                                                                  
 batch_normalization_33 (Ba  (None, 128, 128, 128)        512       ['conv2d_33[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_33 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_33[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_34 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_33[0][0]']       
                                                                                                  
 batch_normalization_34 (Ba  (None, 128, 128, 128)        512       ['conv2d_34[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_34 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_34[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_7 (UpSamplin  (None, 256, 256, 128)        0         ['activation_34[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_7 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_7[0][0]',     
 )                                                                   'activation_20[0][0]']       
                                                                                                  
 conv2d_35 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_7[0][0]']       
                                                                                                  
 batch_normalization_35 (Ba  (None, 256, 256, 64)         256       ['conv2d_35[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_35 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_35[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_36 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_35[0][0]']       
                                                                                                  
 batch_normalization_36 (Ba  (None, 256, 256, 64)         256       ['conv2d_36[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_36 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_36[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_37 (Conv2D)          (None, 256, 256, 1)          65        ['activation_36[0][0]']       
                                                                                                  
 batch_normalization_37 (Ba  (None, 256, 256, 1)          4         ['conv2d_37[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_37 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_37[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31402501 (119.79 MB)
Trainable params: 31390723 (119.75 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
WARNING:absl:`lr` is deprecated in TF-Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
None
Epoch 1/30
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1758877007.910028 1035153 service.cc:145] XLA service 0x14edb1b63db0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1758877007.910053 1035153 service.cc:153]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6
I0000 00:00:1758877008.047200 1035153 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
 1/17 [>.............................] - ETA: 8:38 - loss: 0.3458 - accuracy: 0.5009 - jacard_coef: 0.0837 2/17 [==>...........................] - ETA: 53s - loss: 0.3285 - accuracy: 0.4808 - jacard_coef: 0.0967  3/17 [====>.........................] - ETA: 33s - loss: 0.2991 - accuracy: 0.4096 - jacard_coef: 0.0950 4/17 [======>.......................] - ETA: 25s - loss: 0.2880 - accuracy: 0.3600 - jacard_coef: 0.0912 5/17 [=======>......................] - ETA: 18s - loss: 0.2729 - accuracy: 0.3197 - jacard_coef: 0.0901 6/17 [=========>....................] - ETA: 14s - loss: 0.2600 - accuracy: 0.2981 - jacard_coef: 0.0849 7/17 [===========>..................] - ETA: 11s - loss: 0.2516 - accuracy: 0.2898 - jacard_coef: 0.0847 8/17 [=============>................] - ETA: 8s - loss: 0.2450 - accuracy: 0.2785 - jacard_coef: 0.0837  9/17 [==============>...............] - ETA: 7s - loss: 0.2387 - accuracy: 0.2720 - jacard_coef: 0.084610/17 [================>.............] - ETA: 5s - loss: 0.2339 - accuracy: 0.2670 - jacard_coef: 0.084811/17 [==================>...........] - ETA: 4s - loss: 0.2304 - accuracy: 0.2571 - jacard_coef: 0.083712/17 [====================>.........] - ETA: 3s - loss: 0.2302 - accuracy: 0.2502 - jacard_coef: 0.082713/17 [=====================>........] - ETA: 2s - loss: 0.2273 - accuracy: 0.2467 - jacard_coef: 0.081214/17 [=======================>......] - ETA: 1s - loss: 0.2246 - accuracy: 0.2448 - jacard_coef: 0.082715/17 [=========================>....] - ETA: 1s - loss: 0.2221 - accuracy: 0.2447 - jacard_coef: 0.081116/17 [===========================>..] - ETA: 0s - loss: 0.2199 - accuracy: 0.2432 - jacard_coef: 0.080517/17 [==============================] - ETA: 0s - loss: 0.2196 - accuracy: 0.2438 - jacard_coef: 0.088417/17 [==============================] - 46s 867ms/step - loss: 0.2196 - accuracy: 0.2438 - jacard_coef: 0.0884 - val_loss: 0.3903 - val_accuracy: 0.9296 - val_jacard_coef: 1.4291e-04 - lr: 0.0010
Epoch 2/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1862 - accuracy: 0.2270 - jacard_coef: 0.1233 2/17 [==>...........................] - ETA: 1s - loss: 0.1859 - accuracy: 0.2071 - jacard_coef: 0.0922 3/17 [====>.........................] - ETA: 1s - loss: 0.1850 - accuracy: 0.2209 - jacard_coef: 0.0772 4/17 [======>.......................] - ETA: 1s - loss: 0.1884 - accuracy: 0.2314 - jacard_coef: 0.0758 5/17 [=======>......................] - ETA: 1s - loss: 0.1873 - accuracy: 0.2348 - jacard_coef: 0.0769 6/17 [=========>....................] - ETA: 1s - loss: 0.1870 - accuracy: 0.2509 - jacard_coef: 0.0786 7/17 [===========>..................] - ETA: 1s - loss: 0.1858 - accuracy: 0.2671 - jacard_coef: 0.0805 8/17 [=============>................] - ETA: 1s - loss: 0.1852 - accuracy: 0.2702 - jacard_coef: 0.0835 9/17 [==============>...............] - ETA: 1s - loss: 0.1844 - accuracy: 0.2742 - jacard_coef: 0.079610/17 [================>.............] - ETA: 0s - loss: 0.1836 - accuracy: 0.2847 - jacard_coef: 0.081111/17 [==================>...........] - ETA: 0s - loss: 0.1830 - accuracy: 0.2914 - jacard_coef: 0.083112/17 [====================>.........] - ETA: 0s - loss: 0.1823 - accuracy: 0.3024 - jacard_coef: 0.082813/17 [=====================>........] - ETA: 0s - loss: 0.1817 - accuracy: 0.3148 - jacard_coef: 0.080014/17 [=======================>......] - ETA: 0s - loss: 0.1829 - accuracy: 0.3208 - jacard_coef: 0.079815/17 [=========================>....] - ETA: 0s - loss: 0.1828 - accuracy: 0.3335 - jacard_coef: 0.077516/17 [===========================>..] - ETA: 0s - loss: 0.1830 - accuracy: 0.3452 - jacard_coef: 0.077517/17 [==============================] - 2s 131ms/step - loss: 0.1831 - accuracy: 0.3440 - jacard_coef: 0.0821 - val_loss: 0.6800 - val_accuracy: 0.7966 - val_jacard_coef: 0.0330 - lr: 0.0010
Epoch 3/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1834 - accuracy: 0.2565 - jacard_coef: 0.1192 2/17 [==>...........................] - ETA: 1s - loss: 0.1848 - accuracy: 0.2017 - jacard_coef: 0.1078 3/17 [====>.........................] - ETA: 1s - loss: 0.1849 - accuracy: 0.1971 - jacard_coef: 0.0999 4/17 [======>.......................] - ETA: 1s - loss: 0.1841 - accuracy: 0.1924 - jacard_coef: 0.0856 5/17 [=======>......................] - ETA: 1s - loss: 0.1847 - accuracy: 0.1883 - jacard_coef: 0.0852 6/17 [=========>....................] - ETA: 1s - loss: 0.1837 - accuracy: 0.1976 - jacard_coef: 0.0816 7/17 [===========>..................] - ETA: 1s - loss: 0.1850 - accuracy: 0.1959 - jacard_coef: 0.0810 8/17 [=============>................] - ETA: 1s - loss: 0.1845 - accuracy: 0.2052 - jacard_coef: 0.0862 9/17 [==============>...............] - ETA: 1s - loss: 0.1839 - accuracy: 0.2212 - jacard_coef: 0.084510/17 [================>.............] - ETA: 0s - loss: 0.1834 - accuracy: 0.2387 - jacard_coef: 0.084111/17 [==================>...........] - ETA: 0s - loss: 0.1830 - accuracy: 0.2499 - jacard_coef: 0.081812/17 [====================>.........] - ETA: 0s - loss: 0.1821 - accuracy: 0.2699 - jacard_coef: 0.079213/17 [=====================>........] - ETA: 0s - loss: 0.1816 - accuracy: 0.2807 - jacard_coef: 0.078514/17 [=======================>......] - ETA: 0s - loss: 0.1808 - accuracy: 0.3004 - jacard_coef: 0.076915/17 [=========================>....] - ETA: 0s - loss: 0.1801 - accuracy: 0.3154 - jacard_coef: 0.078016/17 [===========================>..] - ETA: 0s - loss: 0.1796 - accuracy: 0.3292 - jacard_coef: 0.079617/17 [==============================] - 2s 128ms/step - loss: 0.1799 - accuracy: 0.3290 - jacard_coef: 0.0777 - val_loss: 1.0501 - val_accuracy: 0.9296 - val_jacard_coef: 1.8871e-04 - lr: 0.0010
Epoch 4/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1908 - accuracy: 0.3609 - jacard_coef: 0.0970 2/17 [==>...........................] - ETA: 1s - loss: 0.1861 - accuracy: 0.3005 - jacard_coef: 0.0776 3/17 [====>.........................] - ETA: 1s - loss: 0.1856 - accuracy: 0.2669 - jacard_coef: 0.0700 4/17 [======>.......................] - ETA: 1s - loss: 0.1837 - accuracy: 0.2676 - jacard_coef: 0.0649 5/17 [=======>......................] - ETA: 1s - loss: 0.1823 - accuracy: 0.2830 - jacard_coef: 0.0732 6/17 [=========>....................] - ETA: 1s - loss: 0.1815 - accuracy: 0.3015 - jacard_coef: 0.0797 7/17 [===========>..................] - ETA: 1s - loss: 0.1810 - accuracy: 0.3214 - jacard_coef: 0.0752 8/17 [=============>................] - ETA: 1s - loss: 0.1811 - accuracy: 0.3373 - jacard_coef: 0.0778 9/17 [==============>...............] - ETA: 1s - loss: 0.1805 - accuracy: 0.3525 - jacard_coef: 0.078910/17 [================>.............] - ETA: 0s - loss: 0.1803 - accuracy: 0.3549 - jacard_coef: 0.082211/17 [==================>...........] - ETA: 0s - loss: 0.1820 - accuracy: 0.3577 - jacard_coef: 0.081612/17 [====================>.........] - ETA: 0s - loss: 0.1813 - accuracy: 0.3644 - jacard_coef: 0.078313/17 [=====================>........] - ETA: 0s - loss: 0.1819 - accuracy: 0.3664 - jacard_coef: 0.076514/17 [=======================>......] - ETA: 0s - loss: 0.1813 - accuracy: 0.3727 - jacard_coef: 0.075915/17 [=========================>....] - ETA: 0s - loss: 0.1806 - accuracy: 0.3818 - jacard_coef: 0.076216/17 [===========================>..] - ETA: 0s - loss: 0.1807 - accuracy: 0.3904 - jacard_coef: 0.078517/17 [==============================] - 2s 128ms/step - loss: 0.1807 - accuracy: 0.3911 - jacard_coef: 0.0763 - val_loss: 1.1218 - val_accuracy: 0.9304 - val_jacard_coef: 3.4108e-12 - lr: 0.0010
Epoch 5/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1726 - accuracy: 0.4328 - jacard_coef: 0.0601 2/17 [==>...........................] - ETA: 1s - loss: 0.1767 - accuracy: 0.4243 - jacard_coef: 0.0995 3/17 [====>.........................] - ETA: 1s - loss: 0.1766 - accuracy: 0.4116 - jacard_coef: 0.0971 4/17 [======>.......................] - ETA: 1s - loss: 0.1824 - accuracy: 0.3842 - jacard_coef: 0.0874 5/17 [=======>......................] - ETA: 1s - loss: 0.1811 - accuracy: 0.3735 - jacard_coef: 0.0791 6/17 [=========>....................] - ETA: 1s - loss: 0.1800 - accuracy: 0.3730 - jacard_coef: 0.0796 7/17 [===========>..................] - ETA: 1s - loss: 0.1802 - accuracy: 0.3690 - jacard_coef: 0.0808 8/17 [=============>................] - ETA: 1s - loss: 0.1796 - accuracy: 0.3730 - jacard_coef: 0.0795 9/17 [==============>...............] - ETA: 1s - loss: 0.1803 - accuracy: 0.3597 - jacard_coef: 0.079610/17 [================>.............] - ETA: 0s - loss: 0.1802 - accuracy: 0.3698 - jacard_coef: 0.078911/17 [==================>...........] - ETA: 0s - loss: 0.1814 - accuracy: 0.3615 - jacard_coef: 0.077512/17 [====================>.........] - ETA: 0s - loss: 0.1804 - accuracy: 0.3844 - jacard_coef: 0.078213/17 [=====================>........] - ETA: 0s - loss: 0.1799 - accuracy: 0.3807 - jacard_coef: 0.077114/17 [=======================>......] - ETA: 0s - loss: 0.1808 - accuracy: 0.3780 - jacard_coef: 0.077815/17 [=========================>....] - ETA: 0s - loss: 0.1799 - accuracy: 0.3963 - jacard_coef: 0.076716/17 [===========================>..] - ETA: 0s - loss: 0.1792 - accuracy: 0.4045 - jacard_coef: 0.076717/17 [==============================] - 2s 128ms/step - loss: 0.1792 - accuracy: 0.4052 - jacard_coef: 0.0778 - val_loss: 0.4334 - val_accuracy: 0.9213 - val_jacard_coef: 0.0039 - lr: 0.0010
Epoch 6/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1940 - accuracy: 0.5843 - jacard_coef: 0.0828 2/17 [==>...........................] - ETA: 1s - loss: 0.1810 - accuracy: 0.6363 - jacard_coef: 0.0831 3/17 [====>.........................] - ETA: 1s - loss: 0.1760 - accuracy: 0.6692 - jacard_coef: 0.0786 4/17 [======>.......................] - ETA: 1s - loss: 0.1733 - accuracy: 0.6801 - jacard_coef: 0.0743 5/17 [=======>......................] - ETA: 1s - loss: 0.1724 - accuracy: 0.6812 - jacard_coef: 0.0739 6/17 [=========>....................] - ETA: 1s - loss: 0.1743 - accuracy: 0.6665 - jacard_coef: 0.0707 7/17 [===========>..................] - ETA: 1s - loss: 0.1731 - accuracy: 0.6689 - jacard_coef: 0.0708 8/17 [=============>................] - ETA: 1s - loss: 0.1722 - accuracy: 0.6685 - jacard_coef: 0.0663 9/17 [==============>...............] - ETA: 1s - loss: 0.1714 - accuracy: 0.6709 - jacard_coef: 0.068010/17 [================>.............] - ETA: 0s - loss: 0.1708 - accuracy: 0.6715 - jacard_coef: 0.067511/17 [==================>...........] - ETA: 0s - loss: 0.1701 - accuracy: 0.6813 - jacard_coef: 0.065412/17 [====================>.........] - ETA: 0s - loss: 0.1693 - accuracy: 0.6928 - jacard_coef: 0.063813/17 [=====================>........] - ETA: 0s - loss: 0.1687 - accuracy: 0.6882 - jacard_coef: 0.062114/17 [=======================>......] - ETA: 0s - loss: 0.1681 - accuracy: 0.7036 - jacard_coef: 0.059515/17 [=========================>....] - ETA: 0s - loss: 0.1676 - accuracy: 0.7176 - jacard_coef: 0.056216/17 [===========================>..] - ETA: 0s - loss: 0.1671 - accuracy: 0.7271 - jacard_coef: 0.055017/17 [==============================] - 2s 130ms/step - loss: 0.1671 - accuracy: 0.7247 - jacard_coef: 0.0592 - val_loss: 0.1799 - val_accuracy: 0.2408 - val_jacard_coef: 0.0701 - lr: 0.0010
Epoch 7/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1579 - accuracy: 0.9230 - jacard_coef: 0.0479 2/17 [==>...........................] - ETA: 1s - loss: 0.1592 - accuracy: 0.9169 - jacard_coef: 0.0343 3/17 [====>.........................] - ETA: 1s - loss: 0.1593 - accuracy: 0.8860 - jacard_coef: 0.0334 4/17 [======>.......................] - ETA: 1s - loss: 0.1598 - accuracy: 0.8708 - jacard_coef: 0.0363 5/17 [=======>......................] - ETA: 1s - loss: 0.1605 - accuracy: 0.8245 - jacard_coef: 0.0427 6/17 [=========>....................] - ETA: 1s - loss: 0.1605 - accuracy: 0.8298 - jacard_coef: 0.0380 7/17 [===========>..................] - ETA: 1s - loss: 0.1606 - accuracy: 0.8343 - jacard_coef: 0.0396 8/17 [=============>................] - ETA: 1s - loss: 0.1605 - accuracy: 0.8424 - jacard_coef: 0.0396 9/17 [==============>...............] - ETA: 1s - loss: 0.1602 - accuracy: 0.8492 - jacard_coef: 0.036810/17 [================>.............] - ETA: 0s - loss: 0.1601 - accuracy: 0.8473 - jacard_coef: 0.041111/17 [==================>...........] - ETA: 0s - loss: 0.1599 - accuracy: 0.8475 - jacard_coef: 0.041412/17 [====================>.........] - ETA: 0s - loss: 0.1596 - accuracy: 0.8505 - jacard_coef: 0.040313/17 [=====================>........] - ETA: 0s - loss: 0.1593 - accuracy: 0.8537 - jacard_coef: 0.039214/17 [=======================>......] - ETA: 0s - loss: 0.1600 - accuracy: 0.8565 - jacard_coef: 0.038215/17 [=========================>....] - ETA: 0s - loss: 0.1596 - accuracy: 0.8609 - jacard_coef: 0.036416/17 [===========================>..] - ETA: 0s - loss: 0.1596 - accuracy: 0.8632 - jacard_coef: 0.035817/17 [==============================] - 2s 130ms/step - loss: 0.1596 - accuracy: 0.8604 - jacard_coef: 0.0376 - val_loss: 0.1721 - val_accuracy: 0.5462 - val_jacard_coef: 0.0781 - lr: 0.0010
Epoch 8/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1539 - accuracy: 0.9202 - jacard_coef: 0.0060 2/17 [==>...........................] - ETA: 1s - loss: 0.1544 - accuracy: 0.9180 - jacard_coef: 0.0149 3/17 [====>.........................] - ETA: 1s - loss: 0.1559 - accuracy: 0.8864 - jacard_coef: 0.0203 4/17 [======>.......................] - ETA: 1s - loss: 0.1560 - accuracy: 0.8891 - jacard_coef: 0.0173 5/17 [=======>......................] - ETA: 1s - loss: 0.1561 - accuracy: 0.9010 - jacard_coef: 0.0165 6/17 [=========>....................] - ETA: 1s - loss: 0.1559 - accuracy: 0.8995 - jacard_coef: 0.0143 7/17 [===========>..................] - ETA: 1s - loss: 0.1557 - accuracy: 0.9009 - jacard_coef: 0.0123 8/17 [=============>................] - ETA: 1s - loss: 0.1556 - accuracy: 0.8998 - jacard_coef: 0.0113 9/17 [==============>...............] - ETA: 1s - loss: 0.1553 - accuracy: 0.9001 - jacard_coef: 0.010110/17 [================>.............] - ETA: 0s - loss: 0.1550 - accuracy: 0.9021 - jacard_coef: 0.009511/17 [==================>...........] - ETA: 0s - loss: 0.1546 - accuracy: 0.9050 - jacard_coef: 0.009112/17 [====================>.........] - ETA: 0s - loss: 0.1546 - accuracy: 0.9051 - jacard_coef: 0.009013/17 [=====================>........] - ETA: 0s - loss: 0.1541 - accuracy: 0.9063 - jacard_coef: 0.008514/17 [=======================>......] - ETA: 0s - loss: 0.1538 - accuracy: 0.9038 - jacard_coef: 0.011415/17 [=========================>....] - ETA: 0s - loss: 0.1536 - accuracy: 0.9035 - jacard_coef: 0.012516/17 [===========================>..] - ETA: 0s - loss: 0.1535 - accuracy: 0.9032 - jacard_coef: 0.013917/17 [==============================] - 2s 128ms/step - loss: 0.1535 - accuracy: 0.9013 - jacard_coef: 0.0132 - val_loss: 0.1696 - val_accuracy: 0.5464 - val_jacard_coef: 0.0516 - lr: 0.0010
Epoch 9/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1550 - accuracy: 0.8873 - jacard_coef: 1.6929e-12 2/17 [==>...........................] - ETA: 1s - loss: 0.1539 - accuracy: 0.9179 - jacard_coef: 0.0018     3/17 [====>.........................] - ETA: 1s - loss: 0.1547 - accuracy: 0.9039 - jacard_coef: 0.0012 4/17 [======>.......................] - ETA: 1s - loss: 0.1556 - accuracy: 0.8912 - jacard_coef: 0.0027 5/17 [=======>......................] - ETA: 1s - loss: 0.1557 - accuracy: 0.8933 - jacard_coef: 0.0023 6/17 [=========>....................] - ETA: 1s - loss: 0.1555 - accuracy: 0.8966 - jacard_coef: 0.0022 7/17 [===========>..................] - ETA: 1s - loss: 0.1548 - accuracy: 0.9050 - jacard_coef: 0.0019 8/17 [=============>................] - ETA: 1s - loss: 0.1547 - accuracy: 0.9035 - jacard_coef: 0.0019 9/17 [==============>...............] - ETA: 1s - loss: 0.1549 - accuracy: 0.9022 - jacard_coef: 0.003810/17 [================>.............] - ETA: 0s - loss: 0.1547 - accuracy: 0.9025 - jacard_coef: 0.003911/17 [==================>...........] - ETA: 0s - loss: 0.1561 - accuracy: 0.9049 - jacard_coef: 0.004112/17 [====================>.........] - ETA: 0s - loss: 0.1557 - accuracy: 0.9065 - jacard_coef: 0.004413/17 [=====================>........] - ETA: 0s - loss: 0.1554 - accuracy: 0.9081 - jacard_coef: 0.005514/17 [=======================>......] - ETA: 0s - loss: 0.1552 - accuracy: 0.9074 - jacard_coef: 0.007815/17 [=========================>....] - ETA: 0s - loss: 0.1549 - accuracy: 0.9077 - jacard_coef: 0.008416/17 [===========================>..] - ETA: 0s - loss: 0.1550 - accuracy: 0.9059 - jacard_coef: 0.009817/17 [==============================] - 2s 128ms/step - loss: 0.1554 - accuracy: 0.9053 - jacard_coef: 0.0109 - val_loss: 0.1263 - val_accuracy: 0.7862 - val_jacard_coef: 0.0368 - lr: 0.0010
Epoch 10/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1480 - accuracy: 0.9155 - jacard_coef: 0.0197 2/17 [==>...........................] - ETA: 1s - loss: 0.1520 - accuracy: 0.9027 - jacard_coef: 0.0202 3/17 [====>.........................] - ETA: 1s - loss: 0.1514 - accuracy: 0.8838 - jacard_coef: 0.0320 4/17 [======>.......................] - ETA: 1s - loss: 0.1515 - accuracy: 0.8800 - jacard_coef: 0.0309 5/17 [=======>......................] - ETA: 1s - loss: 0.1514 - accuracy: 0.8763 - jacard_coef: 0.0295 6/17 [=========>....................] - ETA: 1s - loss: 0.1512 - accuracy: 0.8790 - jacard_coef: 0.0261 7/17 [===========>..................] - ETA: 1s - loss: 0.1507 - accuracy: 0.8857 - jacard_coef: 0.0234 8/17 [=============>................] - ETA: 1s - loss: 0.1501 - accuracy: 0.8934 - jacard_coef: 0.0205 9/17 [==============>...............] - ETA: 1s - loss: 0.1499 - accuracy: 0.8937 - jacard_coef: 0.018310/17 [================>.............] - ETA: 0s - loss: 0.1500 - accuracy: 0.8889 - jacard_coef: 0.019811/17 [==================>...........] - ETA: 0s - loss: 0.1495 - accuracy: 0.8964 - jacard_coef: 0.018012/17 [====================>.........] - ETA: 0s - loss: 0.1493 - accuracy: 0.8976 - jacard_coef: 0.016513/17 [=====================>........] - ETA: 0s - loss: 0.1491 - accuracy: 0.8988 - jacard_coef: 0.015214/17 [=======================>......] - ETA: 0s - loss: 0.1489 - accuracy: 0.8980 - jacard_coef: 0.014215/17 [=========================>....] - ETA: 0s - loss: 0.1487 - accuracy: 0.9007 - jacard_coef: 0.013516/17 [===========================>..] - ETA: 0s - loss: 0.1484 - accuracy: 0.9013 - jacard_coef: 0.013017/17 [==============================] - 2s 128ms/step - loss: 0.1484 - accuracy: 0.9010 - jacard_coef: 0.0126 - val_loss: 0.1663 - val_accuracy: 0.6196 - val_jacard_coef: 0.0628 - lr: 0.0010
Epoch 11/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1433 - accuracy: 0.9478 - jacard_coef: 0.0046 2/17 [==>...........................] - ETA: 1s - loss: 0.1445 - accuracy: 0.9260 - jacard_coef: 0.0025 3/17 [====>.........................] - ETA: 1s - loss: 0.1452 - accuracy: 0.9171 - jacard_coef: 0.0017 4/17 [======>.......................] - ETA: 1s - loss: 0.1448 - accuracy: 0.9246 - jacard_coef: 0.0015 5/17 [=======>......................] - ETA: 1s - loss: 0.1447 - accuracy: 0.9305 - jacard_coef: 0.0035 6/17 [=========>....................] - ETA: 1s - loss: 0.1452 - accuracy: 0.9256 - jacard_coef: 0.0043 7/17 [===========>..................] - ETA: 1s - loss: 0.1454 - accuracy: 0.9211 - jacard_coef: 0.0041 8/17 [=============>................] - ETA: 1s - loss: 0.1454 - accuracy: 0.9148 - jacard_coef: 0.0072 9/17 [==============>...............] - ETA: 1s - loss: 0.1456 - accuracy: 0.9091 - jacard_coef: 0.010310/17 [================>.............] - ETA: 0s - loss: 0.1455 - accuracy: 0.9085 - jacard_coef: 0.009811/17 [==================>...........] - ETA: 0s - loss: 0.1454 - accuracy: 0.9077 - jacard_coef: 0.009012/17 [====================>.........] - ETA: 0s - loss: 0.1453 - accuracy: 0.9066 - jacard_coef: 0.008613/17 [=====================>........] - ETA: 0s - loss: 0.1452 - accuracy: 0.9074 - jacard_coef: 0.008214/17 [=======================>......] - ETA: 0s - loss: 0.1449 - accuracy: 0.9088 - jacard_coef: 0.007715/17 [=========================>....] - ETA: 0s - loss: 0.1447 - accuracy: 0.9082 - jacard_coef: 0.007316/17 [===========================>..] - ETA: 0s - loss: 0.1443 - accuracy: 0.9100 - jacard_coef: 0.006917/17 [==============================] - 2s 128ms/step - loss: 0.1443 - accuracy: 0.9106 - jacard_coef: 0.0065 - val_loss: 0.1527 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 0.0010
Epoch 12/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1424 - accuracy: 0.9003 - jacard_coef: 1.9129e-12 2/17 [==>...........................] - ETA: 1s - loss: 0.1414 - accuracy: 0.9095 - jacard_coef: 2.1307e-12 3/17 [====>.........................] - ETA: 1s - loss: 0.1412 - accuracy: 0.9052 - jacard_coef: 1.1064e-04 4/17 [======>.......................] - ETA: 1s - loss: 0.1407 - accuracy: 0.9106 - jacard_coef: 8.2983e-05 5/17 [=======>......................] - ETA: 1s - loss: 0.1412 - accuracy: 0.9062 - jacard_coef: 7.3217e-05 6/17 [=========>....................] - ETA: 1s - loss: 0.1408 - accuracy: 0.9115 - jacard_coef: 6.1014e-05 7/17 [===========>..................] - ETA: 1s - loss: 0.1404 - accuracy: 0.9141 - jacard_coef: 5.2298e-05 8/17 [=============>................] - ETA: 1s - loss: 0.1403 - accuracy: 0.9142 - jacard_coef: 1.5507e-04 9/17 [==============>...............] - ETA: 1s - loss: 0.1399 - accuracy: 0.9161 - jacard_coef: 2.2456e-0410/17 [================>.............] - ETA: 0s - loss: 0.1401 - accuracy: 0.9130 - jacard_coef: 0.0014    11/17 [==================>...........] - ETA: 0s - loss: 0.1399 - accuracy: 0.9127 - jacard_coef: 0.001612/17 [====================>.........] - ETA: 0s - loss: 0.1396 - accuracy: 0.9150 - jacard_coef: 0.001513/17 [=====================>........] - ETA: 0s - loss: 0.1391 - accuracy: 0.9176 - jacard_coef: 0.001314/17 [=======================>......] - ETA: 0s - loss: 0.1391 - accuracy: 0.9172 - jacard_coef: 0.001315/17 [=========================>....] - ETA: 0s - loss: 0.1389 - accuracy: 0.9177 - jacard_coef: 0.001216/17 [===========================>..] - ETA: 0s - loss: 0.1390 - accuracy: 0.9157 - jacard_coef: 0.001217/17 [==============================] - 2s 128ms/step - loss: 0.1392 - accuracy: 0.9159 - jacard_coef: 0.0015 - val_loss: 0.1521 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 0.0010
Epoch 13/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1393 - accuracy: 0.9218 - jacard_coef: 0.0227 2/17 [==>...........................] - ETA: 1s - loss: 0.1410 - accuracy: 0.8943 - jacard_coef: 0.0120 3/17 [====>.........................] - ETA: 1s - loss: 0.1403 - accuracy: 0.8956 - jacard_coef: 0.0105 4/17 [======>.......................] - ETA: 1s - loss: 0.1400 - accuracy: 0.8996 - jacard_coef: 0.0108 5/17 [=======>......................] - ETA: 1s - loss: 0.1392 - accuracy: 0.9059 - jacard_coef: 0.0105 6/17 [=========>....................] - ETA: 1s - loss: 0.1389 - accuracy: 0.9079 - jacard_coef: 0.0087 7/17 [===========>..................] - ETA: 1s - loss: 0.1392 - accuracy: 0.9040 - jacard_coef: 0.0104 8/17 [=============>................] - ETA: 1s - loss: 0.1387 - accuracy: 0.9059 - jacard_coef: 0.0093 9/17 [==============>...............] - ETA: 1s - loss: 0.1388 - accuracy: 0.9050 - jacard_coef: 0.008310/17 [================>.............] - ETA: 0s - loss: 0.1380 - accuracy: 0.9119 - jacard_coef: 0.008111/17 [==================>...........] - ETA: 0s - loss: 0.1377 - accuracy: 0.9154 - jacard_coef: 0.007612/17 [====================>.........] - ETA: 0s - loss: 0.1375 - accuracy: 0.9164 - jacard_coef: 0.007013/17 [=====================>........] - ETA: 0s - loss: 0.1376 - accuracy: 0.9159 - jacard_coef: 0.006414/17 [=======================>......] - ETA: 0s - loss: 0.1377 - accuracy: 0.9158 - jacard_coef: 0.006015/17 [=========================>....] - ETA: 0s - loss: 0.1376 - accuracy: 0.9149 - jacard_coef: 0.005616/17 [===========================>..] - ETA: 0s - loss: 0.1383 - accuracy: 0.9128 - jacard_coef: 0.005217/17 [==============================] - 2s 128ms/step - loss: 0.1383 - accuracy: 0.9124 - jacard_coef: 0.0049 - val_loss: 0.1560 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 5.0000e-04
Epoch 14/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1346 - accuracy: 0.9419 - jacard_coef: 3.2809e-12 2/17 [==>...........................] - ETA: 1s - loss: 0.1351 - accuracy: 0.9344 - jacard_coef: 2.9456e-12 3/17 [====>.........................] - ETA: 1s - loss: 0.1368 - accuracy: 0.9167 - jacard_coef: 2.4997e-12 4/17 [======>.......................] - ETA: 1s - loss: 0.1377 - accuracy: 0.9063 - jacard_coef: 2.2558e-12 5/17 [=======>......................] - ETA: 1s - loss: 0.1368 - accuracy: 0.9140 - jacard_coef: 2.4962e-12 6/17 [=========>....................] - ETA: 1s - loss: 0.1366 - accuracy: 0.9147 - jacard_coef: 2.4681e-12 7/17 [===========>..................] - ETA: 1s - loss: 0.1360 - accuracy: 0.9206 - jacard_coef: 6.2009e-06 8/17 [=============>................] - ETA: 1s - loss: 0.1358 - accuracy: 0.9221 - jacard_coef: 0.0013     9/17 [==============>...............] - ETA: 1s - loss: 0.1360 - accuracy: 0.9210 - jacard_coef: 0.001210/17 [================>.............] - ETA: 0s - loss: 0.1358 - accuracy: 0.9218 - jacard_coef: 0.001711/17 [==================>...........] - ETA: 0s - loss: 0.1359 - accuracy: 0.9202 - jacard_coef: 0.001512/17 [====================>.........] - ETA: 0s - loss: 0.1360 - accuracy: 0.9187 - jacard_coef: 0.002213/17 [=====================>........] - ETA: 0s - loss: 0.1360 - accuracy: 0.9182 - jacard_coef: 0.002514/17 [=======================>......] - ETA: 0s - loss: 0.1360 - accuracy: 0.9167 - jacard_coef: 0.002915/17 [=========================>....] - ETA: 0s - loss: 0.1358 - accuracy: 0.9175 - jacard_coef: 0.002716/17 [===========================>..] - ETA: 0s - loss: 0.1362 - accuracy: 0.9162 - jacard_coef: 0.002717/17 [==============================] - 2s 128ms/step - loss: 0.1362 - accuracy: 0.9153 - jacard_coef: 0.0040 - val_loss: 0.1518 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 5.0000e-04
Epoch 15/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1320 - accuracy: 0.9319 - jacard_coef: 0.0080 2/17 [==>...........................] - ETA: 1s - loss: 0.1335 - accuracy: 0.9250 - jacard_coef: 0.0040 3/17 [====>.........................] - ETA: 1s - loss: 0.1337 - accuracy: 0.9214 - jacard_coef: 0.0027 4/17 [======>.......................] - ETA: 1s - loss: 0.1342 - accuracy: 0.9181 - jacard_coef: 0.0020 5/17 [=======>......................] - ETA: 1s - loss: 0.1337 - accuracy: 0.9234 - jacard_coef: 0.0017 6/17 [=========>....................] - ETA: 1s - loss: 0.1335 - accuracy: 0.9234 - jacard_coef: 0.0020 7/17 [===========>..................] - ETA: 1s - loss: 0.1333 - accuracy: 0.9267 - jacard_coef: 0.0017 8/17 [=============>................] - ETA: 1s - loss: 0.1340 - accuracy: 0.9241 - jacard_coef: 0.0015 9/17 [==============>...............] - ETA: 1s - loss: 0.1337 - accuracy: 0.9250 - jacard_coef: 0.001410/17 [================>.............] - ETA: 0s - loss: 0.1334 - accuracy: 0.9264 - jacard_coef: 0.001211/17 [==================>...........] - ETA: 0s - loss: 0.1339 - accuracy: 0.9220 - jacard_coef: 0.001112/17 [====================>.........] - ETA: 0s - loss: 0.1338 - accuracy: 0.9223 - jacard_coef: 0.001013/17 [=====================>........] - ETA: 0s - loss: 0.1337 - accuracy: 0.9230 - jacard_coef: 9.5309e-0414/17 [=======================>......] - ETA: 0s - loss: 0.1337 - accuracy: 0.9227 - jacard_coef: 9.7491e-0415/17 [=========================>....] - ETA: 0s - loss: 0.1340 - accuracy: 0.9184 - jacard_coef: 0.0019    16/17 [===========================>..] - ETA: 0s - loss: 0.1340 - accuracy: 0.9171 - jacard_coef: 0.002017/17 [==============================] - 2s 128ms/step - loss: 0.1341 - accuracy: 0.9163 - jacard_coef: 0.0038 - val_loss: 0.1485 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 5.0000e-04
Epoch 16/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1345 - accuracy: 0.8994 - jacard_coef: 1.3276e-04 2/17 [==>...........................] - ETA: 1s - loss: 0.1326 - accuracy: 0.9153 - jacard_coef: 9.0929e-04 3/17 [====>.........................] - ETA: 1s - loss: 0.1348 - accuracy: 0.9064 - jacard_coef: 0.0018     4/17 [======>.......................] - ETA: 1s - loss: 0.1342 - accuracy: 0.9099 - jacard_coef: 0.0017 5/17 [=======>......................] - ETA: 1s - loss: 0.1336 - accuracy: 0.9122 - jacard_coef: 0.0014 6/17 [=========>....................] - ETA: 1s - loss: 0.1337 - accuracy: 0.9106 - jacard_coef: 0.0022 7/17 [===========>..................] - ETA: 1s - loss: 0.1330 - accuracy: 0.9164 - jacard_coef: 0.0018 8/17 [=============>................] - ETA: 1s - loss: 0.1329 - accuracy: 0.9163 - jacard_coef: 0.0016 9/17 [==============>...............] - ETA: 1s - loss: 0.1329 - accuracy: 0.9158 - jacard_coef: 0.001610/17 [================>.............] - ETA: 0s - loss: 0.1328 - accuracy: 0.9159 - jacard_coef: 0.001411/17 [==================>...........] - ETA: 0s - loss: 0.1325 - accuracy: 0.9185 - jacard_coef: 0.001312/17 [====================>.........] - ETA: 0s - loss: 0.1324 - accuracy: 0.9196 - jacard_coef: 0.001213/17 [=====================>........] - ETA: 0s - loss: 0.1325 - accuracy: 0.9183 - jacard_coef: 0.001114/17 [=======================>......] - ETA: 0s - loss: 0.1329 - accuracy: 0.9141 - jacard_coef: 0.001015/17 [=========================>....] - ETA: 0s - loss: 0.1329 - accuracy: 0.9137 - jacard_coef: 9.5805e-0416/17 [===========================>..] - ETA: 0s - loss: 0.1325 - accuracy: 0.9161 - jacard_coef: 9.1291e-0417/17 [==============================] - 2s 128ms/step - loss: 0.1326 - accuracy: 0.9149 - jacard_coef: 0.0038 - val_loss: 0.1454 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 5.0000e-04
Epoch 17/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1281 - accuracy: 0.9509 - jacard_coef: 0.0027 2/17 [==>...........................] - ETA: 1s - loss: 0.1283 - accuracy: 0.9558 - jacard_coef: 0.0014 3/17 [====>.........................] - ETA: 1s - loss: 0.1298 - accuracy: 0.9459 - jacard_coef: 0.0013 4/17 [======>.......................] - ETA: 1s - loss: 0.1314 - accuracy: 0.9335 - jacard_coef: 0.0013 5/17 [=======>......................] - ETA: 1s - loss: 0.1320 - accuracy: 0.9330 - jacard_coef: 0.0014 6/17 [=========>....................] - ETA: 1s - loss: 0.1347 - accuracy: 0.9237 - jacard_coef: 0.0021 7/17 [===========>..................] - ETA: 1s - loss: 0.1346 - accuracy: 0.9243 - jacard_coef: 0.0018 8/17 [=============>................] - ETA: 1s - loss: 0.1356 - accuracy: 0.9224 - jacard_coef: 0.0041 9/17 [==============>...............] - ETA: 1s - loss: 0.1363 - accuracy: 0.9201 - jacard_coef: 0.004710/17 [================>.............] - ETA: 0s - loss: 0.1362 - accuracy: 0.9184 - jacard_coef: 0.004511/17 [==================>...........] - ETA: 0s - loss: 0.1365 - accuracy: 0.9161 - jacard_coef: 0.004212/17 [====================>.........] - ETA: 0s - loss: 0.1369 - accuracy: 0.9121 - jacard_coef: 0.004013/17 [=====================>........] - ETA: 0s - loss: 0.1381 - accuracy: 0.9119 - jacard_coef: 0.004114/17 [=======================>......] - ETA: 0s - loss: 0.1377 - accuracy: 0.9128 - jacard_coef: 0.003815/17 [=========================>....] - ETA: 0s - loss: 0.1378 - accuracy: 0.9130 - jacard_coef: 0.003616/17 [===========================>..] - ETA: 0s - loss: 0.1376 - accuracy: 0.9147 - jacard_coef: 0.003417/17 [==============================] - 2s 128ms/step - loss: 0.1376 - accuracy: 0.9139 - jacard_coef: 0.0032 - val_loss: 0.1384 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 5.0000e-04
/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(

✓ Training completed successfully!
  Best Val Jaccard: 0.0781 (epoch 7)
  Final Val Loss: 0.1384
  Training Time: 0:01:21.688693
  Stability (std): 0.0119

Results saved to: hyperparameter_optimization_20250926_165036/exp_4_UNet_lr5e-4_bs8/UNet_lr0.0005_bs8_results.json
