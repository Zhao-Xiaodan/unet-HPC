✓ GPU memory growth enabled for 1 GPUs
Loading dataset...
Loaded 144 images and 144 masks
Training set: (129, 256, 256, 3), Validation set: (15, 256, 256, 3)

============================================================
TRAINING: UNet
Learning Rate: 0.005, Batch Size: 8, Epochs: 30
============================================================
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 256, 256, 64)         640       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 256, 256, 64)         256       ['conv2d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 activation (Activation)     (None, 256, 256, 64)         0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['activation[0][0]']          
                                                                                                  
 batch_normalization_1 (Bat  (None, 256, 256, 64)         256       ['conv2d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_1 (Activation)   (None, 256, 256, 64)         0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['activation_1[0][0]']        
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       
                                                                                                  
 batch_normalization_2 (Bat  (None, 128, 128, 128)        512       ['conv2d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_2 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_3 (Conv2D)           (None, 128, 128, 128)        147584    ['activation_2[0][0]']        
                                                                                                  
 batch_normalization_3 (Bat  (None, 128, 128, 128)        512       ['conv2d_3[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_3 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_3[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_3[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 batch_normalization_4 (Bat  (None, 64, 64, 256)          1024      ['conv2d_4[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_4 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_4[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_5 (Conv2D)           (None, 64, 64, 256)          590080    ['activation_4[0][0]']        
                                                                                                  
 batch_normalization_5 (Bat  (None, 64, 64, 256)          1024      ['conv2d_5[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_5 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_5[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_5[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 512)          1180160   ['max_pooling2d_2[0][0]']     
                                                                                                  
 batch_normalization_6 (Bat  (None, 32, 32, 512)          2048      ['conv2d_6[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_6 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_6[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 32, 32, 512)          2359808   ['activation_6[0][0]']        
                                                                                                  
 batch_normalization_7 (Bat  (None, 32, 32, 512)          2048      ['conv2d_7[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_7 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_7[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_3 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_7[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 1024)         4719616   ['max_pooling2d_3[0][0]']     
                                                                                                  
 batch_normalization_8 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_8[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_8 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_8[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 1024)         9438208   ['activation_8[0][0]']        
                                                                                                  
 batch_normalization_9 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_9[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_9 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_9[0][0]'
                                                                    ]                             
                                                                                                  
 up_sampling2d (UpSampling2  (None, 32, 32, 1024)         0         ['activation_9[0][0]']        
 D)                                                                                               
                                                                                                  
 concatenate (Concatenate)   (None, 32, 32, 1536)         0         ['up_sampling2d[0][0]',       
                                                                     'activation_7[0][0]']        
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate[0][0]']         
                                                                                                  
 batch_normalization_10 (Ba  (None, 32, 32, 512)          2048      ['conv2d_10[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_10 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_10[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_10[0][0]']       
                                                                                                  
 batch_normalization_11 (Ba  (None, 32, 32, 512)          2048      ['conv2d_11[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_11 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_11[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 64, 64, 512)          0         ['activation_11[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_1 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_1[0][0]',     
 )                                                                   'activation_5[0][0]']        
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_1[0][0]']       
                                                                                                  
 batch_normalization_12 (Ba  (None, 64, 64, 256)          1024      ['conv2d_12[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_12 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_12[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_13 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_12[0][0]']       
                                                                                                  
 batch_normalization_13 (Ba  (None, 64, 64, 256)          1024      ['conv2d_13[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_13 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_13[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 128, 128, 256)        0         ['activation_13[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_2 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_2[0][0]',     
 )                                                                   'activation_3[0][0]']        
                                                                                                  
 conv2d_14 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_2[0][0]']       
                                                                                                  
 batch_normalization_14 (Ba  (None, 128, 128, 128)        512       ['conv2d_14[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_14 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_14[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_15 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_14[0][0]']       
                                                                                                  
 batch_normalization_15 (Ba  (None, 128, 128, 128)        512       ['conv2d_15[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_15 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_15[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 256, 256, 128)        0         ['activation_15[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_3 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_3[0][0]',     
 )                                                                   'activation_1[0][0]']        
                                                                                                  
 conv2d_16 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_3[0][0]']       
                                                                                                  
 batch_normalization_16 (Ba  (None, 256, 256, 64)         256       ['conv2d_16[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_16 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_16[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_16[0][0]']       
                                                                                                  
 batch_normalization_17 (Ba  (None, 256, 256, 64)         256       ['conv2d_17[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_17 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_17[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_18 (Conv2D)          (None, 256, 256, 1)          65        ['activation_17[0][0]']       
                                                                                                  
 batch_normalization_18 (Ba  (None, 256, 256, 1)          4         ['conv2d_18[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_18 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_18[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31401349 (119.79 MB)
Trainable params: 31389571 (119.74 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
None
✓ focal_loss imported successfully
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_2 (InputLayer)        [(None, 256, 256, 3)]        0         []                            
                                                                                                  
 conv2d_19 (Conv2D)          (None, 256, 256, 64)         1792      ['input_2[0][0]']             
                                                                                                  
 batch_normalization_19 (Ba  (None, 256, 256, 64)         256       ['conv2d_19[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_19 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_19[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_20 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_19[0][0]']       
                                                                                                  
 batch_normalization_20 (Ba  (None, 256, 256, 64)         256       ['conv2d_20[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_20 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_20[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_4 (MaxPoolin  (None, 128, 128, 64)         0         ['activation_20[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_21 (Conv2D)          (None, 128, 128, 128)        73856     ['max_pooling2d_4[0][0]']     
                                                                                                  
 batch_normalization_21 (Ba  (None, 128, 128, 128)        512       ['conv2d_21[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_21 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_21[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_22 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_21[0][0]']       
                                                                                                  
 batch_normalization_22 (Ba  (None, 128, 128, 128)        512       ['conv2d_22[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_22 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_22[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_5 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_22[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_23 (Conv2D)          (None, 64, 64, 256)          295168    ['max_pooling2d_5[0][0]']     
                                                                                                  
 batch_normalization_23 (Ba  (None, 64, 64, 256)          1024      ['conv2d_23[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_23 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_23[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_24 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_23[0][0]']       
                                                                                                  
 batch_normalization_24 (Ba  (None, 64, 64, 256)          1024      ['conv2d_24[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_24 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_24[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_6 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_24[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_25 (Conv2D)          (None, 32, 32, 512)          1180160   ['max_pooling2d_6[0][0]']     
                                                                                                  
 batch_normalization_25 (Ba  (None, 32, 32, 512)          2048      ['conv2d_25[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_25 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_25[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_26 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_25[0][0]']       
                                                                                                  
 batch_normalization_26 (Ba  (None, 32, 32, 512)          2048      ['conv2d_26[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_26 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_26[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_7 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_26[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_27 (Conv2D)          (None, 16, 16, 1024)         4719616   ['max_pooling2d_7[0][0]']     
                                                                                                  
 batch_normalization_27 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_27[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_27 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_27[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_28 (Conv2D)          (None, 16, 16, 1024)         9438208   ['activation_27[0][0]']       
                                                                                                  
 batch_normalization_28 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_28[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_28 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_28[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 1024)         0         ['activation_28[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_4 (Concatenate  (None, 32, 32, 1536)         0         ['up_sampling2d_4[0][0]',     
 )                                                                   'activation_26[0][0]']       
                                                                                                  
 conv2d_29 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate_4[0][0]']       
                                                                                                  
 batch_normalization_29 (Ba  (None, 32, 32, 512)          2048      ['conv2d_29[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_29 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_29[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_30 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_29[0][0]']       
                                                                                                  
 batch_normalization_30 (Ba  (None, 32, 32, 512)          2048      ['conv2d_30[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_30 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_30[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 512)          0         ['activation_30[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_5 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_5[0][0]',     
 )                                                                   'activation_24[0][0]']       
                                                                                                  
 conv2d_31 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_5[0][0]']       
                                                                                                  
 batch_normalization_31 (Ba  (None, 64, 64, 256)          1024      ['conv2d_31[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_31 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_31[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_32 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_31[0][0]']       
                                                                                                  
 batch_normalization_32 (Ba  (None, 64, 64, 256)          1024      ['conv2d_32[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_32 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_32[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_6 (UpSamplin  (None, 128, 128, 256)        0         ['activation_32[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_6 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_6[0][0]',     
 )                                                                   'activation_22[0][0]']       
                                                                                                  
 conv2d_33 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_6[0][0]']       
                                                                                                  
 batch_normalization_33 (Ba  (None, 128, 128, 128)        512       ['conv2d_33[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_33 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_33[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_34 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_33[0][0]']       
                                                                                                  
 batch_normalization_34 (Ba  (None, 128, 128, 128)        512       ['conv2d_34[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_34 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_34[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_7 (UpSamplin  (None, 256, 256, 128)        0         ['activation_34[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_7 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_7[0][0]',     
 )                                                                   'activation_20[0][0]']       
                                                                                                  
 conv2d_35 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_7[0][0]']       
                                                                                                  
 batch_normalization_35 (Ba  (None, 256, 256, 64)         256       ['conv2d_35[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_35 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_35[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_36 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_35[0][0]']       
                                                                                                  
 batch_normalization_36 (Ba  (None, 256, 256, 64)         256       ['conv2d_36[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_36 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_36[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_37 (Conv2D)          (None, 256, 256, 1)          65        ['activation_36[0][0]']       
                                                                                                  
 batch_normalization_37 (Ba  (None, 256, 256, 1)          4         ['conv2d_37[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_37 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_37[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31402501 (119.79 MB)
Trainable params: 31390723 (119.75 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
WARNING:absl:`lr` is deprecated in TF-Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
None
Epoch 1/30
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1758877672.757643 1060163 service.cc:145] XLA service 0x1523cdc866e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1758877672.757666 1060163 service.cc:153]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6
I0000 00:00:1758877672.894405 1060163 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
 1/17 [>.............................] - ETA: 8:32 - loss: 0.3419 - accuracy: 0.5166 - jacard_coef: 0.0996 2/17 [==>...........................] - ETA: 55s - loss: 0.3346 - accuracy: 0.5530 - jacard_coef: 0.0865  3/17 [====>.........................] - ETA: 38s - loss: 0.3185 - accuracy: 0.4977 - jacard_coef: 0.0860 4/17 [======>.......................] - ETA: 29s - loss: 0.3134 - accuracy: 0.5289 - jacard_coef: 0.0832 5/17 [=======>......................] - ETA: 20s - loss: 0.3025 - accuracy: 0.5037 - jacard_coef: 0.0831 6/17 [=========>....................] - ETA: 15s - loss: 0.2948 - accuracy: 0.4916 - jacard_coef: 0.0837 7/17 [===========>..................] - ETA: 12s - loss: 0.2891 - accuracy: 0.4891 - jacard_coef: 0.0809 8/17 [=============>................] - ETA: 9s - loss: 0.2817 - accuracy: 0.4646 - jacard_coef: 0.0833  9/17 [==============>...............] - ETA: 7s - loss: 0.2748 - accuracy: 0.4295 - jacard_coef: 0.078710/17 [================>.............] - ETA: 5s - loss: 0.2683 - accuracy: 0.4062 - jacard_coef: 0.082211/17 [==================>...........] - ETA: 4s - loss: 0.2637 - accuracy: 0.3862 - jacard_coef: 0.081912/17 [====================>.........] - ETA: 3s - loss: 0.2610 - accuracy: 0.3674 - jacard_coef: 0.083213/17 [=====================>........] - ETA: 2s - loss: 0.2577 - accuracy: 0.3508 - jacard_coef: 0.082014/17 [=======================>......] - ETA: 1s - loss: 0.2536 - accuracy: 0.3353 - jacard_coef: 0.080315/17 [=========================>....] - ETA: 1s - loss: 0.2500 - accuracy: 0.3214 - jacard_coef: 0.079216/17 [===========================>..] - ETA: 0s - loss: 0.2466 - accuracy: 0.3109 - jacard_coef: 0.080817/17 [==============================] - ETA: 0s - loss: 0.2462 - accuracy: 0.3090 - jacard_coef: 0.076617/17 [==============================] - 47s 919ms/step - loss: 0.2462 - accuracy: 0.3090 - jacard_coef: 0.0766 - val_loss: 1.1218 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 0.0010
Epoch 2/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1947 - accuracy: 0.1407 - jacard_coef: 0.0766 2/17 [==>...........................] - ETA: 1s - loss: 0.1955 - accuracy: 0.1270 - jacard_coef: 0.0656 3/17 [====>.........................] - ETA: 1s - loss: 0.1941 - accuracy: 0.1311 - jacard_coef: 0.0741 4/17 [======>.......................] - ETA: 1s - loss: 0.1930 - accuracy: 0.1303 - jacard_coef: 0.0750 5/17 [=======>......................] - ETA: 1s - loss: 0.1923 - accuracy: 0.1362 - jacard_coef: 0.0808 6/17 [=========>....................] - ETA: 1s - loss: 0.1922 - accuracy: 0.1314 - jacard_coef: 0.0736 7/17 [===========>..................] - ETA: 1s - loss: 0.1911 - accuracy: 0.1395 - jacard_coef: 0.0788 8/17 [=============>................] - ETA: 1s - loss: 0.1917 - accuracy: 0.1425 - jacard_coef: 0.0809 9/17 [==============>...............] - ETA: 1s - loss: 0.1910 - accuracy: 0.1483 - jacard_coef: 0.079110/17 [================>.............] - ETA: 0s - loss: 0.1902 - accuracy: 0.1596 - jacard_coef: 0.081111/17 [==================>...........] - ETA: 0s - loss: 0.1895 - accuracy: 0.1704 - jacard_coef: 0.083812/17 [====================>.........] - ETA: 0s - loss: 0.1886 - accuracy: 0.1774 - jacard_coef: 0.082313/17 [=====================>........] - ETA: 0s - loss: 0.1878 - accuracy: 0.1873 - jacard_coef: 0.081714/17 [=======================>......] - ETA: 0s - loss: 0.1872 - accuracy: 0.1982 - jacard_coef: 0.081215/17 [=========================>....] - ETA: 0s - loss: 0.1866 - accuracy: 0.2176 - jacard_coef: 0.081016/17 [===========================>..] - ETA: 0s - loss: 0.1862 - accuracy: 0.2383 - jacard_coef: 0.080917/17 [==============================] - 2s 131ms/step - loss: 0.1868 - accuracy: 0.2391 - jacard_coef: 0.0833 - val_loss: 1.1345 - val_accuracy: 0.9286 - val_jacard_coef: 0.0014 - lr: 0.0010
Epoch 3/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1748 - accuracy: 0.5656 - jacard_coef: 0.1089 2/17 [==>...........................] - ETA: 1s - loss: 0.1810 - accuracy: 0.5472 - jacard_coef: 0.0845 3/17 [====>.........................] - ETA: 1s - loss: 0.1827 - accuracy: 0.5350 - jacard_coef: 0.0843 4/17 [======>.......................] - ETA: 1s - loss: 0.1834 - accuracy: 0.5230 - jacard_coef: 0.0880 5/17 [=======>......................] - ETA: 1s - loss: 0.1843 - accuracy: 0.5041 - jacard_coef: 0.0897 6/17 [=========>....................] - ETA: 1s - loss: 0.1839 - accuracy: 0.4920 - jacard_coef: 0.0844 7/17 [===========>..................] - ETA: 1s - loss: 0.1834 - accuracy: 0.4786 - jacard_coef: 0.0802 8/17 [=============>................] - ETA: 1s - loss: 0.1829 - accuracy: 0.4712 - jacard_coef: 0.0841 9/17 [==============>...............] - ETA: 1s - loss: 0.1825 - accuracy: 0.4669 - jacard_coef: 0.079510/17 [================>.............] - ETA: 0s - loss: 0.1820 - accuracy: 0.4590 - jacard_coef: 0.079711/17 [==================>...........] - ETA: 0s - loss: 0.1820 - accuracy: 0.4460 - jacard_coef: 0.081312/17 [====================>.........] - ETA: 0s - loss: 0.1818 - accuracy: 0.4339 - jacard_coef: 0.081413/17 [=====================>........] - ETA: 0s - loss: 0.1815 - accuracy: 0.4276 - jacard_coef: 0.081014/17 [=======================>......] - ETA: 0s - loss: 0.1813 - accuracy: 0.4205 - jacard_coef: 0.082115/17 [=========================>....] - ETA: 0s - loss: 0.1811 - accuracy: 0.4132 - jacard_coef: 0.082116/17 [===========================>..] - ETA: 0s - loss: 0.1808 - accuracy: 0.4071 - jacard_coef: 0.081617/17 [==============================] - 2s 128ms/step - loss: 0.1809 - accuracy: 0.4062 - jacard_coef: 0.0829 - val_loss: 0.6179 - val_accuracy: 0.9302 - val_jacard_coef: 3.3985e-12 - lr: 0.0010
Epoch 4/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1748 - accuracy: 0.4301 - jacard_coef: 0.0686 2/17 [==>...........................] - ETA: 1s - loss: 0.1758 - accuracy: 0.4435 - jacard_coef: 0.0737 3/17 [====>.........................] - ETA: 1s - loss: 0.1743 - accuracy: 0.4518 - jacard_coef: 0.0664 4/17 [======>.......................] - ETA: 1s - loss: 0.1736 - accuracy: 0.4574 - jacard_coef: 0.0588 5/17 [=======>......................] - ETA: 1s - loss: 0.1732 - accuracy: 0.4586 - jacard_coef: 0.0595 6/17 [=========>....................] - ETA: 1s - loss: 0.1727 - accuracy: 0.4638 - jacard_coef: 0.0639 7/17 [===========>..................] - ETA: 1s - loss: 0.1726 - accuracy: 0.4646 - jacard_coef: 0.0617 8/17 [=============>................] - ETA: 1s - loss: 0.1721 - accuracy: 0.4979 - jacard_coef: 0.0619 9/17 [==============>...............] - ETA: 1s - loss: 0.1719 - accuracy: 0.5230 - jacard_coef: 0.063310/17 [================>.............] - ETA: 0s - loss: 0.1714 - accuracy: 0.5476 - jacard_coef: 0.061911/17 [==================>...........] - ETA: 0s - loss: 0.1711 - accuracy: 0.5581 - jacard_coef: 0.065212/17 [====================>.........] - ETA: 0s - loss: 0.1706 - accuracy: 0.5683 - jacard_coef: 0.066313/17 [=====================>........] - ETA: 0s - loss: 0.1702 - accuracy: 0.5756 - jacard_coef: 0.068114/17 [=======================>......] - ETA: 0s - loss: 0.1698 - accuracy: 0.5835 - jacard_coef: 0.074115/17 [=========================>....] - ETA: 0s - loss: 0.1696 - accuracy: 0.5858 - jacard_coef: 0.075216/17 [===========================>..] - ETA: 0s - loss: 0.1695 - accuracy: 0.5897 - jacard_coef: 0.078017/17 [==============================] - 2s 130ms/step - loss: 0.1697 - accuracy: 0.5879 - jacard_coef: 0.0799 - val_loss: 0.4143 - val_accuracy: 0.9266 - val_jacard_coef: 0.0034 - lr: 0.0010
Epoch 5/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1702 - accuracy: 0.6786 - jacard_coef: 0.0672 2/17 [==>...........................] - ETA: 1s - loss: 0.1710 - accuracy: 0.7144 - jacard_coef: 0.0599 3/17 [====>.........................] - ETA: 1s - loss: 0.1702 - accuracy: 0.7290 - jacard_coef: 0.0722 4/17 [======>.......................] - ETA: 1s - loss: 0.1696 - accuracy: 0.7240 - jacard_coef: 0.0589 5/17 [=======>......................] - ETA: 1s - loss: 0.1688 - accuracy: 0.7177 - jacard_coef: 0.0592 6/17 [=========>....................] - ETA: 1s - loss: 0.1686 - accuracy: 0.7057 - jacard_coef: 0.0599 7/17 [===========>..................] - ETA: 1s - loss: 0.1688 - accuracy: 0.6822 - jacard_coef: 0.0673 8/17 [=============>................] - ETA: 1s - loss: 0.1695 - accuracy: 0.6500 - jacard_coef: 0.0714 9/17 [==============>...............] - ETA: 1s - loss: 0.1695 - accuracy: 0.6467 - jacard_coef: 0.072510/17 [================>.............] - ETA: 0s - loss: 0.1690 - accuracy: 0.6612 - jacard_coef: 0.072011/17 [==================>...........] - ETA: 0s - loss: 0.1686 - accuracy: 0.6732 - jacard_coef: 0.074412/17 [====================>.........] - ETA: 0s - loss: 0.1684 - accuracy: 0.6810 - jacard_coef: 0.073913/17 [=====================>........] - ETA: 0s - loss: 0.1683 - accuracy: 0.6841 - jacard_coef: 0.074314/17 [=======================>......] - ETA: 0s - loss: 0.1683 - accuracy: 0.6953 - jacard_coef: 0.071015/17 [=========================>....] - ETA: 0s - loss: 0.1681 - accuracy: 0.7003 - jacard_coef: 0.069116/17 [===========================>..] - ETA: 0s - loss: 0.1678 - accuracy: 0.7064 - jacard_coef: 0.068117/17 [==============================] - 2s 130ms/step - loss: 0.1678 - accuracy: 0.7079 - jacard_coef: 0.0641 - val_loss: 0.1413 - val_accuracy: 0.8707 - val_jacard_coef: 0.0251 - lr: 0.0010
Epoch 6/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1624 - accuracy: 0.8075 - jacard_coef: 0.0513 2/17 [==>...........................] - ETA: 1s - loss: 0.1630 - accuracy: 0.8066 - jacard_coef: 0.0575 3/17 [====>.........................] - ETA: 1s - loss: 0.1625 - accuracy: 0.8223 - jacard_coef: 0.0497 4/17 [======>.......................] - ETA: 1s - loss: 0.1626 - accuracy: 0.8069 - jacard_coef: 0.0576 5/17 [=======>......................] - ETA: 1s - loss: 0.1627 - accuracy: 0.8184 - jacard_coef: 0.0583 6/17 [=========>....................] - ETA: 1s - loss: 0.1621 - accuracy: 0.8324 - jacard_coef: 0.0561 7/17 [===========>..................] - ETA: 1s - loss: 0.1621 - accuracy: 0.8333 - jacard_coef: 0.0524 8/17 [=============>................] - ETA: 1s - loss: 0.1619 - accuracy: 0.8366 - jacard_coef: 0.0517 9/17 [==============>...............] - ETA: 1s - loss: 0.1616 - accuracy: 0.8434 - jacard_coef: 0.047610/17 [================>.............] - ETA: 0s - loss: 0.1619 - accuracy: 0.8453 - jacard_coef: 0.044111/17 [==================>...........] - ETA: 0s - loss: 0.1615 - accuracy: 0.8519 - jacard_coef: 0.041412/17 [====================>.........] - ETA: 0s - loss: 0.1612 - accuracy: 0.8537 - jacard_coef: 0.042513/17 [=====================>........] - ETA: 0s - loss: 0.1609 - accuracy: 0.8593 - jacard_coef: 0.039614/17 [=======================>......] - ETA: 0s - loss: 0.1606 - accuracy: 0.8620 - jacard_coef: 0.036815/17 [=========================>....] - ETA: 0s - loss: 0.1604 - accuracy: 0.8661 - jacard_coef: 0.036316/17 [===========================>..] - ETA: 0s - loss: 0.1603 - accuracy: 0.8681 - jacard_coef: 0.034517/17 [==============================] - 2s 130ms/step - loss: 0.1604 - accuracy: 0.8657 - jacard_coef: 0.0356 - val_loss: 0.1850 - val_accuracy: 0.1935 - val_jacard_coef: 0.0672 - lr: 0.0010
Epoch 7/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1580 - accuracy: 0.8329 - jacard_coef: 0.0463 2/17 [==>...........................] - ETA: 1s - loss: 0.1579 - accuracy: 0.8161 - jacard_coef: 0.0630 3/17 [====>.........................] - ETA: 1s - loss: 0.1578 - accuracy: 0.8005 - jacard_coef: 0.0660 4/17 [======>.......................] - ETA: 1s - loss: 0.1577 - accuracy: 0.7884 - jacard_coef: 0.0690 5/17 [=======>......................] - ETA: 1s - loss: 0.1581 - accuracy: 0.7721 - jacard_coef: 0.0623 6/17 [=========>....................] - ETA: 1s - loss: 0.1580 - accuracy: 0.7650 - jacard_coef: 0.0582 7/17 [===========>..................] - ETA: 1s - loss: 0.1578 - accuracy: 0.7688 - jacard_coef: 0.0661 8/17 [=============>................] - ETA: 1s - loss: 0.1578 - accuracy: 0.7819 - jacard_coef: 0.0607 9/17 [==============>...............] - ETA: 1s - loss: 0.1575 - accuracy: 0.7975 - jacard_coef: 0.054610/17 [================>.............] - ETA: 0s - loss: 0.1574 - accuracy: 0.8094 - jacard_coef: 0.049311/17 [==================>...........] - ETA: 0s - loss: 0.1572 - accuracy: 0.8175 - jacard_coef: 0.044912/17 [====================>.........] - ETA: 0s - loss: 0.1573 - accuracy: 0.8244 - jacard_coef: 0.041313/17 [=====================>........] - ETA: 0s - loss: 0.1570 - accuracy: 0.8319 - jacard_coef: 0.038414/17 [=======================>......] - ETA: 0s - loss: 0.1566 - accuracy: 0.8413 - jacard_coef: 0.035715/17 [=========================>....] - ETA: 0s - loss: 0.1563 - accuracy: 0.8475 - jacard_coef: 0.033416/17 [===========================>..] - ETA: 0s - loss: 0.1561 - accuracy: 0.8533 - jacard_coef: 0.031317/17 [==============================] - 2s 130ms/step - loss: 0.1562 - accuracy: 0.8534 - jacard_coef: 0.0299 - val_loss: 0.1737 - val_accuracy: 0.3298 - val_jacard_coef: 0.0702 - lr: 0.0010
Epoch 8/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1514 - accuracy: 0.9510 - jacard_coef: 1.9459e-04 2/17 [==>...........................] - ETA: 1s - loss: 0.1526 - accuracy: 0.9213 - jacard_coef: 0.0026     3/17 [====>.........................] - ETA: 1s - loss: 0.1528 - accuracy: 0.9192 - jacard_coef: 0.0035 4/17 [======>.......................] - ETA: 1s - loss: 0.1528 - accuracy: 0.9182 - jacard_coef: 0.0037 5/17 [=======>......................] - ETA: 1s - loss: 0.1531 - accuracy: 0.9113 - jacard_coef: 0.0030 6/17 [=========>....................] - ETA: 1s - loss: 0.1532 - accuracy: 0.9125 - jacard_coef: 0.0031 7/17 [===========>..................] - ETA: 1s - loss: 0.1529 - accuracy: 0.9140 - jacard_coef: 0.0028 8/17 [=============>................] - ETA: 1s - loss: 0.1526 - accuracy: 0.9137 - jacard_coef: 0.0025 9/17 [==============>...............] - ETA: 1s - loss: 0.1524 - accuracy: 0.9126 - jacard_coef: 0.002210/17 [================>.............] - ETA: 0s - loss: 0.1520 - accuracy: 0.9139 - jacard_coef: 0.002611/17 [==================>...........] - ETA: 0s - loss: 0.1520 - accuracy: 0.9113 - jacard_coef: 0.005312/17 [====================>.........] - ETA: 0s - loss: 0.1518 - accuracy: 0.9112 - jacard_coef: 0.005213/17 [=====================>........] - ETA: 0s - loss: 0.1515 - accuracy: 0.9122 - jacard_coef: 0.004914/17 [=======================>......] - ETA: 0s - loss: 0.1513 - accuracy: 0.9131 - jacard_coef: 0.004615/17 [=========================>....] - ETA: 0s - loss: 0.1512 - accuracy: 0.9126 - jacard_coef: 0.004316/17 [===========================>..] - ETA: 0s - loss: 0.1511 - accuracy: 0.9132 - jacard_coef: 0.004217/17 [==============================] - 2s 130ms/step - loss: 0.1511 - accuracy: 0.9124 - jacard_coef: 0.0040 - val_loss: 0.1713 - val_accuracy: 0.4756 - val_jacard_coef: 0.0746 - lr: 0.0010
Epoch 9/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1535 - accuracy: 0.8666 - jacard_coef: 0.0013 2/17 [==>...........................] - ETA: 1s - loss: 0.1507 - accuracy: 0.8951 - jacard_coef: 0.0040 3/17 [====>.........................] - ETA: 1s - loss: 0.1503 - accuracy: 0.9018 - jacard_coef: 0.0034 4/17 [======>.......................] - ETA: 1s - loss: 0.1541 - accuracy: 0.8147 - jacard_coef: 0.0220 5/17 [=======>......................] - ETA: 1s - loss: 0.1531 - accuracy: 0.8312 - jacard_coef: 0.0178 6/17 [=========>....................] - ETA: 1s - loss: 0.1525 - accuracy: 0.8441 - jacard_coef: 0.0154 7/17 [===========>..................] - ETA: 1s - loss: 0.1522 - accuracy: 0.8499 - jacard_coef: 0.0136 8/17 [=============>................] - ETA: 1s - loss: 0.1521 - accuracy: 0.8552 - jacard_coef: 0.0132 9/17 [==============>...............] - ETA: 1s - loss: 0.1518 - accuracy: 0.8604 - jacard_coef: 0.011810/17 [================>.............] - ETA: 0s - loss: 0.1514 - accuracy: 0.8680 - jacard_coef: 0.011511/17 [==================>...........] - ETA: 0s - loss: 0.1513 - accuracy: 0.8714 - jacard_coef: 0.010512/17 [====================>.........] - ETA: 0s - loss: 0.1514 - accuracy: 0.8727 - jacard_coef: 0.009813/17 [=====================>........] - ETA: 0s - loss: 0.1513 - accuracy: 0.8758 - jacard_coef: 0.009014/17 [=======================>......] - ETA: 0s - loss: 0.1511 - accuracy: 0.8805 - jacard_coef: 0.008815/17 [=========================>....] - ETA: 0s - loss: 0.1508 - accuracy: 0.8843 - jacard_coef: 0.008316/17 [===========================>..] - ETA: 0s - loss: 0.1508 - accuracy: 0.8850 - jacard_coef: 0.008117/17 [==============================] - 2s 128ms/step - loss: 0.1508 - accuracy: 0.8853 - jacard_coef: 0.0076 - val_loss: 0.1520 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 0.0010
Epoch 10/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1476 - accuracy: 0.9084 - jacard_coef: 0.0093 2/17 [==>...........................] - ETA: 1s - loss: 0.1464 - accuracy: 0.9256 - jacard_coef: 0.0110 3/17 [====>.........................] - ETA: 1s - loss: 0.1470 - accuracy: 0.9197 - jacard_coef: 0.0112 4/17 [======>.......................] - ETA: 1s - loss: 0.1470 - accuracy: 0.9134 - jacard_coef: 0.0128 5/17 [=======>......................] - ETA: 1s - loss: 0.1470 - accuracy: 0.9106 - jacard_coef: 0.0165 6/17 [=========>....................] - ETA: 1s - loss: 0.1470 - accuracy: 0.9072 - jacard_coef: 0.0158 7/17 [===========>..................] - ETA: 1s - loss: 0.1468 - accuracy: 0.9096 - jacard_coef: 0.0136 8/17 [=============>................] - ETA: 1s - loss: 0.1467 - accuracy: 0.9103 - jacard_coef: 0.0119 9/17 [==============>...............] - ETA: 1s - loss: 0.1470 - accuracy: 0.9093 - jacard_coef: 0.010810/17 [================>.............] - ETA: 0s - loss: 0.1470 - accuracy: 0.9079 - jacard_coef: 0.009911/17 [==================>...........] - ETA: 0s - loss: 0.1468 - accuracy: 0.9089 - jacard_coef: 0.009012/17 [====================>.........] - ETA: 0s - loss: 0.1467 - accuracy: 0.9110 - jacard_coef: 0.008413/17 [=====================>........] - ETA: 0s - loss: 0.1468 - accuracy: 0.9095 - jacard_coef: 0.008014/17 [=======================>......] - ETA: 0s - loss: 0.1466 - accuracy: 0.9109 - jacard_coef: 0.007415/17 [=========================>....] - ETA: 0s - loss: 0.1466 - accuracy: 0.9106 - jacard_coef: 0.007016/17 [===========================>..] - ETA: 0s - loss: 0.1468 - accuracy: 0.9076 - jacard_coef: 0.006717/17 [==============================] - 2s 128ms/step - loss: 0.1468 - accuracy: 0.9078 - jacard_coef: 0.0063 - val_loss: 0.1631 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 0.0010
Epoch 11/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1455 - accuracy: 0.9193 - jacard_coef: 0.0070 2/17 [==>...........................] - ETA: 1s - loss: 0.1452 - accuracy: 0.9111 - jacard_coef: 0.0044 3/17 [====>.........................] - ETA: 1s - loss: 0.1443 - accuracy: 0.9157 - jacard_coef: 0.0032 4/17 [======>.......................] - ETA: 1s - loss: 0.1443 - accuracy: 0.9130 - jacard_coef: 0.0030 5/17 [=======>......................] - ETA: 1s - loss: 0.1447 - accuracy: 0.9087 - jacard_coef: 0.0025 6/17 [=========>....................] - ETA: 1s - loss: 0.1444 - accuracy: 0.9094 - jacard_coef: 0.0021 7/17 [===========>..................] - ETA: 1s - loss: 0.1444 - accuracy: 0.9057 - jacard_coef: 0.0018 8/17 [=============>................] - ETA: 1s - loss: 0.1443 - accuracy: 0.9068 - jacard_coef: 0.0016 9/17 [==============>...............] - ETA: 1s - loss: 0.1443 - accuracy: 0.9047 - jacard_coef: 0.001410/17 [================>.............] - ETA: 0s - loss: 0.1437 - accuracy: 0.9097 - jacard_coef: 0.001311/17 [==================>...........] - ETA: 0s - loss: 0.1434 - accuracy: 0.9111 - jacard_coef: 0.001212/17 [====================>.........] - ETA: 0s - loss: 0.1429 - accuracy: 0.9144 - jacard_coef: 0.001113/17 [=====================>........] - ETA: 0s - loss: 0.1428 - accuracy: 0.9143 - jacard_coef: 0.001014/17 [=======================>......] - ETA: 0s - loss: 0.1426 - accuracy: 0.9150 - jacard_coef: 9.8468e-0415/17 [=========================>....] - ETA: 0s - loss: 0.1425 - accuracy: 0.9147 - jacard_coef: 9.2190e-0416/17 [===========================>..] - ETA: 0s - loss: 0.1423 - accuracy: 0.9146 - jacard_coef: 8.6428e-0417/17 [==============================] - 2s 128ms/step - loss: 0.1422 - accuracy: 0.9152 - jacard_coef: 0.0010 - val_loss: 0.1672 - val_accuracy: 0.7981 - val_jacard_coef: 0.0504 - lr: 0.0010
Epoch 12/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1387 - accuracy: 0.9289 - jacard_coef: 2.6822e-12 2/17 [==>...........................] - ETA: 1s - loss: 0.1394 - accuracy: 0.9185 - jacard_coef: 2.8019e-04 3/17 [====>.........................] - ETA: 1s - loss: 0.1401 - accuracy: 0.9190 - jacard_coef: 0.0013     4/17 [======>.......................] - ETA: 1s - loss: 0.1396 - accuracy: 0.9184 - jacard_coef: 0.0081 5/17 [=======>......................] - ETA: 1s - loss: 0.1392 - accuracy: 0.9197 - jacard_coef: 0.0075 6/17 [=========>....................] - ETA: 1s - loss: 0.1394 - accuracy: 0.9161 - jacard_coef: 0.0063 7/17 [===========>..................] - ETA: 1s - loss: 0.1394 - accuracy: 0.9133 - jacard_coef: 0.0055 8/17 [=============>................] - ETA: 1s - loss: 0.1391 - accuracy: 0.9138 - jacard_coef: 0.0048 9/17 [==============>...............] - ETA: 1s - loss: 0.1393 - accuracy: 0.9112 - jacard_coef: 0.004310/17 [================>.............] - ETA: 0s - loss: 0.1390 - accuracy: 0.9122 - jacard_coef: 0.004411/17 [==================>...........] - ETA: 0s - loss: 0.1388 - accuracy: 0.9132 - jacard_coef: 0.004012/17 [====================>.........] - ETA: 0s - loss: 0.1387 - accuracy: 0.9120 - jacard_coef: 0.003713/17 [=====================>........] - ETA: 0s - loss: 0.1386 - accuracy: 0.9120 - jacard_coef: 0.003514/17 [=======================>......] - ETA: 0s - loss: 0.1385 - accuracy: 0.9122 - jacard_coef: 0.003215/17 [=========================>....] - ETA: 0s - loss: 0.1384 - accuracy: 0.9124 - jacard_coef: 0.004116/17 [===========================>..] - ETA: 0s - loss: 0.1381 - accuracy: 0.9136 - jacard_coef: 0.003917/17 [==============================] - 2s 128ms/step - loss: 0.1390 - accuracy: 0.9104 - jacard_coef: 0.0075 - val_loss: 0.1564 - val_accuracy: 0.9301 - val_jacard_coef: 1.0570e-05 - lr: 0.0010
Epoch 13/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1415 - accuracy: 0.8964 - jacard_coef: 0.0067 2/17 [==>...........................] - ETA: 1s - loss: 0.1465 - accuracy: 0.7735 - jacard_coef: 0.0438 3/17 [====>.........................] - ETA: 1s - loss: 0.1513 - accuracy: 0.7038 - jacard_coef: 0.0600 4/17 [======>.......................] - ETA: 1s - loss: 0.1487 - accuracy: 0.7526 - jacard_coef: 0.0463 5/17 [=======>......................] - ETA: 1s - loss: 0.1468 - accuracy: 0.7828 - jacard_coef: 0.0370 6/17 [=========>....................] - ETA: 1s - loss: 0.1469 - accuracy: 0.7980 - jacard_coef: 0.0317 7/17 [===========>..................] - ETA: 1s - loss: 0.1454 - accuracy: 0.8168 - jacard_coef: 0.0271 8/17 [=============>................] - ETA: 1s - loss: 0.1447 - accuracy: 0.8276 - jacard_coef: 0.0238 9/17 [==============>...............] - ETA: 1s - loss: 0.1442 - accuracy: 0.8375 - jacard_coef: 0.022010/17 [================>.............] - ETA: 0s - loss: 0.1436 - accuracy: 0.8461 - jacard_coef: 0.020211/17 [==================>...........] - ETA: 0s - loss: 0.1429 - accuracy: 0.8543 - jacard_coef: 0.019812/17 [====================>.........] - ETA: 0s - loss: 0.1424 - accuracy: 0.8596 - jacard_coef: 0.019413/17 [=====================>........] - ETA: 0s - loss: 0.1422 - accuracy: 0.8630 - jacard_coef: 0.018814/17 [=======================>......] - ETA: 0s - loss: 0.1415 - accuracy: 0.8696 - jacard_coef: 0.017715/17 [=========================>....] - ETA: 0s - loss: 0.1416 - accuracy: 0.8695 - jacard_coef: 0.018216/17 [===========================>..] - ETA: 0s - loss: 0.1414 - accuracy: 0.8707 - jacard_coef: 0.017217/17 [==============================] - 2s 128ms/step - loss: 0.1414 - accuracy: 0.8705 - jacard_coef: 0.0162 - val_loss: 0.1506 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 0.0010
Epoch 14/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1381 - accuracy: 0.9039 - jacard_coef: 0.0012 2/17 [==>...........................] - ETA: 1s - loss: 0.1388 - accuracy: 0.8975 - jacard_coef: 8.5160e-04 3/17 [====>.........................] - ETA: 1s - loss: 0.1371 - accuracy: 0.9096 - jacard_coef: 5.6773e-04 4/17 [======>.......................] - ETA: 1s - loss: 0.1370 - accuracy: 0.9125 - jacard_coef: 5.3442e-04 5/17 [=======>......................] - ETA: 1s - loss: 0.1373 - accuracy: 0.9097 - jacard_coef: 6.7980e-04 6/17 [=========>....................] - ETA: 1s - loss: 0.1375 - accuracy: 0.9061 - jacard_coef: 5.9483e-04 7/17 [===========>..................] - ETA: 1s - loss: 0.1372 - accuracy: 0.9079 - jacard_coef: 0.0012     8/17 [=============>................] - ETA: 1s - loss: 0.1368 - accuracy: 0.9101 - jacard_coef: 0.0011 9/17 [==============>...............] - ETA: 1s - loss: 0.1364 - accuracy: 0.9133 - jacard_coef: 9.7688e-0410/17 [================>.............] - ETA: 0s - loss: 0.1364 - accuracy: 0.9115 - jacard_coef: 0.0031    11/17 [==================>...........] - ETA: 0s - loss: 0.1364 - accuracy: 0.9099 - jacard_coef: 0.002912/17 [====================>.........] - ETA: 0s - loss: 0.1363 - accuracy: 0.9097 - jacard_coef: 0.002813/17 [=====================>........] - ETA: 0s - loss: 0.1364 - accuracy: 0.9101 - jacard_coef: 0.002614/17 [=======================>......] - ETA: 0s - loss: 0.1361 - accuracy: 0.9123 - jacard_coef: 0.002515/17 [=========================>....] - ETA: 0s - loss: 0.1362 - accuracy: 0.9122 - jacard_coef: 0.002816/17 [===========================>..] - ETA: 0s - loss: 0.1361 - accuracy: 0.9128 - jacard_coef: 0.002717/17 [==============================] - 2s 128ms/step - loss: 0.1361 - accuracy: 0.9134 - jacard_coef: 0.0026 - val_loss: 0.1485 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 5.0000e-04
Epoch 15/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1334 - accuracy: 0.9283 - jacard_coef: 0.0029 2/17 [==>...........................] - ETA: 1s - loss: 0.1321 - accuracy: 0.9365 - jacard_coef: 0.0015 3/17 [====>.........................] - ETA: 1s - loss: 0.1345 - accuracy: 0.9146 - jacard_coef: 0.0014 4/17 [======>.......................] - ETA: 1s - loss: 0.1341 - accuracy: 0.9167 - jacard_coef: 0.0011 5/17 [=======>......................] - ETA: 1s - loss: 0.1336 - accuracy: 0.9206 - jacard_coef: 0.0012 6/17 [=========>....................] - ETA: 1s - loss: 0.1342 - accuracy: 0.9149 - jacard_coef: 0.0015 7/17 [===========>..................] - ETA: 1s - loss: 0.1338 - accuracy: 0.9173 - jacard_coef: 0.0016 8/17 [=============>................] - ETA: 1s - loss: 0.1340 - accuracy: 0.9136 - jacard_coef: 0.0014 9/17 [==============>...............] - ETA: 1s - loss: 0.1337 - accuracy: 0.9160 - jacard_coef: 0.001410/17 [================>.............] - ETA: 0s - loss: 0.1336 - accuracy: 0.9169 - jacard_coef: 0.001511/17 [==================>...........] - ETA: 0s - loss: 0.1339 - accuracy: 0.9147 - jacard_coef: 0.002612/17 [====================>.........] - ETA: 0s - loss: 0.1341 - accuracy: 0.9126 - jacard_coef: 0.002413/17 [=====================>........] - ETA: 0s - loss: 0.1340 - accuracy: 0.9145 - jacard_coef: 0.002214/17 [=======================>......] - ETA: 0s - loss: 0.1340 - accuracy: 0.9148 - jacard_coef: 0.002215/17 [=========================>....] - ETA: 0s - loss: 0.1339 - accuracy: 0.9148 - jacard_coef: 0.002116/17 [===========================>..] - ETA: 0s - loss: 0.1337 - accuracy: 0.9157 - jacard_coef: 0.002117/17 [==============================] - 2s 128ms/step - loss: 0.1338 - accuracy: 0.9150 - jacard_coef: 0.0020 - val_loss: 0.1465 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 5.0000e-04
Epoch 16/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1340 - accuracy: 0.9140 - jacard_coef: 0.0033 2/17 [==>...........................] - ETA: 1s - loss: 0.1340 - accuracy: 0.9082 - jacard_coef: 0.0020 3/17 [====>.........................] - ETA: 1s - loss: 0.1335 - accuracy: 0.9116 - jacard_coef: 0.0019 4/17 [======>.......................] - ETA: 1s - loss: 0.1326 - accuracy: 0.9195 - jacard_coef: 0.0015 5/17 [=======>......................] - ETA: 1s - loss: 0.1323 - accuracy: 0.9215 - jacard_coef: 0.0013 6/17 [=========>....................] - ETA: 1s - loss: 0.1326 - accuracy: 0.9177 - jacard_coef: 0.0011 7/17 [===========>..................] - ETA: 1s - loss: 0.1319 - accuracy: 0.9218 - jacard_coef: 0.0015 8/17 [=============>................] - ETA: 1s - loss: 0.1317 - accuracy: 0.9221 - jacard_coef: 0.0013 9/17 [==============>...............] - ETA: 1s - loss: 0.1323 - accuracy: 0.9159 - jacard_coef: 0.001310/17 [================>.............] - ETA: 0s - loss: 0.1321 - accuracy: 0.9164 - jacard_coef: 0.001711/17 [==================>...........] - ETA: 0s - loss: 0.1319 - accuracy: 0.9163 - jacard_coef: 0.001612/17 [====================>.........] - ETA: 0s - loss: 0.1317 - accuracy: 0.9184 - jacard_coef: 0.002013/17 [=====================>........] - ETA: 0s - loss: 0.1316 - accuracy: 0.9188 - jacard_coef: 0.001914/17 [=======================>......] - ETA: 0s - loss: 0.1320 - accuracy: 0.9151 - jacard_coef: 0.001815/17 [=========================>....] - ETA: 0s - loss: 0.1318 - accuracy: 0.9158 - jacard_coef: 0.001816/17 [===========================>..] - ETA: 0s - loss: 0.1318 - accuracy: 0.9158 - jacard_coef: 0.001717/17 [==============================] - 2s 128ms/step - loss: 0.1321 - accuracy: 0.9129 - jacard_coef: 0.0060 - val_loss: 0.1456 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 5.0000e-04
Epoch 17/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1310 - accuracy: 0.9164 - jacard_coef: 2.2819e-12 2/17 [==>...........................] - ETA: 1s - loss: 0.1292 - accuracy: 0.9370 - jacard_coef: 3.1394e-04 3/17 [====>.........................] - ETA: 1s - loss: 0.1308 - accuracy: 0.9250 - jacard_coef: 2.9282e-04 4/17 [======>.......................] - ETA: 1s - loss: 0.1319 - accuracy: 0.9188 - jacard_coef: 5.5840e-04 5/17 [=======>......................] - ETA: 1s - loss: 0.1316 - accuracy: 0.9221 - jacard_coef: 0.0030     6/17 [=========>....................] - ETA: 1s - loss: 0.1321 - accuracy: 0.9190 - jacard_coef: 0.0026 7/17 [===========>..................] - ETA: 1s - loss: 0.1320 - accuracy: 0.9190 - jacard_coef: 0.0040 8/17 [=============>................] - ETA: 1s - loss: 0.1320 - accuracy: 0.9176 - jacard_coef: 0.0036 9/17 [==============>...............] - ETA: 1s - loss: 0.1326 - accuracy: 0.9128 - jacard_coef: 0.006310/17 [================>.............] - ETA: 0s - loss: 0.1322 - accuracy: 0.9152 - jacard_coef: 0.009711/17 [==================>...........] - ETA: 0s - loss: 0.1324 - accuracy: 0.9135 - jacard_coef: 0.008912/17 [====================>.........] - ETA: 0s - loss: 0.1328 - accuracy: 0.9104 - jacard_coef: 0.008313/17 [=====================>........] - ETA: 0s - loss: 0.1327 - accuracy: 0.9108 - jacard_coef: 0.007714/17 [=======================>......] - ETA: 0s - loss: 0.1328 - accuracy: 0.9108 - jacard_coef: 0.007415/17 [=========================>....] - ETA: 0s - loss: 0.1329 - accuracy: 0.9106 - jacard_coef: 0.007116/17 [===========================>..] - ETA: 0s - loss: 0.1325 - accuracy: 0.9120 - jacard_coef: 0.006717/17 [==============================] - 2s 128ms/step - loss: 0.1325 - accuracy: 0.9122 - jacard_coef: 0.0067 - val_loss: 0.1518 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 5.0000e-04
Epoch 18/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1290 - accuracy: 0.9084 - jacard_coef: 0.0435 2/17 [==>...........................] - ETA: 1s - loss: 0.1311 - accuracy: 0.8961 - jacard_coef: 0.0221 3/17 [====>.........................] - ETA: 1s - loss: 0.1302 - accuracy: 0.9051 - jacard_coef: 0.0149 4/17 [======>.......................] - ETA: 1s - loss: 0.1290 - accuracy: 0.9155 - jacard_coef: 0.0112 5/17 [=======>......................] - ETA: 1s - loss: 0.1293 - accuracy: 0.9154 - jacard_coef: 0.0094 6/17 [=========>....................] - ETA: 1s - loss: 0.1292 - accuracy: 0.9178 - jacard_coef: 0.0078 7/17 [===========>..................] - ETA: 1s - loss: 0.1294 - accuracy: 0.9172 - jacard_coef: 0.0067 8/17 [=============>................] - ETA: 1s - loss: 0.1297 - accuracy: 0.9156 - jacard_coef: 0.0059 9/17 [==============>...............] - ETA: 1s - loss: 0.1300 - accuracy: 0.9146 - jacard_coef: 0.005310/17 [================>.............] - ETA: 0s - loss: 0.1305 - accuracy: 0.9110 - jacard_coef: 0.004811/17 [==================>...........] - ETA: 0s - loss: 0.1305 - accuracy: 0.9104 - jacard_coef: 0.004412/17 [====================>.........] - ETA: 0s - loss: 0.1303 - accuracy: 0.9127 - jacard_coef: 0.004013/17 [=====================>........] - ETA: 0s - loss: 0.1303 - accuracy: 0.9135 - jacard_coef: 0.003714/17 [=======================>......] - ETA: 0s - loss: 0.1301 - accuracy: 0.9152 - jacard_coef: 0.003415/17 [=========================>....] - ETA: 0s - loss: 0.1302 - accuracy: 0.9141 - jacard_coef: 0.003216/17 [===========================>..] - ETA: 0s - loss: 0.1304 - accuracy: 0.9135 - jacard_coef: 0.003017/17 [==============================] - 2s 128ms/step - loss: 0.1305 - accuracy: 0.9126 - jacard_coef: 0.0029 - val_loss: 0.1325 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 5.0000e-04
/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(

✓ Training completed successfully!
  Best Val Jaccard: 0.0746 (epoch 8)
  Final Val Loss: 0.1325
  Training Time: 0:01:24.441209
  Stability (std): 0.0092

Results saved to: hyperparameter_optimization_20250926_165036/exp_10_UNet_lr5e-3_bs8/UNet_lr0.005_bs8_results.json
