✓ GPU memory growth enabled for 1 GPUs
Loading dataset...
Loaded 144 images and 144 masks
Training set: (129, 256, 256, 3), Validation set: (15, 256, 256, 3)

============================================================
TRAINING: UNet
Learning Rate: 0.001, Batch Size: 8, Epochs: 30
============================================================
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 256, 256, 64)         640       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 256, 256, 64)         256       ['conv2d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 activation (Activation)     (None, 256, 256, 64)         0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['activation[0][0]']          
                                                                                                  
 batch_normalization_1 (Bat  (None, 256, 256, 64)         256       ['conv2d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_1 (Activation)   (None, 256, 256, 64)         0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['activation_1[0][0]']        
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       
                                                                                                  
 batch_normalization_2 (Bat  (None, 128, 128, 128)        512       ['conv2d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_2 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_3 (Conv2D)           (None, 128, 128, 128)        147584    ['activation_2[0][0]']        
                                                                                                  
 batch_normalization_3 (Bat  (None, 128, 128, 128)        512       ['conv2d_3[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_3 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_3[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_3[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 batch_normalization_4 (Bat  (None, 64, 64, 256)          1024      ['conv2d_4[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_4 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_4[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_5 (Conv2D)           (None, 64, 64, 256)          590080    ['activation_4[0][0]']        
                                                                                                  
 batch_normalization_5 (Bat  (None, 64, 64, 256)          1024      ['conv2d_5[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_5 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_5[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_5[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 512)          1180160   ['max_pooling2d_2[0][0]']     
                                                                                                  
 batch_normalization_6 (Bat  (None, 32, 32, 512)          2048      ['conv2d_6[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_6 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_6[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 32, 32, 512)          2359808   ['activation_6[0][0]']        
                                                                                                  
 batch_normalization_7 (Bat  (None, 32, 32, 512)          2048      ['conv2d_7[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_7 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_7[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_3 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_7[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 1024)         4719616   ['max_pooling2d_3[0][0]']     
                                                                                                  
 batch_normalization_8 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_8[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_8 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_8[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 1024)         9438208   ['activation_8[0][0]']        
                                                                                                  
 batch_normalization_9 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_9[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_9 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_9[0][0]'
                                                                    ]                             
                                                                                                  
 up_sampling2d (UpSampling2  (None, 32, 32, 1024)         0         ['activation_9[0][0]']        
 D)                                                                                               
                                                                                                  
 concatenate (Concatenate)   (None, 32, 32, 1536)         0         ['up_sampling2d[0][0]',       
                                                                     'activation_7[0][0]']        
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate[0][0]']         
                                                                                                  
 batch_normalization_10 (Ba  (None, 32, 32, 512)          2048      ['conv2d_10[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_10 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_10[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_10[0][0]']       
                                                                                                  
 batch_normalization_11 (Ba  (None, 32, 32, 512)          2048      ['conv2d_11[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_11 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_11[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 64, 64, 512)          0         ['activation_11[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_1 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_1[0][0]',     
 )                                                                   'activation_5[0][0]']        
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_1[0][0]']       
                                                                                                  
 batch_normalization_12 (Ba  (None, 64, 64, 256)          1024      ['conv2d_12[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_12 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_12[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_13 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_12[0][0]']       
                                                                                                  
 batch_normalization_13 (Ba  (None, 64, 64, 256)          1024      ['conv2d_13[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_13 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_13[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 128, 128, 256)        0         ['activation_13[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_2 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_2[0][0]',     
 )                                                                   'activation_3[0][0]']        
                                                                                                  
 conv2d_14 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_2[0][0]']       
                                                                                                  
 batch_normalization_14 (Ba  (None, 128, 128, 128)        512       ['conv2d_14[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_14 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_14[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_15 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_14[0][0]']       
                                                                                                  
 batch_normalization_15 (Ba  (None, 128, 128, 128)        512       ['conv2d_15[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_15 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_15[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 256, 256, 128)        0         ['activation_15[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_3 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_3[0][0]',     
 )                                                                   'activation_1[0][0]']        
                                                                                                  
 conv2d_16 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_3[0][0]']       
                                                                                                  
 batch_normalization_16 (Ba  (None, 256, 256, 64)         256       ['conv2d_16[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_16 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_16[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_16[0][0]']       
                                                                                                  
 batch_normalization_17 (Ba  (None, 256, 256, 64)         256       ['conv2d_17[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_17 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_17[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_18 (Conv2D)          (None, 256, 256, 1)          65        ['activation_17[0][0]']       
                                                                                                  
 batch_normalization_18 (Ba  (None, 256, 256, 1)          4         ['conv2d_18[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_18 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_18[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31401349 (119.79 MB)
Trainable params: 31389571 (119.74 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
None
✓ focal_loss imported successfully
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_2 (InputLayer)        [(None, 256, 256, 3)]        0         []                            
                                                                                                  
 conv2d_19 (Conv2D)          (None, 256, 256, 64)         1792      ['input_2[0][0]']             
                                                                                                  
 batch_normalization_19 (Ba  (None, 256, 256, 64)         256       ['conv2d_19[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_19 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_19[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_20 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_19[0][0]']       
                                                                                                  
 batch_normalization_20 (Ba  (None, 256, 256, 64)         256       ['conv2d_20[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_20 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_20[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_4 (MaxPoolin  (None, 128, 128, 64)         0         ['activation_20[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_21 (Conv2D)          (None, 128, 128, 128)        73856     ['max_pooling2d_4[0][0]']     
                                                                                                  
 batch_normalization_21 (Ba  (None, 128, 128, 128)        512       ['conv2d_21[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_21 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_21[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_22 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_21[0][0]']       
                                                                                                  
 batch_normalization_22 (Ba  (None, 128, 128, 128)        512       ['conv2d_22[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_22 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_22[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_5 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_22[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_23 (Conv2D)          (None, 64, 64, 256)          295168    ['max_pooling2d_5[0][0]']     
                                                                                                  
 batch_normalization_23 (Ba  (None, 64, 64, 256)          1024      ['conv2d_23[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_23 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_23[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_24 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_23[0][0]']       
                                                                                                  
 batch_normalization_24 (Ba  (None, 64, 64, 256)          1024      ['conv2d_24[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_24 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_24[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_6 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_24[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_25 (Conv2D)          (None, 32, 32, 512)          1180160   ['max_pooling2d_6[0][0]']     
                                                                                                  
 batch_normalization_25 (Ba  (None, 32, 32, 512)          2048      ['conv2d_25[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_25 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_25[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_26 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_25[0][0]']       
                                                                                                  
 batch_normalization_26 (Ba  (None, 32, 32, 512)          2048      ['conv2d_26[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_26 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_26[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_7 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_26[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_27 (Conv2D)          (None, 16, 16, 1024)         4719616   ['max_pooling2d_7[0][0]']     
                                                                                                  
 batch_normalization_27 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_27[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_27 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_27[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_28 (Conv2D)          (None, 16, 16, 1024)         9438208   ['activation_27[0][0]']       
                                                                                                  
 batch_normalization_28 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_28[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_28 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_28[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 1024)         0         ['activation_28[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_4 (Concatenate  (None, 32, 32, 1536)         0         ['up_sampling2d_4[0][0]',     
 )                                                                   'activation_26[0][0]']       
                                                                                                  
 conv2d_29 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate_4[0][0]']       
                                                                                                  
 batch_normalization_29 (Ba  (None, 32, 32, 512)          2048      ['conv2d_29[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_29 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_29[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_30 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_29[0][0]']       
                                                                                                  
 batch_normalization_30 (Ba  (None, 32, 32, 512)          2048      ['conv2d_30[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_30 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_30[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 512)          0         ['activation_30[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_5 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_5[0][0]',     
 )                                                                   'activation_24[0][0]']       
                                                                                                  
 conv2d_31 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_5[0][0]']       
                                                                                                  
 batch_normalization_31 (Ba  (None, 64, 64, 256)          1024      ['conv2d_31[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_31 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_31[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_32 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_31[0][0]']       
                                                                                                  
 batch_normalization_32 (Ba  (None, 64, 64, 256)          1024      ['conv2d_32[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_32 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_32[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_6 (UpSamplin  (None, 128, 128, 256)        0         ['activation_32[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_6 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_6[0][0]',     
 )                                                                   'activation_22[0][0]']       
                                                                                                  
 conv2d_33 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_6[0][0]']       
                                                                                                  
 batch_normalization_33 (Ba  (None, 128, 128, 128)        512       ['conv2d_33[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_33 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_33[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_34 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_33[0][0]']       
                                                                                                  
 batch_normalization_34 (Ba  (None, 128, 128, 128)        512       ['conv2d_34[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_34 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_34[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_7 (UpSamplin  (None, 256, 256, 128)        0         ['activation_34[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_7 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_7[0][0]',     
 )                                                                   'activation_20[0][0]']       
                                                                                                  
 conv2d_35 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_7[0][0]']       
                                                                                                  
 batch_normalization_35 (Ba  (None, 256, 256, 64)         256       ['conv2d_35[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_35 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_35[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_36 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_35[0][0]']       
                                                                                                  
 batch_normalization_36 (Ba  (None, 256, 256, 64)         256       ['conv2d_36[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_36 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_36[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_37 (Conv2D)          (None, 256, 256, 1)          65        ['activation_36[0][0]']       
                                                                                                  
 batch_normalization_37 (Ba  (None, 256, 256, 1)          4         ['conv2d_37[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_37 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_37[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31402501 (119.79 MB)
Trainable params: 31390723 (119.75 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
WARNING:absl:`lr` is deprecated in TF-Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
None
Epoch 1/30
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1758877348.517895 1047958 service.cc:145] XLA service 0x146629c20470 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1758877348.517919 1047958 service.cc:153]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6
I0000 00:00:1758877348.654818 1047958 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
 1/17 [>.............................] - ETA: 8:34 - loss: 0.3451 - accuracy: 0.5031 - jacard_coef: 0.0648 2/17 [==>...........................] - ETA: 59s - loss: 0.3218 - accuracy: 0.4470 - jacard_coef: 0.0635  3/17 [====>.........................] - ETA: 35s - loss: 0.2874 - accuracy: 0.3872 - jacard_coef: 0.0826 4/17 [======>.......................] - ETA: 26s - loss: 0.2667 - accuracy: 0.3466 - jacard_coef: 0.0824 5/17 [=======>......................] - ETA: 18s - loss: 0.2562 - accuracy: 0.3151 - jacard_coef: 0.0856 6/17 [=========>....................] - ETA: 13s - loss: 0.2460 - accuracy: 0.2890 - jacard_coef: 0.0797 7/17 [===========>..................] - ETA: 10s - loss: 0.2398 - accuracy: 0.2657 - jacard_coef: 0.0784 8/17 [=============>................] - ETA: 8s - loss: 0.2366 - accuracy: 0.2620 - jacard_coef: 0.0819  9/17 [==============>...............] - ETA: 6s - loss: 0.2310 - accuracy: 0.2596 - jacard_coef: 0.079810/17 [================>.............] - ETA: 5s - loss: 0.2281 - accuracy: 0.2658 - jacard_coef: 0.080511/17 [==================>...........] - ETA: 4s - loss: 0.2278 - accuracy: 0.2581 - jacard_coef: 0.078912/17 [====================>.........] - ETA: 3s - loss: 0.2251 - accuracy: 0.2585 - jacard_coef: 0.082413/17 [=====================>........] - ETA: 2s - loss: 0.2222 - accuracy: 0.2593 - jacard_coef: 0.083814/17 [=======================>......] - ETA: 1s - loss: 0.2208 - accuracy: 0.2559 - jacard_coef: 0.084915/17 [=========================>....] - ETA: 1s - loss: 0.2198 - accuracy: 0.2501 - jacard_coef: 0.083216/17 [===========================>..] - ETA: 0s - loss: 0.2176 - accuracy: 0.2509 - jacard_coef: 0.081217/17 [==============================] - ETA: 0s - loss: 0.2174 - accuracy: 0.2506 - jacard_coef: 0.079817/17 [==============================] - 46s 855ms/step - loss: 0.2174 - accuracy: 0.2506 - jacard_coef: 0.0798 - val_loss: 1.1062 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 0.0010
Epoch 2/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1843 - accuracy: 0.3133 - jacard_coef: 0.0613 2/17 [==>...........................] - ETA: 1s - loss: 0.1854 - accuracy: 0.2918 - jacard_coef: 0.0735 3/17 [====>.........................] - ETA: 1s - loss: 0.1837 - accuracy: 0.3090 - jacard_coef: 0.0755 4/17 [======>.......................] - ETA: 1s - loss: 0.1824 - accuracy: 0.3158 - jacard_coef: 0.0827 5/17 [=======>......................] - ETA: 1s - loss: 0.1828 - accuracy: 0.2986 - jacard_coef: 0.0827 6/17 [=========>....................] - ETA: 1s - loss: 0.1824 - accuracy: 0.3070 - jacard_coef: 0.0824 7/17 [===========>..................] - ETA: 1s - loss: 0.1821 - accuracy: 0.3133 - jacard_coef: 0.0748 8/17 [=============>................] - ETA: 1s - loss: 0.1815 - accuracy: 0.3236 - jacard_coef: 0.0729 9/17 [==============>...............] - ETA: 1s - loss: 0.1806 - accuracy: 0.3403 - jacard_coef: 0.072010/17 [================>.............] - ETA: 0s - loss: 0.1801 - accuracy: 0.3498 - jacard_coef: 0.071011/17 [==================>...........] - ETA: 0s - loss: 0.1799 - accuracy: 0.3580 - jacard_coef: 0.073812/17 [====================>.........] - ETA: 0s - loss: 0.1805 - accuracy: 0.3809 - jacard_coef: 0.073913/17 [=====================>........] - ETA: 0s - loss: 0.1804 - accuracy: 0.3970 - jacard_coef: 0.073314/17 [=======================>......] - ETA: 0s - loss: 0.1802 - accuracy: 0.4092 - jacard_coef: 0.077215/17 [=========================>....] - ETA: 0s - loss: 0.1798 - accuracy: 0.4199 - jacard_coef: 0.077616/17 [===========================>..] - ETA: 0s - loss: 0.1794 - accuracy: 0.4223 - jacard_coef: 0.077617/17 [==============================] - ETA: 0s - loss: 0.1796 - accuracy: 0.4218 - jacard_coef: 0.081817/17 [==============================] - 2s 134ms/step - loss: 0.1796 - accuracy: 0.4218 - jacard_coef: 0.0818 - val_loss: 0.1199 - val_accuracy: 0.9195 - val_jacard_coef: 0.0181 - lr: 0.0010
Epoch 3/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1781 - accuracy: 0.3206 - jacard_coef: 0.0464 2/17 [==>...........................] - ETA: 1s - loss: 0.1796 - accuracy: 0.3087 - jacard_coef: 0.0664 3/17 [====>.........................] - ETA: 1s - loss: 0.1830 - accuracy: 0.2918 - jacard_coef: 0.0756 4/17 [======>.......................] - ETA: 1s - loss: 0.1842 - accuracy: 0.2731 - jacard_coef: 0.0730 5/17 [=======>......................] - ETA: 1s - loss: 0.1839 - accuracy: 0.2814 - jacard_coef: 0.0735 6/17 [=========>....................] - ETA: 1s - loss: 0.1848 - accuracy: 0.2853 - jacard_coef: 0.0822 7/17 [===========>..................] - ETA: 1s - loss: 0.1854 - accuracy: 0.2831 - jacard_coef: 0.0807 8/17 [=============>................] - ETA: 1s - loss: 0.1855 - accuracy: 0.2716 - jacard_coef: 0.0813 9/17 [==============>...............] - ETA: 1s - loss: 0.1857 - accuracy: 0.2660 - jacard_coef: 0.083710/17 [================>.............] - ETA: 0s - loss: 0.1865 - accuracy: 0.2742 - jacard_coef: 0.083011/17 [==================>...........] - ETA: 0s - loss: 0.1860 - accuracy: 0.2927 - jacard_coef: 0.082112/17 [====================>.........] - ETA: 0s - loss: 0.1864 - accuracy: 0.2988 - jacard_coef: 0.082113/17 [=====================>........] - ETA: 0s - loss: 0.1859 - accuracy: 0.2988 - jacard_coef: 0.082314/17 [=======================>......] - ETA: 0s - loss: 0.1856 - accuracy: 0.3082 - jacard_coef: 0.082015/17 [=========================>....] - ETA: 0s - loss: 0.1848 - accuracy: 0.3212 - jacard_coef: 0.083716/17 [===========================>..] - ETA: 0s - loss: 0.1842 - accuracy: 0.3297 - jacard_coef: 0.081217/17 [==============================] - 2s 127ms/step - loss: 0.1842 - accuracy: 0.3302 - jacard_coef: 0.0765 - val_loss: 0.4437 - val_accuracy: 0.9302 - val_jacard_coef: 2.4789e-04 - lr: 0.0010
Epoch 4/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1757 - accuracy: 0.4821 - jacard_coef: 0.0819 2/17 [==>...........................] - ETA: 1s - loss: 0.1758 - accuracy: 0.5123 - jacard_coef: 0.0679 3/17 [====>.........................] - ETA: 1s - loss: 0.1743 - accuracy: 0.5116 - jacard_coef: 0.0600 4/17 [======>.......................] - ETA: 1s - loss: 0.1743 - accuracy: 0.4936 - jacard_coef: 0.0582 5/17 [=======>......................] - ETA: 1s - loss: 0.1757 - accuracy: 0.5222 - jacard_coef: 0.0629 6/17 [=========>....................] - ETA: 1s - loss: 0.1747 - accuracy: 0.5410 - jacard_coef: 0.0632 7/17 [===========>..................] - ETA: 1s - loss: 0.1738 - accuracy: 0.5628 - jacard_coef: 0.0645 8/17 [=============>................] - ETA: 1s - loss: 0.1734 - accuracy: 0.5625 - jacard_coef: 0.0678 9/17 [==============>...............] - ETA: 1s - loss: 0.1728 - accuracy: 0.5686 - jacard_coef: 0.071210/17 [================>.............] - ETA: 0s - loss: 0.1724 - accuracy: 0.5663 - jacard_coef: 0.067711/17 [==================>...........] - ETA: 0s - loss: 0.1717 - accuracy: 0.5792 - jacard_coef: 0.070312/17 [====================>.........] - ETA: 0s - loss: 0.1717 - accuracy: 0.5749 - jacard_coef: 0.071313/17 [=====================>........] - ETA: 0s - loss: 0.1717 - accuracy: 0.5725 - jacard_coef: 0.074914/17 [=======================>......] - ETA: 0s - loss: 0.1714 - accuracy: 0.5745 - jacard_coef: 0.076515/17 [=========================>....] - ETA: 0s - loss: 0.1713 - accuracy: 0.5690 - jacard_coef: 0.077716/17 [===========================>..] - ETA: 0s - loss: 0.1711 - accuracy: 0.5711 - jacard_coef: 0.078317/17 [==============================] - 2s 128ms/step - loss: 0.1711 - accuracy: 0.5713 - jacard_coef: 0.0821 - val_loss: 0.1515 - val_accuracy: 0.9081 - val_jacard_coef: 0.0104 - lr: 0.0010
Epoch 5/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1674 - accuracy: 0.6038 - jacard_coef: 0.0624 2/17 [==>...........................] - ETA: 1s - loss: 0.1666 - accuracy: 0.6794 - jacard_coef: 0.0841 3/17 [====>.........................] - ETA: 1s - loss: 0.1653 - accuracy: 0.7562 - jacard_coef: 0.0615 4/17 [======>.......................] - ETA: 1s - loss: 0.1670 - accuracy: 0.7441 - jacard_coef: 0.0658 5/17 [=======>......................] - ETA: 1s - loss: 0.1661 - accuracy: 0.7474 - jacard_coef: 0.0647 6/17 [=========>....................] - ETA: 1s - loss: 0.1654 - accuracy: 0.7409 - jacard_coef: 0.0644 7/17 [===========>..................] - ETA: 1s - loss: 0.1650 - accuracy: 0.7476 - jacard_coef: 0.0645 8/17 [=============>................] - ETA: 1s - loss: 0.1645 - accuracy: 0.7485 - jacard_coef: 0.0617 9/17 [==============>...............] - ETA: 1s - loss: 0.1642 - accuracy: 0.7478 - jacard_coef: 0.062710/17 [================>.............] - ETA: 0s - loss: 0.1652 - accuracy: 0.7260 - jacard_coef: 0.063411/17 [==================>...........] - ETA: 0s - loss: 0.1653 - accuracy: 0.7333 - jacard_coef: 0.062312/17 [====================>.........] - ETA: 0s - loss: 0.1657 - accuracy: 0.7302 - jacard_coef: 0.063913/17 [=====================>........] - ETA: 0s - loss: 0.1658 - accuracy: 0.7239 - jacard_coef: 0.068114/17 [=======================>......] - ETA: 0s - loss: 0.1658 - accuracy: 0.7172 - jacard_coef: 0.068515/17 [=========================>....] - ETA: 0s - loss: 0.1660 - accuracy: 0.7165 - jacard_coef: 0.067016/17 [===========================>..] - ETA: 0s - loss: 0.1661 - accuracy: 0.7042 - jacard_coef: 0.069017/17 [==============================] - 2s 127ms/step - loss: 0.1662 - accuracy: 0.7022 - jacard_coef: 0.0651 - val_loss: 0.0843 - val_accuracy: 0.9183 - val_jacard_coef: 0.0077 - lr: 0.0010
Epoch 6/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1657 - accuracy: 0.6898 - jacard_coef: 0.0713 2/17 [==>...........................] - ETA: 1s - loss: 0.1735 - accuracy: 0.6785 - jacard_coef: 0.0670 3/17 [====>.........................] - ETA: 1s - loss: 0.1700 - accuracy: 0.6932 - jacard_coef: 0.0651 4/17 [======>.......................] - ETA: 1s - loss: 0.1681 - accuracy: 0.6995 - jacard_coef: 0.0615 5/17 [=======>......................] - ETA: 1s - loss: 0.1671 - accuracy: 0.7224 - jacard_coef: 0.0591 6/17 [=========>....................] - ETA: 1s - loss: 0.1670 - accuracy: 0.7305 - jacard_coef: 0.0591 7/17 [===========>..................] - ETA: 1s - loss: 0.1661 - accuracy: 0.7307 - jacard_coef: 0.0612 8/17 [=============>................] - ETA: 1s - loss: 0.1656 - accuracy: 0.7332 - jacard_coef: 0.0621 9/17 [==============>...............] - ETA: 1s - loss: 0.1651 - accuracy: 0.7335 - jacard_coef: 0.062610/17 [================>.............] - ETA: 0s - loss: 0.1647 - accuracy: 0.7263 - jacard_coef: 0.064011/17 [==================>...........] - ETA: 0s - loss: 0.1642 - accuracy: 0.7391 - jacard_coef: 0.062712/17 [====================>.........] - ETA: 0s - loss: 0.1638 - accuracy: 0.7461 - jacard_coef: 0.060813/17 [=====================>........] - ETA: 0s - loss: 0.1633 - accuracy: 0.7574 - jacard_coef: 0.057814/17 [=======================>......] - ETA: 0s - loss: 0.1630 - accuracy: 0.7494 - jacard_coef: 0.057515/17 [=========================>....] - ETA: 0s - loss: 0.1629 - accuracy: 0.7490 - jacard_coef: 0.058616/17 [===========================>..] - ETA: 0s - loss: 0.1632 - accuracy: 0.7393 - jacard_coef: 0.061017/17 [==============================] - 2s 128ms/step - loss: 0.1634 - accuracy: 0.7384 - jacard_coef: 0.0650 - val_loss: 0.0963 - val_accuracy: 0.9180 - val_jacard_coef: 0.0076 - lr: 0.0010
Epoch 7/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1591 - accuracy: 0.5912 - jacard_coef: 0.0763 2/17 [==>...........................] - ETA: 1s - loss: 0.1588 - accuracy: 0.6807 - jacard_coef: 0.0730 3/17 [====>.........................] - ETA: 1s - loss: 0.1595 - accuracy: 0.6861 - jacard_coef: 0.0774 4/17 [======>.......................] - ETA: 1s - loss: 0.1591 - accuracy: 0.7021 - jacard_coef: 0.0708 5/17 [=======>......................] - ETA: 1s - loss: 0.1619 - accuracy: 0.6846 - jacard_coef: 0.0788 6/17 [=========>....................] - ETA: 1s - loss: 0.1627 - accuracy: 0.7155 - jacard_coef: 0.0717 7/17 [===========>..................] - ETA: 1s - loss: 0.1624 - accuracy: 0.7389 - jacard_coef: 0.0653 8/17 [=============>................] - ETA: 1s - loss: 0.1627 - accuracy: 0.7410 - jacard_coef: 0.0665 9/17 [==============>...............] - ETA: 1s - loss: 0.1627 - accuracy: 0.7449 - jacard_coef: 0.065610/17 [================>.............] - ETA: 0s - loss: 0.1631 - accuracy: 0.7280 - jacard_coef: 0.068211/17 [==================>...........] - ETA: 0s - loss: 0.1631 - accuracy: 0.7324 - jacard_coef: 0.066912/17 [====================>.........] - ETA: 0s - loss: 0.1633 - accuracy: 0.7228 - jacard_coef: 0.065513/17 [=====================>........] - ETA: 0s - loss: 0.1641 - accuracy: 0.7335 - jacard_coef: 0.063714/17 [=======================>......] - ETA: 0s - loss: 0.1653 - accuracy: 0.7349 - jacard_coef: 0.064615/17 [=========================>....] - ETA: 0s - loss: 0.1656 - accuracy: 0.7329 - jacard_coef: 0.063216/17 [===========================>..] - ETA: 0s - loss: 0.1652 - accuracy: 0.7370 - jacard_coef: 0.062217/17 [==============================] - 2s 130ms/step - loss: 0.1652 - accuracy: 0.7381 - jacard_coef: 0.0588 - val_loss: 0.1652 - val_accuracy: 0.5866 - val_jacard_coef: 0.0574 - lr: 0.0010
Epoch 8/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1709 - accuracy: 0.8911 - jacard_coef: 0.0488 2/17 [==>...........................] - ETA: 1s - loss: 0.1641 - accuracy: 0.8595 - jacard_coef: 0.0401 3/17 [====>.........................] - ETA: 1s - loss: 0.1626 - accuracy: 0.8046 - jacard_coef: 0.0523 4/17 [======>.......................] - ETA: 1s - loss: 0.1606 - accuracy: 0.8139 - jacard_coef: 0.0529 5/17 [=======>......................] - ETA: 1s - loss: 0.1597 - accuracy: 0.8039 - jacard_coef: 0.0583 6/17 [=========>....................] - ETA: 1s - loss: 0.1586 - accuracy: 0.8102 - jacard_coef: 0.0554 7/17 [===========>..................] - ETA: 1s - loss: 0.1583 - accuracy: 0.8050 - jacard_coef: 0.0557 8/17 [=============>................] - ETA: 1s - loss: 0.1578 - accuracy: 0.7960 - jacard_coef: 0.0589 9/17 [==============>...............] - ETA: 1s - loss: 0.1574 - accuracy: 0.7996 - jacard_coef: 0.060010/17 [================>.............] - ETA: 0s - loss: 0.1569 - accuracy: 0.8055 - jacard_coef: 0.056711/17 [==================>...........] - ETA: 0s - loss: 0.1564 - accuracy: 0.8162 - jacard_coef: 0.051812/17 [====================>.........] - ETA: 0s - loss: 0.1559 - accuracy: 0.8251 - jacard_coef: 0.048113/17 [=====================>........] - ETA: 0s - loss: 0.1556 - accuracy: 0.8319 - jacard_coef: 0.044414/17 [=======================>......] - ETA: 0s - loss: 0.1550 - accuracy: 0.8394 - jacard_coef: 0.041215/17 [=========================>....] - ETA: 0s - loss: 0.1546 - accuracy: 0.8462 - jacard_coef: 0.039216/17 [===========================>..] - ETA: 0s - loss: 0.1542 - accuracy: 0.8511 - jacard_coef: 0.036817/17 [==============================] - 2s 130ms/step - loss: 0.1543 - accuracy: 0.8489 - jacard_coef: 0.0414 - val_loss: 0.1781 - val_accuracy: 0.4047 - val_jacard_coef: 0.0755 - lr: 0.0010
Epoch 9/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1504 - accuracy: 0.9187 - jacard_coef: 2.3470e-12 2/17 [==>...........................] - ETA: 1s - loss: 0.1575 - accuracy: 0.8801 - jacard_coef: 0.0313     3/17 [====>.........................] - ETA: 1s - loss: 0.1564 - accuracy: 0.8529 - jacard_coef: 0.0391 4/17 [======>.......................] - ETA: 1s - loss: 0.1565 - accuracy: 0.8329 - jacard_coef: 0.0477 5/17 [=======>......................] - ETA: 1s - loss: 0.1560 - accuracy: 0.8224 - jacard_coef: 0.0469 6/17 [=========>....................] - ETA: 1s - loss: 0.1566 - accuracy: 0.8061 - jacard_coef: 0.0458 7/17 [===========>..................] - ETA: 1s - loss: 0.1562 - accuracy: 0.8102 - jacard_coef: 0.0430 8/17 [=============>................] - ETA: 1s - loss: 0.1560 - accuracy: 0.8150 - jacard_coef: 0.0409 9/17 [==============>...............] - ETA: 1s - loss: 0.1559 - accuracy: 0.8266 - jacard_coef: 0.038110/17 [================>.............] - ETA: 0s - loss: 0.1571 - accuracy: 0.8129 - jacard_coef: 0.037311/17 [==================>...........] - ETA: 0s - loss: 0.1564 - accuracy: 0.8195 - jacard_coef: 0.036612/17 [====================>.........] - ETA: 0s - loss: 0.1562 - accuracy: 0.8232 - jacard_coef: 0.037313/17 [=====================>........] - ETA: 0s - loss: 0.1560 - accuracy: 0.8282 - jacard_coef: 0.036414/17 [=======================>......] - ETA: 0s - loss: 0.1562 - accuracy: 0.8303 - jacard_coef: 0.037215/17 [=========================>....] - ETA: 0s - loss: 0.1561 - accuracy: 0.8319 - jacard_coef: 0.036416/17 [===========================>..] - ETA: 0s - loss: 0.1560 - accuracy: 0.8343 - jacard_coef: 0.036117/17 [==============================] - 2s 128ms/step - loss: 0.1562 - accuracy: 0.8335 - jacard_coef: 0.0371 - val_loss: 0.1787 - val_accuracy: 0.2318 - val_jacard_coef: 0.0678 - lr: 0.0010
Epoch 10/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1504 - accuracy: 0.8883 - jacard_coef: 0.0095 2/17 [==>...........................] - ETA: 1s - loss: 0.1501 - accuracy: 0.8870 - jacard_coef: 0.0122 3/17 [====>.........................] - ETA: 1s - loss: 0.1524 - accuracy: 0.8910 - jacard_coef: 0.0171 4/17 [======>.......................] - ETA: 1s - loss: 0.1523 - accuracy: 0.8829 - jacard_coef: 0.0190 5/17 [=======>......................] - ETA: 1s - loss: 0.1515 - accuracy: 0.8762 - jacard_coef: 0.0226 6/17 [=========>....................] - ETA: 1s - loss: 0.1510 - accuracy: 0.8745 - jacard_coef: 0.0242 7/17 [===========>..................] - ETA: 1s - loss: 0.1506 - accuracy: 0.8767 - jacard_coef: 0.0244 8/17 [=============>................] - ETA: 1s - loss: 0.1507 - accuracy: 0.8764 - jacard_coef: 0.0267 9/17 [==============>...............] - ETA: 1s - loss: 0.1504 - accuracy: 0.8741 - jacard_coef: 0.028510/17 [================>.............] - ETA: 0s - loss: 0.1507 - accuracy: 0.8642 - jacard_coef: 0.037811/17 [==================>...........] - ETA: 0s - loss: 0.1504 - accuracy: 0.8632 - jacard_coef: 0.037812/17 [====================>.........] - ETA: 0s - loss: 0.1502 - accuracy: 0.8597 - jacard_coef: 0.038113/17 [=====================>........] - ETA: 0s - loss: 0.1497 - accuracy: 0.8537 - jacard_coef: 0.035714/17 [=======================>......] - ETA: 0s - loss: 0.1496 - accuracy: 0.8497 - jacard_coef: 0.037615/17 [=========================>....] - ETA: 0s - loss: 0.1493 - accuracy: 0.8510 - jacard_coef: 0.038116/17 [===========================>..] - ETA: 0s - loss: 0.1493 - accuracy: 0.8544 - jacard_coef: 0.036317/17 [==============================] - 2s 128ms/step - loss: 0.1493 - accuracy: 0.8543 - jacard_coef: 0.0345 - val_loss: 0.1654 - val_accuracy: 0.8213 - val_jacard_coef: 0.0317 - lr: 0.0010
Epoch 11/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1496 - accuracy: 0.8783 - jacard_coef: 0.0142 2/17 [==>...........................] - ETA: 1s - loss: 0.1474 - accuracy: 0.8325 - jacard_coef: 0.0394 3/17 [====>.........................] - ETA: 1s - loss: 0.1465 - accuracy: 0.8326 - jacard_coef: 0.0344 4/17 [======>.......................] - ETA: 1s - loss: 0.1456 - accuracy: 0.8504 - jacard_coef: 0.0339 5/17 [=======>......................] - ETA: 1s - loss: 0.1466 - accuracy: 0.8272 - jacard_coef: 0.0329 6/17 [=========>....................] - ETA: 1s - loss: 0.1459 - accuracy: 0.8438 - jacard_coef: 0.0274 7/17 [===========>..................] - ETA: 1s - loss: 0.1465 - accuracy: 0.8525 - jacard_coef: 0.0267 8/17 [=============>................] - ETA: 1s - loss: 0.1463 - accuracy: 0.8568 - jacard_coef: 0.0233 9/17 [==============>...............] - ETA: 1s - loss: 0.1459 - accuracy: 0.8639 - jacard_coef: 0.022010/17 [================>.............] - ETA: 0s - loss: 0.1459 - accuracy: 0.8652 - jacard_coef: 0.019811/17 [==================>...........] - ETA: 0s - loss: 0.1456 - accuracy: 0.8681 - jacard_coef: 0.018712/17 [====================>.........] - ETA: 0s - loss: 0.1451 - accuracy: 0.8740 - jacard_coef: 0.017113/17 [=====================>........] - ETA: 0s - loss: 0.1449 - accuracy: 0.8765 - jacard_coef: 0.015814/17 [=======================>......] - ETA: 0s - loss: 0.1450 - accuracy: 0.8766 - jacard_coef: 0.016915/17 [=========================>....] - ETA: 0s - loss: 0.1447 - accuracy: 0.8784 - jacard_coef: 0.015816/17 [===========================>..] - ETA: 0s - loss: 0.1445 - accuracy: 0.8811 - jacard_coef: 0.014817/17 [==============================] - 2s 128ms/step - loss: 0.1445 - accuracy: 0.8814 - jacard_coef: 0.0139 - val_loss: 0.1809 - val_accuracy: 0.1947 - val_jacard_coef: 0.0680 - lr: 0.0010
Epoch 12/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1417 - accuracy: 0.9249 - jacard_coef: 2.5402e-12 2/17 [==>...........................] - ETA: 1s - loss: 0.1399 - accuracy: 0.9323 - jacard_coef: 2.8488e-12 3/17 [====>.........................] - ETA: 1s - loss: 0.1392 - accuracy: 0.9374 - jacard_coef: 3.1165e-12 4/17 [======>.......................] - ETA: 1s - loss: 0.1389 - accuracy: 0.9384 - jacard_coef: 3.1482e-12 5/17 [=======>......................] - ETA: 1s - loss: 0.1410 - accuracy: 0.9289 - jacard_coef: 3.8122e-04 6/17 [=========>....................] - ETA: 1s - loss: 0.1403 - accuracy: 0.9324 - jacard_coef: 3.1768e-04 7/17 [===========>..................] - ETA: 1s - loss: 0.1402 - accuracy: 0.9324 - jacard_coef: 0.0010     8/17 [=============>................] - ETA: 1s - loss: 0.1403 - accuracy: 0.9265 - jacard_coef: 8.9960e-04 9/17 [==============>...............] - ETA: 1s - loss: 0.1400 - accuracy: 0.9259 - jacard_coef: 7.9964e-0410/17 [================>.............] - ETA: 0s - loss: 0.1400 - accuracy: 0.9230 - jacard_coef: 0.0018    11/17 [==================>...........] - ETA: 0s - loss: 0.1398 - accuracy: 0.9219 - jacard_coef: 0.001712/17 [====================>.........] - ETA: 0s - loss: 0.1399 - accuracy: 0.9186 - jacard_coef: 0.001513/17 [=====================>........] - ETA: 0s - loss: 0.1397 - accuracy: 0.9188 - jacard_coef: 0.001414/17 [=======================>......] - ETA: 0s - loss: 0.1396 - accuracy: 0.9187 - jacard_coef: 0.001415/17 [=========================>....] - ETA: 0s - loss: 0.1397 - accuracy: 0.9151 - jacard_coef: 0.001316/17 [===========================>..] - ETA: 0s - loss: 0.1395 - accuracy: 0.9157 - jacard_coef: 0.001317/17 [==============================] - 2s 128ms/step - loss: 0.1395 - accuracy: 0.9154 - jacard_coef: 0.0018 - val_loss: 0.1854 - val_accuracy: 0.1616 - val_jacard_coef: 0.0686 - lr: 0.0010
Epoch 13/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1336 - accuracy: 0.9497 - jacard_coef: 3.7887e-12 2/17 [==>...........................] - ETA: 1s - loss: 0.1346 - accuracy: 0.9361 - jacard_coef: 3.1271e-12 3/17 [====>.........................] - ETA: 1s - loss: 0.1364 - accuracy: 0.9209 - jacard_coef: 0.0029     4/17 [======>.......................] - ETA: 1s - loss: 0.1359 - accuracy: 0.9248 - jacard_coef: 0.0022 5/17 [=======>......................] - ETA: 1s - loss: 0.1362 - accuracy: 0.9161 - jacard_coef: 0.0081 6/17 [=========>....................] - ETA: 1s - loss: 0.1363 - accuracy: 0.9114 - jacard_coef: 0.0088 7/17 [===========>..................] - ETA: 1s - loss: 0.1360 - accuracy: 0.9150 - jacard_coef: 0.0076 8/17 [=============>................] - ETA: 1s - loss: 0.1360 - accuracy: 0.9136 - jacard_coef: 0.0066 9/17 [==============>...............] - ETA: 1s - loss: 0.1361 - accuracy: 0.9120 - jacard_coef: 0.005910/17 [================>.............] - ETA: 0s - loss: 0.1367 - accuracy: 0.9063 - jacard_coef: 0.005311/17 [==================>...........] - ETA: 0s - loss: 0.1364 - accuracy: 0.9086 - jacard_coef: 0.004812/17 [====================>.........] - ETA: 0s - loss: 0.1364 - accuracy: 0.9114 - jacard_coef: 0.004513/17 [=====================>........] - ETA: 0s - loss: 0.1365 - accuracy: 0.9098 - jacard_coef: 0.004214/17 [=======================>......] - ETA: 0s - loss: 0.1362 - accuracy: 0.9112 - jacard_coef: 0.003915/17 [=========================>....] - ETA: 0s - loss: 0.1362 - accuracy: 0.9110 - jacard_coef: 0.003616/17 [===========================>..] - ETA: 0s - loss: 0.1359 - accuracy: 0.9134 - jacard_coef: 0.003417/17 [==============================] - 2s 128ms/step - loss: 0.1360 - accuracy: 0.9129 - jacard_coef: 0.0032 - val_loss: 0.1558 - val_accuracy: 0.9300 - val_jacard_coef: 2.5806e-04 - lr: 0.0010
Epoch 14/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1341 - accuracy: 0.9263 - jacard_coef: 2.5867e-12 2/17 [==>...........................] - ETA: 1s - loss: 0.1328 - accuracy: 0.9346 - jacard_coef: 2.9632e-12 3/17 [====>.........................] - ETA: 1s - loss: 0.1332 - accuracy: 0.9270 - jacard_coef: 2.6979e-12 4/17 [======>.......................] - ETA: 1s - loss: 0.1326 - accuracy: 0.9323 - jacard_coef: 2.9392e-12 5/17 [=======>......................] - ETA: 1s - loss: 0.1326 - accuracy: 0.9310 - jacard_coef: 2.8662e-12 6/17 [=========>....................] - ETA: 1s - loss: 0.1329 - accuracy: 0.9273 - jacard_coef: 2.7362e-12 7/17 [===========>..................] - ETA: 1s - loss: 0.1333 - accuracy: 0.9239 - jacard_coef: 2.6280e-12 8/17 [=============>................] - ETA: 1s - loss: 0.1336 - accuracy: 0.9202 - jacard_coef: 2.5250e-12 9/17 [==============>...............] - ETA: 1s - loss: 0.1338 - accuracy: 0.9212 - jacard_coef: 2.5454e-1210/17 [================>.............] - ETA: 0s - loss: 0.1341 - accuracy: 0.9186 - jacard_coef: 2.4718e-1211/17 [==================>...........] - ETA: 0s - loss: 0.1342 - accuracy: 0.9167 - jacard_coef: 2.4171e-1212/17 [====================>.........] - ETA: 0s - loss: 0.1339 - accuracy: 0.9181 - jacard_coef: 2.4539e-1213/17 [=====================>........] - ETA: 0s - loss: 0.1339 - accuracy: 0.9170 - jacard_coef: 1.9768e-0514/17 [=======================>......] - ETA: 0s - loss: 0.1341 - accuracy: 0.9149 - jacard_coef: 1.8356e-0515/17 [=========================>....] - ETA: 0s - loss: 0.1339 - accuracy: 0.9154 - jacard_coef: 2.0821e-0416/17 [===========================>..] - ETA: 0s - loss: 0.1336 - accuracy: 0.9169 - jacard_coef: 1.9714e-0417/17 [==============================] - 2s 128ms/step - loss: 0.1341 - accuracy: 0.9141 - jacard_coef: 0.0032 - val_loss: 0.1571 - val_accuracy: 0.9304 - val_jacard_coef: 3.4099e-12 - lr: 5.0000e-04
Epoch 15/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1307 - accuracy: 0.9434 - jacard_coef: 3.3714e-12 2/17 [==>...........................] - ETA: 1s - loss: 0.1357 - accuracy: 0.9176 - jacard_coef: 2.5663e-12 3/17 [====>.........................] - ETA: 1s - loss: 0.1359 - accuracy: 0.9224 - jacard_coef: 0.0030     4/17 [======>.......................] - ETA: 1s - loss: 0.1388 - accuracy: 0.9192 - jacard_coef: 0.0082 5/17 [=======>......................] - ETA: 1s - loss: 0.1399 - accuracy: 0.9170 - jacard_coef: 0.0170 6/17 [=========>....................] - ETA: 1s - loss: 0.1400 - accuracy: 0.9163 - jacard_coef: 0.0197 7/17 [===========>..................] - ETA: 1s - loss: 0.1421 - accuracy: 0.9113 - jacard_coef: 0.0178 8/17 [=============>................] - ETA: 1s - loss: 0.1464 - accuracy: 0.9068 - jacard_coef: 0.0168 9/17 [==============>...............] - ETA: 1s - loss: 0.1487 - accuracy: 0.9055 - jacard_coef: 0.016410/17 [================>.............] - ETA: 0s - loss: 0.1485 - accuracy: 0.9036 - jacard_coef: 0.014911/17 [==================>...........] - ETA: 0s - loss: 0.1485 - accuracy: 0.9002 - jacard_coef: 0.013812/17 [====================>.........] - ETA: 0s - loss: 0.1483 - accuracy: 0.8988 - jacard_coef: 0.012813/17 [=====================>........] - ETA: 0s - loss: 0.1489 - accuracy: 0.9009 - jacard_coef: 0.012314/17 [=======================>......] - ETA: 0s - loss: 0.1484 - accuracy: 0.9021 - jacard_coef: 0.011415/17 [=========================>....] - ETA: 0s - loss: 0.1480 - accuracy: 0.9016 - jacard_coef: 0.010616/17 [===========================>..] - ETA: 0s - loss: 0.1484 - accuracy: 0.9037 - jacard_coef: 0.010117/17 [==============================] - 2s 128ms/step - loss: 0.1483 - accuracy: 0.9040 - jacard_coef: 0.0095 - val_loss: 0.9688 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 5.0000e-04
Epoch 16/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1391 - accuracy: 0.9651 - jacard_coef: 5.4726e-12 2/17 [==>...........................] - ETA: 1s - loss: 0.1448 - accuracy: 0.9389 - jacard_coef: 3.8281e-12 3/17 [====>.........................] - ETA: 1s - loss: 0.1499 - accuracy: 0.9243 - jacard_coef: 3.1582e-12 4/17 [======>.......................] - ETA: 1s - loss: 0.1464 - accuracy: 0.9222 - jacard_coef: 2.9367e-12 5/17 [=======>......................] - ETA: 1s - loss: 0.1458 - accuracy: 0.9111 - jacard_coef: 2.6350e-12 6/17 [=========>....................] - ETA: 1s - loss: 0.1444 - accuracy: 0.9113 - jacard_coef: 1.4495e-05 7/17 [===========>..................] - ETA: 1s - loss: 0.1428 - accuracy: 0.9158 - jacard_coef: 1.2424e-05 8/17 [=============>................] - ETA: 1s - loss: 0.1414 - accuracy: 0.9201 - jacard_coef: 1.0871e-05 9/17 [==============>...............] - ETA: 1s - loss: 0.1409 - accuracy: 0.9190 - jacard_coef: 9.6631e-0610/17 [================>.............] - ETA: 0s - loss: 0.1402 - accuracy: 0.9193 - jacard_coef: 8.6968e-0611/17 [==================>...........] - ETA: 0s - loss: 0.1405 - accuracy: 0.9188 - jacard_coef: 1.2641e-0412/17 [====================>.........] - ETA: 0s - loss: 0.1402 - accuracy: 0.9186 - jacard_coef: 1.1587e-0413/17 [=====================>........] - ETA: 0s - loss: 0.1399 - accuracy: 0.9168 - jacard_coef: 1.0696e-0414/17 [=======================>......] - ETA: 0s - loss: 0.1397 - accuracy: 0.9159 - jacard_coef: 1.2354e-0415/17 [=========================>....] - ETA: 0s - loss: 0.1392 - accuracy: 0.9170 - jacard_coef: 1.1530e-0416/17 [===========================>..] - ETA: 0s - loss: 0.1388 - accuracy: 0.9177 - jacard_coef: 1.0810e-0417/17 [==============================] - 2s 128ms/step - loss: 0.1388 - accuracy: 0.9172 - jacard_coef: 1.1392e-04 - val_loss: 0.3073 - val_accuracy: 0.9304 - val_jacard_coef: 8.4830e-05 - lr: 5.0000e-04
Epoch 17/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1384 - accuracy: 0.8755 - jacard_coef: 1.5325e-12 2/17 [==>...........................] - ETA: 1s - loss: 0.1356 - accuracy: 0.8924 - jacard_coef: 1.8167e-12 3/17 [====>.........................] - ETA: 1s - loss: 0.1331 - accuracy: 0.9133 - jacard_coef: 2.6252e-12 4/17 [======>.......................] - ETA: 1s - loss: 0.1329 - accuracy: 0.9146 - jacard_coef: 5.8517e-06 5/17 [=======>......................] - ETA: 1s - loss: 0.1332 - accuracy: 0.9150 - jacard_coef: 4.6813e-06 6/17 [=========>....................] - ETA: 1s - loss: 0.1333 - accuracy: 0.9130 - jacard_coef: 3.9011e-06 7/17 [===========>..................] - ETA: 1s - loss: 0.1336 - accuracy: 0.9096 - jacard_coef: 3.3438e-06 8/17 [=============>................] - ETA: 1s - loss: 0.1334 - accuracy: 0.9123 - jacard_coef: 2.9258e-06 9/17 [==============>...............] - ETA: 1s - loss: 0.1348 - accuracy: 0.9121 - jacard_coef: 1.2060e-0510/17 [================>.............] - ETA: 0s - loss: 0.1344 - accuracy: 0.9138 - jacard_coef: 1.0854e-0511/17 [==================>...........] - ETA: 0s - loss: 0.1336 - accuracy: 0.9187 - jacard_coef: 9.8673e-0612/17 [====================>.........] - ETA: 0s - loss: 0.1336 - accuracy: 0.9186 - jacard_coef: 9.0450e-0613/17 [=====================>........] - ETA: 0s - loss: 0.1331 - accuracy: 0.9205 - jacard_coef: 8.3492e-0614/17 [=======================>......] - ETA: 0s - loss: 0.1332 - accuracy: 0.9197 - jacard_coef: 5.1462e-0515/17 [=========================>....] - ETA: 0s - loss: 0.1334 - accuracy: 0.9169 - jacard_coef: 4.8031e-0516/17 [===========================>..] - ETA: 0s - loss: 0.1332 - accuracy: 0.9168 - jacard_coef: 4.5029e-0517/17 [==============================] - 2s 128ms/step - loss: 0.1332 - accuracy: 0.9168 - jacard_coef: 4.2381e-05 - val_loss: 0.1330 - val_accuracy: 0.9300 - val_jacard_coef: 4.5350e-04 - lr: 5.0000e-04
Epoch 18/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1408 - accuracy: 0.8916 - jacard_coef: 0.0012 2/17 [==>...........................] - ETA: 1s - loss: 0.1347 - accuracy: 0.9115 - jacard_coef: 5.8859e-04 3/17 [====>.........................] - ETA: 1s - loss: 0.1340 - accuracy: 0.9135 - jacard_coef: 3.9239e-04 4/17 [======>.......................] - ETA: 1s - loss: 0.1327 - accuracy: 0.9199 - jacard_coef: 2.9429e-04 5/17 [=======>......................] - ETA: 1s - loss: 0.1326 - accuracy: 0.9176 - jacard_coef: 2.3543e-04 6/17 [=========>....................] - ETA: 1s - loss: 0.1324 - accuracy: 0.9171 - jacard_coef: 3.1881e-04 7/17 [===========>..................] - ETA: 1s - loss: 0.1325 - accuracy: 0.9164 - jacard_coef: 2.7327e-04 8/17 [=============>................] - ETA: 1s - loss: 0.1328 - accuracy: 0.9133 - jacard_coef: 2.5896e-04 9/17 [==============>...............] - ETA: 1s - loss: 0.1323 - accuracy: 0.9165 - jacard_coef: 6.2010e-0410/17 [================>.............] - ETA: 0s - loss: 0.1321 - accuracy: 0.9174 - jacard_coef: 6.4445e-0411/17 [==================>...........] - ETA: 0s - loss: 0.1315 - accuracy: 0.9219 - jacard_coef: 5.8586e-0412/17 [====================>.........] - ETA: 0s - loss: 0.1320 - accuracy: 0.9170 - jacard_coef: 5.3704e-0413/17 [=====================>........] - ETA: 0s - loss: 0.1318 - accuracy: 0.9175 - jacard_coef: 5.5304e-0414/17 [=======================>......] - ETA: 0s - loss: 0.1318 - accuracy: 0.9172 - jacard_coef: 5.6558e-0415/17 [=========================>....] - ETA: 0s - loss: 0.1316 - accuracy: 0.9189 - jacard_coef: 5.2787e-0416/17 [===========================>..] - ETA: 0s - loss: 0.1322 - accuracy: 0.9168 - jacard_coef: 5.3452e-0417/17 [==============================] - 2s 128ms/step - loss: 0.1322 - accuracy: 0.9166 - jacard_coef: 5.0307e-04 - val_loss: 0.1383 - val_accuracy: 0.9304 - val_jacard_coef: 3.4110e-12 - lr: 5.0000e-04
/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(

✓ Training completed successfully!
  Best Val Jaccard: 0.0755 (epoch 8)
  Final Val Loss: 0.1383
  Training Time: 0:01:23.444804
  Stability (std): 0.2417

Results saved to: hyperparameter_optimization_20250926_165036/exp_7_UNet_lr1e-3_bs8/UNet_lr0.001_bs8_results.json
