âœ“ GPU memory growth enabled for 1 GPUs
Loading dataset...
Loaded 144 images and 144 masks
Training set: (129, 256, 256, 3), Validation set: (15, 256, 256, 3)

============================================================
TRAINING: UNet
Learning Rate: 0.0005, Batch Size: 16, Epochs: 30
============================================================
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 256, 256, 64)         640       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 256, 256, 64)         256       ['conv2d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 activation (Activation)     (None, 256, 256, 64)         0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['activation[0][0]']          
                                                                                                  
 batch_normalization_1 (Bat  (None, 256, 256, 64)         256       ['conv2d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_1 (Activation)   (None, 256, 256, 64)         0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['activation_1[0][0]']        
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       
                                                                                                  
 batch_normalization_2 (Bat  (None, 128, 128, 128)        512       ['conv2d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_2 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_3 (Conv2D)           (None, 128, 128, 128)        147584    ['activation_2[0][0]']        
                                                                                                  
 batch_normalization_3 (Bat  (None, 128, 128, 128)        512       ['conv2d_3[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_3 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_3[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_3[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 batch_normalization_4 (Bat  (None, 64, 64, 256)          1024      ['conv2d_4[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_4 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_4[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_5 (Conv2D)           (None, 64, 64, 256)          590080    ['activation_4[0][0]']        
                                                                                                  
 batch_normalization_5 (Bat  (None, 64, 64, 256)          1024      ['conv2d_5[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_5 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_5[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_5[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 512)          1180160   ['max_pooling2d_2[0][0]']     
                                                                                                  
 batch_normalization_6 (Bat  (None, 32, 32, 512)          2048      ['conv2d_6[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_6 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_6[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 32, 32, 512)          2359808   ['activation_6[0][0]']        
                                                                                                  
 batch_normalization_7 (Bat  (None, 32, 32, 512)          2048      ['conv2d_7[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_7 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_7[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_3 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_7[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 1024)         4719616   ['max_pooling2d_3[0][0]']     
                                                                                                  
 batch_normalization_8 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_8[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_8 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_8[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 1024)         9438208   ['activation_8[0][0]']        
                                                                                                  
 batch_normalization_9 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_9[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_9 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_9[0][0]'
                                                                    ]                             
                                                                                                  
 up_sampling2d (UpSampling2  (None, 32, 32, 1024)         0         ['activation_9[0][0]']        
 D)                                                                                               
                                                                                                  
 concatenate (Concatenate)   (None, 32, 32, 1536)         0         ['up_sampling2d[0][0]',       
                                                                     'activation_7[0][0]']        
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate[0][0]']         
                                                                                                  
 batch_normalization_10 (Ba  (None, 32, 32, 512)          2048      ['conv2d_10[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_10 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_10[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_10[0][0]']       
                                                                                                  
 batch_normalization_11 (Ba  (None, 32, 32, 512)          2048      ['conv2d_11[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_11 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_11[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 64, 64, 512)          0         ['activation_11[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_1 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_1[0][0]',     
 )                                                                   'activation_5[0][0]']        
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_1[0][0]']       
                                                                                                  
 batch_normalization_12 (Ba  (None, 64, 64, 256)          1024      ['conv2d_12[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_12 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_12[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_13 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_12[0][0]']       
                                                                                                  
 batch_normalization_13 (Ba  (None, 64, 64, 256)          1024      ['conv2d_13[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_13 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_13[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 128, 128, 256)        0         ['activation_13[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_2 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_2[0][0]',     
 )                                                                   'activation_3[0][0]']        
                                                                                                  
 conv2d_14 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_2[0][0]']       
                                                                                                  
 batch_normalization_14 (Ba  (None, 128, 128, 128)        512       ['conv2d_14[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_14 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_14[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_15 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_14[0][0]']       
                                                                                                  
 batch_normalization_15 (Ba  (None, 128, 128, 128)        512       ['conv2d_15[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_15 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_15[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 256, 256, 128)        0         ['activation_15[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_3 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_3[0][0]',     
 )                                                                   'activation_1[0][0]']        
                                                                                                  
 conv2d_16 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_3[0][0]']       
                                                                                                  
 batch_normalization_16 (Ba  (None, 256, 256, 64)         256       ['conv2d_16[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_16 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_16[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_16[0][0]']       
                                                                                                  
 batch_normalization_17 (Ba  (None, 256, 256, 64)         256       ['conv2d_17[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_17 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_17[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_18 (Conv2D)          (None, 256, 256, 1)          65        ['activation_17[0][0]']       
                                                                                                  
 batch_normalization_18 (Ba  (None, 256, 256, 1)          4         ['conv2d_18[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_18 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_18[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31401349 (119.79 MB)
Trainable params: 31389571 (119.74 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
None
âœ“ focal_loss imported successfully
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_2 (InputLayer)        [(None, 256, 256, 3)]        0         []                            
                                                                                                  
 conv2d_19 (Conv2D)          (None, 256, 256, 64)         1792      ['input_2[0][0]']             
                                                                                                  
 batch_normalization_19 (Ba  (None, 256, 256, 64)         256       ['conv2d_19[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_19 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_19[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_20 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_19[0][0]']       
                                                                                                  
 batch_normalization_20 (Ba  (None, 256, 256, 64)         256       ['conv2d_20[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_20 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_20[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_4 (MaxPoolin  (None, 128, 128, 64)         0         ['activation_20[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_21 (Conv2D)          (None, 128, 128, 128)        73856     ['max_pooling2d_4[0][0]']     
                                                                                                  
 batch_normalization_21 (Ba  (None, 128, 128, 128)        512       ['conv2d_21[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_21 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_21[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_22 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_21[0][0]']       
                                                                                                  
 batch_normalization_22 (Ba  (None, 128, 128, 128)        512       ['conv2d_22[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_22 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_22[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_5 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_22[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_23 (Conv2D)          (None, 64, 64, 256)          295168    ['max_pooling2d_5[0][0]']     
                                                                                                  
 batch_normalization_23 (Ba  (None, 64, 64, 256)          1024      ['conv2d_23[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_23 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_23[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_24 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_23[0][0]']       
                                                                                                  
 batch_normalization_24 (Ba  (None, 64, 64, 256)          1024      ['conv2d_24[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_24 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_24[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_6 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_24[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_25 (Conv2D)          (None, 32, 32, 512)          1180160   ['max_pooling2d_6[0][0]']     
                                                                                                  
 batch_normalization_25 (Ba  (None, 32, 32, 512)          2048      ['conv2d_25[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_25 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_25[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_26 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_25[0][0]']       
                                                                                                  
 batch_normalization_26 (Ba  (None, 32, 32, 512)          2048      ['conv2d_26[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_26 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_26[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_7 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_26[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_27 (Conv2D)          (None, 16, 16, 1024)         4719616   ['max_pooling2d_7[0][0]']     
                                                                                                  
 batch_normalization_27 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_27[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_27 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_27[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_28 (Conv2D)          (None, 16, 16, 1024)         9438208   ['activation_27[0][0]']       
                                                                                                  
 batch_normalization_28 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_28[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_28 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_28[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 1024)         0         ['activation_28[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_4 (Concatenate  (None, 32, 32, 1536)         0         ['up_sampling2d_4[0][0]',     
 )                                                                   'activation_26[0][0]']       
                                                                                                  
 conv2d_29 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate_4[0][0]']       
                                                                                                  
 batch_normalization_29 (Ba  (None, 32, 32, 512)          2048      ['conv2d_29[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_29 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_29[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_30 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_29[0][0]']       
                                                                                                  
 batch_normalization_30 (Ba  (None, 32, 32, 512)          2048      ['conv2d_30[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_30 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_30[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 512)          0         ['activation_30[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_5 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_5[0][0]',     
 )                                                                   'activation_24[0][0]']       
                                                                                                  
 conv2d_31 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_5[0][0]']       
                                                                                                  
 batch_normalization_31 (Ba  (None, 64, 64, 256)          1024      ['conv2d_31[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_31 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_31[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_32 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_31[0][0]']       
                                                                                                  
 batch_normalization_32 (Ba  (None, 64, 64, 256)          1024      ['conv2d_32[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_32 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_32[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_6 (UpSamplin  (None, 128, 128, 256)        0         ['activation_32[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_6 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_6[0][0]',     
 )                                                                   'activation_22[0][0]']       
                                                                                                  
 conv2d_33 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_6[0][0]']       
                                                                                                  
 batch_normalization_33 (Ba  (None, 128, 128, 128)        512       ['conv2d_33[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_33 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_33[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_34 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_33[0][0]']       
                                                                                                  
 batch_normalization_34 (Ba  (None, 128, 128, 128)        512       ['conv2d_34[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_34 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_34[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_7 (UpSamplin  (None, 256, 256, 128)        0         ['activation_34[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_7 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_7[0][0]',     
 )                                                                   'activation_20[0][0]']       
                                                                                                  
 conv2d_35 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_7[0][0]']       
                                                                                                  
 batch_normalization_35 (Ba  (None, 256, 256, 64)         256       ['conv2d_35[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_35 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_35[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_36 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_35[0][0]']       
                                                                                                  
 batch_normalization_36 (Ba  (None, 256, 256, 64)         256       ['conv2d_36[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_36 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_36[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_37 (Conv2D)          (None, 256, 256, 1)          65        ['activation_36[0][0]']       
                                                                                                  
 batch_normalization_37 (Ba  (None, 256, 256, 1)          4         ['conv2d_37[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_37 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_37[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31402501 (119.79 MB)
Trainable params: 31390723 (119.75 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
WARNING:absl:`lr` is deprecated in TF-Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
None
Epoch 1/30
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1758877105.906270 1039268 service.cc:145] XLA service 0x148669c5e390 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1758877105.906294 1039268 service.cc:153]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6
I0000 00:00:1758877106.043459 1039268 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
1/9 [==>...........................] - ETA: 4:48 - loss: 0.3466 - accuracy: 0.5095 - jacard_coef: 0.06362/9 [=====>........................] - ETA: 42s - loss: 0.3218 - accuracy: 0.4689 - jacard_coef: 0.0632 3/9 [=========>....................] - ETA: 26s - loss: 0.3027 - accuracy: 0.4129 - jacard_coef: 0.06924/9 [============>.................] - ETA: 19s - loss: 0.2803 - accuracy: 0.3677 - jacard_coef: 0.07685/9 [===============>..............] - ETA: 12s - loss: 0.2657 - accuracy: 0.3323 - jacard_coef: 0.07766/9 [===================>..........] - ETA: 8s - loss: 0.2558 - accuracy: 0.3065 - jacard_coef: 0.0775 7/9 [======================>.......] - ETA: 4s - loss: 0.2487 - accuracy: 0.2874 - jacard_coef: 0.08188/9 [=========================>....] - ETA: 2s - loss: 0.2431 - accuracy: 0.2683 - jacard_coef: 0.08239/9 [==============================] - ETA: 0s - loss: 0.2427 - accuracy: 0.2681 - jacard_coef: 0.09489/9 [==============================] - 56s 3s/step - loss: 0.2427 - accuracy: 0.2681 - jacard_coef: 0.0948 - val_loss: 0.1445 - val_accuracy: 0.9304 - val_jacard_coef: 1.4616e-12 - lr: 0.0010
Epoch 2/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1993 - accuracy: 0.1243 - jacard_coef: 0.05572/9 [=====>........................] - ETA: 1s - loss: 0.1967 - accuracy: 0.1425 - jacard_coef: 0.07263/9 [=========>....................] - ETA: 1s - loss: 0.1960 - accuracy: 0.1475 - jacard_coef: 0.07424/9 [============>.................] - ETA: 1s - loss: 0.1949 - accuracy: 0.1587 - jacard_coef: 0.08305/9 [===============>..............] - ETA: 0s - loss: 0.1947 - accuracy: 0.1542 - jacard_coef: 0.07656/9 [===================>..........] - ETA: 0s - loss: 0.1938 - accuracy: 0.1534 - jacard_coef: 0.07677/9 [======================>.......] - ETA: 0s - loss: 0.1938 - accuracy: 0.1555 - jacard_coef: 0.08138/9 [=========================>....] - ETA: 0s - loss: 0.1933 - accuracy: 0.1560 - jacard_coef: 0.08339/9 [==============================] - ETA: 0s - loss: 0.1932 - accuracy: 0.1563 - jacard_coef: 0.09159/9 [==============================] - 2s 233ms/step - loss: 0.1932 - accuracy: 0.1563 - jacard_coef: 0.0915 - val_loss: 0.8863 - val_accuracy: 0.9304 - val_jacard_coef: 1.4616e-12 - lr: 0.0010
Epoch 3/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1861 - accuracy: 0.1549 - jacard_coef: 0.08642/9 [=====>........................] - ETA: 1s - loss: 0.1866 - accuracy: 0.1552 - jacard_coef: 0.08693/9 [=========>....................] - ETA: 1s - loss: 0.1872 - accuracy: 0.1530 - jacard_coef: 0.08134/9 [============>.................] - ETA: 1s - loss: 0.1861 - accuracy: 0.1595 - jacard_coef: 0.08515/9 [===============>..............] - ETA: 0s - loss: 0.1858 - accuracy: 0.1637 - jacard_coef: 0.08766/9 [===================>..........] - ETA: 0s - loss: 0.1858 - accuracy: 0.1694 - jacard_coef: 0.09047/9 [======================>.......] - ETA: 0s - loss: 0.1854 - accuracy: 0.1719 - jacard_coef: 0.08848/9 [=========================>....] - ETA: 0s - loss: 0.1855 - accuracy: 0.1719 - jacard_coef: 0.08529/9 [==============================] - 2s 228ms/step - loss: 0.1855 - accuracy: 0.1720 - jacard_coef: 0.0827 - val_loss: 1.0112 - val_accuracy: 0.9304 - val_jacard_coef: 1.4616e-12 - lr: 0.0010
Epoch 4/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1828 - accuracy: 0.1875 - jacard_coef: 0.07912/9 [=====>........................] - ETA: 1s - loss: 0.1816 - accuracy: 0.2046 - jacard_coef: 0.08453/9 [=========>....................] - ETA: 1s - loss: 0.1815 - accuracy: 0.2195 - jacard_coef: 0.09394/9 [============>.................] - ETA: 1s - loss: 0.1823 - accuracy: 0.2213 - jacard_coef: 0.08685/9 [===============>..............] - ETA: 0s - loss: 0.1824 - accuracy: 0.2288 - jacard_coef: 0.08626/9 [===================>..........] - ETA: 0s - loss: 0.1825 - accuracy: 0.2385 - jacard_coef: 0.08397/9 [======================>.......] - ETA: 0s - loss: 0.1823 - accuracy: 0.2480 - jacard_coef: 0.08368/9 [=========================>....] - ETA: 0s - loss: 0.1819 - accuracy: 0.2565 - jacard_coef: 0.08579/9 [==============================] - 2s 228ms/step - loss: 0.1818 - accuracy: 0.2573 - jacard_coef: 0.0975 - val_loss: 0.7690 - val_accuracy: 0.9304 - val_jacard_coef: 1.4616e-12 - lr: 0.0010
Epoch 5/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1775 - accuracy: 0.3411 - jacard_coef: 0.13222/9 [=====>........................] - ETA: 1s - loss: 0.1786 - accuracy: 0.3179 - jacard_coef: 0.10303/9 [=========>....................] - ETA: 1s - loss: 0.1783 - accuracy: 0.3262 - jacard_coef: 0.09824/9 [============>.................] - ETA: 1s - loss: 0.1784 - accuracy: 0.3381 - jacard_coef: 0.08995/9 [===============>..............] - ETA: 0s - loss: 0.1780 - accuracy: 0.3502 - jacard_coef: 0.09176/9 [===================>..........] - ETA: 0s - loss: 0.1775 - accuracy: 0.3683 - jacard_coef: 0.08597/9 [======================>.......] - ETA: 0s - loss: 0.1769 - accuracy: 0.3906 - jacard_coef: 0.08608/9 [=========================>....] - ETA: 0s - loss: 0.1764 - accuracy: 0.4125 - jacard_coef: 0.08719/9 [==============================] - 2s 234ms/step - loss: 0.1767 - accuracy: 0.4114 - jacard_coef: 0.0938 - val_loss: 0.4577 - val_accuracy: 0.9201 - val_jacard_coef: 0.0082 - lr: 0.0010
Epoch 6/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1751 - accuracy: 0.5728 - jacard_coef: 0.09112/9 [=====>........................] - ETA: 1s - loss: 0.1751 - accuracy: 0.5833 - jacard_coef: 0.10473/9 [=========>....................] - ETA: 1s - loss: 0.1752 - accuracy: 0.5715 - jacard_coef: 0.08904/9 [============>.................] - ETA: 1s - loss: 0.1749 - accuracy: 0.5700 - jacard_coef: 0.09015/9 [===============>..............] - ETA: 0s - loss: 0.1754 - accuracy: 0.5623 - jacard_coef: 0.08916/9 [===================>..........] - ETA: 0s - loss: 0.1753 - accuracy: 0.5524 - jacard_coef: 0.08357/9 [======================>.......] - ETA: 0s - loss: 0.1754 - accuracy: 0.5443 - jacard_coef: 0.08418/9 [=========================>....] - ETA: 0s - loss: 0.1751 - accuracy: 0.5426 - jacard_coef: 0.08409/9 [==============================] - 2s 228ms/step - loss: 0.1751 - accuracy: 0.5422 - jacard_coef: 0.0831 - val_loss: 1.1122 - val_accuracy: 0.9304 - val_jacard_coef: 1.4612e-12 - lr: 0.0010
Epoch 7/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1729 - accuracy: 0.5196 - jacard_coef: 0.07452/9 [=====>........................] - ETA: 1s - loss: 0.1727 - accuracy: 0.5287 - jacard_coef: 0.07543/9 [=========>....................] - ETA: 1s - loss: 0.1719 - accuracy: 0.5488 - jacard_coef: 0.07374/9 [============>.................] - ETA: 1s - loss: 0.1716 - accuracy: 0.5646 - jacard_coef: 0.07335/9 [===============>..............] - ETA: 0s - loss: 0.1709 - accuracy: 0.5895 - jacard_coef: 0.07186/9 [===================>..........] - ETA: 0s - loss: 0.1702 - accuracy: 0.6235 - jacard_coef: 0.07117/9 [======================>.......] - ETA: 0s - loss: 0.1695 - accuracy: 0.6515 - jacard_coef: 0.06968/9 [=========================>....] - ETA: 0s - loss: 0.1689 - accuracy: 0.6694 - jacard_coef: 0.07049/9 [==============================] - 2s 228ms/step - loss: 0.1692 - accuracy: 0.6680 - jacard_coef: 0.0788 - val_loss: 1.1067 - val_accuracy: 0.9269 - val_jacard_coef: 1.3915e-12 - lr: 0.0010
Epoch 8/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1646 - accuracy: 0.8602 - jacard_coef: 0.03572/9 [=====>........................] - ETA: 1s - loss: 0.1661 - accuracy: 0.7339 - jacard_coef: 0.04453/9 [=========>....................] - ETA: 1s - loss: 0.1666 - accuracy: 0.7120 - jacard_coef: 0.05264/9 [============>.................] - ETA: 1s - loss: 0.1673 - accuracy: 0.6901 - jacard_coef: 0.05675/9 [===============>..............] - ETA: 0s - loss: 0.1675 - accuracy: 0.6982 - jacard_coef: 0.05646/9 [===================>..........] - ETA: 0s - loss: 0.1676 - accuracy: 0.7044 - jacard_coef: 0.05757/9 [======================>.......] - ETA: 0s - loss: 0.1678 - accuracy: 0.7126 - jacard_coef: 0.05898/9 [=========================>....] - ETA: 0s - loss: 0.1677 - accuracy: 0.7173 - jacard_coef: 0.05819/9 [==============================] - 2s 228ms/step - loss: 0.1677 - accuracy: 0.7177 - jacard_coef: 0.0517 - val_loss: 1.1186 - val_accuracy: 0.9279 - val_jacard_coef: 1.4099e-12 - lr: 0.0010
Epoch 9/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1668 - accuracy: 0.7498 - jacard_coef: 0.06802/9 [=====>........................] - ETA: 1s - loss: 0.1667 - accuracy: 0.7384 - jacard_coef: 0.06053/9 [=========>....................] - ETA: 1s - loss: 0.1664 - accuracy: 0.7211 - jacard_coef: 0.06074/9 [============>.................] - ETA: 1s - loss: 0.1666 - accuracy: 0.7332 - jacard_coef: 0.06445/9 [===============>..............] - ETA: 0s - loss: 0.1662 - accuracy: 0.7519 - jacard_coef: 0.06046/9 [===================>..........] - ETA: 0s - loss: 0.1658 - accuracy: 0.7688 - jacard_coef: 0.05677/9 [======================>.......] - ETA: 0s - loss: 0.1652 - accuracy: 0.7885 - jacard_coef: 0.05168/9 [=========================>....] - ETA: 0s - loss: 0.1648 - accuracy: 0.7974 - jacard_coef: 0.04749/9 [==============================] - 2s 233ms/step - loss: 0.1648 - accuracy: 0.7970 - jacard_coef: 0.0492 - val_loss: 14.0876 - val_accuracy: 0.0904 - val_jacard_coef: 0.0701 - lr: 0.0010
Epoch 10/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1601 - accuracy: 0.8992 - jacard_coef: 0.02352/9 [=====>........................] - ETA: 1s - loss: 0.1601 - accuracy: 0.8966 - jacard_coef: 0.01703/9 [=========>....................] - ETA: 1s - loss: 0.1598 - accuracy: 0.9041 - jacard_coef: 0.01404/9 [============>.................] - ETA: 1s - loss: 0.1605 - accuracy: 0.8714 - jacard_coef: 0.02655/9 [===============>..............] - ETA: 0s - loss: 0.1603 - accuracy: 0.8768 - jacard_coef: 0.02266/9 [===================>..........] - ETA: 0s - loss: 0.1602 - accuracy: 0.8813 - jacard_coef: 0.01977/9 [======================>.......] - ETA: 0s - loss: 0.1600 - accuracy: 0.8865 - jacard_coef: 0.01828/9 [=========================>....] - ETA: 0s - loss: 0.1600 - accuracy: 0.8866 - jacard_coef: 0.01729/9 [==============================] - 2s 228ms/step - loss: 0.1600 - accuracy: 0.8868 - jacard_coef: 0.0172 - val_loss: 1.0995 - val_accuracy: 0.9256 - val_jacard_coef: 0.0039 - lr: 0.0010
Epoch 11/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1589 - accuracy: 0.9181 - jacard_coef: 0.01022/9 [=====>........................] - ETA: 1s - loss: 0.1587 - accuracy: 0.9104 - jacard_coef: 0.01183/9 [=========>....................] - ETA: 1s - loss: 0.1587 - accuracy: 0.9088 - jacard_coef: 0.00954/9 [============>.................] - ETA: 1s - loss: 0.1582 - accuracy: 0.9125 - jacard_coef: 0.00795/9 [===============>..............] - ETA: 0s - loss: 0.1581 - accuracy: 0.9131 - jacard_coef: 0.00656/9 [===================>..........] - ETA: 0s - loss: 0.1577 - accuracy: 0.9108 - jacard_coef: 0.00567/9 [======================>.......] - ETA: 0s - loss: 0.1573 - accuracy: 0.9128 - jacard_coef: 0.00498/9 [=========================>....] - ETA: 0s - loss: 0.1570 - accuracy: 0.9136 - jacard_coef: 0.00439/9 [==============================] - 2s 228ms/step - loss: 0.1571 - accuracy: 0.9129 - jacard_coef: 0.0039 - val_loss: 1.0487 - val_accuracy: 0.9304 - val_jacard_coef: 1.4606e-12 - lr: 0.0010
Epoch 12/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1554 - accuracy: 0.8959 - jacard_coef: 3.6635e-042/9 [=====>........................] - ETA: 1s - loss: 0.1549 - accuracy: 0.9041 - jacard_coef: 5.6331e-043/9 [=========>....................] - ETA: 1s - loss: 0.1547 - accuracy: 0.9041 - jacard_coef: 0.0014    4/9 [============>.................] - ETA: 1s - loss: 0.1546 - accuracy: 0.9041 - jacard_coef: 0.00315/9 [===============>..............] - ETA: 0s - loss: 0.1542 - accuracy: 0.9107 - jacard_coef: 0.00286/9 [===================>..........] - ETA: 0s - loss: 0.1540 - accuracy: 0.9110 - jacard_coef: 0.00307/9 [======================>.......] - ETA: 0s - loss: 0.1541 - accuracy: 0.9076 - jacard_coef: 0.00768/9 [=========================>....] - ETA: 0s - loss: 0.1538 - accuracy: 0.9107 - jacard_coef: 0.00699/9 [==============================] - 2s 228ms/step - loss: 0.1544 - accuracy: 0.9073 - jacard_coef: 0.0237 - val_loss: 0.8888 - val_accuracy: 0.9270 - val_jacard_coef: 0.0029 - lr: 0.0010
Epoch 13/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1562 - accuracy: 0.8959 - jacard_coef: 0.02202/9 [=====>........................] - ETA: 1s - loss: 0.1570 - accuracy: 0.8496 - jacard_coef: 0.03643/9 [=========>....................] - ETA: 1s - loss: 0.1567 - accuracy: 0.8504 - jacard_coef: 0.04014/9 [============>.................] - ETA: 1s - loss: 0.1561 - accuracy: 0.8437 - jacard_coef: 0.04285/9 [===============>..............] - ETA: 0s - loss: 0.1557 - accuracy: 0.8432 - jacard_coef: 0.04266/9 [===================>..........] - ETA: 0s - loss: 0.1554 - accuracy: 0.8411 - jacard_coef: 0.04417/9 [======================>.......] - ETA: 0s - loss: 0.1551 - accuracy: 0.8435 - jacard_coef: 0.04328/9 [=========================>....] - ETA: 0s - loss: 0.1548 - accuracy: 0.8504 - jacard_coef: 0.04009/9 [==============================] - 2s 228ms/step - loss: 0.1550 - accuracy: 0.8473 - jacard_coef: 0.0483 - val_loss: 0.9680 - val_accuracy: 0.9232 - val_jacard_coef: 0.0028 - lr: 0.0010
Epoch 14/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1528 - accuracy: 0.9136 - jacard_coef: 0.00562/9 [=====>........................] - ETA: 1s - loss: 0.1528 - accuracy: 0.9090 - jacard_coef: 0.01013/9 [=========>....................] - ETA: 1s - loss: 0.1537 - accuracy: 0.8893 - jacard_coef: 0.01904/9 [============>.................] - ETA: 1s - loss: 0.1537 - accuracy: 0.8802 - jacard_coef: 0.02315/9 [===============>..............] - ETA: 0s - loss: 0.1542 - accuracy: 0.8755 - jacard_coef: 0.02536/9 [===================>..........] - ETA: 0s - loss: 0.1543 - accuracy: 0.8767 - jacard_coef: 0.02437/9 [======================>.......] - ETA: 0s - loss: 0.1541 - accuracy: 0.8826 - jacard_coef: 0.02108/9 [=========================>....] - ETA: 0s - loss: 0.1540 - accuracy: 0.8845 - jacard_coef: 0.01889/9 [==============================] - 2s 229ms/step - loss: 0.1541 - accuracy: 0.8842 - jacard_coef: 0.0188 - val_loss: 0.9077 - val_accuracy: 0.9237 - val_jacard_coef: 0.0028 - lr: 0.0010
Epoch 15/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1516 - accuracy: 0.9114 - jacard_coef: 9.9972e-042/9 [=====>........................] - ETA: 1s - loss: 0.1523 - accuracy: 0.9004 - jacard_coef: 0.0032    3/9 [=========>....................] - ETA: 1s - loss: 0.1520 - accuracy: 0.9045 - jacard_coef: 0.00614/9 [============>.................] - ETA: 1s - loss: 0.1525 - accuracy: 0.8946 - jacard_coef: 0.00725/9 [===============>..............] - ETA: 0s - loss: 0.1523 - accuracy: 0.8963 - jacard_coef: 0.01026/9 [===================>..........] - ETA: 0s - loss: 0.1522 - accuracy: 0.9005 - jacard_coef: 0.01197/9 [======================>.......] - ETA: 0s - loss: 0.1520 - accuracy: 0.9023 - jacard_coef: 0.01138/9 [=========================>....] - ETA: 0s - loss: 0.1517 - accuracy: 0.9037 - jacard_coef: 0.01159/9 [==============================] - 2s 228ms/step - loss: 0.1518 - accuracy: 0.9031 - jacard_coef: 0.0114 - val_loss: 0.7093 - val_accuracy: 0.9265 - val_jacard_coef: 6.9196e-04 - lr: 5.0000e-04
Epoch 16/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1505 - accuracy: 0.9099 - jacard_coef: 0.00152/9 [=====>........................] - ETA: 1s - loss: 0.1498 - accuracy: 0.9249 - jacard_coef: 0.00153/9 [=========>....................] - ETA: 1s - loss: 0.1504 - accuracy: 0.9103 - jacard_coef: 0.00164/9 [============>.................] - ETA: 1s - loss: 0.1510 - accuracy: 0.9083 - jacard_coef: 0.00145/9 [===============>..............] - ETA: 0s - loss: 0.1504 - accuracy: 0.9144 - jacard_coef: 0.00156/9 [===================>..........] - ETA: 0s - loss: 0.1502 - accuracy: 0.9159 - jacard_coef: 0.00147/9 [======================>.......] - ETA: 0s - loss: 0.1500 - accuracy: 0.9159 - jacard_coef: 0.00138/9 [=========================>....] - ETA: 0s - loss: 0.1500 - accuracy: 0.9144 - jacard_coef: 0.00189/9 [==============================] - 2s 228ms/step - loss: 0.1500 - accuracy: 0.9139 - jacard_coef: 0.0016 - val_loss: 0.3655 - val_accuracy: 0.9196 - val_jacard_coef: 0.0065 - lr: 5.0000e-04
Epoch 17/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1493 - accuracy: 0.9079 - jacard_coef: 0.00292/9 [=====>........................] - ETA: 1s - loss: 0.1496 - accuracy: 0.9090 - jacard_coef: 0.00263/9 [=========>....................] - ETA: 1s - loss: 0.1491 - accuracy: 0.9183 - jacard_coef: 0.00644/9 [============>.................] - ETA: 1s - loss: 0.1487 - accuracy: 0.9192 - jacard_coef: 0.00505/9 [===============>..............] - ETA: 0s - loss: 0.1489 - accuracy: 0.9138 - jacard_coef: 0.00476/9 [===================>..........] - ETA: 0s - loss: 0.1488 - accuracy: 0.9117 - jacard_coef: 0.00407/9 [======================>.......] - ETA: 0s - loss: 0.1488 - accuracy: 0.9105 - jacard_coef: 0.00398/9 [=========================>....] - ETA: 0s - loss: 0.1487 - accuracy: 0.9108 - jacard_coef: 0.00379/9 [==============================] - 2s 228ms/step - loss: 0.1488 - accuracy: 0.9098 - jacard_coef: 0.0033 - val_loss: 0.1040 - val_accuracy: 0.9239 - val_jacard_coef: 0.0046 - lr: 5.0000e-04
Epoch 18/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1485 - accuracy: 0.8940 - jacard_coef: 0.00172/9 [=====>........................] - ETA: 1s - loss: 0.1478 - accuracy: 0.9081 - jacard_coef: 8.7173e-043/9 [=========>....................] - ETA: 1s - loss: 0.1477 - accuracy: 0.9095 - jacard_coef: 6.0293e-044/9 [============>.................] - ETA: 1s - loss: 0.1473 - accuracy: 0.9159 - jacard_coef: 8.0699e-045/9 [===============>..............] - ETA: 0s - loss: 0.1474 - accuracy: 0.9166 - jacard_coef: 7.6421e-046/9 [===================>..........] - ETA: 0s - loss: 0.1474 - accuracy: 0.9166 - jacard_coef: 6.3685e-047/9 [======================>.......] - ETA: 0s - loss: 0.1475 - accuracy: 0.9164 - jacard_coef: 5.4587e-048/9 [=========================>....] - ETA: 0s - loss: 0.1474 - accuracy: 0.9163 - jacard_coef: 5.4234e-049/9 [==============================] - 2s 228ms/step - loss: 0.1474 - accuracy: 0.9164 - jacard_coef: 4.8208e-04 - val_loss: 0.0877 - val_accuracy: 0.9289 - val_jacard_coef: 7.5736e-04 - lr: 5.0000e-04
Epoch 19/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1467 - accuracy: 0.9186 - jacard_coef: 0.00162/9 [=====>........................] - ETA: 1s - loss: 0.1468 - accuracy: 0.9104 - jacard_coef: 8.2598e-043/9 [=========>....................] - ETA: 1s - loss: 0.1464 - accuracy: 0.9152 - jacard_coef: 0.0011    4/9 [============>.................] - ETA: 1s - loss: 0.1464 - accuracy: 0.9111 - jacard_coef: 8.4667e-045/9 [===============>..............] - ETA: 0s - loss: 0.1460 - accuracy: 0.9171 - jacard_coef: 7.0973e-046/9 [===================>..........] - ETA: 0s - loss: 0.1462 - accuracy: 0.9159 - jacard_coef: 7.2188e-047/9 [======================>.......] - ETA: 0s - loss: 0.1461 - accuracy: 0.9159 - jacard_coef: 8.8268e-048/9 [=========================>....] - ETA: 0s - loss: 0.1460 - accuracy: 0.9166 - jacard_coef: 7.8294e-049/9 [==============================] - 2s 229ms/step - loss: 0.1462 - accuracy: 0.9138 - jacard_coef: 0.0089 - val_loss: 0.1065 - val_accuracy: 0.9177 - val_jacard_coef: 0.0091 - lr: 5.0000e-04
/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(

âœ“ Training completed successfully!
  Best Val Jaccard: 0.0701 (epoch 9)
  Final Val Loss: 0.1065
  Training Time: 0:01:34.201222
  Stability (std): 0.3969

Results saved to: hyperparameter_optimization_20250926_165036/exp_5_UNet_lr5e-4_bs16/UNet_lr0.0005_bs16_results.json
