=== MITOCHONDRIA SEGMENTATION TRAINING WRAPPER ===

âœ“ focal_loss already available

Starting mitochondria segmentation training...
==================================================
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 256, 256, 64)         640       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 256, 256, 64)         256       ['conv2d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 activation (Activation)     (None, 256, 256, 64)         0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['activation[0][0]']          
                                                                                                  
 batch_normalization_1 (Bat  (None, 256, 256, 64)         256       ['conv2d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_1 (Activation)   (None, 256, 256, 64)         0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['activation_1[0][0]']        
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       
                                                                                                  
 batch_normalization_2 (Bat  (None, 128, 128, 128)        512       ['conv2d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_2 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_3 (Conv2D)           (None, 128, 128, 128)        147584    ['activation_2[0][0]']        
                                                                                                  
 batch_normalization_3 (Bat  (None, 128, 128, 128)        512       ['conv2d_3[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_3 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_3[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_3[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 batch_normalization_4 (Bat  (None, 64, 64, 256)          1024      ['conv2d_4[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_4 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_4[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_5 (Conv2D)           (None, 64, 64, 256)          590080    ['activation_4[0][0]']        
                                                                                                  
 batch_normalization_5 (Bat  (None, 64, 64, 256)          1024      ['conv2d_5[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_5 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_5[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_5[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 512)          1180160   ['max_pooling2d_2[0][0]']     
                                                                                                  
 batch_normalization_6 (Bat  (None, 32, 32, 512)          2048      ['conv2d_6[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_6 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_6[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 32, 32, 512)          2359808   ['activation_6[0][0]']        
                                                                                                  
 batch_normalization_7 (Bat  (None, 32, 32, 512)          2048      ['conv2d_7[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_7 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_7[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_3 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_7[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 1024)         4719616   ['max_pooling2d_3[0][0]']     
                                                                                                  
 batch_normalization_8 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_8[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_8 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_8[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 1024)         9438208   ['activation_8[0][0]']        
                                                                                                  
 batch_normalization_9 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_9[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_9 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_9[0][0]'
                                                                    ]                             
                                                                                                  
 up_sampling2d (UpSampling2  (None, 32, 32, 1024)         0         ['activation_9[0][0]']        
 D)                                                                                               
                                                                                                  
 concatenate (Concatenate)   (None, 32, 32, 1536)         0         ['up_sampling2d[0][0]',       
                                                                     'activation_7[0][0]']        
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate[0][0]']         
                                                                                                  
 batch_normalization_10 (Ba  (None, 32, 32, 512)          2048      ['conv2d_10[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_10 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_10[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_10[0][0]']       
                                                                                                  
 batch_normalization_11 (Ba  (None, 32, 32, 512)          2048      ['conv2d_11[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_11 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_11[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 64, 64, 512)          0         ['activation_11[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_1 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_1[0][0]',     
 )                                                                   'activation_5[0][0]']        
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_1[0][0]']       
                                                                                                  
 batch_normalization_12 (Ba  (None, 64, 64, 256)          1024      ['conv2d_12[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_12 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_12[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_13 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_12[0][0]']       
                                                                                                  
 batch_normalization_13 (Ba  (None, 64, 64, 256)          1024      ['conv2d_13[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_13 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_13[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 128, 128, 256)        0         ['activation_13[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_2 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_2[0][0]',     
 )                                                                   'activation_3[0][0]']        
                                                                                                  
 conv2d_14 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_2[0][0]']       
                                                                                                  
 batch_normalization_14 (Ba  (None, 128, 128, 128)        512       ['conv2d_14[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_14 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_14[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_15 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_14[0][0]']       
                                                                                                  
 batch_normalization_15 (Ba  (None, 128, 128, 128)        512       ['conv2d_15[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_15 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_15[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 256, 256, 128)        0         ['activation_15[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_3 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_3[0][0]',     
 )                                                                   'activation_1[0][0]']        
                                                                                                  
 conv2d_16 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_3[0][0]']       
                                                                                                  
 batch_normalization_16 (Ba  (None, 256, 256, 64)         256       ['conv2d_16[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_16 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_16[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_16[0][0]']       
                                                                                                  
 batch_normalization_17 (Ba  (None, 256, 256, 64)         256       ['conv2d_17[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_17 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_17[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_18 (Conv2D)          (None, 256, 256, 1)          65        ['activation_17[0][0]']       
                                                                                                  
 batch_normalization_18 (Ba  (None, 256, 256, 1)          4         ['conv2d_18[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_18 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_18[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31401349 (119.79 MB)
Trainable params: 31389571 (119.74 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
None
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_2 (InputLayer)        [(None, 256, 256, 3)]        0         []                            
                                                                                                  
 conv2d_19 (Conv2D)          (None, 256, 256, 64)         1792      ['input_2[0][0]']             
                                                                                                  
 batch_normalization_19 (Ba  (None, 256, 256, 64)         256       ['conv2d_19[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_19 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_19[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_20 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_19[0][0]']       
                                                                                                  
 batch_normalization_20 (Ba  (None, 256, 256, 64)         256       ['conv2d_20[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_20 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_20[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_4 (MaxPoolin  (None, 128, 128, 64)         0         ['activation_20[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_21 (Conv2D)          (None, 128, 128, 128)        73856     ['max_pooling2d_4[0][0]']     
                                                                                                  
 batch_normalization_21 (Ba  (None, 128, 128, 128)        512       ['conv2d_21[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_21 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_21[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_22 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_21[0][0]']       
                                                                                                  
 batch_normalization_22 (Ba  (None, 128, 128, 128)        512       ['conv2d_22[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_22 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_22[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_5 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_22[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_23 (Conv2D)          (None, 64, 64, 256)          295168    ['max_pooling2d_5[0][0]']     
                                                                                                  
 batch_normalization_23 (Ba  (None, 64, 64, 256)          1024      ['conv2d_23[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_23 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_23[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_24 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_23[0][0]']       
                                                                                                  
 batch_normalization_24 (Ba  (None, 64, 64, 256)          1024      ['conv2d_24[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_24 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_24[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_6 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_24[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_25 (Conv2D)          (None, 32, 32, 512)          1180160   ['max_pooling2d_6[0][0]']     
                                                                                                  
 batch_normalization_25 (Ba  (None, 32, 32, 512)          2048      ['conv2d_25[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_25 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_25[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_26 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_25[0][0]']       
                                                                                                  
 batch_normalization_26 (Ba  (None, 32, 32, 512)          2048      ['conv2d_26[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_26 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_26[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_7 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_26[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_27 (Conv2D)          (None, 16, 16, 1024)         4719616   ['max_pooling2d_7[0][0]']     
                                                                                                  
 batch_normalization_27 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_27[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_27 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_27[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_28 (Conv2D)          (None, 16, 16, 1024)         9438208   ['activation_27[0][0]']       
                                                                                                  
 batch_normalization_28 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_28[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_28 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_28[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 1024)         0         ['activation_28[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_4 (Concatenate  (None, 32, 32, 1536)         0         ['up_sampling2d_4[0][0]',     
 )                                                                   'activation_26[0][0]']       
                                                                                                  
 conv2d_29 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate_4[0][0]']       
                                                                                                  
 batch_normalization_29 (Ba  (None, 32, 32, 512)          2048      ['conv2d_29[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_29 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_29[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_30 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_29[0][0]']       
                                                                                                  
 batch_normalization_30 (Ba  (None, 32, 32, 512)          2048      ['conv2d_30[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_30 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_30[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 512)          0         ['activation_30[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_5 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_5[0][0]',     
 )                                                                   'activation_24[0][0]']       
                                                                                                  
 conv2d_31 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_5[0][0]']       
                                                                                                  
 batch_normalization_31 (Ba  (None, 64, 64, 256)          1024      ['conv2d_31[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_31 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_31[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_32 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_31[0][0]']       
                                                                                                  
 batch_normalization_32 (Ba  (None, 64, 64, 256)          1024      ['conv2d_32[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_32 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_32[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_6 (UpSamplin  (None, 128, 128, 256)        0         ['activation_32[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_6 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_6[0][0]',     
 )                                                                   'activation_22[0][0]']       
                                                                                                  
 conv2d_33 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_6[0][0]']       
                                                                                                  
 batch_normalization_33 (Ba  (None, 128, 128, 128)        512       ['conv2d_33[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_33 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_33[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_34 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_33[0][0]']       
                                                                                                  
 batch_normalization_34 (Ba  (None, 128, 128, 128)        512       ['conv2d_34[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_34 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_34[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_7 (UpSamplin  (None, 256, 256, 128)        0         ['activation_34[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_7 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_7[0][0]',     
 )                                                                   'activation_20[0][0]']       
                                                                                                  
 conv2d_35 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_7[0][0]']       
                                                                                                  
 batch_normalization_35 (Ba  (None, 256, 256, 64)         256       ['conv2d_35[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_35 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_35[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_36 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_35[0][0]']       
                                                                                                  
 batch_normalization_36 (Ba  (None, 256, 256, 64)         256       ['conv2d_36[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_36 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_36[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_37 (Conv2D)          (None, 256, 256, 1)          65        ['activation_36[0][0]']       
                                                                                                  
 batch_normalization_37 (Ba  (None, 256, 256, 1)          4         ['conv2d_37[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_37 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_37[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31402501 (119.79 MB)
Trainable params: 31390723 (119.75 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
WARNING:absl:`lr` is deprecated in TF-Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
None
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_2 (InputLayer)        [(None, 256, 256, 3)]        0         []                            
                                                                                                  
 conv2d_19 (Conv2D)          (None, 256, 256, 64)         1792      ['input_2[0][0]']             
                                                                                                  
 batch_normalization_19 (Ba  (None, 256, 256, 64)         256       ['conv2d_19[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_19 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_19[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_20 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_19[0][0]']       
                                                                                                  
 batch_normalization_20 (Ba  (None, 256, 256, 64)         256       ['conv2d_20[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_20 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_20[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_4 (MaxPoolin  (None, 128, 128, 64)         0         ['activation_20[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_21 (Conv2D)          (None, 128, 128, 128)        73856     ['max_pooling2d_4[0][0]']     
                                                                                                  
 batch_normalization_21 (Ba  (None, 128, 128, 128)        512       ['conv2d_21[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_21 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_21[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_22 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_21[0][0]']       
                                                                                                  
 batch_normalization_22 (Ba  (None, 128, 128, 128)        512       ['conv2d_22[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_22 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_22[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_5 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_22[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_23 (Conv2D)          (None, 64, 64, 256)          295168    ['max_pooling2d_5[0][0]']     
                                                                                                  
 batch_normalization_23 (Ba  (None, 64, 64, 256)          1024      ['conv2d_23[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_23 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_23[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_24 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_23[0][0]']       
                                                                                                  
 batch_normalization_24 (Ba  (None, 64, 64, 256)          1024      ['conv2d_24[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_24 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_24[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_6 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_24[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_25 (Conv2D)          (None, 32, 32, 512)          1180160   ['max_pooling2d_6[0][0]']     
                                                                                                  
 batch_normalization_25 (Ba  (None, 32, 32, 512)          2048      ['conv2d_25[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_25 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_25[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_26 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_25[0][0]']       
                                                                                                  
 batch_normalization_26 (Ba  (None, 32, 32, 512)          2048      ['conv2d_26[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_26 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_26[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_7 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_26[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_27 (Conv2D)          (None, 16, 16, 1024)         4719616   ['max_pooling2d_7[0][0]']     
                                                                                                  
 batch_normalization_27 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_27[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_27 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_27[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_28 (Conv2D)          (None, 16, 16, 1024)         9438208   ['activation_27[0][0]']       
                                                                                                  
 batch_normalization_28 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_28[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_28 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_28[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 1024)         0         ['activation_28[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_4 (Concatenate  (None, 32, 32, 1536)         0         ['up_sampling2d_4[0][0]',     
 )                                                                   'activation_26[0][0]']       
                                                                                                  
 conv2d_29 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate_4[0][0]']       
                                                                                                  
 batch_normalization_29 (Ba  (None, 32, 32, 512)          2048      ['conv2d_29[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_29 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_29[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_30 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_29[0][0]']       
                                                                                                  
 batch_normalization_30 (Ba  (None, 32, 32, 512)          2048      ['conv2d_30[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_30 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_30[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 512)          0         ['activation_30[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_5 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_5[0][0]',     
 )                                                                   'activation_24[0][0]']       
                                                                                                  
 conv2d_31 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_5[0][0]']       
                                                                                                  
 batch_normalization_31 (Ba  (None, 64, 64, 256)          1024      ['conv2d_31[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_31 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_31[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_32 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_31[0][0]']       
                                                                                                  
 batch_normalization_32 (Ba  (None, 64, 64, 256)          1024      ['conv2d_32[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_32 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_32[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_6 (UpSamplin  (None, 128, 128, 256)        0         ['activation_32[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_6 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_6[0][0]',     
 )                                                                   'activation_22[0][0]']       
                                                                                                  
 conv2d_33 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_6[0][0]']       
                                                                                                  
 batch_normalization_33 (Ba  (None, 128, 128, 128)        512       ['conv2d_33[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_33 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_33[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_34 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_33[0][0]']       
                                                                                                  
 batch_normalization_34 (Ba  (None, 128, 128, 128)        512       ['conv2d_34[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_34 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_34[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_7 (UpSamplin  (None, 256, 256, 128)        0         ['activation_34[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_7 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_7[0][0]',     
 )                                                                   'activation_20[0][0]']       
                                                                                                  
 conv2d_35 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_7[0][0]']       
                                                                                                  
 batch_normalization_35 (Ba  (None, 256, 256, 64)         256       ['conv2d_35[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_35 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_35[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_36 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_35[0][0]']       
                                                                                                  
 batch_normalization_36 (Ba  (None, 256, 256, 64)         256       ['conv2d_36[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_36 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_36[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_37 (Conv2D)          (None, 256, 256, 1)          65        ['activation_36[0][0]']       
                                                                                                  
 batch_normalization_37 (Ba  (None, 256, 256, 1)          4         ['conv2d_37[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_37 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_37[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31402501 (119.79 MB)
Trainable params: 31390723 (119.75 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
None
Epoch 1/100
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1758876677.272470 1006211 service.cc:145] XLA service 0x1496884865e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1758876677.272499 1006211 service.cc:153]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6
I0000 00:00:1758876677.435312 1006211 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
 1/17 [>.............................] - ETA: 8:05 - loss: 0.3475 - accuracy: 0.5002 - jacard_coef: 0.0734 2/17 [==>...........................] - ETA: 54s - loss: 0.3201 - accuracy: 0.4771 - jacard_coef: 0.0850  3/17 [====>.........................] - ETA: 32s - loss: 0.2987 - accuracy: 0.3950 - jacard_coef: 0.0810 4/17 [======>.......................] - ETA: 23s - loss: 0.2855 - accuracy: 0.3431 - jacard_coef: 0.0803 5/17 [=======>......................] - ETA: 17s - loss: 0.2699 - accuracy: 0.3314 - jacard_coef: 0.0908 6/17 [=========>....................] - ETA: 13s - loss: 0.2622 - accuracy: 0.3007 - jacard_coef: 0.0852 7/17 [===========>..................] - ETA: 10s - loss: 0.2545 - accuracy: 0.2847 - jacard_coef: 0.0820 8/17 [=============>................] - ETA: 8s - loss: 0.2492 - accuracy: 0.2787 - jacard_coef: 0.0813  9/17 [==============>...............] - ETA: 6s - loss: 0.2429 - accuracy: 0.2734 - jacard_coef: 0.077510/17 [================>.............] - ETA: 5s - loss: 0.2379 - accuracy: 0.2716 - jacard_coef: 0.074511/17 [==================>...........] - ETA: 4s - loss: 0.2336 - accuracy: 0.2815 - jacard_coef: 0.078012/17 [====================>.........] - ETA: 3s - loss: 0.2310 - accuracy: 0.2839 - jacard_coef: 0.077213/17 [=====================>........] - ETA: 2s - loss: 0.2276 - accuracy: 0.2780 - jacard_coef: 0.078214/17 [=======================>......] - ETA: 1s - loss: 0.2245 - accuracy: 0.2780 - jacard_coef: 0.078315/17 [=========================>....] - ETA: 1s - loss: 0.2222 - accuracy: 0.2832 - jacard_coef: 0.077816/17 [===========================>..] - ETA: 0s - loss: 0.2196 - accuracy: 0.2918 - jacard_coef: 0.078817/17 [==============================] - ETA: 0s - loss: 0.2195 - accuracy: 0.2922 - jacard_coef: 0.0861
Epoch 1: val_jacard_coef improved from -inf to 0.00000, saving model to best_unet_model.h5
/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(
17/17 [==============================] - 47s 1s/step - loss: 0.2195 - accuracy: 0.2922 - jacard_coef: 0.0861 - val_loss: 1.4770 - val_accuracy: 0.9084 - val_jacard_coef: 2.2203e-12 - lr: 0.0010
Epoch 2/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1809 - accuracy: 0.3982 - jacard_coef: 0.0808 2/17 [==>...........................] - ETA: 1s - loss: 0.1841 - accuracy: 0.3009 - jacard_coef: 0.0774 3/17 [====>.........................] - ETA: 1s - loss: 0.1873 - accuracy: 0.2615 - jacard_coef: 0.0767 4/17 [======>.......................] - ETA: 1s - loss: 0.1874 - accuracy: 0.2637 - jacard_coef: 0.0789 5/17 [=======>......................] - ETA: 1s - loss: 0.1873 - accuracy: 0.2749 - jacard_coef: 0.0886 6/17 [=========>....................] - ETA: 1s - loss: 0.1869 - accuracy: 0.2918 - jacard_coef: 0.0843 7/17 [===========>..................] - ETA: 1s - loss: 0.1872 - accuracy: 0.2841 - jacard_coef: 0.0817 8/17 [=============>................] - ETA: 1s - loss: 0.1882 - accuracy: 0.2861 - jacard_coef: 0.0809 9/17 [==============>...............] - ETA: 0s - loss: 0.1877 - accuracy: 0.2824 - jacard_coef: 0.077310/17 [================>.............] - ETA: 0s - loss: 0.1867 - accuracy: 0.2909 - jacard_coef: 0.074411/17 [==================>...........] - ETA: 0s - loss: 0.1862 - accuracy: 0.2969 - jacard_coef: 0.076912/17 [====================>.........] - ETA: 0s - loss: 0.1860 - accuracy: 0.3031 - jacard_coef: 0.075813/17 [=====================>........] - ETA: 0s - loss: 0.1853 - accuracy: 0.3104 - jacard_coef: 0.077014/17 [=======================>......] - ETA: 0s - loss: 0.1845 - accuracy: 0.3237 - jacard_coef: 0.077015/17 [=========================>....] - ETA: 0s - loss: 0.1839 - accuracy: 0.3335 - jacard_coef: 0.075816/17 [===========================>..] - ETA: 0s - loss: 0.1832 - accuracy: 0.3473 - jacard_coef: 0.0759
Epoch 2: val_jacard_coef improved from 0.00000 to 0.00099, saving model to best_unet_model.h5
17/17 [==============================] - 5s 332ms/step - loss: 0.1833 - accuracy: 0.3477 - jacard_coef: 0.0823 - val_loss: 1.1038 - val_accuracy: 0.9076 - val_jacard_coef: 9.9268e-04 - lr: 0.0010
Epoch 3/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1725 - accuracy: 0.5491 - jacard_coef: 0.0820 2/17 [==>...........................] - ETA: 1s - loss: 0.1757 - accuracy: 0.4124 - jacard_coef: 0.0810 3/17 [====>.........................] - ETA: 1s - loss: 0.1806 - accuracy: 0.3496 - jacard_coef: 0.0782 4/17 [======>.......................] - ETA: 1s - loss: 0.1811 - accuracy: 0.3250 - jacard_coef: 0.0798 5/17 [=======>......................] - ETA: 1s - loss: 0.1819 - accuracy: 0.3147 - jacard_coef: 0.0919 6/17 [=========>....................] - ETA: 1s - loss: 0.1822 - accuracy: 0.3325 - jacard_coef: 0.0857 7/17 [===========>..................] - ETA: 1s - loss: 0.1839 - accuracy: 0.3296 - jacard_coef: 0.0829 8/17 [=============>................] - ETA: 1s - loss: 0.1858 - accuracy: 0.3318 - jacard_coef: 0.0825 9/17 [==============>...............] - ETA: 0s - loss: 0.1849 - accuracy: 0.3280 - jacard_coef: 0.079210/17 [================>.............] - ETA: 0s - loss: 0.1839 - accuracy: 0.3327 - jacard_coef: 0.075711/17 [==================>...........] - ETA: 0s - loss: 0.1831 - accuracy: 0.3372 - jacard_coef: 0.079512/17 [====================>.........] - ETA: 0s - loss: 0.1828 - accuracy: 0.3556 - jacard_coef: 0.077713/17 [=====================>........] - ETA: 0s - loss: 0.1820 - accuracy: 0.3662 - jacard_coef: 0.079014/17 [=======================>......] - ETA: 0s - loss: 0.1811 - accuracy: 0.3858 - jacard_coef: 0.078615/17 [=========================>....] - ETA: 0s - loss: 0.1806 - accuracy: 0.4054 - jacard_coef: 0.078416/17 [===========================>..] - ETA: 0s - loss: 0.1799 - accuracy: 0.4219 - jacard_coef: 0.0781
Epoch 3: val_jacard_coef improved from 0.00099 to 0.00417, saving model to best_unet_model.h5
17/17 [==============================] - 5s 334ms/step - loss: 0.1804 - accuracy: 0.4215 - jacard_coef: 0.0853 - val_loss: 0.6443 - val_accuracy: 0.9045 - val_jacard_coef: 0.0042 - lr: 0.0010
Epoch 4/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1685 - accuracy: 0.6741 - jacard_coef: 0.0812 2/17 [==>...........................] - ETA: 1s - loss: 0.1708 - accuracy: 0.6055 - jacard_coef: 0.0822 3/17 [====>.........................] - ETA: 1s - loss: 0.1728 - accuracy: 0.5794 - jacard_coef: 0.0799 4/17 [======>.......................] - ETA: 1s - loss: 0.1726 - accuracy: 0.5738 - jacard_coef: 0.0826 5/17 [=======>......................] - ETA: 1s - loss: 0.1726 - accuracy: 0.5687 - jacard_coef: 0.0892 6/17 [=========>....................] - ETA: 1s - loss: 0.1729 - accuracy: 0.5815 - jacard_coef: 0.0820 7/17 [===========>..................] - ETA: 1s - loss: 0.1727 - accuracy: 0.5823 - jacard_coef: 0.0788 8/17 [=============>................] - ETA: 1s - loss: 0.1740 - accuracy: 0.5855 - jacard_coef: 0.0762 9/17 [==============>...............] - ETA: 0s - loss: 0.1737 - accuracy: 0.5847 - jacard_coef: 0.071910/17 [================>.............] - ETA: 0s - loss: 0.1731 - accuracy: 0.5946 - jacard_coef: 0.068111/17 [==================>...........] - ETA: 0s - loss: 0.1727 - accuracy: 0.5951 - jacard_coef: 0.071612/17 [====================>.........] - ETA: 0s - loss: 0.1729 - accuracy: 0.5999 - jacard_coef: 0.070513/17 [=====================>........] - ETA: 0s - loss: 0.1725 - accuracy: 0.6053 - jacard_coef: 0.071714/17 [=======================>......] - ETA: 0s - loss: 0.1720 - accuracy: 0.6144 - jacard_coef: 0.071315/17 [=========================>....] - ETA: 0s - loss: 0.1718 - accuracy: 0.6200 - jacard_coef: 0.070216/17 [===========================>..] - ETA: 0s - loss: 0.1714 - accuracy: 0.6287 - jacard_coef: 0.0699
Epoch 4: val_jacard_coef improved from 0.00417 to 0.07610, saving model to best_unet_model.h5
17/17 [==============================] - 5s 320ms/step - loss: 0.1716 - accuracy: 0.6273 - jacard_coef: 0.0778 - val_loss: 0.3634 - val_accuracy: 0.7369 - val_jacard_coef: 0.0761 - lr: 0.0010
Epoch 5/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1686 - accuracy: 0.6943 - jacard_coef: 0.0764 2/17 [==>...........................] - ETA: 1s - loss: 0.1675 - accuracy: 0.6613 - jacard_coef: 0.0800 3/17 [====>.........................] - ETA: 1s - loss: 0.1708 - accuracy: 0.6119 - jacard_coef: 0.0759 4/17 [======>.......................] - ETA: 1s - loss: 0.1711 - accuracy: 0.5931 - jacard_coef: 0.0788 5/17 [=======>......................] - ETA: 1s - loss: 0.1724 - accuracy: 0.5694 - jacard_coef: 0.0860 6/17 [=========>....................] - ETA: 1s - loss: 0.1723 - accuracy: 0.5624 - jacard_coef: 0.0821 7/17 [===========>..................] - ETA: 1s - loss: 0.1728 - accuracy: 0.5583 - jacard_coef: 0.0795 8/17 [=============>................] - ETA: 1s - loss: 0.1730 - accuracy: 0.5571 - jacard_coef: 0.0784 9/17 [==============>...............] - ETA: 0s - loss: 0.1728 - accuracy: 0.5613 - jacard_coef: 0.075610/17 [================>.............] - ETA: 0s - loss: 0.1728 - accuracy: 0.5677 - jacard_coef: 0.072311/17 [==================>...........] - ETA: 0s - loss: 0.1725 - accuracy: 0.5742 - jacard_coef: 0.073512/17 [====================>.........] - ETA: 0s - loss: 0.1718 - accuracy: 0.5838 - jacard_coef: 0.072313/17 [=====================>........] - ETA: 0s - loss: 0.1716 - accuracy: 0.5907 - jacard_coef: 0.071614/17 [=======================>......] - ETA: 0s - loss: 0.1712 - accuracy: 0.6035 - jacard_coef: 0.070315/17 [=========================>....] - ETA: 0s - loss: 0.1707 - accuracy: 0.6155 - jacard_coef: 0.068416/17 [===========================>..] - ETA: 0s - loss: 0.1706 - accuracy: 0.6227 - jacard_coef: 0.0686
Epoch 5: val_jacard_coef did not improve from 0.07610
17/17 [==============================] - 2s 125ms/step - loss: 0.1706 - accuracy: 0.6239 - jacard_coef: 0.0705 - val_loss: 1.2453 - val_accuracy: 0.8934 - val_jacard_coef: 0.0121 - lr: 0.0010
Epoch 6/100
 1/17 [>.............................] - ETA: 1s - loss: 0.1623 - accuracy: 0.8495 - jacard_coef: 0.0575 2/17 [==>...........................] - ETA: 1s - loss: 0.1613 - accuracy: 0.8556 - jacard_coef: 0.0481 3/17 [====>.........................] - ETA: 1s - loss: 0.1623 - accuracy: 0.8467 - jacard_coef: 0.0443 4/17 [======>.......................] - ETA: 1s - loss: 0.1619 - accuracy: 0.8434 - jacard_coef: 0.0449 5/17 [=======>......................] - ETA: 1s - loss: 0.1619 - accuracy: 0.8336 - jacard_coef: 0.0549 6/17 [=========>....................] - ETA: 1s - loss: 0.1615 - accuracy: 0.8376 - jacard_coef: 0.0531 7/17 [===========>..................] - ETA: 1s - loss: 0.1614 - accuracy: 0.8382 - jacard_coef: 0.0487 8/17 [=============>................] - ETA: 1s - loss: 0.1612 - accuracy: 0.8385 - jacard_coef: 0.0495 9/17 [==============>...............] - ETA: 0s - loss: 0.1608 - accuracy: 0.8417 - jacard_coef: 0.047510/17 [================>.............] - ETA: 0s - loss: 0.1607 - accuracy: 0.8457 - jacard_coef: 0.044611/17 [==================>...........] - ETA: 0s - loss: 0.1605 - accuracy: 0.8461 - jacard_coef: 0.044612/17 [====================>.........] - ETA: 0s - loss: 0.1602 - accuracy: 0.8491 - jacard_coef: 0.043113/17 [=====================>........] - ETA: 0s - loss: 0.1601 - accuracy: 0.8506 - jacard_coef: 0.042814/17 [=======================>......] - ETA: 0s - loss: 0.1598 - accuracy: 0.8529 - jacard_coef: 0.041415/17 [=========================>....] - ETA: 0s - loss: 0.1596 - accuracy: 0.8565 - jacard_coef: 0.040116/17 [===========================>..] - ETA: 0s - loss: 0.1595 - accuracy: 0.8582 - jacard_coef: 0.0400
Epoch 6: val_jacard_coef did not improve from 0.07610
17/17 [==============================] - 2s 125ms/step - loss: 0.1595 - accuracy: 0.8578 - jacard_coef: 0.0414 - val_loss: 0.9291 - val_accuracy: 0.8907 - val_jacard_coef: 0.0142 - lr: 0.0010
Epoch 7/100
 1/17 [>.............................] - ETA: 1s - loss: 0.1557 - accuracy: 0.8697 - jacard_coef: 0.0404 2/17 [==>...........................] - ETA: 1s - loss: 0.1549 - accuracy: 0.8728 - jacard_coef: 0.0343 3/17 [====>.........................] - ETA: 1s - loss: 0.1555 - accuracy: 0.8644 - jacard_coef: 0.0343 4/17 [======>.......................] - ETA: 1s - loss: 0.1554 - accuracy: 0.8661 - jacard_coef: 0.0322 5/17 [=======>......................] - ETA: 1s - loss: 0.1556 - accuracy: 0.8619 - jacard_coef: 0.0355 6/17 [=========>....................] - ETA: 1s - loss: 0.1553 - accuracy: 0.8712 - jacard_coef: 0.0328 7/17 [===========>..................] - ETA: 1s - loss: 0.1551 - accuracy: 0.8773 - jacard_coef: 0.0283 8/17 [=============>................] - ETA: 1s - loss: 0.1549 - accuracy: 0.8821 - jacard_coef: 0.0257 9/17 [==============>...............] - ETA: 1s - loss: 0.1544 - accuracy: 0.8895 - jacard_coef: 0.023810/17 [================>.............] - ETA: 0s - loss: 0.1542 - accuracy: 0.8959 - jacard_coef: 0.021611/17 [==================>...........] - ETA: 0s - loss: 0.1542 - accuracy: 0.8947 - jacard_coef: 0.019812/17 [====================>.........] - ETA: 0s - loss: 0.1540 - accuracy: 0.8967 - jacard_coef: 0.019213/17 [=====================>........] - ETA: 0s - loss: 0.1539 - accuracy: 0.8975 - jacard_coef: 0.017814/17 [=======================>......] - ETA: 0s - loss: 0.1538 - accuracy: 0.8985 - jacard_coef: 0.016715/17 [=========================>....] - ETA: 0s - loss: 0.1537 - accuracy: 0.9003 - jacard_coef: 0.015916/17 [===========================>..] - ETA: 0s - loss: 0.1536 - accuracy: 0.8995 - jacard_coef: 0.0168
Epoch 7: val_jacard_coef did not improve from 0.07610
17/17 [==============================] - 2s 125ms/step - loss: 0.1536 - accuracy: 0.8987 - jacard_coef: 0.0180 - val_loss: 0.3977 - val_accuracy: 0.8838 - val_jacard_coef: 0.0181 - lr: 0.0010
Epoch 8/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1510 - accuracy: 0.9029 - jacard_coef: 0.0164 2/17 [==>...........................] - ETA: 1s - loss: 0.1504 - accuracy: 0.9061 - jacard_coef: 0.0156 3/17 [====>.........................] - ETA: 1s - loss: 0.1506 - accuracy: 0.9029 - jacard_coef: 0.0187 4/17 [======>.......................] - ETA: 1s - loss: 0.1504 - accuracy: 0.9008 - jacard_coef: 0.0212 5/17 [=======>......................] - ETA: 1s - loss: 0.1512 - accuracy: 0.8783 - jacard_coef: 0.0322 6/17 [=========>....................] - ETA: 1s - loss: 0.1508 - accuracy: 0.8837 - jacard_coef: 0.0306 7/17 [===========>..................] - ETA: 1s - loss: 0.1507 - accuracy: 0.8873 - jacard_coef: 0.0264 8/17 [=============>................] - ETA: 1s - loss: 0.1506 - accuracy: 0.8900 - jacard_coef: 0.0254 9/17 [==============>...............] - ETA: 1s - loss: 0.1501 - accuracy: 0.8969 - jacard_coef: 0.022710/17 [================>.............] - ETA: 0s - loss: 0.1499 - accuracy: 0.9026 - jacard_coef: 0.020511/17 [==================>...........] - ETA: 0s - loss: 0.1500 - accuracy: 0.9009 - jacard_coef: 0.018612/17 [====================>.........] - ETA: 0s - loss: 0.1499 - accuracy: 0.9032 - jacard_coef: 0.017713/17 [=====================>........] - ETA: 0s - loss: 0.1498 - accuracy: 0.9035 - jacard_coef: 0.016414/17 [=======================>......] - ETA: 0s - loss: 0.1498 - accuracy: 0.9046 - jacard_coef: 0.015215/17 [=========================>....] - ETA: 0s - loss: 0.1496 - accuracy: 0.9063 - jacard_coef: 0.014316/17 [===========================>..] - ETA: 0s - loss: 0.1496 - accuracy: 0.9064 - jacard_coef: 0.0138
Epoch 8: val_jacard_coef did not improve from 0.07610
17/17 [==============================] - 2s 125ms/step - loss: 0.1496 - accuracy: 0.9056 - jacard_coef: 0.0130 - val_loss: 0.1667 - val_accuracy: 0.8599 - val_jacard_coef: 0.0326 - lr: 0.0010
Epoch 9/100
 1/17 [>.............................] - ETA: 1s - loss: 0.1469 - accuracy: 0.9132 - jacard_coef: 0.0132 2/17 [==>...........................] - ETA: 1s - loss: 0.1465 - accuracy: 0.9111 - jacard_coef: 0.0212 3/17 [====>.........................] - ETA: 1s - loss: 0.1469 - accuracy: 0.8927 - jacard_coef: 0.0296 4/17 [======>.......................] - ETA: 1s - loss: 0.1468 - accuracy: 0.8931 - jacard_coef: 0.0249 5/17 [=======>......................] - ETA: 1s - loss: 0.1475 - accuracy: 0.8836 - jacard_coef: 0.0248 6/17 [=========>....................] - ETA: 1s - loss: 0.1472 - accuracy: 0.8898 - jacard_coef: 0.0257 7/17 [===========>..................] - ETA: 1s - loss: 0.1470 - accuracy: 0.8957 - jacard_coef: 0.0220 8/17 [=============>................] - ETA: 1s - loss: 0.1468 - accuracy: 0.8990 - jacard_coef: 0.0193 9/17 [==============>...............] - ETA: 1s - loss: 0.1464 - accuracy: 0.9051 - jacard_coef: 0.017110/17 [================>.............] - ETA: 0s - loss: 0.1461 - accuracy: 0.9101 - jacard_coef: 0.015411/17 [==================>...........] - ETA: 0s - loss: 0.1463 - accuracy: 0.9077 - jacard_coef: 0.014012/17 [====================>.........] - ETA: 0s - loss: 0.1462 - accuracy: 0.9096 - jacard_coef: 0.013013/17 [=====================>........] - ETA: 0s - loss: 0.1461 - accuracy: 0.9095 - jacard_coef: 0.012014/17 [=======================>......] - ETA: 0s - loss: 0.1461 - accuracy: 0.9102 - jacard_coef: 0.011115/17 [=========================>....] - ETA: 0s - loss: 0.1459 - accuracy: 0.9116 - jacard_coef: 0.010416/17 [===========================>..] - ETA: 0s - loss: 0.1459 - accuracy: 0.9113 - jacard_coef: 0.0101
Epoch 9: val_jacard_coef did not improve from 0.07610
17/17 [==============================] - 2s 125ms/step - loss: 0.1459 - accuracy: 0.9105 - jacard_coef: 0.0095 - val_loss: 0.1572 - val_accuracy: 0.9058 - val_jacard_coef: 0.0022 - lr: 0.0010
Epoch 10/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1440 - accuracy: 0.9128 - jacard_coef: 0.0142 2/17 [==>...........................] - ETA: 1s - loss: 0.1433 - accuracy: 0.9181 - jacard_coef: 0.0108 3/17 [====>.........................] - ETA: 1s - loss: 0.1434 - accuracy: 0.9164 - jacard_coef: 0.0106 4/17 [======>.......................] - ETA: 1s - loss: 0.1434 - accuracy: 0.9131 - jacard_coef: 0.0095 5/17 [=======>......................] - ETA: 1s - loss: 0.1446 - accuracy: 0.9002 - jacard_coef: 0.0115 6/17 [=========>....................] - ETA: 1s - loss: 0.1443 - accuracy: 0.9014 - jacard_coef: 0.0140 7/17 [===========>..................] - ETA: 1s - loss: 0.1441 - accuracy: 0.9049 - jacard_coef: 0.0121 8/17 [=============>................] - ETA: 1s - loss: 0.1440 - accuracy: 0.9069 - jacard_coef: 0.0108 9/17 [==============>...............] - ETA: 1s - loss: 0.1436 - accuracy: 0.9121 - jacard_coef: 0.009610/17 [================>.............] - ETA: 0s - loss: 0.1434 - accuracy: 0.9163 - jacard_coef: 0.008711/17 [==================>...........] - ETA: 0s - loss: 0.1436 - accuracy: 0.9134 - jacard_coef: 0.007912/17 [====================>.........] - ETA: 0s - loss: 0.1435 - accuracy: 0.9147 - jacard_coef: 0.007313/17 [=====================>........] - ETA: 0s - loss: 0.1436 - accuracy: 0.9142 - jacard_coef: 0.006814/17 [=======================>......] - ETA: 0s - loss: 0.1436 - accuracy: 0.9145 - jacard_coef: 0.006415/17 [=========================>....] - ETA: 0s - loss: 0.1435 - accuracy: 0.9157 - jacard_coef: 0.005916/17 [===========================>..] - ETA: 0s - loss: 0.1435 - accuracy: 0.9152 - jacard_coef: 0.0056
Epoch 10: val_jacard_coef did not improve from 0.07610
17/17 [==============================] - 2s 125ms/step - loss: 0.1436 - accuracy: 0.9144 - jacard_coef: 0.0052 - val_loss: 0.1187 - val_accuracy: 0.8917 - val_jacard_coef: 0.0222 - lr: 0.0010
Epoch 11/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1424 - accuracy: 0.9164 - jacard_coef: 0.0014 2/17 [==>...........................] - ETA: 1s - loss: 0.1418 - accuracy: 0.9132 - jacard_coef: 0.0085 3/17 [====>.........................] - ETA: 1s - loss: 0.1420 - accuracy: 0.9064 - jacard_coef: 0.0106 4/17 [======>.......................] - ETA: 1s - loss: 0.1421 - accuracy: 0.9022 - jacard_coef: 0.0114 5/17 [=======>......................] - ETA: 1s - loss: 0.1429 - accuracy: 0.8922 - jacard_coef: 0.0139 6/17 [=========>....................] - ETA: 1s - loss: 0.1424 - accuracy: 0.8993 - jacard_coef: 0.0126 7/17 [===========>..................] - ETA: 1s - loss: 0.1421 - accuracy: 0.9040 - jacard_coef: 0.0109 8/17 [=============>................] - ETA: 1s - loss: 0.1419 - accuracy: 0.9061 - jacard_coef: 0.0096 9/17 [==============>...............] - ETA: 1s - loss: 0.1414 - accuracy: 0.9113 - jacard_coef: 0.008510/17 [================>.............] - ETA: 0s - loss: 0.1411 - accuracy: 0.9155 - jacard_coef: 0.007711/17 [==================>...........] - ETA: 0s - loss: 0.1412 - accuracy: 0.9126 - jacard_coef: 0.007112/17 [====================>.........] - ETA: 0s - loss: 0.1410 - accuracy: 0.9140 - jacard_coef: 0.006513/17 [=====================>........] - ETA: 0s - loss: 0.1410 - accuracy: 0.9136 - jacard_coef: 0.006014/17 [=======================>......] - ETA: 0s - loss: 0.1409 - accuracy: 0.9140 - jacard_coef: 0.005615/17 [=========================>....] - ETA: 0s - loss: 0.1408 - accuracy: 0.9152 - jacard_coef: 0.005216/17 [===========================>..] - ETA: 0s - loss: 0.1407 - accuracy: 0.9148 - jacard_coef: 0.0049
Epoch 11: val_jacard_coef did not improve from 0.07610
17/17 [==============================] - 2s 125ms/step - loss: 0.1408 - accuracy: 0.9140 - jacard_coef: 0.0046 - val_loss: 0.1471 - val_accuracy: 0.9065 - val_jacard_coef: 7.7167e-04 - lr: 0.0010
Epoch 12/100
 1/17 [>.............................] - ETA: 1s - loss: 0.1385 - accuracy: 0.9178 - jacard_coef: 2.3215e-12 2/17 [==>...........................] - ETA: 1s - loss: 0.1378 - accuracy: 0.9226 - jacard_coef: 4.7187e-04 3/17 [====>.........................] - ETA: 1s - loss: 0.1386 - accuracy: 0.9197 - jacard_coef: 0.0026     4/17 [======>.......................] - ETA: 1s - loss: 0.1388 - accuracy: 0.9159 - jacard_coef: 0.0030 5/17 [=======>......................] - ETA: 1s - loss: 0.1397 - accuracy: 0.9029 - jacard_coef: 0.0049 6/17 [=========>....................] - ETA: 1s - loss: 0.1394 - accuracy: 0.9074 - jacard_coef: 0.0057 7/17 [===========>..................] - ETA: 1s - loss: 0.1391 - accuracy: 0.9108 - jacard_coef: 0.0050 8/17 [=============>................] - ETA: 1s - loss: 0.1389 - accuracy: 0.9122 - jacard_coef: 0.0044 9/17 [==============>...............] - ETA: 1s - loss: 0.1384 - accuracy: 0.9168 - jacard_coef: 0.003910/17 [================>.............] - ETA: 0s - loss: 0.1380 - accuracy: 0.9207 - jacard_coef: 0.003511/17 [==================>...........] - ETA: 0s - loss: 0.1383 - accuracy: 0.9174 - jacard_coef: 0.003212/17 [====================>.........] - ETA: 0s - loss: 0.1381 - accuracy: 0.9185 - jacard_coef: 0.002913/17 [=====================>........] - ETA: 0s - loss: 0.1382 - accuracy: 0.9177 - jacard_coef: 0.002714/17 [=======================>......] - ETA: 0s - loss: 0.1381 - accuracy: 0.9178 - jacard_coef: 0.002515/17 [=========================>....] - ETA: 0s - loss: 0.1380 - accuracy: 0.9187 - jacard_coef: 0.002316/17 [===========================>..] - ETA: 0s - loss: 0.1379 - accuracy: 0.9181 - jacard_coef: 0.0022
Epoch 12: val_jacard_coef did not improve from 0.07610
17/17 [==============================] - 2s 125ms/step - loss: 0.1380 - accuracy: 0.9173 - jacard_coef: 0.0020 - val_loss: 0.1531 - val_accuracy: 0.8505 - val_jacard_coef: 0.0388 - lr: 0.0010
Epoch 13/100
 1/17 [>.............................] - ETA: 1s - loss: 0.1361 - accuracy: 0.9180 - jacard_coef: 2.7897e-04 2/17 [==>...........................] - ETA: 1s - loss: 0.1353 - accuracy: 0.9231 - jacard_coef: 1.3949e-04 3/17 [====>.........................] - ETA: 1s - loss: 0.1351 - accuracy: 0.9239 - jacard_coef: 1.2706e-04 4/17 [======>.......................] - ETA: 1s - loss: 0.1352 - accuracy: 0.9216 - jacard_coef: 9.5294e-05 5/17 [=======>......................] - ETA: 1s - loss: 0.1364 - accuracy: 0.9090 - jacard_coef: 7.6235e-05 6/17 [=========>....................] - ETA: 1s - loss: 0.1359 - accuracy: 0.9143 - jacard_coef: 2.2404e-04 7/17 [===========>..................] - ETA: 1s - loss: 0.1355 - accuracy: 0.9170 - jacard_coef: 1.9614e-04 8/17 [=============>................] - ETA: 1s - loss: 0.1354 - accuracy: 0.9176 - jacard_coef: 1.7466e-04 9/17 [==============>...............] - ETA: 1s - loss: 0.1348 - accuracy: 0.9217 - jacard_coef: 1.5526e-0410/17 [================>.............] - ETA: 0s - loss: 0.1344 - accuracy: 0.9250 - jacard_coef: 1.3973e-0411/17 [==================>...........] - ETA: 0s - loss: 0.1347 - accuracy: 0.9213 - jacard_coef: 1.2703e-0412/17 [====================>.........] - ETA: 0s - loss: 0.1345 - accuracy: 0.9221 - jacard_coef: 1.1644e-0413/17 [=====================>........] - ETA: 0s - loss: 0.1346 - accuracy: 0.9210 - jacard_coef: 1.0749e-0414/17 [=======================>......] - ETA: 0s - loss: 0.1345 - accuracy: 0.9208 - jacard_coef: 9.9808e-0515/17 [=========================>....] - ETA: 0s - loss: 0.1344 - accuracy: 0.9215 - jacard_coef: 9.3154e-0516/17 [===========================>..] - ETA: 0s - loss: 0.1343 - accuracy: 0.9207 - jacard_coef: 1.0046e-04
Epoch 13: val_jacard_coef did not improve from 0.07610
17/17 [==============================] - 2s 125ms/step - loss: 0.1344 - accuracy: 0.9198 - jacard_coef: 9.4553e-05 - val_loss: 0.1464 - val_accuracy: 0.9084 - val_jacard_coef: 2.2203e-12 - lr: 0.0010
Epoch 14/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1327 - accuracy: 0.9155 - jacard_coef: 0.0035 2/17 [==>...........................] - ETA: 1s - loss: 0.1319 - accuracy: 0.9218 - jacard_coef: 0.0017 3/17 [====>.........................] - ETA: 1s - loss: 0.1317 - accuracy: 0.9230 - jacard_coef: 0.0018 4/17 [======>.......................] - ETA: 1s - loss: 0.1319 - accuracy: 0.9208 - jacard_coef: 0.0022 5/17 [=======>......................] - ETA: 1s - loss: 0.1333 - accuracy: 0.9084 - jacard_coef: 0.0018 6/17 [=========>....................] - ETA: 1s - loss: 0.1328 - accuracy: 0.9136 - jacard_coef: 0.0016 7/17 [===========>..................] - ETA: 1s - loss: 0.1324 - accuracy: 0.9165 - jacard_coef: 0.0014 8/17 [=============>................] - ETA: 1s - loss: 0.1323 - accuracy: 0.9171 - jacard_coef: 0.0012 9/17 [==============>...............] - ETA: 1s - loss: 0.1317 - accuracy: 0.9213 - jacard_coef: 0.001110/17 [================>.............] - ETA: 0s - loss: 0.1314 - accuracy: 0.9246 - jacard_coef: 9.8428e-0411/17 [==================>...........] - ETA: 0s - loss: 0.1317 - accuracy: 0.9210 - jacard_coef: 8.9480e-0412/17 [====================>.........] - ETA: 0s - loss: 0.1316 - accuracy: 0.9218 - jacard_coef: 8.2024e-0413/17 [=====================>........] - ETA: 0s - loss: 0.1316 - accuracy: 0.9207 - jacard_coef: 7.5714e-0414/17 [=======================>......] - ETA: 0s - loss: 0.1315 - accuracy: 0.9206 - jacard_coef: 8.5105e-0415/17 [=========================>....] - ETA: 0s - loss: 0.1314 - accuracy: 0.9214 - jacard_coef: 7.9431e-0416/17 [===========================>..] - ETA: 0s - loss: 0.1314 - accuracy: 0.9205 - jacard_coef: 0.0010    
Epoch 14: val_jacard_coef did not improve from 0.07610
17/17 [==============================] - 2s 125ms/step - loss: 0.1315 - accuracy: 0.9197 - jacard_coef: 9.4299e-04 - val_loss: 0.1423 - val_accuracy: 0.9084 - val_jacard_coef: 2.2203e-12 - lr: 0.0010
Epoch 15/100
 1/17 [>.............................] - ETA: 1s - loss: 0.1296 - accuracy: 0.9077 - jacard_coef: 0.0903 2/17 [==>...........................] - ETA: 1s - loss: 0.1291 - accuracy: 0.9121 - jacard_coef: 0.0585 3/17 [====>.........................] - ETA: 1s - loss: 0.1292 - accuracy: 0.9064 - jacard_coef: 0.0601 4/17 [======>.......................] - ETA: 1s - loss: 0.1295 - accuracy: 0.9084 - jacard_coef: 0.0457 5/17 [=======>......................] - ETA: 1s - loss: 0.1311 - accuracy: 0.8984 - jacard_coef: 0.0365 6/17 [=========>....................] - ETA: 1s - loss: 0.1304 - accuracy: 0.9054 - jacard_coef: 0.0305 7/17 [===========>..................] - ETA: 1s - loss: 0.1301 - accuracy: 0.9095 - jacard_coef: 0.0261 8/17 [=============>................] - ETA: 1s - loss: 0.1300 - accuracy: 0.9110 - jacard_coef: 0.0229 9/17 [==============>...............] - ETA: 1s - loss: 0.1294 - accuracy: 0.9158 - jacard_coef: 0.020310/17 [================>.............] - ETA: 0s - loss: 0.1290 - accuracy: 0.9197 - jacard_coef: 0.018311/17 [==================>...........] - ETA: 0s - loss: 0.1294 - accuracy: 0.9165 - jacard_coef: 0.016612/17 [====================>.........] - ETA: 0s - loss: 0.1293 - accuracy: 0.9177 - jacard_coef: 0.015213/17 [=====================>........] - ETA: 0s - loss: 0.1293 - accuracy: 0.9170 - jacard_coef: 0.014114/17 [=======================>......] - ETA: 0s - loss: 0.1293 - accuracy: 0.9172 - jacard_coef: 0.013115/17 [=========================>....] - ETA: 0s - loss: 0.1291 - accuracy: 0.9181 - jacard_coef: 0.012216/17 [===========================>..] - ETA: 0s - loss: 0.1291 - accuracy: 0.9176 - jacard_coef: 0.0114
Epoch 15: val_jacard_coef did not improve from 0.07610
17/17 [==============================] - 2s 125ms/step - loss: 0.1292 - accuracy: 0.9167 - jacard_coef: 0.0108 - val_loss: 0.1347 - val_accuracy: 0.9084 - val_jacard_coef: 2.2203e-12 - lr: 0.0010
Epoch 16/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1275 - accuracy: 0.9169 - jacard_coef: 0.0017 2/17 [==>...........................] - ETA: 1s - loss: 0.1273 - accuracy: 0.9221 - jacard_coef: 8.5873e-04 3/17 [====>.........................] - ETA: 1s - loss: 0.1270 - accuracy: 0.9232 - jacard_coef: 5.7249e-04 4/17 [======>.......................] - ETA: 1s - loss: 0.1275 - accuracy: 0.9199 - jacard_coef: 0.0018     5/17 [=======>......................] - ETA: 1s - loss: 0.1290 - accuracy: 0.9076 - jacard_coef: 0.0014 6/17 [=========>....................] - ETA: 1s - loss: 0.1283 - accuracy: 0.9132 - jacard_coef: 0.0012 7/17 [===========>..................] - ETA: 1s - loss: 0.1279 - accuracy: 0.9161 - jacard_coef: 0.0010 8/17 [=============>................] - ETA: 1s - loss: 0.1277 - accuracy: 0.9168 - jacard_coef: 8.8360e-04 9/17 [==============>...............] - ETA: 1s - loss: 0.1271 - accuracy: 0.9210 - jacard_coef: 7.8542e-0410/17 [================>.............] - ETA: 0s - loss: 0.1267 - accuracy: 0.9244 - jacard_coef: 7.0688e-0411/17 [==================>...........] - ETA: 0s - loss: 0.1271 - accuracy: 0.9208 - jacard_coef: 6.4262e-0412/17 [====================>.........] - ETA: 0s - loss: 0.1269 - accuracy: 0.9216 - jacard_coef: 5.8906e-0413/17 [=====================>........] - ETA: 0s - loss: 0.1270 - accuracy: 0.9206 - jacard_coef: 5.4375e-0414/17 [=======================>......] - ETA: 0s - loss: 0.1269 - accuracy: 0.9205 - jacard_coef: 5.0491e-0415/17 [=========================>....] - ETA: 0s - loss: 0.1268 - accuracy: 0.9212 - jacard_coef: 4.7125e-0416/17 [===========================>..] - ETA: 0s - loss: 0.1268 - accuracy: 0.9205 - jacard_coef: 4.4180e-04
Epoch 16: val_jacard_coef did not improve from 0.07610
17/17 [==============================] - 2s 125ms/step - loss: 0.1269 - accuracy: 0.9196 - jacard_coef: 4.1581e-04 - val_loss: 0.1310 - val_accuracy: 0.9084 - val_jacard_coef: 2.2203e-12 - lr: 0.0010
Epoch 17/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1250 - accuracy: 0.9180 - jacard_coef: 2.3251e-12 2/17 [==>...........................] - ETA: 1s - loss: 0.1243 - accuracy: 0.9231 - jacard_coef: 3.9896e-05 3/17 [====>.........................] - ETA: 1s - loss: 0.1242 - accuracy: 0.9201 - jacard_coef: 0.0114     4/17 [======>.......................] - ETA: 1s - loss: 0.1246 - accuracy: 0.9143 - jacard_coef: 0.0267 5/17 [=======>......................] - ETA: 1s - loss: 0.1264 - accuracy: 0.8990 - jacard_coef: 0.0272 6/17 [=========>....................] - ETA: 1s - loss: 0.1259 - accuracy: 0.9011 - jacard_coef: 0.0278 7/17 [===========>..................] - ETA: 1s - loss: 0.1255 - accuracy: 0.9057 - jacard_coef: 0.0238 8/17 [=============>................] - ETA: 1s - loss: 0.1253 - accuracy: 0.9077 - jacard_coef: 0.0209 9/17 [==============>...............] - ETA: 1s - loss: 0.1247 - accuracy: 0.9128 - jacard_coef: 0.018610/17 [================>.............] - ETA: 0s - loss: 0.1242 - accuracy: 0.9170 - jacard_coef: 0.016711/17 [==================>...........] - ETA: 0s - loss: 0.1246 - accuracy: 0.9141 - jacard_coef: 0.015212/17 [====================>.........] - ETA: 0s - loss: 0.1245 - accuracy: 0.9154 - jacard_coef: 0.013913/17 [=====================>........] - ETA: 0s - loss: 0.1245 - accuracy: 0.9149 - jacard_coef: 0.012914/17 [=======================>......] - ETA: 0s - loss: 0.1245 - accuracy: 0.9152 - jacard_coef: 0.011915/17 [=========================>....] - ETA: 0s - loss: 0.1243 - accuracy: 0.9163 - jacard_coef: 0.011116/17 [===========================>..] - ETA: 0s - loss: 0.1243 - accuracy: 0.9159 - jacard_coef: 0.0105
Epoch 17: val_jacard_coef did not improve from 0.07610
17/17 [==============================] - 2s 125ms/step - loss: 0.1244 - accuracy: 0.9150 - jacard_coef: 0.0099 - val_loss: 0.1298 - val_accuracy: 0.9084 - val_jacard_coef: 2.2203e-12 - lr: 0.0010
Epoch 18/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1236 - accuracy: 0.9179 - jacard_coef: 2.3236e-12 2/17 [==>...........................] - ETA: 1s - loss: 0.1228 - accuracy: 0.9231 - jacard_coef: 2.4924e-12 3/17 [====>.........................] - ETA: 1s - loss: 0.1224 - accuracy: 0.9239 - jacard_coef: 2.5157e-12 4/17 [======>.......................] - ETA: 1s - loss: 0.1228 - accuracy: 0.9218 - jacard_coef: 1.1814e-04 5/17 [=======>......................] - ETA: 1s - loss: 0.1246 - accuracy: 0.9092 - jacard_coef: 9.4509e-05 6/17 [=========>....................] - ETA: 1s - loss: 0.1238 - accuracy: 0.9145 - jacard_coef: 7.8758e-05 7/17 [===========>..................] - ETA: 1s - loss: 0.1234 - accuracy: 0.9172 - jacard_coef: 6.7507e-05 8/17 [=============>................] - ETA: 1s - loss: 0.1233 - accuracy: 0.9177 - jacard_coef: 6.8162e-05 9/17 [==============>...............] - ETA: 1s - loss: 0.1226 - accuracy: 0.9218 - jacard_coef: 6.0588e-0510/17 [================>.............] - ETA: 0s - loss: 0.1221 - accuracy: 0.9251 - jacard_coef: 5.4529e-0511/17 [==================>...........] - ETA: 0s - loss: 0.1225 - accuracy: 0.9214 - jacard_coef: 4.9572e-0512/17 [====================>.........] - ETA: 0s - loss: 0.1224 - accuracy: 0.9222 - jacard_coef: 4.5441e-0513/17 [=====================>........] - ETA: 0s - loss: 0.1225 - accuracy: 0.9211 - jacard_coef: 4.1946e-0514/17 [=======================>......] - ETA: 0s - loss: 0.1224 - accuracy: 0.9210 - jacard_coef: 3.8950e-0515/17 [=========================>....] - ETA: 0s - loss: 0.1223 - accuracy: 0.9217 - jacard_coef: 3.6353e-0516/17 [===========================>..] - ETA: 0s - loss: 0.1223 - accuracy: 0.9209 - jacard_coef: 3.4081e-05
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.

Epoch 18: val_jacard_coef did not improve from 0.07610
17/17 [==============================] - 2s 125ms/step - loss: 0.1224 - accuracy: 0.9200 - jacard_coef: 3.2076e-05 - val_loss: 0.1228 - val_accuracy: 0.9084 - val_jacard_coef: 2.2203e-12 - lr: 0.0010
Epoch 19/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1199 - accuracy: 0.9172 - jacard_coef: 0.0550 2/17 [==>...........................] - ETA: 1s - loss: 0.1195 - accuracy: 0.9195 - jacard_coef: 0.0601 3/17 [====>.........................] - ETA: 1s - loss: 0.1196 - accuracy: 0.9149 - jacard_coef: 0.0662 4/17 [======>.......................] - ETA: 1s - loss: 0.1258 - accuracy: 0.8908 - jacard_coef: 0.0701 5/17 [=======>......................] - ETA: 1s - loss: 0.1267 - accuracy: 0.8844 - jacard_coef: 0.0561 6/17 [=========>....................] - ETA: 1s - loss: 0.1254 - accuracy: 0.8939 - jacard_coef: 0.0467 7/17 [===========>..................] - ETA: 1s - loss: 0.1247 - accuracy: 0.8996 - jacard_coef: 0.0401 8/17 [=============>................] - ETA: 1s - loss: 0.1245 - accuracy: 0.9022 - jacard_coef: 0.0351 9/17 [==============>...............] - ETA: 1s - loss: 0.1236 - accuracy: 0.9078 - jacard_coef: 0.031210/17 [================>.............] - ETA: 0s - loss: 0.1230 - accuracy: 0.9122 - jacard_coef: 0.028111/17 [==================>...........] - ETA: 0s - loss: 0.1234 - accuracy: 0.9094 - jacard_coef: 0.025812/17 [====================>.........] - ETA: 0s - loss: 0.1232 - accuracy: 0.9111 - jacard_coef: 0.024113/17 [=====================>........] - ETA: 0s - loss: 0.1233 - accuracy: 0.9108 - jacard_coef: 0.022414/17 [=======================>......] - ETA: 0s - loss: 0.1232 - accuracy: 0.9114 - jacard_coef: 0.020815/17 [=========================>....] - ETA: 0s - loss: 0.1231 - accuracy: 0.9127 - jacard_coef: 0.019516/17 [===========================>..] - ETA: 0s - loss: 0.1232 - accuracy: 0.9125 - jacard_coef: 0.0183
Epoch 19: val_jacard_coef did not improve from 0.07610
17/17 [==============================] - 2s 125ms/step - loss: 0.1233 - accuracy: 0.9116 - jacard_coef: 0.0174 - val_loss: 0.8888 - val_accuracy: 0.7196 - val_jacard_coef: 0.0490 - lr: 5.0000e-04
Epoch 19: early stopping
Restoring model weights from the end of the best epoch: 4.
WARNING:absl:`lr` is deprecated in TF-Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
UNet execution time is:  0:01:35.369133
Model: "Attention_UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_3 (InputLayer)        [(None, 256, 256, 3)]        0         []                            
                                                                                                  
 conv2d_38 (Conv2D)          (None, 256, 256, 64)         1792      ['input_3[0][0]']             
                                                                                                  
 batch_normalization_38 (Ba  (None, 256, 256, 64)         256       ['conv2d_38[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_38 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_38[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_39 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_38[0][0]']       
                                                                                                  
 batch_normalization_39 (Ba  (None, 256, 256, 64)         256       ['conv2d_39[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_39 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_39[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_8 (MaxPoolin  (None, 128, 128, 64)         0         ['activation_39[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_40 (Conv2D)          (None, 128, 128, 128)        73856     ['max_pooling2d_8[0][0]']     
                                                                                                  
 batch_normalization_40 (Ba  (None, 128, 128, 128)        512       ['conv2d_40[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_40 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_40[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_41 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_40[0][0]']       
                                                                                                  
 batch_normalization_41 (Ba  (None, 128, 128, 128)        512       ['conv2d_41[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_41 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_41[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_9 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_41[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_42 (Conv2D)          (None, 64, 64, 256)          295168    ['max_pooling2d_9[0][0]']     
                                                                                                  
 batch_normalization_42 (Ba  (None, 64, 64, 256)          1024      ['conv2d_42[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_42 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_42[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_43 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_42[0][0]']       
                                                                                                  
 batch_normalization_43 (Ba  (None, 64, 64, 256)          1024      ['conv2d_43[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_43 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_43[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_10 (MaxPooli  (None, 32, 32, 256)          0         ['activation_43[0][0]']       
 ng2D)                                                                                            
                                                                                                  
 conv2d_44 (Conv2D)          (None, 32, 32, 512)          1180160   ['max_pooling2d_10[0][0]']    
                                                                                                  
 batch_normalization_44 (Ba  (None, 32, 32, 512)          2048      ['conv2d_44[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_44 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_44[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_45 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_44[0][0]']       
                                                                                                  
 batch_normalization_45 (Ba  (None, 32, 32, 512)          2048      ['conv2d_45[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_45 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_45[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_11 (MaxPooli  (None, 16, 16, 512)          0         ['activation_45[0][0]']       
 ng2D)                                                                                            
                                                                                                  
 conv2d_46 (Conv2D)          (None, 16, 16, 1024)         4719616   ['max_pooling2d_11[0][0]']    
                                                                                                  
 batch_normalization_46 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_46[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_46 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_46[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_47 (Conv2D)          (None, 16, 16, 1024)         9438208   ['activation_46[0][0]']       
                                                                                                  
 batch_normalization_47 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_47[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_47 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_47[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_48 (Conv2D)          (None, 16, 16, 512)          524800    ['activation_47[0][0]']       
                                                                                                  
 batch_normalization_48 (Ba  (None, 16, 16, 512)          2048      ['conv2d_48[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_48 (Activation)  (None, 16, 16, 512)          0         ['batch_normalization_48[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_50 (Conv2D)          (None, 16, 16, 512)          262656    ['activation_48[0][0]']       
                                                                                                  
 conv2d_transpose (Conv2DTr  (None, 16, 16, 512)          2359808   ['conv2d_50[0][0]']           
 anspose)                                                                                         
                                                                                                  
 conv2d_49 (Conv2D)          (None, 16, 16, 512)          1049088   ['activation_45[0][0]']       
                                                                                                  
 add (Add)                   (None, 16, 16, 512)          0         ['conv2d_transpose[0][0]',    
                                                                     'conv2d_49[0][0]']           
                                                                                                  
 activation_49 (Activation)  (None, 16, 16, 512)          0         ['add[0][0]']                 
                                                                                                  
 conv2d_51 (Conv2D)          (None, 16, 16, 1)            513       ['activation_49[0][0]']       
                                                                                                  
 activation_50 (Activation)  (None, 16, 16, 1)            0         ['conv2d_51[0][0]']           
                                                                                                  
 up_sampling2d_8 (UpSamplin  (None, 32, 32, 1)            0         ['activation_50[0][0]']       
 g2D)                                                                                             
                                                                                                  
 lambda (Lambda)             (None, 32, 32, 512)          0         ['up_sampling2d_8[0][0]']     
                                                                                                  
 multiply (Multiply)         (None, 32, 32, 512)          0         ['lambda[0][0]',              
                                                                     'activation_45[0][0]']       
                                                                                                  
 conv2d_52 (Conv2D)          (None, 32, 32, 512)          262656    ['multiply[0][0]']            
                                                                                                  
 up_sampling2d_9 (UpSamplin  (None, 32, 32, 1024)         0         ['activation_47[0][0]']       
 g2D)                                                                                             
                                                                                                  
 batch_normalization_49 (Ba  (None, 32, 32, 512)          2048      ['conv2d_52[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 concatenate_8 (Concatenate  (None, 32, 32, 1536)         0         ['up_sampling2d_9[0][0]',     
 )                                                                   'batch_normalization_49[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_53 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate_8[0][0]']       
                                                                                                  
 batch_normalization_50 (Ba  (None, 32, 32, 512)          2048      ['conv2d_53[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_51 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_50[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_54 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_51[0][0]']       
                                                                                                  
 batch_normalization_51 (Ba  (None, 32, 32, 512)          2048      ['conv2d_54[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_52 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_51[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_55 (Conv2D)          (None, 32, 32, 256)          131328    ['activation_52[0][0]']       
                                                                                                  
 batch_normalization_52 (Ba  (None, 32, 32, 256)          1024      ['conv2d_55[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_53 (Activation)  (None, 32, 32, 256)          0         ['batch_normalization_52[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_57 (Conv2D)          (None, 32, 32, 256)          65792     ['activation_53[0][0]']       
                                                                                                  
 conv2d_transpose_1 (Conv2D  (None, 32, 32, 256)          590080    ['conv2d_57[0][0]']           
 Transpose)                                                                                       
                                                                                                  
 conv2d_56 (Conv2D)          (None, 32, 32, 256)          262400    ['activation_43[0][0]']       
                                                                                                  
 add_1 (Add)                 (None, 32, 32, 256)          0         ['conv2d_transpose_1[0][0]',  
                                                                     'conv2d_56[0][0]']           
                                                                                                  
 activation_54 (Activation)  (None, 32, 32, 256)          0         ['add_1[0][0]']               
                                                                                                  
 conv2d_58 (Conv2D)          (None, 32, 32, 1)            257       ['activation_54[0][0]']       
                                                                                                  
 activation_55 (Activation)  (None, 32, 32, 1)            0         ['conv2d_58[0][0]']           
                                                                                                  
 up_sampling2d_10 (UpSampli  (None, 64, 64, 1)            0         ['activation_55[0][0]']       
 ng2D)                                                                                            
                                                                                                  
 lambda_1 (Lambda)           (None, 64, 64, 256)          0         ['up_sampling2d_10[0][0]']    
                                                                                                  
 multiply_1 (Multiply)       (None, 64, 64, 256)          0         ['lambda_1[0][0]',            
                                                                     'activation_43[0][0]']       
                                                                                                  
 conv2d_59 (Conv2D)          (None, 64, 64, 256)          65792     ['multiply_1[0][0]']          
                                                                                                  
 up_sampling2d_11 (UpSampli  (None, 64, 64, 512)          0         ['activation_52[0][0]']       
 ng2D)                                                                                            
                                                                                                  
 batch_normalization_53 (Ba  (None, 64, 64, 256)          1024      ['conv2d_59[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 concatenate_9 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_11[0][0]',    
 )                                                                   'batch_normalization_53[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_60 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_9[0][0]']       
                                                                                                  
 batch_normalization_54 (Ba  (None, 64, 64, 256)          1024      ['conv2d_60[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_56 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_54[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_61 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_56[0][0]']       
                                                                                                  
 batch_normalization_55 (Ba  (None, 64, 64, 256)          1024      ['conv2d_61[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_57 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_55[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_62 (Conv2D)          (None, 64, 64, 128)          32896     ['activation_57[0][0]']       
                                                                                                  
 batch_normalization_56 (Ba  (None, 64, 64, 128)          512       ['conv2d_62[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_58 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_56[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_64 (Conv2D)          (None, 64, 64, 128)          16512     ['activation_58[0][0]']       
                                                                                                  
 conv2d_transpose_2 (Conv2D  (None, 64, 64, 128)          147584    ['conv2d_64[0][0]']           
 Transpose)                                                                                       
                                                                                                  
 conv2d_63 (Conv2D)          (None, 64, 64, 128)          65664     ['activation_41[0][0]']       
                                                                                                  
 add_2 (Add)                 (None, 64, 64, 128)          0         ['conv2d_transpose_2[0][0]',  
                                                                     'conv2d_63[0][0]']           
                                                                                                  
 activation_59 (Activation)  (None, 64, 64, 128)          0         ['add_2[0][0]']               
                                                                                                  
 conv2d_65 (Conv2D)          (None, 64, 64, 1)            129       ['activation_59[0][0]']       
                                                                                                  
 activation_60 (Activation)  (None, 64, 64, 1)            0         ['conv2d_65[0][0]']           
                                                                                                  
 up_sampling2d_12 (UpSampli  (None, 128, 128, 1)          0         ['activation_60[0][0]']       
 ng2D)                                                                                            
                                                                                                  
 lambda_2 (Lambda)           (None, 128, 128, 128)        0         ['up_sampling2d_12[0][0]']    
                                                                                                  
 multiply_2 (Multiply)       (None, 128, 128, 128)        0         ['lambda_2[0][0]',            
                                                                     'activation_41[0][0]']       
                                                                                                  
 conv2d_66 (Conv2D)          (None, 128, 128, 128)        16512     ['multiply_2[0][0]']          
                                                                                                  
 up_sampling2d_13 (UpSampli  (None, 128, 128, 256)        0         ['activation_57[0][0]']       
 ng2D)                                                                                            
                                                                                                  
 batch_normalization_57 (Ba  (None, 128, 128, 128)        512       ['conv2d_66[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 concatenate_10 (Concatenat  (None, 128, 128, 384)        0         ['up_sampling2d_13[0][0]',    
 e)                                                                  'batch_normalization_57[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_67 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_10[0][0]']      
                                                                                                  
 batch_normalization_58 (Ba  (None, 128, 128, 128)        512       ['conv2d_67[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_61 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_58[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_68 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_61[0][0]']       
                                                                                                  
 batch_normalization_59 (Ba  (None, 128, 128, 128)        512       ['conv2d_68[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_62 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_59[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_69 (Conv2D)          (None, 128, 128, 64)         8256      ['activation_62[0][0]']       
                                                                                                  
 batch_normalization_60 (Ba  (None, 128, 128, 64)         256       ['conv2d_69[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_63 (Activation)  (None, 128, 128, 64)         0         ['batch_normalization_60[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_71 (Conv2D)          (None, 128, 128, 64)         4160      ['activation_63[0][0]']       
                                                                                                  
 conv2d_transpose_3 (Conv2D  (None, 128, 128, 64)         36928     ['conv2d_71[0][0]']           
 Transpose)                                                                                       
                                                                                                  
 conv2d_70 (Conv2D)          (None, 128, 128, 64)         16448     ['activation_39[0][0]']       
                                                                                                  
 add_3 (Add)                 (None, 128, 128, 64)         0         ['conv2d_transpose_3[0][0]',  
                                                                     'conv2d_70[0][0]']           
                                                                                                  
 activation_64 (Activation)  (None, 128, 128, 64)         0         ['add_3[0][0]']               
                                                                                                  
 conv2d_72 (Conv2D)          (None, 128, 128, 1)          65        ['activation_64[0][0]']       
                                                                                                  
 activation_65 (Activation)  (None, 128, 128, 1)          0         ['conv2d_72[0][0]']           
                                                                                                  
 up_sampling2d_14 (UpSampli  (None, 256, 256, 1)          0         ['activation_65[0][0]']       
 ng2D)                                                                                            
                                                                                                  
 lambda_3 (Lambda)           (None, 256, 256, 64)         0         ['up_sampling2d_14[0][0]']    
                                                                                                  
 multiply_3 (Multiply)       (None, 256, 256, 64)         0         ['lambda_3[0][0]',            
                                                                     'activation_39[0][0]']       
                                                                                                  
 conv2d_73 (Conv2D)          (None, 256, 256, 64)         4160      ['multiply_3[0][0]']          
                                                                                                  
 up_sampling2d_15 (UpSampli  (None, 256, 256, 128)        0         ['activation_62[0][0]']       
 ng2D)                                                                                            
                                                                                                  
 batch_normalization_61 (Ba  (None, 256, 256, 64)         256       ['conv2d_73[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 concatenate_11 (Concatenat  (None, 256, 256, 192)        0         ['up_sampling2d_15[0][0]',    
 e)                                                                  'batch_normalization_61[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_74 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_11[0][0]']      
                                                                                                  
 batch_normalization_62 (Ba  (None, 256, 256, 64)         256       ['conv2d_74[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_66 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_62[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_75 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_66[0][0]']       
                                                                                                  
 batch_normalization_63 (Ba  (None, 256, 256, 64)         256       ['conv2d_75[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_67 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_63[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_76 (Conv2D)          (None, 256, 256, 1)          65        ['activation_67[0][0]']       
                                                                                                  
 batch_normalization_64 (Ba  (None, 256, 256, 1)          4         ['conv2d_76[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_68 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_64[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 37334665 (142.42 MB)
Trainable params: 37319047 (142.36 MB)
Non-trainable params: 15618 (61.01 KB)
__________________________________________________________________________________________________
None
Epoch 1/100
 1/17 [>.............................] - ETA: 5:53 - loss: 0.3449 - accuracy: 0.5113 - jacard_coef: 0.0773 2/17 [==>...........................] - ETA: 2s - loss: 0.3178 - accuracy: 0.4871 - jacard_coef: 0.0857   3/17 [====>.........................] - ETA: 2s - loss: 0.2937 - accuracy: 0.4200 - jacard_coef: 0.0817 4/17 [======>.......................] - ETA: 2s - loss: 0.2752 - accuracy: 0.3627 - jacard_coef: 0.0834 5/17 [=======>......................] - ETA: 2s - loss: 0.2639 - accuracy: 0.3351 - jacard_coef: 0.0936 6/17 [=========>....................] - ETA: 1s - loss: 0.2541 - accuracy: 0.3004 - jacard_coef: 0.0881 7/17 [===========>..................] - ETA: 1s - loss: 0.2481 - accuracy: 0.2744 - jacard_coef: 0.0851 8/17 [=============>................] - ETA: 1s - loss: 0.2438 - accuracy: 0.2582 - jacard_coef: 0.0843 9/17 [==============>...............] - ETA: 1s - loss: 0.2389 - accuracy: 0.2420 - jacard_coef: 0.080010/17 [================>.............] - ETA: 1s - loss: 0.2338 - accuracy: 0.2369 - jacard_coef: 0.076711/17 [==================>...........] - ETA: 1s - loss: 0.2307 - accuracy: 0.2385 - jacard_coef: 0.079912/17 [====================>.........] - ETA: 0s - loss: 0.2281 - accuracy: 0.2395 - jacard_coef: 0.078813/17 [=====================>........] - ETA: 0s - loss: 0.2250 - accuracy: 0.2455 - jacard_coef: 0.079814/17 [=======================>......] - ETA: 0s - loss: 0.2221 - accuracy: 0.2505 - jacard_coef: 0.080015/17 [=========================>....] - ETA: 0s - loss: 0.2196 - accuracy: 0.2552 - jacard_coef: 0.079016/17 [===========================>..] - ETA: 0s - loss: 0.2171 - accuracy: 0.2659 - jacard_coef: 0.079717/17 [==============================] - ETA: 0s - loss: 0.2168 - accuracy: 0.2670 - jacard_coef: 0.0852
Epoch 1: val_jacard_coef improved from -inf to 0.00000, saving model to best_attention_unet_model.h5
17/17 [==============================] - 34s 747ms/step - loss: 0.2168 - accuracy: 0.2670 - jacard_coef: 0.0852 - val_loss: 1.2265 - val_accuracy: 0.9082 - val_jacard_coef: 2.2169e-12 - lr: 0.0010
Epoch 2/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1814 - accuracy: 0.4017 - jacard_coef: 0.0808 2/17 [==>...........................] - ETA: 2s - loss: 0.1805 - accuracy: 0.4167 - jacard_coef: 0.0820 3/17 [====>.........................] - ETA: 2s - loss: 0.1842 - accuracy: 0.4001 - jacard_coef: 0.0769 4/17 [======>.......................] - ETA: 2s - loss: 0.1833 - accuracy: 0.4039 - jacard_coef: 0.0805 5/17 [=======>......................] - ETA: 2s - loss: 0.1832 - accuracy: 0.3976 - jacard_coef: 0.0912 6/17 [=========>....................] - ETA: 1s - loss: 0.1833 - accuracy: 0.3972 - jacard_coef: 0.0853 7/17 [===========>..................] - ETA: 1s - loss: 0.1826 - accuracy: 0.3924 - jacard_coef: 0.0822 8/17 [=============>................] - ETA: 1s - loss: 0.1827 - accuracy: 0.3785 - jacard_coef: 0.0816 9/17 [==============>...............] - ETA: 1s - loss: 0.1818 - accuracy: 0.3807 - jacard_coef: 0.078610/17 [================>.............] - ETA: 1s - loss: 0.1812 - accuracy: 0.3884 - jacard_coef: 0.075011/17 [==================>...........] - ETA: 1s - loss: 0.1805 - accuracy: 0.3986 - jacard_coef: 0.078912/17 [====================>.........] - ETA: 0s - loss: 0.1800 - accuracy: 0.4065 - jacard_coef: 0.077413/17 [=====================>........] - ETA: 0s - loss: 0.1795 - accuracy: 0.4138 - jacard_coef: 0.078614/17 [=======================>......] - ETA: 0s - loss: 0.1789 - accuracy: 0.4208 - jacard_coef: 0.078515/17 [=========================>....] - ETA: 0s - loss: 0.1786 - accuracy: 0.4240 - jacard_coef: 0.076916/17 [===========================>..] - ETA: 0s - loss: 0.1781 - accuracy: 0.4307 - jacard_coef: 0.0779
Epoch 2: val_jacard_coef improved from 0.00000 to 0.00248, saving model to best_attention_unet_model.h5
17/17 [==============================] - 7s 422ms/step - loss: 0.1781 - accuracy: 0.4307 - jacard_coef: 0.0850 - val_loss: 1.3181 - val_accuracy: 0.8998 - val_jacard_coef: 0.0025 - lr: 0.0010
Epoch 3/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1725 - accuracy: 0.4153 - jacard_coef: 0.0797 2/17 [==>...........................] - ETA: 2s - loss: 0.1714 - accuracy: 0.4501 - jacard_coef: 0.0825 3/17 [====>.........................] - ETA: 2s - loss: 0.1737 - accuracy: 0.4273 - jacard_coef: 0.0778 4/17 [======>.......................] - ETA: 2s - loss: 0.1733 - accuracy: 0.4552 - jacard_coef: 0.0825 5/17 [=======>......................] - ETA: 2s - loss: 0.1731 - accuracy: 0.4772 - jacard_coef: 0.0877 6/17 [=========>....................] - ETA: 1s - loss: 0.1727 - accuracy: 0.4923 - jacard_coef: 0.0821 7/17 [===========>..................] - ETA: 1s - loss: 0.1723 - accuracy: 0.5035 - jacard_coef: 0.0807 8/17 [=============>................] - ETA: 1s - loss: 0.1725 - accuracy: 0.5159 - jacard_coef: 0.0797 9/17 [==============>...............] - ETA: 1s - loss: 0.1721 - accuracy: 0.5335 - jacard_coef: 0.074810/17 [================>.............] - ETA: 1s - loss: 0.1716 - accuracy: 0.5481 - jacard_coef: 0.071611/17 [==================>...........] - ETA: 1s - loss: 0.1713 - accuracy: 0.5682 - jacard_coef: 0.073312/17 [====================>.........] - ETA: 0s - loss: 0.1709 - accuracy: 0.5820 - jacard_coef: 0.072213/17 [=====================>........] - ETA: 0s - loss: 0.1707 - accuracy: 0.5865 - jacard_coef: 0.073114/17 [=======================>......] - ETA: 0s - loss: 0.1703 - accuracy: 0.5929 - jacard_coef: 0.072215/17 [=========================>....] - ETA: 0s - loss: 0.1701 - accuracy: 0.5943 - jacard_coef: 0.071016/17 [===========================>..] - ETA: 0s - loss: 0.1699 - accuracy: 0.5962 - jacard_coef: 0.0718
Epoch 3: val_jacard_coef improved from 0.00248 to 0.03488, saving model to best_attention_unet_model.h5
17/17 [==============================] - 7s 450ms/step - loss: 0.1699 - accuracy: 0.5960 - jacard_coef: 0.0798 - val_loss: 0.1301 - val_accuracy: 0.8642 - val_jacard_coef: 0.0349 - lr: 0.0010
Epoch 4/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1643 - accuracy: 0.8102 - jacard_coef: 0.0581 2/17 [==>...........................] - ETA: 2s - loss: 0.1647 - accuracy: 0.7229 - jacard_coef: 0.0670 3/17 [====>.........................] - ETA: 2s - loss: 0.1648 - accuracy: 0.6942 - jacard_coef: 0.0653 4/17 [======>.......................] - ETA: 2s - loss: 0.1652 - accuracy: 0.6680 - jacard_coef: 0.0726 5/17 [=======>......................] - ETA: 2s - loss: 0.1654 - accuracy: 0.6687 - jacard_coef: 0.0797 6/17 [=========>....................] - ETA: 1s - loss: 0.1654 - accuracy: 0.6805 - jacard_coef: 0.0754 7/17 [===========>..................] - ETA: 1s - loss: 0.1653 - accuracy: 0.7008 - jacard_coef: 0.0718 8/17 [=============>................] - ETA: 1s - loss: 0.1655 - accuracy: 0.7167 - jacard_coef: 0.0711 9/17 [==============>...............] - ETA: 1s - loss: 0.1652 - accuracy: 0.7399 - jacard_coef: 0.064410/17 [================>.............] - ETA: 1s - loss: 0.1649 - accuracy: 0.7521 - jacard_coef: 0.061511/17 [==================>...........] - ETA: 1s - loss: 0.1648 - accuracy: 0.7598 - jacard_coef: 0.060512/17 [====================>.........] - ETA: 0s - loss: 0.1648 - accuracy: 0.7669 - jacard_coef: 0.057513/17 [=====================>........] - ETA: 0s - loss: 0.1647 - accuracy: 0.7684 - jacard_coef: 0.058214/17 [=======================>......] - ETA: 0s - loss: 0.1646 - accuracy: 0.7701 - jacard_coef: 0.058615/17 [=========================>....] - ETA: 0s - loss: 0.1644 - accuracy: 0.7706 - jacard_coef: 0.059916/17 [===========================>..] - ETA: 0s - loss: 0.1643 - accuracy: 0.7679 - jacard_coef: 0.0608
Epoch 4: val_jacard_coef improved from 0.03488 to 0.04067, saving model to best_attention_unet_model.h5
17/17 [==============================] - 8s 465ms/step - loss: 0.1645 - accuracy: 0.7657 - jacard_coef: 0.0680 - val_loss: 0.3596 - val_accuracy: 0.8495 - val_jacard_coef: 0.0407 - lr: 0.0010
Epoch 5/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1656 - accuracy: 0.8856 - jacard_coef: 0.0243 2/17 [==>...........................] - ETA: 2s - loss: 0.1685 - accuracy: 0.7436 - jacard_coef: 0.0540 3/17 [====>.........................] - ETA: 2s - loss: 0.1694 - accuracy: 0.7820 - jacard_coef: 0.0514 4/17 [======>.......................] - ETA: 2s - loss: 0.1695 - accuracy: 0.7992 - jacard_coef: 0.0498 5/17 [=======>......................] - ETA: 2s - loss: 0.1700 - accuracy: 0.7941 - jacard_coef: 0.0502 6/17 [=========>....................] - ETA: 1s - loss: 0.1700 - accuracy: 0.8019 - jacard_coef: 0.0486 7/17 [===========>..................] - ETA: 1s - loss: 0.1702 - accuracy: 0.7552 - jacard_coef: 0.0512 8/17 [=============>................] - ETA: 1s - loss: 0.1708 - accuracy: 0.7636 - jacard_coef: 0.0508 9/17 [==============>...............] - ETA: 1s - loss: 0.1706 - accuracy: 0.7790 - jacard_coef: 0.047510/17 [================>.............] - ETA: 1s - loss: 0.1699 - accuracy: 0.7929 - jacard_coef: 0.043211/17 [==================>...........] - ETA: 1s - loss: 0.1698 - accuracy: 0.7979 - jacard_coef: 0.042612/17 [====================>.........] - ETA: 0s - loss: 0.1698 - accuracy: 0.8043 - jacard_coef: 0.042413/17 [=====================>........] - ETA: 0s - loss: 0.1694 - accuracy: 0.8085 - jacard_coef: 0.044014/17 [=======================>......] - ETA: 0s - loss: 0.1690 - accuracy: 0.8097 - jacard_coef: 0.044315/17 [=========================>....] - ETA: 0s - loss: 0.1687 - accuracy: 0.8115 - jacard_coef: 0.043316/17 [===========================>..] - ETA: 0s - loss: 0.1683 - accuracy: 0.8130 - jacard_coef: 0.0441
Epoch 5: val_jacard_coef improved from 0.04067 to 0.08842, saving model to best_attention_unet_model.h5
17/17 [==============================] - 7s 449ms/step - loss: 0.1683 - accuracy: 0.8110 - jacard_coef: 0.0502 - val_loss: 0.1740 - val_accuracy: 0.6247 - val_jacard_coef: 0.0884 - lr: 0.0010
Epoch 6/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1602 - accuracy: 0.8398 - jacard_coef: 0.0572 2/17 [==>...........................] - ETA: 2s - loss: 0.1625 - accuracy: 0.8182 - jacard_coef: 0.0589 3/17 [====>.........................] - ETA: 2s - loss: 0.1629 - accuracy: 0.7923 - jacard_coef: 0.0619 4/17 [======>.......................] - ETA: 2s - loss: 0.1628 - accuracy: 0.7793 - jacard_coef: 0.0637 5/17 [=======>......................] - ETA: 2s - loss: 0.1630 - accuracy: 0.7750 - jacard_coef: 0.0702 6/17 [=========>....................] - ETA: 1s - loss: 0.1628 - accuracy: 0.7962 - jacard_coef: 0.0655 7/17 [===========>..................] - ETA: 1s - loss: 0.1626 - accuracy: 0.8057 - jacard_coef: 0.0652 8/17 [=============>................] - ETA: 1s - loss: 0.1629 - accuracy: 0.8198 - jacard_coef: 0.0580 9/17 [==============>...............] - ETA: 1s - loss: 0.1626 - accuracy: 0.8321 - jacard_coef: 0.053910/17 [================>.............] - ETA: 1s - loss: 0.1621 - accuracy: 0.8435 - jacard_coef: 0.048511/17 [==================>...........] - ETA: 1s - loss: 0.1621 - accuracy: 0.8461 - jacard_coef: 0.045912/17 [====================>.........] - ETA: 0s - loss: 0.1622 - accuracy: 0.8465 - jacard_coef: 0.045813/17 [=====================>........] - ETA: 0s - loss: 0.1620 - accuracy: 0.8462 - jacard_coef: 0.048214/17 [=======================>......] - ETA: 0s - loss: 0.1618 - accuracy: 0.8417 - jacard_coef: 0.049915/17 [=========================>....] - ETA: 0s - loss: 0.1615 - accuracy: 0.8425 - jacard_coef: 0.049616/17 [===========================>..] - ETA: 0s - loss: 0.1612 - accuracy: 0.8431 - jacard_coef: 0.0512
Epoch 6: val_jacard_coef did not improve from 0.08842
17/17 [==============================] - 3s 175ms/step - loss: 0.1612 - accuracy: 0.8424 - jacard_coef: 0.0576 - val_loss: 0.1358 - val_accuracy: 0.8924 - val_jacard_coef: 0.0130 - lr: 0.0010
Epoch 7/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1546 - accuracy: 0.8929 - jacard_coef: 0.0220 2/17 [==>...........................] - ETA: 2s - loss: 0.1566 - accuracy: 0.8167 - jacard_coef: 0.0526 3/17 [====>.........................] - ETA: 2s - loss: 0.1568 - accuracy: 0.7796 - jacard_coef: 0.0622 4/17 [======>.......................] - ETA: 2s - loss: 0.1564 - accuracy: 0.8057 - jacard_coef: 0.0660 5/17 [=======>......................] - ETA: 2s - loss: 0.1568 - accuracy: 0.8090 - jacard_coef: 0.0578 6/17 [=========>....................] - ETA: 1s - loss: 0.1567 - accuracy: 0.8259 - jacard_coef: 0.0487 7/17 [===========>..................] - ETA: 1s - loss: 0.1563 - accuracy: 0.8385 - jacard_coef: 0.0462 8/17 [=============>................] - ETA: 1s - loss: 0.1563 - accuracy: 0.8480 - jacard_coef: 0.0421 9/17 [==============>...............] - ETA: 1s - loss: 0.1560 - accuracy: 0.8595 - jacard_coef: 0.037610/17 [================>.............] - ETA: 1s - loss: 0.1554 - accuracy: 0.8689 - jacard_coef: 0.033811/17 [==================>...........] - ETA: 1s - loss: 0.1555 - accuracy: 0.8702 - jacard_coef: 0.030812/17 [====================>.........] - ETA: 0s - loss: 0.1556 - accuracy: 0.8752 - jacard_coef: 0.028313/17 [=====================>........] - ETA: 0s - loss: 0.1554 - accuracy: 0.8777 - jacard_coef: 0.026214/17 [=======================>......] - ETA: 0s - loss: 0.1552 - accuracy: 0.8805 - jacard_coef: 0.024315/17 [=========================>....] - ETA: 0s - loss: 0.1550 - accuracy: 0.8838 - jacard_coef: 0.022716/17 [===========================>..] - ETA: 0s - loss: 0.1548 - accuracy: 0.8849 - jacard_coef: 0.0218
Epoch 7: val_jacard_coef did not improve from 0.08842
17/17 [==============================] - 3s 175ms/step - loss: 0.1549 - accuracy: 0.8830 - jacard_coef: 0.0394 - val_loss: 0.1312 - val_accuracy: 0.8560 - val_jacard_coef: 0.0417 - lr: 0.0010
Epoch 8/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1502 - accuracy: 0.8472 - jacard_coef: 0.1226 2/17 [==>...........................] - ETA: 2s - loss: 0.1516 - accuracy: 0.7766 - jacard_coef: 0.1116 3/17 [====>.........................] - ETA: 2s - loss: 0.1529 - accuracy: 0.7338 - jacard_coef: 0.0984 4/17 [======>.......................] - ETA: 2s - loss: 0.1533 - accuracy: 0.7186 - jacard_coef: 0.0937 5/17 [=======>......................] - ETA: 2s - loss: 0.1541 - accuracy: 0.7235 - jacard_coef: 0.1005 6/17 [=========>....................] - ETA: 1s - loss: 0.1538 - accuracy: 0.7578 - jacard_coef: 0.0842 7/17 [===========>..................] - ETA: 1s - loss: 0.1542 - accuracy: 0.7775 - jacard_coef: 0.0789 8/17 [=============>................] - ETA: 1s - loss: 0.1542 - accuracy: 0.7905 - jacard_coef: 0.0734 9/17 [==============>...............] - ETA: 1s - loss: 0.1541 - accuracy: 0.8008 - jacard_coef: 0.065710/17 [================>.............] - ETA: 1s - loss: 0.1536 - accuracy: 0.8117 - jacard_coef: 0.060011/17 [==================>...........] - ETA: 1s - loss: 0.1537 - accuracy: 0.8150 - jacard_coef: 0.058112/17 [====================>.........] - ETA: 0s - loss: 0.1537 - accuracy: 0.8239 - jacard_coef: 0.053813/17 [=====================>........] - ETA: 0s - loss: 0.1534 - accuracy: 0.8303 - jacard_coef: 0.049814/17 [=======================>......] - ETA: 0s - loss: 0.1532 - accuracy: 0.8367 - jacard_coef: 0.046215/17 [=========================>....] - ETA: 0s - loss: 0.1529 - accuracy: 0.8430 - jacard_coef: 0.043116/17 [===========================>..] - ETA: 0s - loss: 0.1528 - accuracy: 0.8471 - jacard_coef: 0.0405
Epoch 8: val_jacard_coef did not improve from 0.08842
17/17 [==============================] - 3s 175ms/step - loss: 0.1528 - accuracy: 0.8448 - jacard_coef: 0.0486 - val_loss: 0.1020 - val_accuracy: 0.9083 - val_jacard_coef: 4.4387e-05 - lr: 0.0010
Epoch 9/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1480 - accuracy: 0.9173 - jacard_coef: 2.3051e-12 2/17 [==>...........................] - ETA: 2s - loss: 0.1490 - accuracy: 0.9214 - jacard_coef: 6.8992e-04 3/17 [====>.........................] - ETA: 2s - loss: 0.1491 - accuracy: 0.9213 - jacard_coef: 0.0011     4/17 [======>.......................] - ETA: 2s - loss: 0.1491 - accuracy: 0.9179 - jacard_coef: 0.0013 5/17 [=======>......................] - ETA: 2s - loss: 0.1498 - accuracy: 0.9045 - jacard_coef: 0.0026 6/17 [=========>....................] - ETA: 1s - loss: 0.1495 - accuracy: 0.9093 - jacard_coef: 0.0024 7/17 [===========>..................] - ETA: 1s - loss: 0.1493 - accuracy: 0.9122 - jacard_coef: 0.0052 8/17 [=============>................] - ETA: 1s - loss: 0.1495 - accuracy: 0.9131 - jacard_coef: 0.0069 9/17 [==============>...............] - ETA: 1s - loss: 0.1491 - accuracy: 0.9172 - jacard_coef: 0.006210/17 [================>.............] - ETA: 1s - loss: 0.1486 - accuracy: 0.9205 - jacard_coef: 0.005611/17 [==================>...........] - ETA: 1s - loss: 0.1486 - accuracy: 0.9168 - jacard_coef: 0.005212/17 [====================>.........] - ETA: 0s - loss: 0.1487 - accuracy: 0.9177 - jacard_coef: 0.005213/17 [=====================>........] - ETA: 0s - loss: 0.1486 - accuracy: 0.9167 - jacard_coef: 0.004814/17 [=======================>......] - ETA: 0s - loss: 0.1484 - accuracy: 0.9166 - jacard_coef: 0.004415/17 [=========================>....] - ETA: 0s - loss: 0.1481 - accuracy: 0.9175 - jacard_coef: 0.004216/17 [===========================>..] - ETA: 0s - loss: 0.1480 - accuracy: 0.9168 - jacard_coef: 0.0040
Epoch 9: val_jacard_coef did not improve from 0.08842
17/17 [==============================] - 3s 175ms/step - loss: 0.1480 - accuracy: 0.9153 - jacard_coef: 0.0214 - val_loss: 0.1196 - val_accuracy: 0.8909 - val_jacard_coef: 0.0149 - lr: 0.0010
Epoch 10/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1439 - accuracy: 0.9176 - jacard_coef: 2.3141e-12 2/17 [==>...........................] - ETA: 2s - loss: 0.1445 - accuracy: 0.8660 - jacard_coef: 0.0501     3/17 [====>.........................] - ETA: 2s - loss: 0.1466 - accuracy: 0.7682 - jacard_coef: 0.0579 4/17 [======>.......................] - ETA: 2s - loss: 0.1466 - accuracy: 0.8008 - jacard_coef: 0.0541 5/17 [=======>......................] - ETA: 2s - loss: 0.1473 - accuracy: 0.8123 - jacard_coef: 0.0433 6/17 [=========>....................] - ETA: 1s - loss: 0.1466 - accuracy: 0.8337 - jacard_coef: 0.0363 7/17 [===========>..................] - ETA: 1s - loss: 0.1462 - accuracy: 0.8479 - jacard_coef: 0.0311 8/17 [=============>................] - ETA: 1s - loss: 0.1462 - accuracy: 0.8571 - jacard_coef: 0.0276 9/17 [==============>...............] - ETA: 1s - loss: 0.1458 - accuracy: 0.8678 - jacard_coef: 0.024610/17 [================>.............] - ETA: 1s - loss: 0.1452 - accuracy: 0.8765 - jacard_coef: 0.022211/17 [==================>...........] - ETA: 1s - loss: 0.1454 - accuracy: 0.8771 - jacard_coef: 0.020212/17 [====================>.........] - ETA: 0s - loss: 0.1454 - accuracy: 0.8815 - jacard_coef: 0.018913/17 [=====================>........] - ETA: 0s - loss: 0.1454 - accuracy: 0.8835 - jacard_coef: 0.017414/17 [=======================>......] - ETA: 0s - loss: 0.1452 - accuracy: 0.8859 - jacard_coef: 0.016215/17 [=========================>....] - ETA: 0s - loss: 0.1450 - accuracy: 0.8889 - jacard_coef: 0.015116/17 [===========================>..] - ETA: 0s - loss: 0.1449 - accuracy: 0.8901 - jacard_coef: 0.0142
Epoch 10: val_jacard_coef improved from 0.08842 to 0.08973, saving model to best_attention_unet_model.h5
17/17 [==============================] - 6s 394ms/step - loss: 0.1455 - accuracy: 0.8870 - jacard_coef: 0.0224 - val_loss: 0.2010 - val_accuracy: 0.2527 - val_jacard_coef: 0.0897 - lr: 0.0010
Epoch 11/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1420 - accuracy: 0.9134 - jacard_coef: 4.4044e-05 2/17 [==>...........................] - ETA: 2s - loss: 0.1426 - accuracy: 0.9150 - jacard_coef: 6.0491e-04 3/17 [====>.........................] - ETA: 2s - loss: 0.1426 - accuracy: 0.9157 - jacard_coef: 5.9503e-04 4/17 [======>.......................] - ETA: 2s - loss: 0.1426 - accuracy: 0.9140 - jacard_coef: 0.0012     5/17 [=======>......................] - ETA: 2s - loss: 0.1437 - accuracy: 0.9018 - jacard_coef: 0.0014 6/17 [=========>....................] - ETA: 1s - loss: 0.1431 - accuracy: 0.9078 - jacard_coef: 0.0013 7/17 [===========>..................] - ETA: 1s - loss: 0.1430 - accuracy: 0.9113 - jacard_coef: 0.0017 8/17 [=============>................] - ETA: 1s - loss: 0.1431 - accuracy: 0.9123 - jacard_coef: 0.0020 9/17 [==============>...............] - ETA: 1s - loss: 0.1427 - accuracy: 0.9164 - jacard_coef: 0.001810/17 [================>.............] - ETA: 1s - loss: 0.1422 - accuracy: 0.9195 - jacard_coef: 0.001611/17 [==================>...........] - ETA: 1s - loss: 0.1423 - accuracy: 0.9153 - jacard_coef: 0.002412/17 [====================>.........] - ETA: 0s - loss: 0.1423 - accuracy: 0.9147 - jacard_coef: 0.003913/17 [=====================>........] - ETA: 0s - loss: 0.1422 - accuracy: 0.9135 - jacard_coef: 0.004214/17 [=======================>......] - ETA: 0s - loss: 0.1421 - accuracy: 0.9132 - jacard_coef: 0.004015/17 [=========================>....] - ETA: 0s - loss: 0.1419 - accuracy: 0.9142 - jacard_coef: 0.003816/17 [===========================>..] - ETA: 0s - loss: 0.1418 - accuracy: 0.9133 - jacard_coef: 0.0038
Epoch 11: val_jacard_coef did not improve from 0.08973
17/17 [==============================] - 3s 175ms/step - loss: 0.1421 - accuracy: 0.9106 - jacard_coef: 0.0137 - val_loss: 0.1396 - val_accuracy: 0.9084 - val_jacard_coef: 2.2203e-12 - lr: 0.0010
Epoch 12/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1393 - accuracy: 0.9170 - jacard_coef: 2.5286e-04 2/17 [==>...........................] - ETA: 2s - loss: 0.1398 - accuracy: 0.9221 - jacard_coef: 1.6571e-04 3/17 [====>.........................] - ETA: 2s - loss: 0.1427 - accuracy: 0.9024 - jacard_coef: 0.0129     4/17 [======>.......................] - ETA: 2s - loss: 0.1427 - accuracy: 0.9047 - jacard_coef: 0.0113 5/17 [=======>......................] - ETA: 2s - loss: 0.1439 - accuracy: 0.8917 - jacard_coef: 0.0108 6/17 [=========>....................] - ETA: 1s - loss: 0.1431 - accuracy: 0.8967 - jacard_coef: 0.0090 7/17 [===========>..................] - ETA: 1s - loss: 0.1427 - accuracy: 0.9009 - jacard_coef: 0.0100 8/17 [=============>................] - ETA: 1s - loss: 0.1426 - accuracy: 0.9032 - jacard_coef: 0.0098 9/17 [==============>...............] - ETA: 1s - loss: 0.1419 - accuracy: 0.9083 - jacard_coef: 0.008810/17 [================>.............] - ETA: 1s - loss: 0.1411 - accuracy: 0.9129 - jacard_coef: 0.007911/17 [==================>...........] - ETA: 1s - loss: 0.1412 - accuracy: 0.9102 - jacard_coef: 0.007212/17 [====================>.........] - ETA: 0s - loss: 0.1410 - accuracy: 0.9118 - jacard_coef: 0.006913/17 [=====================>........] - ETA: 0s - loss: 0.1409 - accuracy: 0.9114 - jacard_coef: 0.006414/17 [=======================>......] - ETA: 0s - loss: 0.1406 - accuracy: 0.9119 - jacard_coef: 0.005915/17 [=========================>....] - ETA: 0s - loss: 0.1404 - accuracy: 0.9130 - jacard_coef: 0.005816/17 [===========================>..] - ETA: 0s - loss: 0.1402 - accuracy: 0.9123 - jacard_coef: 0.0055
Epoch 12: val_jacard_coef did not improve from 0.08973
17/17 [==============================] - 3s 175ms/step - loss: 0.1404 - accuracy: 0.9092 - jacard_coef: 0.0164 - val_loss: 0.1678 - val_accuracy: 0.7279 - val_jacard_coef: 0.0673 - lr: 0.0010
Epoch 13/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1372 - accuracy: 0.9002 - jacard_coef: 0.0012 2/17 [==>...........................] - ETA: 2s - loss: 0.1373 - accuracy: 0.9069 - jacard_coef: 0.0014 3/17 [====>.........................] - ETA: 2s - loss: 0.1374 - accuracy: 0.9110 - jacard_coef: 0.0029 4/17 [======>.......................] - ETA: 2s - loss: 0.1375 - accuracy: 0.9109 - jacard_coef: 0.0023 5/17 [=======>......................] - ETA: 2s - loss: 0.1389 - accuracy: 0.8998 - jacard_coef: 0.0021 6/17 [=========>....................] - ETA: 1s - loss: 0.1383 - accuracy: 0.9061 - jacard_coef: 0.0018 7/17 [===========>..................] - ETA: 1s - loss: 0.1381 - accuracy: 0.9100 - jacard_coef: 0.0016 8/17 [=============>................] - ETA: 1s - loss: 0.1382 - accuracy: 0.9114 - jacard_coef: 0.0015 9/17 [==============>...............] - ETA: 1s - loss: 0.1377 - accuracy: 0.9159 - jacard_coef: 0.001310/17 [================>.............] - ETA: 1s - loss: 0.1370 - accuracy: 0.9195 - jacard_coef: 0.001211/17 [==================>...........] - ETA: 1s - loss: 0.1373 - accuracy: 0.9159 - jacard_coef: 0.001112/17 [====================>.........] - ETA: 0s - loss: 0.1372 - accuracy: 0.9166 - jacard_coef: 0.002713/17 [=====================>........] - ETA: 0s - loss: 0.1372 - accuracy: 0.9155 - jacard_coef: 0.002514/17 [=======================>......] - ETA: 0s - loss: 0.1370 - accuracy: 0.9155 - jacard_coef: 0.002415/17 [=========================>....] - ETA: 0s - loss: 0.1368 - accuracy: 0.9162 - jacard_coef: 0.004016/17 [===========================>..] - ETA: 0s - loss: 0.1367 - accuracy: 0.9154 - jacard_coef: 0.0037
Epoch 13: val_jacard_coef did not improve from 0.08973
17/17 [==============================] - 3s 175ms/step - loss: 0.1368 - accuracy: 0.9147 - jacard_coef: 0.0109 - val_loss: 0.1721 - val_accuracy: 0.7420 - val_jacard_coef: 0.0566 - lr: 0.0010
Epoch 14/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1346 - accuracy: 0.9151 - jacard_coef: 2.9203e-04 2/17 [==>...........................] - ETA: 2s - loss: 0.1347 - accuracy: 0.9208 - jacard_coef: 8.3297e-04 3/17 [====>.........................] - ETA: 2s - loss: 0.1349 - accuracy: 0.8901 - jacard_coef: 0.0198     4/17 [======>.......................] - ETA: 2s - loss: 0.1353 - accuracy: 0.8962 - jacard_coef: 0.0149 5/17 [=======>......................] - ETA: 2s - loss: 0.1361 - accuracy: 0.8714 - jacard_coef: 0.0420 6/17 [=========>....................] - ETA: 1s - loss: 0.1356 - accuracy: 0.8830 - jacard_coef: 0.0351 7/17 [===========>..................] - ETA: 1s - loss: 0.1352 - accuracy: 0.8902 - jacard_coef: 0.0301 8/17 [=============>................] - ETA: 1s - loss: 0.1353 - accuracy: 0.8941 - jacard_coef: 0.0264 9/17 [==============>...............] - ETA: 1s - loss: 0.1347 - accuracy: 0.9007 - jacard_coef: 0.023410/17 [================>.............] - ETA: 1s - loss: 0.1340 - accuracy: 0.9061 - jacard_coef: 0.021111/17 [==================>...........] - ETA: 1s - loss: 0.1342 - accuracy: 0.9041 - jacard_coef: 0.019212/17 [====================>.........] - ETA: 0s - loss: 0.1342 - accuracy: 0.9062 - jacard_coef: 0.017813/17 [=====================>........] - ETA: 0s - loss: 0.1341 - accuracy: 0.9064 - jacard_coef: 0.016514/17 [=======================>......] - ETA: 0s - loss: 0.1339 - accuracy: 0.9073 - jacard_coef: 0.015315/17 [=========================>....] - ETA: 0s - loss: 0.1337 - accuracy: 0.9089 - jacard_coef: 0.014416/17 [===========================>..] - ETA: 0s - loss: 0.1336 - accuracy: 0.9088 - jacard_coef: 0.0135
Epoch 14: val_jacard_coef did not improve from 0.08973
17/17 [==============================] - 3s 175ms/step - loss: 0.1337 - accuracy: 0.9082 - jacard_coef: 0.0320 - val_loss: 0.1535 - val_accuracy: 0.9084 - val_jacard_coef: 2.2203e-12 - lr: 0.0010
Epoch 15/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1312 - accuracy: 0.9163 - jacard_coef: 2.2776e-12 2/17 [==>...........................] - ETA: 2s - loss: 0.1309 - accuracy: 0.9213 - jacard_coef: 7.7475e-04 3/17 [====>.........................] - ETA: 2s - loss: 0.1310 - accuracy: 0.9225 - jacard_coef: 5.1650e-04 4/17 [======>.......................] - ETA: 2s - loss: 0.1313 - accuracy: 0.9207 - jacard_coef: 3.8738e-04 5/17 [=======>......................] - ETA: 2s - loss: 0.1323 - accuracy: 0.9082 - jacard_coef: 3.0990e-04 6/17 [=========>....................] - ETA: 1s - loss: 0.1317 - accuracy: 0.9136 - jacard_coef: 4.0846e-04 7/17 [===========>..................] - ETA: 1s - loss: 0.1315 - accuracy: 0.9165 - jacard_coef: 4.1983e-04 8/17 [=============>................] - ETA: 1s - loss: 0.1316 - accuracy: 0.9171 - jacard_coef: 4.8293e-04 9/17 [==============>...............] - ETA: 1s - loss: 0.1311 - accuracy: 0.9212 - jacard_coef: 5.1568e-0410/17 [================>.............] - ETA: 1s - loss: 0.1305 - accuracy: 0.9245 - jacard_coef: 4.6411e-0411/17 [==================>...........] - ETA: 1s - loss: 0.1307 - accuracy: 0.9208 - jacard_coef: 4.2638e-0412/17 [====================>.........] - ETA: 0s - loss: 0.1307 - accuracy: 0.9214 - jacard_coef: 8.5028e-0413/17 [=====================>........] - ETA: 0s - loss: 0.1307 - accuracy: 0.9203 - jacard_coef: 7.8487e-0414/17 [=======================>......] - ETA: 0s - loss: 0.1306 - accuracy: 0.9202 - jacard_coef: 7.2881e-0415/17 [=========================>....] - ETA: 0s - loss: 0.1304 - accuracy: 0.9209 - jacard_coef: 9.5857e-0416/17 [===========================>..] - ETA: 0s - loss: 0.1304 - accuracy: 0.9199 - jacard_coef: 8.9866e-04
Epoch 15: val_jacard_coef did not improve from 0.08973
17/17 [==============================] - 3s 175ms/step - loss: 0.1307 - accuracy: 0.9183 - jacard_coef: 0.0167 - val_loss: 0.1497 - val_accuracy: 0.9084 - val_jacard_coef: 2.2203e-12 - lr: 0.0010
Epoch 16/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1288 - accuracy: 0.9164 - jacard_coef: 2.2821e-12 2/17 [==>...........................] - ETA: 2s - loss: 0.1287 - accuracy: 0.9219 - jacard_coef: 4.9909e-04 3/17 [====>.........................] - ETA: 2s - loss: 0.1328 - accuracy: 0.9190 - jacard_coef: 0.0047     4/17 [======>.......................] - ETA: 2s - loss: 0.1334 - accuracy: 0.9180 - jacard_coef: 0.0035 5/17 [=======>......................] - ETA: 2s - loss: 0.1358 - accuracy: 0.8989 - jacard_coef: 0.0238 6/17 [=========>....................] - ETA: 1s - loss: 0.1351 - accuracy: 0.9059 - jacard_coef: 0.0202 7/17 [===========>..................] - ETA: 1s - loss: 0.1357 - accuracy: 0.9098 - jacard_coef: 0.0174 8/17 [=============>................] - ETA: 1s - loss: 0.1365 - accuracy: 0.9107 - jacard_coef: 0.0156 9/17 [==============>...............] - ETA: 1s - loss: 0.1353 - accuracy: 0.9148 - jacard_coef: 0.014010/17 [================>.............] - ETA: 1s - loss: 0.1342 - accuracy: 0.9184 - jacard_coef: 0.012611/17 [==================>...........] - ETA: 1s - loss: 0.1341 - accuracy: 0.9152 - jacard_coef: 0.011512/17 [====================>.........] - ETA: 0s - loss: 0.1338 - accuracy: 0.9164 - jacard_coef: 0.010713/17 [=====================>........] - ETA: 0s - loss: 0.1335 - accuracy: 0.9158 - jacard_coef: 0.009914/17 [=======================>......] - ETA: 0s - loss: 0.1331 - accuracy: 0.9160 - jacard_coef: 0.009215/17 [=========================>....] - ETA: 0s - loss: 0.1326 - accuracy: 0.9170 - jacard_coef: 0.008616/17 [===========================>..] - ETA: 0s - loss: 0.1324 - accuracy: 0.9164 - jacard_coef: 0.0081
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.

Epoch 16: val_jacard_coef did not improve from 0.08973
17/17 [==============================] - 3s 175ms/step - loss: 0.1325 - accuracy: 0.9152 - jacard_coef: 0.0276 - val_loss: 0.1655 - val_accuracy: 0.9084 - val_jacard_coef: 2.2203e-12 - lr: 0.0010
Epoch 17/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1265 - accuracy: 0.9142 - jacard_coef: 2.2233e-12 2/17 [==>...........................] - ETA: 2s - loss: 0.1266 - accuracy: 0.9192 - jacard_coef: 8.9191e-04 3/17 [====>.........................] - ETA: 2s - loss: 0.1267 - accuracy: 0.9203 - jacard_coef: 5.9461e-04 4/17 [======>.......................] - ETA: 2s - loss: 0.1270 - accuracy: 0.9184 - jacard_coef: 0.0021     5/17 [=======>......................] - ETA: 2s - loss: 0.1286 - accuracy: 0.9063 - jacard_coef: 0.0017 6/17 [=========>....................] - ETA: 1s - loss: 0.1278 - accuracy: 0.9120 - jacard_coef: 0.0016 7/17 [===========>..................] - ETA: 1s - loss: 0.1275 - accuracy: 0.9151 - jacard_coef: 0.0014 8/17 [=============>................] - ETA: 1s - loss: 0.1277 - accuracy: 0.9159 - jacard_coef: 0.0014 9/17 [==============>...............] - ETA: 1s - loss: 0.1271 - accuracy: 0.9201 - jacard_coef: 0.001310/17 [================>.............] - ETA: 1s - loss: 0.1265 - accuracy: 0.9236 - jacard_coef: 0.001211/17 [==================>...........] - ETA: 1s - loss: 0.1269 - accuracy: 0.9200 - jacard_coef: 0.001112/17 [====================>.........] - ETA: 0s - loss: 0.1268 - accuracy: 0.9208 - jacard_coef: 0.001113/17 [=====================>........] - ETA: 0s - loss: 0.1269 - accuracy: 0.9198 - jacard_coef: 0.001014/17 [=======================>......] - ETA: 0s - loss: 0.1268 - accuracy: 0.9198 - jacard_coef: 9.5606e-0415/17 [=========================>....] - ETA: 0s - loss: 0.1266 - accuracy: 0.9205 - jacard_coef: 9.5619e-0416/17 [===========================>..] - ETA: 0s - loss: 0.1267 - accuracy: 0.9197 - jacard_coef: 9.1574e-04
Epoch 17: val_jacard_coef did not improve from 0.08973
17/17 [==============================] - 3s 175ms/step - loss: 0.1268 - accuracy: 0.9186 - jacard_coef: 9.8383e-04 - val_loss: 0.1631 - val_accuracy: 0.9084 - val_jacard_coef: 2.2203e-12 - lr: 5.0000e-04
Epoch 18/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1251 - accuracy: 0.9165 - jacard_coef: 2.2850e-12 2/17 [==>...........................] - ETA: 2s - loss: 0.1247 - accuracy: 0.9219 - jacard_coef: 5.3724e-04 3/17 [====>.........................] - ETA: 2s - loss: 0.1249 - accuracy: 0.9229 - jacard_coef: 3.5816e-04 4/17 [======>.......................] - ETA: 2s - loss: 0.1253 - accuracy: 0.9209 - jacard_coef: 2.6862e-04 5/17 [=======>......................] - ETA: 2s - loss: 0.1270 - accuracy: 0.9084 - jacard_coef: 2.1490e-04 6/17 [=========>....................] - ETA: 1s - loss: 0.1262 - accuracy: 0.9138 - jacard_coef: 3.1369e-04 7/17 [===========>..................] - ETA: 1s - loss: 0.1259 - accuracy: 0.9167 - jacard_coef: 2.7709e-04 8/17 [=============>................] - ETA: 1s - loss: 0.1260 - accuracy: 0.9173 - jacard_coef: 3.7023e-04 9/17 [==============>...............] - ETA: 1s - loss: 0.1254 - accuracy: 0.9213 - jacard_coef: 3.7472e-0410/17 [================>.............] - ETA: 1s - loss: 0.1247 - accuracy: 0.9246 - jacard_coef: 3.3725e-0411/17 [==================>...........] - ETA: 1s - loss: 0.1252 - accuracy: 0.9209 - jacard_coef: 3.2144e-0412/17 [====================>.........] - ETA: 0s - loss: 0.1251 - accuracy: 0.9216 - jacard_coef: 5.2435e-0413/17 [=====================>........] - ETA: 0s - loss: 0.1252 - accuracy: 0.9205 - jacard_coef: 4.8717e-0414/17 [=======================>......] - ETA: 0s - loss: 0.1251 - accuracy: 0.9203 - jacard_coef: 4.5237e-0415/17 [=========================>....] - ETA: 0s - loss: 0.1250 - accuracy: 0.9210 - jacard_coef: 4.8800e-0416/17 [===========================>..] - ETA: 0s - loss: 0.1250 - accuracy: 0.9202 - jacard_coef: 4.5750e-04
Epoch 18: val_jacard_coef did not improve from 0.08973
17/17 [==============================] - 3s 175ms/step - loss: 0.1251 - accuracy: 0.9196 - jacard_coef: 0.0236 - val_loss: 0.1543 - val_accuracy: 0.9084 - val_jacard_coef: 2.2203e-12 - lr: 5.0000e-04
Epoch 19/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1234 - accuracy: 0.9173 - jacard_coef: 2.3060e-12 2/17 [==>...........................] - ETA: 2s - loss: 0.1231 - accuracy: 0.9226 - jacard_coef: 3.9615e-04 3/17 [====>.........................] - ETA: 2s - loss: 0.1234 - accuracy: 0.9234 - jacard_coef: 2.6410e-04 4/17 [======>.......................] - ETA: 2s - loss: 0.1239 - accuracy: 0.9213 - jacard_coef: 1.9808e-04 5/17 [=======>......................] - ETA: 2s - loss: 0.1255 - accuracy: 0.9088 - jacard_coef: 1.5846e-04 6/17 [=========>....................] - ETA: 1s - loss: 0.1248 - accuracy: 0.9141 - jacard_coef: 2.9922e-04 7/17 [===========>..................] - ETA: 1s - loss: 0.1244 - accuracy: 0.9169 - jacard_coef: 2.7703e-04 8/17 [=============>................] - ETA: 1s - loss: 0.1246 - accuracy: 0.9175 - jacard_coef: 3.7028e-04 9/17 [==============>...............] - ETA: 1s - loss: 0.1240 - accuracy: 0.9216 - jacard_coef: 3.3375e-0410/17 [================>.............] - ETA: 1s - loss: 0.1234 - accuracy: 0.9249 - jacard_coef: 3.0037e-0411/17 [==================>...........] - ETA: 1s - loss: 0.1238 - accuracy: 0.9212 - jacard_coef: 2.8353e-0412/17 [====================>.........] - ETA: 0s - loss: 0.1238 - accuracy: 0.9219 - jacard_coef: 4.6167e-0413/17 [=====================>........] - ETA: 0s - loss: 0.1238 - accuracy: 0.9209 - jacard_coef: 4.2615e-0414/17 [=======================>......] - ETA: 0s - loss: 0.1238 - accuracy: 0.9207 - jacard_coef: 3.9571e-0415/17 [=========================>....] - ETA: 0s - loss: 0.1236 - accuracy: 0.9214 - jacard_coef: 4.3160e-0416/17 [===========================>..] - ETA: 0s - loss: 0.1236 - accuracy: 0.9206 - jacard_coef: 4.0463e-04
Epoch 19: val_jacard_coef did not improve from 0.08973
17/17 [==============================] - 3s 175ms/step - loss: 0.1236 - accuracy: 0.9196 - jacard_coef: 0.0220 - val_loss: 0.1400 - val_accuracy: 0.9084 - val_jacard_coef: 2.2203e-12 - lr: 5.0000e-04
Epoch 20/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1220 - accuracy: 0.9171 - jacard_coef: 2.3003e-12 2/17 [==>...........................] - ETA: 2s - loss: 0.1218 - accuracy: 0.9223 - jacard_coef: 5.2515e-04 3/17 [====>.........................] - ETA: 2s - loss: 0.1222 - accuracy: 0.9233 - jacard_coef: 3.5010e-04 4/17 [======>.......................] - ETA: 2s - loss: 0.1226 - accuracy: 0.9212 - jacard_coef: 2.6258e-04 5/17 [=======>......................] - ETA: 2s - loss: 0.1245 - accuracy: 0.9087 - jacard_coef: 2.1006e-04 6/17 [=========>....................] - ETA: 1s - loss: 0.1237 - accuracy: 0.9140 - jacard_coef: 2.7722e-04 7/17 [===========>..................] - ETA: 1s - loss: 0.1233 - accuracy: 0.9169 - jacard_coef: 2.3762e-04 8/17 [=============>................] - ETA: 1s - loss: 0.1235 - accuracy: 0.9175 - jacard_coef: 2.6579e-04 9/17 [==============>...............] - ETA: 1s - loss: 0.1228 - accuracy: 0.9215 - jacard_coef: 2.4088e-0410/17 [================>.............] - ETA: 1s - loss: 0.1222 - accuracy: 0.9249 - jacard_coef: 2.1679e-0411/17 [==================>...........] - ETA: 1s - loss: 0.1227 - accuracy: 0.9212 - jacard_coef: 1.9708e-0412/17 [====================>.........] - ETA: 0s - loss: 0.1227 - accuracy: 0.9219 - jacard_coef: 2.8071e-0413/17 [=====================>........] - ETA: 0s - loss: 0.1228 - accuracy: 0.9209 - jacard_coef: 2.5912e-0414/17 [=======================>......] - ETA: 0s - loss: 0.1227 - accuracy: 0.9207 - jacard_coef: 2.4061e-0415/17 [=========================>....] - ETA: 0s - loss: 0.1225 - accuracy: 0.9214 - jacard_coef: 2.3193e-0416/17 [===========================>..] - ETA: 0s - loss: 0.1226 - accuracy: 0.9206 - jacard_coef: 2.1744e-04
Epoch 20: val_jacard_coef did not improve from 0.08973
17/17 [==============================] - 3s 176ms/step - loss: 0.1227 - accuracy: 0.9195 - jacard_coef: 0.0134 - val_loss: 0.1470 - val_accuracy: 0.9084 - val_jacard_coef: 2.2203e-12 - lr: 5.0000e-04
Epoch 21/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1213 - accuracy: 0.9175 - jacard_coef: 2.3110e-12 2/17 [==>...........................] - ETA: 2s - loss: 0.1209 - accuracy: 0.9227 - jacard_coef: 3.3064e-04 3/17 [====>.........................] - ETA: 2s - loss: 0.1211 - accuracy: 0.9236 - jacard_coef: 2.2043e-04 4/17 [======>.......................] - ETA: 2s - loss: 0.1215 - accuracy: 0.9215 - jacard_coef: 1.6532e-04 5/17 [=======>......................] - ETA: 2s - loss: 0.1232 - accuracy: 0.9089 - jacard_coef: 1.3226e-04 6/17 [=========>....................] - ETA: 1s - loss: 0.1224 - accuracy: 0.9143 - jacard_coef: 1.5880e-04 7/17 [===========>..................] - ETA: 1s - loss: 0.1220 - accuracy: 0.9171 - jacard_coef: 1.4435e-04 8/17 [=============>................] - ETA: 1s - loss: 0.1221 - accuracy: 0.9177 - jacard_coef: 1.5068e-04 9/17 [==============>...............] - ETA: 1s - loss: 0.1215 - accuracy: 0.9217 - jacard_coef: 1.3394e-0410/17 [================>.............] - ETA: 1s - loss: 0.1208 - accuracy: 0.9250 - jacard_coef: 1.2054e-0411/17 [==================>...........] - ETA: 1s - loss: 0.1213 - accuracy: 0.9213 - jacard_coef: 1.0958e-0412/17 [====================>.........] - ETA: 0s - loss: 0.1213 - accuracy: 0.9220 - jacard_coef: 2.3886e-0413/17 [=====================>........] - ETA: 0s - loss: 0.1214 - accuracy: 0.9210 - jacard_coef: 2.2049e-0414/17 [=======================>......] - ETA: 0s - loss: 0.1213 - accuracy: 0.9208 - jacard_coef: 2.0474e-0415/17 [=========================>....] - ETA: 0s - loss: 0.1212 - accuracy: 0.9215 - jacard_coef: 2.0949e-0416/17 [===========================>..] - ETA: 0s - loss: 0.1212 - accuracy: 0.9207 - jacard_coef: 1.9640e-04
Epoch 21: val_jacard_coef did not improve from 0.08973
17/17 [==============================] - 3s 175ms/step - loss: 0.1212 - accuracy: 0.9199 - jacard_coef: 0.0197 - val_loss: 0.1334 - val_accuracy: 0.9084 - val_jacard_coef: 2.2203e-12 - lr: 5.0000e-04
Epoch 22/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1205 - accuracy: 0.9173 - jacard_coef: 2.3057e-12 2/17 [==>...........................] - ETA: 2s - loss: 0.1200 - accuracy: 0.9225 - jacard_coef: 3.1651e-04 3/17 [====>.........................] - ETA: 2s - loss: 0.1203 - accuracy: 0.9234 - jacard_coef: 2.1101e-04 4/17 [======>.......................] - ETA: 2s - loss: 0.1208 - accuracy: 0.9213 - jacard_coef: 1.5826e-04 5/17 [=======>......................] - ETA: 2s - loss: 0.1223 - accuracy: 0.9088 - jacard_coef: 1.2661e-04 6/17 [=========>....................] - ETA: 1s - loss: 0.1215 - accuracy: 0.9142 - jacard_coef: 1.6487e-04 7/17 [===========>..................] - ETA: 1s - loss: 0.1212 - accuracy: 0.9170 - jacard_coef: 1.4132e-04 8/17 [=============>................] - ETA: 1s - loss: 0.1212 - accuracy: 0.9176 - jacard_coef: 1.4801e-04 9/17 [==============>...............] - ETA: 1s - loss: 0.1206 - accuracy: 0.9216 - jacard_coef: 1.4999e-0410/17 [================>.............] - ETA: 1s - loss: 0.1200 - accuracy: 0.9249 - jacard_coef: 1.3499e-0411/17 [==================>...........] - ETA: 1s - loss: 0.1204 - accuracy: 0.9212 - jacard_coef: 1.2272e-0412/17 [====================>.........] - ETA: 0s - loss: 0.1204 - accuracy: 0.9219 - jacard_coef: 3.0928e-0413/17 [=====================>........] - ETA: 0s - loss: 0.1204 - accuracy: 0.9209 - jacard_coef: 2.8549e-0414/17 [=======================>......] - ETA: 0s - loss: 0.1203 - accuracy: 0.9207 - jacard_coef: 2.6510e-0415/17 [=========================>....] - ETA: 0s - loss: 0.1202 - accuracy: 0.9214 - jacard_coef: 2.5294e-0416/17 [===========================>..] - ETA: 0s - loss: 0.1202 - accuracy: 0.9206 - jacard_coef: 2.3713e-04
Epoch 22: val_jacard_coef did not improve from 0.08973
17/17 [==============================] - 3s 175ms/step - loss: 0.1202 - accuracy: 0.9194 - jacard_coef: 0.0242 - val_loss: 0.1285 - val_accuracy: 0.9084 - val_jacard_coef: 2.2203e-12 - lr: 5.0000e-04
Epoch 23/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1192 - accuracy: 0.9168 - jacard_coef: 2.2924e-12 2/17 [==>...........................] - ETA: 2s - loss: 0.1188 - accuracy: 0.9219 - jacard_coef: 7.7068e-04 3/17 [====>.........................] - ETA: 2s - loss: 0.1189 - accuracy: 0.9224 - jacard_coef: 9.2025e-04 4/17 [======>.......................] - ETA: 2s - loss: 0.1195 - accuracy: 0.9205 - jacard_coef: 6.9019e-04 5/17 [=======>......................] - ETA: 2s - loss: 0.1214 - accuracy: 0.9081 - jacard_coef: 5.7366e-04 6/17 [=========>....................] - ETA: 1s - loss: 0.1206 - accuracy: 0.9136 - jacard_coef: 6.6129e-04 7/17 [===========>..................] - ETA: 1s - loss: 0.1202 - accuracy: 0.9164 - jacard_coef: 9.6435e-04 8/17 [=============>................] - ETA: 1s - loss: 0.1204 - accuracy: 0.9171 - jacard_coef: 9.8650e-04 9/17 [==============>...............] - ETA: 1s - loss: 0.1197 - accuracy: 0.9212 - jacard_coef: 8.7689e-0410/17 [================>.............] - ETA: 1s - loss: 0.1190 - accuracy: 0.9245 - jacard_coef: 7.8920e-0411/17 [==================>...........] - ETA: 1s - loss: 0.1196 - accuracy: 0.9208 - jacard_coef: 7.1745e-0412/17 [====================>.........] - ETA: 0s - loss: 0.1196 - accuracy: 0.9216 - jacard_coef: 7.1223e-0413/17 [=====================>........] - ETA: 0s - loss: 0.1197 - accuracy: 0.9206 - jacard_coef: 6.5744e-0414/17 [=======================>......] - ETA: 0s - loss: 0.1196 - accuracy: 0.9204 - jacard_coef: 6.1048e-0415/17 [=========================>....] - ETA: 0s - loss: 0.1194 - accuracy: 0.9211 - jacard_coef: 6.1411e-0416/17 [===========================>..] - ETA: 0s - loss: 0.1195 - accuracy: 0.9203 - jacard_coef: 5.7573e-04
Epoch 23: val_jacard_coef did not improve from 0.08973
17/17 [==============================] - 3s 175ms/step - loss: 0.1196 - accuracy: 0.9191 - jacard_coef: 0.0148 - val_loss: 0.1197 - val_accuracy: 0.9084 - val_jacard_coef: 2.2203e-12 - lr: 5.0000e-04
Epoch 24/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1185 - accuracy: 0.9176 - jacard_coef: 2.3155e-12 2/17 [==>...........................] - ETA: 2s - loss: 0.1184 - accuracy: 0.9228 - jacard_coef: 2.5146e-04 3/17 [====>.........................] - ETA: 2s - loss: 0.1186 - accuracy: 0.9236 - jacard_coef: 1.6764e-04 4/17 [======>.......................] - ETA: 2s - loss: 0.1192 - accuracy: 0.9214 - jacard_coef: 1.2573e-04 5/17 [=======>......................] - ETA: 2s - loss: 0.1211 - accuracy: 0.9088 - jacard_coef: 1.0058e-04 6/17 [=========>....................] - ETA: 1s - loss: 0.1203 - accuracy: 0.9142 - jacard_coef: 8.9209e-05 7/17 [===========>..................] - ETA: 1s - loss: 0.1199 - accuracy: 0.9170 - jacard_coef: 8.8792e-05 8/17 [=============>................] - ETA: 1s - loss: 0.1201 - accuracy: 0.9176 - jacard_coef: 1.5373e-04 9/17 [==============>...............] - ETA: 1s - loss: 0.1195 - accuracy: 0.9216 - jacard_coef: 1.3665e-0410/17 [================>.............] - ETA: 1s - loss: 0.1188 - accuracy: 0.9249 - jacard_coef: 1.2298e-0411/17 [==================>...........] - ETA: 1s - loss: 0.1193 - accuracy: 0.9213 - jacard_coef: 1.1180e-0412/17 [====================>.........] - ETA: 0s - loss: 0.1193 - accuracy: 0.9220 - jacard_coef: 1.8695e-0413/17 [=====================>........] - ETA: 0s - loss: 0.1194 - accuracy: 0.9210 - jacard_coef: 1.7257e-0414/17 [=======================>......] - ETA: 0s - loss: 0.1193 - accuracy: 0.9209 - jacard_coef: 1.6024e-0415/17 [=========================>....] - ETA: 0s - loss: 0.1192 - accuracy: 0.9216 - jacard_coef: 1.5696e-0416/17 [===========================>..] - ETA: 0s - loss: 0.1192 - accuracy: 0.9208 - jacard_coef: 1.4715e-04
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.

Epoch 24: val_jacard_coef did not improve from 0.08973
17/17 [==============================] - 3s 175ms/step - loss: 0.1192 - accuracy: 0.9200 - jacard_coef: 0.0208 - val_loss: 0.1161 - val_accuracy: 0.9084 - val_jacard_coef: 2.2203e-12 - lr: 5.0000e-04
Epoch 25/100
 1/17 [>.............................] - ETA: 2s - loss: 0.1182 - accuracy: 0.9177 - jacard_coef: 2.3169e-12 2/17 [==>...........................] - ETA: 2s - loss: 0.1177 - accuracy: 0.9228 - jacard_coef: 2.5096e-04 3/17 [====>.........................] - ETA: 2s - loss: 0.1181 - accuracy: 0.9235 - jacard_coef: 1.6731e-04 4/17 [======>.......................] - ETA: 2s - loss: 0.1185 - accuracy: 0.9214 - jacard_coef: 1.2548e-04 5/17 [=======>......................] - ETA: 2s - loss: 0.1205 - accuracy: 0.9087 - jacard_coef: 1.0039e-04 6/17 [=========>....................] - ETA: 1s - loss: 0.1197 - accuracy: 0.9141 - jacard_coef: 2.3417e-04 7/17 [===========>..................] - ETA: 1s - loss: 0.1192 - accuracy: 0.9168 - jacard_coef: 2.0072e-04 8/17 [=============>................] - ETA: 1s - loss: 0.1192 - accuracy: 0.9174 - jacard_coef: 3.6692e-04 9/17 [==============>...............] - ETA: 1s - loss: 0.1186 - accuracy: 0.9215 - jacard_coef: 3.2615e-0410/17 [================>.............] - ETA: 1s - loss: 0.1179 - accuracy: 0.9248 - jacard_coef: 2.9354e-0411/17 [==================>...........] - ETA: 1s - loss: 0.1184 - accuracy: 0.9211 - jacard_coef: 2.6685e-0412/17 [====================>.........] - ETA: 0s - loss: 0.1184 - accuracy: 0.9219 - jacard_coef: 3.5848e-0413/17 [=====================>........] - ETA: 0s - loss: 0.1185 - accuracy: 0.9209 - jacard_coef: 3.3090e-0414/17 [=======================>......] - ETA: 0s - loss: 0.1184 - accuracy: 0.9207 - jacard_coef: 3.0727e-0415/17 [=========================>....] - ETA: 0s - loss: 0.1182 - accuracy: 0.9214 - jacard_coef: 2.9232e-0416/17 [===========================>..] - ETA: 0s - loss: 0.1182 - accuracy: 0.9207 - jacard_coef: 2.7405e-04
Epoch 25: val_jacard_coef did not improve from 0.08973
17/17 [==============================] - 3s 175ms/step - loss: 0.1182 - accuracy: 0.9194 - jacard_coef: 0.0237 - val_loss: 0.1148 - val_accuracy: 0.9084 - val_jacard_coef: 2.2203e-12 - lr: 2.5000e-04
Epoch 25: early stopping
Restoring model weights from the end of the best epoch: 10.
WARNING:absl:`lr` is deprecated in TF-Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
Attention UNet execution time is:  0:02:06.678658
Model: "AttentionResUNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_4 (InputLayer)        [(None, 256, 256, 3)]        0         []                            
                                                                                                  
 conv2d_77 (Conv2D)          (None, 256, 256, 64)         1792      ['input_4[0][0]']             
                                                                                                  
 batch_normalization_65 (Ba  (None, 256, 256, 64)         256       ['conv2d_77[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_69 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_65[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_79 (Conv2D)          (None, 256, 256, 64)         256       ['input_4[0][0]']             
                                                                                                  
 conv2d_78 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_69[0][0]']       
                                                                                                  
 batch_normalization_67 (Ba  (None, 256, 256, 64)         256       ['conv2d_79[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 batch_normalization_66 (Ba  (None, 256, 256, 64)         256       ['conv2d_78[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 add_4 (Add)                 (None, 256, 256, 64)         0         ['batch_normalization_67[0][0]
                                                                    ',                            
                                                                     'batch_normalization_66[0][0]
                                                                    ']                            
                                                                                                  
 activation_70 (Activation)  (None, 256, 256, 64)         0         ['add_4[0][0]']               
                                                                                                  
 max_pooling2d_12 (MaxPooli  (None, 128, 128, 64)         0         ['activation_70[0][0]']       
 ng2D)                                                                                            
                                                                                                  
 conv2d_80 (Conv2D)          (None, 128, 128, 128)        73856     ['max_pooling2d_12[0][0]']    
                                                                                                  
 batch_normalization_68 (Ba  (None, 128, 128, 128)        512       ['conv2d_80[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_71 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_68[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_82 (Conv2D)          (None, 128, 128, 128)        8320      ['max_pooling2d_12[0][0]']    
                                                                                                  
 conv2d_81 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_71[0][0]']       
                                                                                                  
 batch_normalization_70 (Ba  (None, 128, 128, 128)        512       ['conv2d_82[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 batch_normalization_69 (Ba  (None, 128, 128, 128)        512       ['conv2d_81[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 add_5 (Add)                 (None, 128, 128, 128)        0         ['batch_normalization_70[0][0]
                                                                    ',                            
                                                                     'batch_normalization_69[0][0]
                                                                    ']                            
                                                                                                  
 activation_72 (Activation)  (None, 128, 128, 128)        0         ['add_5[0][0]']               
                                                                                                  
 max_pooling2d_13 (MaxPooli  (None, 64, 64, 128)          0         ['activation_72[0][0]']       
 ng2D)                                                                                            
                                                                                                  
 conv2d_83 (Conv2D)          (None, 64, 64, 256)          295168    ['max_pooling2d_13[0][0]']    
                                                                                                  
 batch_normalization_71 (Ba  (None, 64, 64, 256)          1024      ['conv2d_83[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_73 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_71[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_85 (Conv2D)          (None, 64, 64, 256)          33024     ['max_pooling2d_13[0][0]']    
                                                                                                  
 conv2d_84 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_73[0][0]']       
                                                                                                  
 batch_normalization_73 (Ba  (None, 64, 64, 256)          1024      ['conv2d_85[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 batch_normalization_72 (Ba  (None, 64, 64, 256)          1024      ['conv2d_84[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 add_6 (Add)                 (None, 64, 64, 256)          0         ['batch_normalization_73[0][0]
                                                                    ',                            
                                                                     'batch_normalization_72[0][0]
                                                                    ']                            
                                                                                                  
 activation_74 (Activation)  (None, 64, 64, 256)          0         ['add_6[0][0]']               
                                                                                                  
 max_pooling2d_14 (MaxPooli  (None, 32, 32, 256)          0         ['activation_74[0][0]']       
 ng2D)                                                                                            
                                                                                                  
 conv2d_86 (Conv2D)          (None, 32, 32, 512)          1180160   ['max_pooling2d_14[0][0]']    
                                                                                                  
 batch_normalization_74 (Ba  (None, 32, 32, 512)          2048      ['conv2d_86[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_75 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_74[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_88 (Conv2D)          (None, 32, 32, 512)          131584    ['max_pooling2d_14[0][0]']    
                                                                                                  
 conv2d_87 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_75[0][0]']       
                                                                                                  
 batch_normalization_76 (Ba  (None, 32, 32, 512)          2048      ['conv2d_88[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 batch_normalization_75 (Ba  (None, 32, 32, 512)          2048      ['conv2d_87[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 add_7 (Add)                 (None, 32, 32, 512)          0         ['batch_normalization_76[0][0]
                                                                    ',                            
                                                                     'batch_normalization_75[0][0]
                                                                    ']                            
                                                                                                  
 activation_76 (Activation)  (None, 32, 32, 512)          0         ['add_7[0][0]']               
                                                                                                  
 max_pooling2d_15 (MaxPooli  (None, 16, 16, 512)          0         ['activation_76[0][0]']       
 ng2D)                                                                                            
                                                                                                  
 conv2d_89 (Conv2D)          (None, 16, 16, 1024)         4719616   ['max_pooling2d_15[0][0]']    
                                                                                                  
 batch_normalization_77 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_89[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_77 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_77[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_91 (Conv2D)          (None, 16, 16, 1024)         525312    ['max_pooling2d_15[0][0]']    
                                                                                                  
 conv2d_90 (Conv2D)          (None, 16, 16, 1024)         9438208   ['activation_77[0][0]']       
                                                                                                  
 batch_normalization_79 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_91[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 batch_normalization_78 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_90[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 add_8 (Add)                 (None, 16, 16, 1024)         0         ['batch_normalization_79[0][0]
                                                                    ',                            
                                                                     'batch_normalization_78[0][0]
                                                                    ']                            
                                                                                                  
 activation_78 (Activation)  (None, 16, 16, 1024)         0         ['add_8[0][0]']               
                                                                                                  
 conv2d_92 (Conv2D)          (None, 16, 16, 512)          524800    ['activation_78[0][0]']       
                                                                                                  
 batch_normalization_80 (Ba  (None, 16, 16, 512)          2048      ['conv2d_92[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_79 (Activation)  (None, 16, 16, 512)          0         ['batch_normalization_80[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_94 (Conv2D)          (None, 16, 16, 512)          262656    ['activation_79[0][0]']       
                                                                                                  
 conv2d_transpose_4 (Conv2D  (None, 16, 16, 512)          2359808   ['conv2d_94[0][0]']           
 Transpose)                                                                                       
                                                                                                  
 conv2d_93 (Conv2D)          (None, 16, 16, 512)          1049088   ['activation_76[0][0]']       
                                                                                                  
 add_9 (Add)                 (None, 16, 16, 512)          0         ['conv2d_transpose_4[0][0]',  
                                                                     'conv2d_93[0][0]']           
                                                                                                  
 activation_80 (Activation)  (None, 16, 16, 512)          0         ['add_9[0][0]']               
                                                                                                  
 conv2d_95 (Conv2D)          (None, 16, 16, 1)            513       ['activation_80[0][0]']       
                                                                                                  
 activation_81 (Activation)  (None, 16, 16, 1)            0         ['conv2d_95[0][0]']           
                                                                                                  
 up_sampling2d_16 (UpSampli  (None, 32, 32, 1)            0         ['activation_81[0][0]']       
 ng2D)                                                                                            
                                                                                                  
 lambda_4 (Lambda)           (None, 32, 32, 512)          0         ['up_sampling2d_16[0][0]']    
                                                                                                  
 multiply_4 (Multiply)       (None, 32, 32, 512)          0         ['lambda_4[0][0]',            
                                                                     'activation_76[0][0]']       
                                                                                                  
 conv2d_96 (Conv2D)          (None, 32, 32, 512)          262656    ['multiply_4[0][0]']          
                                                                                                  
 up_sampling2d_17 (UpSampli  (None, 32, 32, 1024)         0         ['activation_78[0][0]']       
 ng2D)                                                                                            
                                                                                                  
 batch_normalization_81 (Ba  (None, 32, 32, 512)          2048      ['conv2d_96[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 concatenate_12 (Concatenat  (None, 32, 32, 1536)         0         ['up_sampling2d_17[0][0]',    
 e)                                                                  'batch_normalization_81[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_97 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate_12[0][0]']      
                                                                                                  
 batch_normalization_82 (Ba  (None, 32, 32, 512)          2048      ['conv2d_97[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_82 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_82[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_99 (Conv2D)          (None, 32, 32, 512)          786944    ['concatenate_12[0][0]']      
                                                                                                  
 conv2d_98 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_82[0][0]']       
                                                                                                  
 batch_normalization_84 (Ba  (None, 32, 32, 512)          2048      ['conv2d_99[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 batch_normalization_83 (Ba  (None, 32, 32, 512)          2048      ['conv2d_98[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 add_10 (Add)                (None, 32, 32, 512)          0         ['batch_normalization_84[0][0]
                                                                    ',                            
                                                                     'batch_normalization_83[0][0]
                                                                    ']                            
                                                                                                  
 activation_83 (Activation)  (None, 32, 32, 512)          0         ['add_10[0][0]']              
                                                                                                  
 conv2d_100 (Conv2D)         (None, 32, 32, 256)          131328    ['activation_83[0][0]']       
                                                                                                  
 batch_normalization_85 (Ba  (None, 32, 32, 256)          1024      ['conv2d_100[0][0]']          
 tchNormalization)                                                                                
                                                                                                  
 activation_84 (Activation)  (None, 32, 32, 256)          0         ['batch_normalization_85[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_102 (Conv2D)         (None, 32, 32, 256)          65792     ['activation_84[0][0]']       
                                                                                                  
 conv2d_transpose_5 (Conv2D  (None, 32, 32, 256)          590080    ['conv2d_102[0][0]']          
 Transpose)                                                                                       
                                                                                                  
 conv2d_101 (Conv2D)         (None, 32, 32, 256)          262400    ['activation_74[0][0]']       
                                                                                                  
 add_11 (Add)                (None, 32, 32, 256)          0         ['conv2d_transpose_5[0][0]',  
                                                                     'conv2d_101[0][0]']          
                                                                                                  
 activation_85 (Activation)  (None, 32, 32, 256)          0         ['add_11[0][0]']              
                                                                                                  
 conv2d_103 (Conv2D)         (None, 32, 32, 1)            257       ['activation_85[0][0]']       
                                                                                                  
 activation_86 (Activation)  (None, 32, 32, 1)            0         ['conv2d_103[0][0]']          
                                                                                                  
 up_sampling2d_18 (UpSampli  (None, 64, 64, 1)            0         ['activation_86[0][0]']       
 ng2D)                                                                                            
                                                                                                  
 lambda_5 (Lambda)           (None, 64, 64, 256)          0         ['up_sampling2d_18[0][0]']    
                                                                                                  
 multiply_5 (Multiply)       (None, 64, 64, 256)          0         ['lambda_5[0][0]',            
                                                                     'activation_74[0][0]']       
                                                                                                  
 conv2d_104 (Conv2D)         (None, 64, 64, 256)          65792     ['multiply_5[0][0]']          
                                                                                                  
 up_sampling2d_19 (UpSampli  (None, 64, 64, 512)          0         ['activation_83[0][0]']       
 ng2D)                                                                                            
                                                                                                  
 batch_normalization_86 (Ba  (None, 64, 64, 256)          1024      ['conv2d_104[0][0]']          
 tchNormalization)                                                                                
                                                                                                  
 concatenate_13 (Concatenat  (None, 64, 64, 768)          0         ['up_sampling2d_19[0][0]',    
 e)                                                                  'batch_normalization_86[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_105 (Conv2D)         (None, 64, 64, 256)          1769728   ['concatenate_13[0][0]']      
                                                                                                  
 batch_normalization_87 (Ba  (None, 64, 64, 256)          1024      ['conv2d_105[0][0]']          
 tchNormalization)                                                                                
                                                                                                  
 activation_87 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_87[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_107 (Conv2D)         (None, 64, 64, 256)          196864    ['concatenate_13[0][0]']      
                                                                                                  
 conv2d_106 (Conv2D)         (None, 64, 64, 256)          590080    ['activation_87[0][0]']       
                                                                                                  
 batch_normalization_89 (Ba  (None, 64, 64, 256)          1024      ['conv2d_107[0][0]']          
 tchNormalization)                                                                                
                                                                                                  
 batch_normalization_88 (Ba  (None, 64, 64, 256)          1024      ['conv2d_106[0][0]']          
 tchNormalization)                                                                                
                                                                                                  
 add_12 (Add)                (None, 64, 64, 256)          0         ['batch_normalization_89[0][0]
                                                                    ',                            
                                                                     'batch_normalization_88[0][0]
                                                                    ']                            
                                                                                                  
 activation_88 (Activation)  (None, 64, 64, 256)          0         ['add_12[0][0]']              
                                                                                                  
 conv2d_108 (Conv2D)         (None, 64, 64, 128)          32896     ['activation_88[0][0]']       
                                                                                                  
 batch_normalization_90 (Ba  (None, 64, 64, 128)          512       ['conv2d_108[0][0]']          
 tchNormalization)                                                                                
                                                                                                  
 activation_89 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_90[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_110 (Conv2D)         (None, 64, 64, 128)          16512     ['activation_89[0][0]']       
                                                                                                  
 conv2d_transpose_6 (Conv2D  (None, 64, 64, 128)          147584    ['conv2d_110[0][0]']          
 Transpose)                                                                                       
                                                                                                  
 conv2d_109 (Conv2D)         (None, 64, 64, 128)          65664     ['activation_72[0][0]']       
                                                                                                  
 add_13 (Add)                (None, 64, 64, 128)          0         ['conv2d_transpose_6[0][0]',  
                                                                     'conv2d_109[0][0]']          
                                                                                                  
 activation_90 (Activation)  (None, 64, 64, 128)          0         ['add_13[0][0]']              
                                                                                                  
 conv2d_111 (Conv2D)         (None, 64, 64, 1)            129       ['activation_90[0][0]']       
                                                                                                  
 activation_91 (Activation)  (None, 64, 64, 1)            0         ['conv2d_111[0][0]']          
                                                                                                  
 up_sampling2d_20 (UpSampli  (None, 128, 128, 1)          0         ['activation_91[0][0]']       
 ng2D)                                                                                            
                                                                                                  
 lambda_6 (Lambda)           (None, 128, 128, 128)        0         ['up_sampling2d_20[0][0]']    
                                                                                                  
 multiply_6 (Multiply)       (None, 128, 128, 128)        0         ['lambda_6[0][0]',            
                                                                     'activation_72[0][0]']       
                                                                                                  
 conv2d_112 (Conv2D)         (None, 128, 128, 128)        16512     ['multiply_6[0][0]']          
                                                                                                  
 up_sampling2d_21 (UpSampli  (None, 128, 128, 256)        0         ['activation_88[0][0]']       
 ng2D)                                                                                            
                                                                                                  
 batch_normalization_91 (Ba  (None, 128, 128, 128)        512       ['conv2d_112[0][0]']          
 tchNormalization)                                                                                
                                                                                                  
 concatenate_14 (Concatenat  (None, 128, 128, 384)        0         ['up_sampling2d_21[0][0]',    
 e)                                                                  'batch_normalization_91[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_113 (Conv2D)         (None, 128, 128, 128)        442496    ['concatenate_14[0][0]']      
                                                                                                  
 batch_normalization_92 (Ba  (None, 128, 128, 128)        512       ['conv2d_113[0][0]']          
 tchNormalization)                                                                                
                                                                                                  
 activation_92 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_92[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_115 (Conv2D)         (None, 128, 128, 128)        49280     ['concatenate_14[0][0]']      
                                                                                                  
 conv2d_114 (Conv2D)         (None, 128, 128, 128)        147584    ['activation_92[0][0]']       
                                                                                                  
 batch_normalization_94 (Ba  (None, 128, 128, 128)        512       ['conv2d_115[0][0]']          
 tchNormalization)                                                                                
                                                                                                  
 batch_normalization_93 (Ba  (None, 128, 128, 128)        512       ['conv2d_114[0][0]']          
 tchNormalization)                                                                                
                                                                                                  
 add_14 (Add)                (None, 128, 128, 128)        0         ['batch_normalization_94[0][0]
                                                                    ',                            
                                                                     'batch_normalization_93[0][0]
                                                                    ']                            
                                                                                                  
 activation_93 (Activation)  (None, 128, 128, 128)        0         ['add_14[0][0]']              
                                                                                                  
 conv2d_116 (Conv2D)         (None, 128, 128, 64)         8256      ['activation_93[0][0]']       
                                                                                                  
 batch_normalization_95 (Ba  (None, 128, 128, 64)         256       ['conv2d_116[0][0]']          
 tchNormalization)                                                                                
                                                                                                  
 activation_94 (Activation)  (None, 128, 128, 64)         0         ['batch_normalization_95[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_118 (Conv2D)         (None, 128, 128, 64)         4160      ['activation_94[0][0]']       
                                                                                                  
 conv2d_transpose_7 (Conv2D  (None, 128, 128, 64)         36928     ['conv2d_118[0][0]']          
 Transpose)                                                                                       
                                                                                                  
 conv2d_117 (Conv2D)         (None, 128, 128, 64)         16448     ['activation_70[0][0]']       
                                                                                                  
 add_15 (Add)                (None, 128, 128, 64)         0         ['conv2d_transpose_7[0][0]',  
                                                                     'conv2d_117[0][0]']          
                                                                                                  
 activation_95 (Activation)  (None, 128, 128, 64)         0         ['add_15[0][0]']              
                                                                                                  
 conv2d_119 (Conv2D)         (None, 128, 128, 1)          65        ['activation_95[0][0]']       
                                                                                                  
 activation_96 (Activation)  (None, 128, 128, 1)          0         ['conv2d_119[0][0]']          
                                                                                                  
 up_sampling2d_22 (UpSampli  (None, 256, 256, 1)          0         ['activation_96[0][0]']       
 ng2D)                                                                                            
                                                                                                  
 lambda_7 (Lambda)           (None, 256, 256, 64)         0         ['up_sampling2d_22[0][0]']    
                                                                                                  
 multiply_7 (Multiply)       (None, 256, 256, 64)         0         ['lambda_7[0][0]',            
                                                                     'activation_70[0][0]']       
                                                                                                  
 conv2d_120 (Conv2D)         (None, 256, 256, 64)         4160      ['multiply_7[0][0]']          
                                                                                                  
 up_sampling2d_23 (UpSampli  (None, 256, 256, 128)        0         ['activation_93[0][0]']       
 ng2D)                                                                                            
                                                                                                  
 batch_normalization_96 (Ba  (None, 256, 256, 64)         256       ['conv2d_120[0][0]']          
 tchNormalization)                                                                                
                                                                                                  
 concatenate_15 (Concatenat  (None, 256, 256, 192)        0         ['up_sampling2d_23[0][0]',    
 e)                                                                  'batch_normalization_96[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_121 (Conv2D)         (None, 256, 256, 64)         110656    ['concatenate_15[0][0]']      
                                                                                                  
 batch_normalization_97 (Ba  (None, 256, 256, 64)         256       ['conv2d_121[0][0]']          
 tchNormalization)                                                                                
                                                                                                  
 activation_97 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_97[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_123 (Conv2D)         (None, 256, 256, 64)         12352     ['concatenate_15[0][0]']      
                                                                                                  
 conv2d_122 (Conv2D)         (None, 256, 256, 64)         36928     ['activation_97[0][0]']       
                                                                                                  
 batch_normalization_99 (Ba  (None, 256, 256, 64)         256       ['conv2d_123[0][0]']          
 tchNormalization)                                                                                
                                                                                                  
 batch_normalization_98 (Ba  (None, 256, 256, 64)         256       ['conv2d_122[0][0]']          
 tchNormalization)                                                                                
                                                                                                  
 add_16 (Add)                (None, 256, 256, 64)         0         ['batch_normalization_99[0][0]
                                                                    ',                            
                                                                     'batch_normalization_98[0][0]
                                                                    ']                            
                                                                                                  
 activation_98 (Activation)  (None, 256, 256, 64)         0         ['add_16[0][0]']              
                                                                                                  
 conv2d_124 (Conv2D)         (None, 256, 256, 1)          65        ['activation_98[0][0]']       
                                                                                                  
 batch_normalization_100 (B  (None, 256, 256, 1)          4         ['conv2d_124[0][0]']          
 atchNormalization)                                                                               
                                                                                                  
 activation_99 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_100[0][0
                                                                    ]']                           
                                                                                                  
==================================================================================================
Total params: 39090377 (149.12 MB)
Trainable params: 39068871 (149.04 MB)
Non-trainable params: 21506 (84.01 KB)
__________________________________________________________________________________________________
None
Epoch 1/100
 1/17 [>.............................] - ETA: 6:49 - loss: 0.3459 - accuracy: 0.5301 - jacard_coef: 0.0733 2/17 [==>...........................] - ETA: 3s - loss: 0.3174 - accuracy: 0.5007 - jacard_coef: 0.0839   3/17 [====>.........................] - ETA: 2s - loss: 0.2969 - accuracy: 0.4663 - jacard_coef: 0.0812 4/17 [======>.......................] - ETA: 2s - loss: 0.2820 - accuracy: 0.4494 - jacard_coef: 0.0834 5/17 [=======>......................] - ETA: 2s - loss: 0.2689 - accuracy: 0.4487 - jacard_coef: 0.0917 6/17 [=========>....................] - ETA: 2s - loss: 0.2571 - accuracy: 0.4276 - jacard_coef: 0.0857 7/17 [===========>..................] - ETA: 2s - loss: 0.2489 - accuracy: 0.3973 - jacard_coef: 0.0819 8/17 [=============>................] - ETA: 1s - loss: 0.2418 - accuracy: 0.3799 - jacard_coef: 0.0814 9/17 [==============>...............] - ETA: 1s - loss: 0.2358 - accuracy: 0.3770 - jacard_coef: 0.078010/17 [================>.............] - ETA: 1s - loss: 0.2310 - accuracy: 0.3797 - jacard_coef: 0.074211/17 [==================>...........] - ETA: 1s - loss: 0.2266 - accuracy: 0.3789 - jacard_coef: 0.078312/17 [====================>.........] - ETA: 1s - loss: 0.2226 - accuracy: 0.3786 - jacard_coef: 0.077313/17 [=====================>........] - ETA: 0s - loss: 0.2233 - accuracy: 0.3762 - jacard_coef: 0.077614/17 [=======================>......] - ETA: 0s - loss: 0.2208 - accuracy: 0.3782 - jacard_coef: 0.077715/17 [=========================>....] - ETA: 0s - loss: 0.2184 - accuracy: 0.3795 - jacard_coef: 0.077116/17 [===========================>..] - ETA: 0s - loss: 0.2164 - accuracy: 0.3774 - jacard_coef: 0.078117/17 [==============================] - ETA: 0s - loss: 0.2164 - accuracy: 0.3774 - jacard_coef: 0.0836
Epoch 1: val_jacard_coef improved from -inf to 0.09199, saving model to best_attention_resunet_model.h5
17/17 [==============================] - 37s 709ms/step - loss: 0.2164 - accuracy: 0.3774 - jacard_coef: 0.0836 - val_loss: 14.3022 - val_accuracy: 0.1063 - val_jacard_coef: 0.0920 - lr: 0.0010
Epoch 2/100
 1/17 [>.............................] - ETA: 3s - loss: 0.1879 - accuracy: 0.3851 - jacard_coef: 0.0655 2/17 [==>...........................] - ETA: 3s - loss: 0.1889 - accuracy: 0.3704 - jacard_coef: 0.0709 3/17 [====>.........................] - ETA: 2s - loss: 0.1891 - accuracy: 0.3761 - jacard_coef: 0.0699 4/17 [======>.......................] - ETA: 2s - loss: 0.1902 - accuracy: 0.3911 - jacard_coef: 0.0759 5/17 [=======>......................] - ETA: 2s - loss: 0.1899 - accuracy: 0.3956 - jacard_coef: 0.0847 6/17 [=========>....................] - ETA: 2s - loss: 0.1902 - accuracy: 0.3818 - jacard_coef: 0.0805 7/17 [===========>..................] - ETA: 2s - loss: 0.1907 - accuracy: 0.3629 - jacard_coef: 0.0785 8/17 [=============>................] - ETA: 1s - loss: 0.1906 - accuracy: 0.3530 - jacard_coef: 0.0785 9/17 [==============>...............] - ETA: 1s - loss: 0.1900 - accuracy: 0.3474 - jacard_coef: 0.075410/17 [================>.............] - ETA: 1s - loss: 0.1897 - accuracy: 0.3430 - jacard_coef: 0.072511/17 [==================>...........] - ETA: 1s - loss: 0.1889 - accuracy: 0.3459 - jacard_coef: 0.076712/17 [====================>.........] - ETA: 1s - loss: 0.1884 - accuracy: 0.3487 - jacard_coef: 0.076313/17 [=====================>........] - ETA: 0s - loss: 0.1879 - accuracy: 0.3536 - jacard_coef: 0.077514/17 [=======================>......] - ETA: 0s - loss: 0.1873 - accuracy: 0.3595 - jacard_coef: 0.077915/17 [=========================>....] - ETA: 0s - loss: 0.1866 - accuracy: 0.3660 - jacard_coef: 0.076516/17 [===========================>..] - ETA: 0s - loss: 0.1858 - accuracy: 0.3733 - jacard_coef: 0.0778
Epoch 2: val_jacard_coef improved from 0.09199 to 0.09263, saving model to best_attention_resunet_model.h5
17/17 [==============================] - 8s 488ms/step - loss: 0.1858 - accuracy: 0.3740 - jacard_coef: 0.0840 - val_loss: 0.7005 - val_accuracy: 0.2276 - val_jacard_coef: 0.0926 - lr: 0.0010
Epoch 3/100
 1/17 [>.............................] - ETA: 3s - loss: 0.1732 - accuracy: 0.4903 - jacard_coef: 0.0711 2/17 [==>...........................] - ETA: 3s - loss: 0.1726 - accuracy: 0.4924 - jacard_coef: 0.0740 3/17 [====>.........................] - ETA: 2s - loss: 0.1729 - accuracy: 0.4895 - jacard_coef: 0.0727 4/17 [======>.......................] - ETA: 2s - loss: 0.1734 - accuracy: 0.5024 - jacard_coef: 0.0751 5/17 [=======>......................] - ETA: 2s - loss: 0.1732 - accuracy: 0.5188 - jacard_coef: 0.0866 6/17 [=========>....................] - ETA: 2s - loss: 0.1726 - accuracy: 0.5405 - jacard_coef: 0.0828 7/17 [===========>..................] - ETA: 2s - loss: 0.1719 - accuracy: 0.5615 - jacard_coef: 0.0794 8/17 [=============>................] - ETA: 1s - loss: 0.1713 - accuracy: 0.5881 - jacard_coef: 0.0757 9/17 [==============>...............] - ETA: 1s - loss: 0.1729 - accuracy: 0.5812 - jacard_coef: 0.072110/17 [================>.............] - ETA: 1s - loss: 0.1726 - accuracy: 0.5873 - jacard_coef: 0.070911/17 [==================>...........] - ETA: 1s - loss: 0.1726 - accuracy: 0.5792 - jacard_coef: 0.075512/17 [====================>.........] - ETA: 1s - loss: 0.1728 - accuracy: 0.5662 - jacard_coef: 0.075713/17 [=====================>........] - ETA: 0s - loss: 0.1732 - accuracy: 0.5539 - jacard_coef: 0.077114/17 [=======================>......] - ETA: 0s - loss: 0.1735 - accuracy: 0.5421 - jacard_coef: 0.077215/17 [=========================>....] - ETA: 0s - loss: 0.1737 - accuracy: 0.5320 - jacard_coef: 0.076216/17 [===========================>..] - ETA: 0s - loss: 0.1738 - accuracy: 0.5293 - jacard_coef: 0.0783
Epoch 3: val_jacard_coef did not improve from 0.09263
17/17 [==============================] - 3s 200ms/step - loss: 0.1738 - accuracy: 0.5297 - jacard_coef: 0.0863 - val_loss: 0.8839 - val_accuracy: 0.9079 - val_jacard_coef: 2.2092e-12 - lr: 0.0010
Epoch 4/100
 1/17 [>.............................] - ETA: 3s - loss: 0.1745 - accuracy: 0.5393 - jacard_coef: 0.0633 2/17 [==>...........................] - ETA: 3s - loss: 0.1749 - accuracy: 0.5269 - jacard_coef: 0.0524 3/17 [====>.........................] - ETA: 2s - loss: 0.1754 - accuracy: 0.5186 - jacard_coef: 0.0603 4/17 [======>.......................] - ETA: 2s - loss: 0.1763 - accuracy: 0.5054 - jacard_coef: 0.0650 5/17 [=======>......................] - ETA: 2s - loss: 0.1760 - accuracy: 0.5042 - jacard_coef: 0.0775 6/17 [=========>....................] - ETA: 2s - loss: 0.1762 - accuracy: 0.5081 - jacard_coef: 0.0740 7/17 [===========>..................] - ETA: 2s - loss: 0.1764 - accuracy: 0.5149 - jacard_coef: 0.0720 8/17 [=============>................] - ETA: 1s - loss: 0.1762 - accuracy: 0.5256 - jacard_coef: 0.0727 9/17 [==============>...............] - ETA: 1s - loss: 0.1763 - accuracy: 0.5370 - jacard_coef: 0.071110/17 [================>.............] - ETA: 1s - loss: 0.1763 - accuracy: 0.5469 - jacard_coef: 0.067211/17 [==================>...........] - ETA: 1s - loss: 0.1757 - accuracy: 0.5569 - jacard_coef: 0.073112/17 [====================>.........] - ETA: 1s - loss: 0.1754 - accuracy: 0.5659 - jacard_coef: 0.073313/17 [=====================>........] - ETA: 0s - loss: 0.1750 - accuracy: 0.5760 - jacard_coef: 0.076014/17 [=======================>......] - ETA: 0s - loss: 0.1747 - accuracy: 0.5850 - jacard_coef: 0.076015/17 [=========================>....] - ETA: 0s - loss: 0.1742 - accuracy: 0.5944 - jacard_coef: 0.073416/17 [===========================>..] - ETA: 0s - loss: 0.1737 - accuracy: 0.6061 - jacard_coef: 0.0739
Epoch 4: val_jacard_coef did not improve from 0.09263
17/17 [==============================] - 3s 200ms/step - loss: 0.1736 - accuracy: 0.6073 - jacard_coef: 0.0735 - val_loss: 0.2045 - val_accuracy: 0.8814 - val_jacard_coef: 0.0121 - lr: 0.0010
Epoch 5/100
 1/17 [>.............................] - ETA: 3s - loss: 0.1620 - accuracy: 0.8743 - jacard_coef: 0.0398 2/17 [==>...........................] - ETA: 3s - loss: 0.1614 - accuracy: 0.8795 - jacard_coef: 0.0321 3/17 [====>.........................] - ETA: 2s - loss: 0.1610 - accuracy: 0.8742 - jacard_coef: 0.0438 4/17 [======>.......................] - ETA: 2s - loss: 0.1610 - accuracy: 0.8541 - jacard_coef: 0.0486 5/17 [=======>......................] - ETA: 2s - loss: 0.1609 - accuracy: 0.8411 - jacard_coef: 0.0591 6/17 [=========>....................] - ETA: 2s - loss: 0.1605 - accuracy: 0.8433 - jacard_coef: 0.0558 7/17 [===========>..................] - ETA: 2s - loss: 0.1602 - accuracy: 0.8463 - jacard_coef: 0.0523 8/17 [=============>................] - ETA: 1s - loss: 0.1599 - accuracy: 0.8483 - jacard_coef: 0.0510 9/17 [==============>...............] - ETA: 1s - loss: 0.1594 - accuracy: 0.8538 - jacard_coef: 0.056910/17 [================>.............] - ETA: 1s - loss: 0.1591 - accuracy: 0.8554 - jacard_coef: 0.053411/17 [==================>...........] - ETA: 1s - loss: 0.1598 - accuracy: 0.8320 - jacard_coef: 0.060312/17 [====================>.........] - ETA: 1s - loss: 0.1597 - accuracy: 0.8376 - jacard_coef: 0.057513/17 [=====================>........] - ETA: 0s - loss: 0.1597 - accuracy: 0.8407 - jacard_coef: 0.056314/17 [=======================>......] - ETA: 0s - loss: 0.1598 - accuracy: 0.8436 - jacard_coef: 0.053615/17 [=========================>....] - ETA: 0s - loss: 0.1599 - accuracy: 0.8468 - jacard_coef: 0.051016/17 [===========================>..] - ETA: 0s - loss: 0.1600 - accuracy: 0.8485 - jacard_coef: 0.0494
Epoch 5: val_jacard_coef did not improve from 0.09263
17/17 [==============================] - 3s 200ms/step - loss: 0.1600 - accuracy: 0.8479 - jacard_coef: 0.0470 - val_loss: 0.1556 - val_accuracy: 0.8929 - val_jacard_coef: 0.0241 - lr: 0.0010
Epoch 6/100
 1/17 [>.............................] - ETA: 3s - loss: 0.1615 - accuracy: 0.8949 - jacard_coef: 0.0036 2/17 [==>...........................] - ETA: 3s - loss: 0.1616 - accuracy: 0.9067 - jacard_coef: 0.0027 3/17 [====>.........................] - ETA: 2s - loss: 0.1617 - accuracy: 0.9112 - jacard_coef: 0.0050 4/17 [======>.......................] - ETA: 2s - loss: 0.1624 - accuracy: 0.9090 - jacard_coef: 0.0163 5/17 [=======>......................] - ETA: 2s - loss: 0.1626 - accuracy: 0.8941 - jacard_coef: 0.0178 6/17 [=========>....................] - ETA: 2s - loss: 0.1625 - accuracy: 0.8966 - jacard_coef: 0.0194 7/17 [===========>..................] - ETA: 2s - loss: 0.1627 - accuracy: 0.8979 - jacard_coef: 0.0219 8/17 [=============>................] - ETA: 1s - loss: 0.1625 - accuracy: 0.8959 - jacard_coef: 0.0231 9/17 [==============>...............] - ETA: 1s - loss: 0.1622 - accuracy: 0.8987 - jacard_coef: 0.030210/17 [================>.............] - ETA: 1s - loss: 0.1619 - accuracy: 0.8995 - jacard_coef: 0.027411/17 [==================>...........] - ETA: 1s - loss: 0.1617 - accuracy: 0.8968 - jacard_coef: 0.034912/17 [====================>.........] - ETA: 1s - loss: 0.1613 - accuracy: 0.8963 - jacard_coef: 0.035513/17 [=====================>........] - ETA: 0s - loss: 0.1611 - accuracy: 0.8947 - jacard_coef: 0.038614/17 [=======================>......] - ETA: 0s - loss: 0.1608 - accuracy: 0.8933 - jacard_coef: 0.040115/17 [=========================>....] - ETA: 0s - loss: 0.1605 - accuracy: 0.8921 - jacard_coef: 0.039216/17 [===========================>..] - ETA: 0s - loss: 0.1602 - accuracy: 0.8895 - jacard_coef: 0.0395
Epoch 6: val_jacard_coef did not improve from 0.09263
17/17 [==============================] - 3s 200ms/step - loss: 0.1602 - accuracy: 0.8887 - jacard_coef: 0.0393 - val_loss: 0.1648 - val_accuracy: 0.8943 - val_jacard_coef: 0.0262 - lr: 0.0010
Epoch 7/100
 1/17 [>.............................] - ETA: 3s - loss: 0.1544 - accuracy: 0.8829 - jacard_coef: 0.0855 2/17 [==>...........................] - ETA: 3s - loss: 0.1540 - accuracy: 0.8927 - jacard_coef: 0.0926 3/17 [====>.........................] - ETA: 2s - loss: 0.1539 - accuracy: 0.8981 - jacard_coef: 0.0805 4/17 [======>.......................] - ETA: 2s - loss: 0.1539 - accuracy: 0.8980 - jacard_coef: 0.0826 5/17 [=======>......................] - ETA: 2s - loss: 0.1544 - accuracy: 0.8833 - jacard_coef: 0.0759 6/17 [=========>....................] - ETA: 2s - loss: 0.1541 - accuracy: 0.8863 - jacard_coef: 0.0695 7/17 [===========>..................] - ETA: 2s - loss: 0.1538 - accuracy: 0.8883 - jacard_coef: 0.0648 8/17 [=============>................] - ETA: 1s - loss: 0.1537 - accuracy: 0.8871 - jacard_coef: 0.0611 9/17 [==============>...............] - ETA: 1s - loss: 0.1534 - accuracy: 0.8906 - jacard_coef: 0.065110/17 [================>.............] - ETA: 1s - loss: 0.1531 - accuracy: 0.8924 - jacard_coef: 0.058611/17 [==================>...........] - ETA: 1s - loss: 0.1531 - accuracy: 0.8906 - jacard_coef: 0.063712/17 [====================>.........] - ETA: 1s - loss: 0.1529 - accuracy: 0.8916 - jacard_coef: 0.061813/17 [=====================>........] - ETA: 0s - loss: 0.1528 - accuracy: 0.8913 - jacard_coef: 0.062214/17 [=======================>......] - ETA: 0s - loss: 0.1527 - accuracy: 0.8918 - jacard_coef: 0.061415/17 [=========================>....] - ETA: 0s - loss: 0.1526 - accuracy: 0.8928 - jacard_coef: 0.058016/17 [===========================>..] - ETA: 0s - loss: 0.1524 - accuracy: 0.8926 - jacard_coef: 0.0557
Epoch 7: val_jacard_coef did not improve from 0.09263
17/17 [==============================] - 3s 200ms/step - loss: 0.1524 - accuracy: 0.8920 - jacard_coef: 0.0544 - val_loss: 0.1619 - val_accuracy: 0.9084 - val_jacard_coef: 2.2203e-12 - lr: 0.0010
Epoch 8/100
 1/17 [>.............................] - ETA: 3s - loss: 0.1495 - accuracy: 0.9103 - jacard_coef: 0.0867 2/17 [==>...........................] - ETA: 3s - loss: 0.1489 - accuracy: 0.9126 - jacard_coef: 0.0997 3/17 [====>.........................] - ETA: 2s - loss: 0.1487 - accuracy: 0.9114 - jacard_coef: 0.0896 4/17 [======>.......................] - ETA: 2s - loss: 0.1489 - accuracy: 0.9063 - jacard_coef: 0.0893 5/17 [=======>......................] - ETA: 2s - loss: 0.1495 - accuracy: 0.8876 - jacard_coef: 0.0831 6/17 [=========>....................] - ETA: 2s - loss: 0.1492 - accuracy: 0.8870 - jacard_coef: 0.0775 7/17 [===========>..................] - ETA: 2s - loss: 0.1491 - accuracy: 0.8849 - jacard_coef: 0.0712 8/17 [=============>................] - ETA: 1s - loss: 0.1490 - accuracy: 0.8818 - jacard_coef: 0.0681 9/17 [==============>...............] - ETA: 1s - loss: 0.1486 - accuracy: 0.8835 - jacard_coef: 0.071310/17 [================>.............] - ETA: 1s - loss: 0.1484 - accuracy: 0.8840 - jacard_coef: 0.064311/17 [==================>...........] - ETA: 1s - loss: 0.1484 - accuracy: 0.8841 - jacard_coef: 0.058512/17 [====================>.........] - ETA: 1s - loss: 0.1483 - accuracy: 0.8879 - jacard_coef: 0.053713/17 [=====================>........] - ETA: 0s - loss: 0.1482 - accuracy: 0.8895 - jacard_coef: 0.049714/17 [=======================>......] - ETA: 0s - loss: 0.1481 - accuracy: 0.8915 - jacard_coef: 0.046215/17 [=========================>....] - ETA: 0s - loss: 0.1480 - accuracy: 0.8939 - jacard_coef: 0.043516/17 [===========================>..] - ETA: 0s - loss: 0.1479 - accuracy: 0.8947 - jacard_coef: 0.0409
Epoch 8: val_jacard_coef did not improve from 0.09263
17/17 [==============================] - 3s 200ms/step - loss: 0.1479 - accuracy: 0.8940 - jacard_coef: 0.0385 - val_loss: 0.1598 - val_accuracy: 0.9084 - val_jacard_coef: 2.2203e-12 - lr: 0.0010
Epoch 9/100
 1/17 [>.............................] - ETA: 3s - loss: 0.1459 - accuracy: 0.9179 - jacard_coef: 2.3234e-12 2/17 [==>...........................] - ETA: 3s - loss: 0.1454 - accuracy: 0.9231 - jacard_coef: 2.4909e-12 3/17 [====>.........................] - ETA: 2s - loss: 0.1453 - accuracy: 0.9239 - jacard_coef: 2.5133e-12 4/17 [======>.......................] - ETA: 2s - loss: 0.1456 - accuracy: 0.9211 - jacard_coef: 0.0134     5/17 [=======>......................] - ETA: 2s - loss: 0.1463 - accuracy: 0.9055 - jacard_coef: 0.0158 6/17 [=========>....................] - ETA: 2s - loss: 0.1459 - accuracy: 0.9073 - jacard_coef: 0.0162 7/17 [===========>..................] - ETA: 2s - loss: 0.1457 - accuracy: 0.9092 - jacard_coef: 0.0192 8/17 [=============>................] - ETA: 1s - loss: 0.1457 - accuracy: 0.9069 - jacard_coef: 0.0189 9/17 [==============>...............] - ETA: 1s - loss: 0.1453 - accuracy: 0.9102 - jacard_coef: 0.026310/17 [================>.............] - ETA: 1s - loss: 0.1450 - accuracy: 0.9115 - jacard_coef: 0.023711/17 [==================>...........] - ETA: 1s - loss: 0.1451 - accuracy: 0.9087 - jacard_coef: 0.028412/17 [====================>.........] - ETA: 1s - loss: 0.1449 - accuracy: 0.9090 - jacard_coef: 0.028613/17 [=====================>........] - ETA: 0s - loss: 0.1449 - accuracy: 0.9078 - jacard_coef: 0.030514/17 [=======================>......] - ETA: 0s - loss: 0.1448 - accuracy: 0.9074 - jacard_coef: 0.031715/17 [=========================>....] - ETA: 0s - loss: 0.1447 - accuracy: 0.9075 - jacard_coef: 0.030316/17 [===========================>..] - ETA: 0s - loss: 0.1446 - accuracy: 0.9061 - jacard_coef: 0.0297
Epoch 9: val_jacard_coef did not improve from 0.09263
17/17 [==============================] - 3s 200ms/step - loss: 0.1446 - accuracy: 0.9055 - jacard_coef: 0.0319 - val_loss: 0.1529 - val_accuracy: 0.9084 - val_jacard_coef: 2.2203e-12 - lr: 0.0010
Epoch 10/100
 1/17 [>.............................] - ETA: 3s - loss: 0.1424 - accuracy: 0.9077 - jacard_coef: 0.1139 2/17 [==>...........................] - ETA: 3s - loss: 0.1419 - accuracy: 0.9078 - jacard_coef: 0.1220 3/17 [====>.........................] - ETA: 2s - loss: 0.1418 - accuracy: 0.9062 - jacard_coef: 0.1091 4/17 [======>.......................] - ETA: 2s - loss: 0.1422 - accuracy: 0.9011 - jacard_coef: 0.1051 5/17 [=======>......................] - ETA: 2s - loss: 0.1432 - accuracy: 0.8828 - jacard_coef: 0.0958 6/17 [=========>....................] - ETA: 2s - loss: 0.1429 - accuracy: 0.8836 - jacard_coef: 0.0872 7/17 [===========>..................] - ETA: 2s - loss: 0.1428 - accuracy: 0.8832 - jacard_coef: 0.0797 8/17 [=============>................] - ETA: 1s - loss: 0.1427 - accuracy: 0.8813 - jacard_coef: 0.0745 9/17 [==============>...............] - ETA: 1s - loss: 0.1423 - accuracy: 0.8847 - jacard_coef: 0.077610/17 [================>.............] - ETA: 1s - loss: 0.1420 - accuracy: 0.8869 - jacard_coef: 0.069811/17 [==================>...........] - ETA: 1s - loss: 0.1422 - accuracy: 0.8862 - jacard_coef: 0.070812/17 [====================>.........] - ETA: 1s - loss: 0.1420 - accuracy: 0.8898 - jacard_coef: 0.065213/17 [=====================>........] - ETA: 0s - loss: 0.1419 - accuracy: 0.8913 - jacard_coef: 0.060214/17 [=======================>......] - ETA: 0s - loss: 0.1418 - accuracy: 0.8933 - jacard_coef: 0.055915/17 [=========================>....] - ETA: 0s - loss: 0.1417 - accuracy: 0.8958 - jacard_coef: 0.052216/17 [===========================>..] - ETA: 0s - loss: 0.1416 - accuracy: 0.8966 - jacard_coef: 0.0489
Epoch 10: val_jacard_coef did not improve from 0.09263
17/17 [==============================] - 3s 200ms/step - loss: 0.1417 - accuracy: 0.8959 - jacard_coef: 0.0460 - val_loss: 0.1472 - val_accuracy: 0.9084 - val_jacard_coef: 2.2202e-12 - lr: 0.0010
Epoch 11/100
 1/17 [>.............................] - ETA: 3s - loss: 0.1396 - accuracy: 0.9179 - jacard_coef: 2.3245e-12 2/17 [==>...........................] - ETA: 3s - loss: 0.1392 - accuracy: 0.9231 - jacard_coef: 2.4919e-12 3/17 [====>.........................] - ETA: 2s - loss: 0.1391 - accuracy: 0.9239 - jacard_coef: 2.5147e-12 4/17 [======>.......................] - ETA: 2s - loss: 0.1393 - accuracy: 0.9217 - jacard_coef: 2.4486e-12 5/17 [=======>......................] - ETA: 2s - loss: 0.1403 - accuracy: 0.9091 - jacard_coef: 2.2289e-12 6/17 [=========>....................] - ETA: 2s - loss: 0.1399 - accuracy: 0.9140 - jacard_coef: 3.6017e-04 7/17 [===========>..................] - ETA: 2s - loss: 0.1397 - accuracy: 0.9158 - jacard_coef: 0.0030     8/17 [=============>................] - ETA: 1s - loss: 0.1396 - accuracy: 0.9139 - jacard_coef: 0.0041 9/17 [==============>...............] - ETA: 1s - loss: 0.1392 - accuracy: 0.9169 - jacard_coef: 0.010110/17 [================>.............] - ETA: 1s - loss: 0.1389 - accuracy: 0.9187 - jacard_coef: 0.009111/17 [==================>...........] - ETA: 1s - loss: 0.1390 - accuracy: 0.9156 - jacard_coef: 0.008312/17 [====================>.........] - ETA: 1s - loss: 0.1389 - accuracy: 0.9160 - jacard_coef: 0.008913/17 [=====================>........] - ETA: 0s - loss: 0.1389 - accuracy: 0.9154 - jacard_coef: 0.008414/17 [=======================>......] - ETA: 0s - loss: 0.1388 - accuracy: 0.9157 - jacard_coef: 0.007815/17 [=========================>....] - ETA: 0s - loss: 0.1387 - accuracy: 0.9167 - jacard_coef: 0.007216/17 [===========================>..] - ETA: 0s - loss: 0.1386 - accuracy: 0.9162 - jacard_coef: 0.0068
Epoch 11: val_jacard_coef did not improve from 0.09263
17/17 [==============================] - 3s 201ms/step - loss: 0.1387 - accuracy: 0.9154 - jacard_coef: 0.0064 - val_loss: 0.1478 - val_accuracy: 0.9083 - val_jacard_coef: 2.2199e-12 - lr: 0.0010
Epoch 12/100
 1/17 [>.............................] - ETA: 3s - loss: 0.1367 - accuracy: 0.9180 - jacard_coef: 2.3248e-12 2/17 [==>...........................] - ETA: 3s - loss: 0.1361 - accuracy: 0.9231 - jacard_coef: 2.4919e-12 3/17 [====>.........................] - ETA: 2s - loss: 0.1362 - accuracy: 0.9236 - jacard_coef: 8.4422e-05 4/17 [======>.......................] - ETA: 2s - loss: 0.1367 - accuracy: 0.9212 - jacard_coef: 0.0086     5/17 [=======>......................] - ETA: 2s - loss: 0.1376 - accuracy: 0.9066 - jacard_coef: 0.0114 6/17 [=========>....................] - ETA: 2s - loss: 0.1372 - accuracy: 0.9084 - jacard_coef: 0.0130 7/17 [===========>..................] - ETA: 2s - loss: 0.1370 - accuracy: 0.9099 - jacard_coef: 0.0162 8/17 [=============>................] - ETA: 1s - loss: 0.1370 - accuracy: 0.9076 - jacard_coef: 0.0172 9/17 [==============>...............] - ETA: 1s - loss: 0.1365 - accuracy: 0.9111 - jacard_coef: 0.023410/17 [================>.............] - ETA: 1s - loss: 0.1362 - accuracy: 0.9135 - jacard_coef: 0.021111/17 [==================>...........] - ETA: 1s - loss: 0.1364 - accuracy: 0.9108 - jacard_coef: 0.019112/17 [====================>.........] - ETA: 1s - loss: 0.1362 - accuracy: 0.9122 - jacard_coef: 0.018213/17 [=====================>........] - ETA: 0s - loss: 0.1362 - accuracy: 0.9119 - jacard_coef: 0.016814/17 [=======================>......] - ETA: 0s - loss: 0.1361 - accuracy: 0.9124 - jacard_coef: 0.015615/17 [=========================>....] - ETA: 0s - loss: 0.1360 - accuracy: 0.9137 - jacard_coef: 0.014516/17 [===========================>..] - ETA: 0s - loss: 0.1359 - accuracy: 0.9134 - jacard_coef: 0.0136
Epoch 12: val_jacard_coef did not improve from 0.09263
17/17 [==============================] - 3s 201ms/step - loss: 0.1360 - accuracy: 0.9126 - jacard_coef: 0.0128 - val_loss: 0.1307 - val_accuracy: 0.9083 - val_jacard_coef: 2.2197e-12 - lr: 0.0010
Epoch 13/100
 1/17 [>.............................] - ETA: 3s - loss: 0.1340 - accuracy: 0.9179 - jacard_coef: 2.3243e-12 2/17 [==>...........................] - ETA: 3s - loss: 0.1333 - accuracy: 0.9231 - jacard_coef: 2.4914e-12 3/17 [====>.........................] - ETA: 2s - loss: 0.1333 - accuracy: 0.9238 - jacard_coef: 0.0011     4/17 [======>.......................] - ETA: 2s - loss: 0.1336 - accuracy: 0.9208 - jacard_coef: 0.0184 5/17 [=======>......................] - ETA: 2s - loss: 0.1347 - accuracy: 0.9062 - jacard_coef: 0.0190 6/17 [=========>....................] - ETA: 2s - loss: 0.1343 - accuracy: 0.9091 - jacard_coef: 0.0184 7/17 [===========>..................] - ETA: 2s - loss: 0.1340 - accuracy: 0.9111 - jacard_coef: 0.0199 8/17 [=============>................] - ETA: 1s - loss: 0.1341 - accuracy: 0.9103 - jacard_coef: 0.0189 9/17 [==============>...............] - ETA: 1s - loss: 0.1336 - accuracy: 0.9146 - jacard_coef: 0.022010/17 [================>.............] - ETA: 1s - loss: 0.1333 - accuracy: 0.9173 - jacard_coef: 0.019811/17 [==================>...........] - ETA: 1s - loss: 0.1335 - accuracy: 0.9144 - jacard_coef: 0.019712/17 [====================>.........] - ETA: 1s - loss: 0.1333 - accuracy: 0.9151 - jacard_coef: 0.019713/17 [=====================>........] - ETA: 0s - loss: 0.1333 - accuracy: 0.9143 - jacard_coef: 0.019914/17 [=======================>......] - ETA: 0s - loss: 0.1332 - accuracy: 0.9139 - jacard_coef: 0.020715/17 [=========================>....] - ETA: 0s - loss: 0.1331 - accuracy: 0.9142 - jacard_coef: 0.019616/17 [===========================>..] - ETA: 0s - loss: 0.1330 - accuracy: 0.9132 - jacard_coef: 0.0190
Epoch 13: val_jacard_coef did not improve from 0.09263
17/17 [==============================] - 3s 200ms/step - loss: 0.1331 - accuracy: 0.9125 - jacard_coef: 0.0205 - val_loss: 0.1281 - val_accuracy: 0.9083 - val_jacard_coef: 2.2197e-12 - lr: 0.0010
Epoch 14/100
 1/17 [>.............................] - ETA: 3s - loss: 0.1313 - accuracy: 0.9134 - jacard_coef: 0.0984 2/17 [==>...........................] - ETA: 3s - loss: 0.1305 - accuracy: 0.9157 - jacard_coef: 0.1108 3/17 [====>.........................] - ETA: 2s - loss: 0.1305 - accuracy: 0.9149 - jacard_coef: 0.0999 4/17 [======>.......................] - ETA: 2s - loss: 0.1311 - accuracy: 0.9105 - jacard_coef: 0.0998 5/17 [=======>......................] - ETA: 2s - loss: 0.1322 - accuracy: 0.8935 - jacard_coef: 0.0908 6/17 [=========>....................] - ETA: 2s - loss: 0.1318 - accuracy: 0.8946 - jacard_coef: 0.0819 7/17 [===========>..................] - ETA: 2s - loss: 0.1318 - accuracy: 0.8955 - jacard_coef: 0.0761 8/17 [=============>................] - ETA: 1s - loss: 0.1318 - accuracy: 0.8937 - jacard_coef: 0.0698 9/17 [==============>...............] - ETA: 1s - loss: 0.1313 - accuracy: 0.8975 - jacard_coef: 0.073510/17 [================>.............] - ETA: 1s - loss: 0.1310 - accuracy: 0.9016 - jacard_coef: 0.066111/17 [==================>...........] - ETA: 1s - loss: 0.1312 - accuracy: 0.9000 - jacard_coef: 0.060112/17 [====================>.........] - ETA: 1s - loss: 0.1310 - accuracy: 0.9026 - jacard_coef: 0.055113/17 [=====================>........] - ETA: 0s - loss: 0.1310 - accuracy: 0.9030 - jacard_coef: 0.050914/17 [=======================>......] - ETA: 0s - loss: 0.1309 - accuracy: 0.9042 - jacard_coef: 0.047215/17 [=========================>....] - ETA: 0s - loss: 0.1307 - accuracy: 0.9060 - jacard_coef: 0.044116/17 [===========================>..] - ETA: 0s - loss: 0.1307 - accuracy: 0.9062 - jacard_coef: 0.0413
Epoch 14: val_jacard_coef did not improve from 0.09263
17/17 [==============================] - 3s 200ms/step - loss: 0.1307 - accuracy: 0.9054 - jacard_coef: 0.0389 - val_loss: 0.1356 - val_accuracy: 0.9083 - val_jacard_coef: 2.2197e-12 - lr: 0.0010
Epoch 15/100
 1/17 [>.............................] - ETA: 3s - loss: 0.1289 - accuracy: 0.9179 - jacard_coef: 2.3242e-12 2/17 [==>...........................] - ETA: 3s - loss: 0.1282 - accuracy: 0.9231 - jacard_coef: 2.4913e-12 3/17 [====>.........................] - ETA: 2s - loss: 0.1282 - accuracy: 0.9239 - jacard_coef: 2.5606e-05 4/17 [======>.......................] - ETA: 2s - loss: 0.1285 - accuracy: 0.9216 - jacard_coef: 0.0051     5/17 [=======>......................] - ETA: 2s - loss: 0.1298 - accuracy: 0.9062 - jacard_coef: 0.0097 6/17 [=========>....................] - ETA: 2s - loss: 0.1292 - accuracy: 0.9081 - jacard_coef: 0.0118 7/17 [===========>..................] - ETA: 2s - loss: 0.1290 - accuracy: 0.9093 - jacard_coef: 0.0154 8/17 [=============>................] - ETA: 1s - loss: 0.1290 - accuracy: 0.9082 - jacard_coef: 0.0165 9/17 [==============>...............] - ETA: 1s - loss: 0.1285 - accuracy: 0.9122 - jacard_coef: 0.022010/17 [================>.............] - ETA: 1s - loss: 0.1281 - accuracy: 0.9147 - jacard_coef: 0.019811/17 [==================>...........] - ETA: 1s - loss: 0.1283 - accuracy: 0.9120 - jacard_coef: 0.019912/17 [====================>.........] - ETA: 1s - loss: 0.1281 - accuracy: 0.9131 - jacard_coef: 0.019613/17 [=====================>........] - ETA: 0s - loss: 0.1282 - accuracy: 0.9128 - jacard_coef: 0.018114/17 [=======================>......] - ETA: 0s - loss: 0.1281 - accuracy: 0.9132 - jacard_coef: 0.016815/17 [=========================>....] - ETA: 0s - loss: 0.1280 - accuracy: 0.9144 - jacard_coef: 0.015716/17 [===========================>..] - ETA: 0s - loss: 0.1279 - accuracy: 0.9141 - jacard_coef: 0.0147
Epoch 15: val_jacard_coef did not improve from 0.09263
17/17 [==============================] - 3s 200ms/step - loss: 0.1279 - accuracy: 0.9133 - jacard_coef: 0.0139 - val_loss: 0.1195 - val_accuracy: 0.9083 - val_jacard_coef: 2.2197e-12 - lr: 0.0010
Epoch 16/100
 1/17 [>.............................] - ETA: 3s - loss: 0.1269 - accuracy: 0.9180 - jacard_coef: 2.3250e-12 2/17 [==>...........................] - ETA: 3s - loss: 0.1264 - accuracy: 0.9231 - jacard_coef: 2.4918e-12 3/17 [====>.........................] - ETA: 2s - loss: 0.1262 - accuracy: 0.9232 - jacard_coef: 5.4658e-04 4/17 [======>.......................] - ETA: 2s - loss: 0.1267 - accuracy: 0.9204 - jacard_coef: 0.0160     5/17 [=======>......................] - ETA: 2s - loss: 0.1278 - accuracy: 0.9049 - jacard_coef: 0.0209 6/17 [=========>....................] - ETA: 2s - loss: 0.1272 - accuracy: 0.9062 - jacard_coef: 0.0224 7/17 [===========>..................] - ETA: 2s - loss: 0.1271 - accuracy: 0.9077 - jacard_coef: 0.0251 8/17 [=============>................] - ETA: 1s - loss: 0.1270 - accuracy: 0.9068 - jacard_coef: 0.0245 9/17 [==============>...............] - ETA: 1s - loss: 0.1265 - accuracy: 0.9121 - jacard_coef: 0.021810/17 [================>.............] - ETA: 1s - loss: 0.1261 - accuracy: 0.9164 - jacard_coef: 0.019611/17 [==================>...........] - ETA: 1s - loss: 0.1264 - accuracy: 0.9135 - jacard_coef: 0.017812/17 [====================>.........] - ETA: 1s - loss: 0.1261 - accuracy: 0.9149 - jacard_coef: 0.016313/17 [=====================>........] - ETA: 0s - loss: 0.1261 - accuracy: 0.9144 - jacard_coef: 0.015114/17 [=======================>......] - ETA: 0s - loss: 0.1260 - accuracy: 0.9148 - jacard_coef: 0.014015/17 [=========================>....] - ETA: 0s - loss: 0.1258 - accuracy: 0.9159 - jacard_coef: 0.013116/17 [===========================>..] - ETA: 0s - loss: 0.1258 - accuracy: 0.9155 - jacard_coef: 0.0123
Epoch 16: val_jacard_coef did not improve from 0.09263
17/17 [==============================] - 3s 200ms/step - loss: 0.1259 - accuracy: 0.9146 - jacard_coef: 0.0115 - val_loss: 0.1339 - val_accuracy: 0.9083 - val_jacard_coef: 2.2197e-12 - lr: 0.0010
Epoch 17/100
 1/17 [>.............................] - ETA: 3s - loss: 0.1237 - accuracy: 0.9180 - jacard_coef: 2.3248e-12 2/17 [==>...........................] - ETA: 3s - loss: 0.1230 - accuracy: 0.9231 - jacard_coef: 2.4918e-12 3/17 [====>.........................] - ETA: 2s - loss: 0.1231 - accuracy: 0.9239 - jacard_coef: 3.4143e-05 4/17 [======>.......................] - ETA: 2s - loss: 0.1236 - accuracy: 0.9218 - jacard_coef: 2.5608e-05 5/17 [=======>......................] - ETA: 2s - loss: 0.1248 - accuracy: 0.9092 - jacard_coef: 2.0486e-05 6/17 [=========>....................] - ETA: 2s - loss: 0.1242 - accuracy: 0.9128 - jacard_coef: 9.9076e-04 7/17 [===========>..................] - ETA: 2s - loss: 0.1241 - accuracy: 0.9145 - jacard_coef: 0.0052     8/17 [=============>................] - ETA: 1s - loss: 0.1240 - accuracy: 0.9138 - jacard_coef: 0.0063 9/17 [==============>...............] - ETA: 1s - loss: 0.1235 - accuracy: 0.9179 - jacard_coef: 0.008110/17 [================>.............] - ETA: 1s - loss: 0.1231 - accuracy: 0.9201 - jacard_coef: 0.007311/17 [==================>...........] - ETA: 1s - loss: 0.1233 - accuracy: 0.9168 - jacard_coef: 0.007212/17 [====================>.........] - ETA: 1s - loss: 0.1231 - accuracy: 0.9175 - jacard_coef: 0.008213/17 [=====================>........] - ETA: 0s - loss: 0.1231 - accuracy: 0.9167 - jacard_coef: 0.007714/17 [=======================>......] - ETA: 0s - loss: 0.1230 - accuracy: 0.9169 - jacard_coef: 0.007115/17 [=========================>....] - ETA: 0s - loss: 0.1229 - accuracy: 0.9178 - jacard_coef: 0.006716/17 [===========================>..] - ETA: 0s - loss: 0.1228 - accuracy: 0.9173 - jacard_coef: 0.0063
Epoch 17: val_jacard_coef did not improve from 0.09263
17/17 [==============================] - 3s 200ms/step - loss: 0.1229 - accuracy: 0.9164 - jacard_coef: 0.0059 - val_loss: 0.1367 - val_accuracy: 0.9083 - val_jacard_coef: 2.2194e-12 - lr: 0.0010
Epoch 17: early stopping
Restoring model weights from the end of the best epoch: 2.
Attention ResUnet execution time is:  0:01:36.296252
Traceback (most recent call last):
  File "/scratch/phyzxi/unet-HPC/run_mitochondria_training.py", line 94, in <module>
    main()
  File "/scratch/phyzxi/unet-HPC/run_mitochondria_training.py", line 91, in main
    exec(open('224_225_226_mito_segm_using_various_unet_models.py').read())
  File "<string>", line 258, in <module>
  File "/usr/local/lib/python3.10/dist-packages/tf_keras/src/saving/saving_api.py", line 262, in load_model
    return legacy_sm_saving_lib.load_model(
  File "/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/usr/local/lib/python3.10/dist-packages/tf_keras/src/saving/legacy/save.py", line 233, in load_model
    raise IOError(
OSError: No file or directory found at models/mitochondria_AttResUnet_50epochs_B_focal.hdf5
