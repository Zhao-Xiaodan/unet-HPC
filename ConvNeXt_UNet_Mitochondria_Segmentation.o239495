=======================================================================
CONVNEXT-UNET DEDICATED TRAINING - MITOCHONDRIA SEGMENTATION
=======================================================================
Model: ConvNeXt-UNet (Modern CNN with improved efficiency)
Task: Mitochondria semantic segmentation
Framework: TensorFlow/Keras with enhanced dataset management
Expected Training Time: 6-8 hours

Job started on Wed Oct  1 11:53:09 PM +08 2025
Running on node: GN-A40-097
Job ID: 239495.stdct-mgmt-02
Available GPUs: GPU-33961ece-d144-6477-790d-f2e9b0695a10
Memory: 503Gi, CPUs: 36

=== CONVNEXT-UNET TRAINING CONFIGURATION ===
Dataset Images: ./dataset_full_stack/images/ (1980 patches - REQUIRED)
Dataset Masks: ./dataset_full_stack/masks/ (1980 patches - REQUIRED)
Alternative: ./dataset/images/ and ./dataset/masks/
Image Size: 256x256x3
Batch Size: 4 (optimized for ConvNeXt)
Learning Rate: 1e-4 (Adam optimizer)
Epochs: 100 (with early stopping)
Loss Function: Binary Focal Loss
Special Features: Enhanced dataset cache management
==============================================

TensorFlow Container: /app1/common/singularity-img/hopper/tensorflow/tensorflow_2.16.1-cuda_12.5.0_24.06.sif

=== AGGRESSIVE CACHE CLEARING ===
Performing comprehensive cache clearing to prevent dataset conflicts...
Clearing TensorFlow dataset caches...
Clearing Python cache...
Clearing previous model checkpoints...
Unique session ID: convnext_1759333990_284867
âœ“ Aggressive cache clearing completed
==================================

=== PRE-EXECUTION CHECKS ===
1. Checking dataset structure...
   âœ“ Full stack dataset directories found (PREFERRED)
   âœ“ Images found: 1980 files
   âœ“ Masks found: 1980 files

2. Checking Python files...
   âœ“ convnext_unet_training.py found
   âœ“ modern_unet_models.py found
==========================

=== TENSORFLOW & GPU STATUS ===
Python version: 3.10.12
TensorFlow version: 2.16.1
CUDA built support: True
Physical GPUs found: 1
  GPU 0: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')
âœ“ GPU memory growth enabled
âœ“ GPU operation test successful

ConvNeXt-UNet memory requirements:
- Expected GPU memory: 8-12 GB
- Batch size: 4 (optimized)
- Model parameters: ~15-25M
===============================

=== CONVNEXT-UNET MODEL VALIDATION ===
Testing ConvNeXt-UNet creation to validate implementation...
2025-10-01 15:53:59.136200: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
Testing ConvNeXt-UNet model creation...
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 256, 256, 64)         640       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 256, 256, 64)         256       ['conv2d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 activation (Activation)     (None, 256, 256, 64)         0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['activation[0][0]']          
                                                                                                  
 batch_normalization_1 (Bat  (None, 256, 256, 64)         256       ['conv2d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_1 (Activation)   (None, 256, 256, 64)         0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['activation_1[0][0]']        
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       
                                                                                                  
 batch_normalization_2 (Bat  (None, 128, 128, 128)        512       ['conv2d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_2 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_3 (Conv2D)           (None, 128, 128, 128)        147584    ['activation_2[0][0]']        
                                                                                                  
 batch_normalization_3 (Bat  (None, 128, 128, 128)        512       ['conv2d_3[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_3 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_3[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_3[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 batch_normalization_4 (Bat  (None, 64, 64, 256)          1024      ['conv2d_4[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_4 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_4[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_5 (Conv2D)           (None, 64, 64, 256)          590080    ['activation_4[0][0]']        
                                                                                                  
 batch_normalization_5 (Bat  (None, 64, 64, 256)          1024      ['conv2d_5[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_5 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_5[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_5[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 512)          1180160   ['max_pooling2d_2[0][0]']     
                                                                                                  
 batch_normalization_6 (Bat  (None, 32, 32, 512)          2048      ['conv2d_6[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_6 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_6[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 32, 32, 512)          2359808   ['activation_6[0][0]']        
                                                                                                  
 batch_normalization_7 (Bat  (None, 32, 32, 512)          2048      ['conv2d_7[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_7 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_7[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_3 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_7[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 1024)         4719616   ['max_pooling2d_3[0][0]']     
                                                                                                  
 batch_normalization_8 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_8[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_8 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_8[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 1024)         9438208   ['activation_8[0][0]']        
                                                                                                  
 batch_normalization_9 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_9[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_9 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_9[0][0]'
                                                                    ]                             
                                                                                                  
 up_sampling2d (UpSampling2  (None, 32, 32, 1024)         0         ['activation_9[0][0]']        
 D)                                                                                               
                                                                                                  
 concatenate (Concatenate)   (None, 32, 32, 1536)         0         ['up_sampling2d[0][0]',       
                                                                     'activation_7[0][0]']        
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate[0][0]']         
                                                                                                  
 batch_normalization_10 (Ba  (None, 32, 32, 512)          2048      ['conv2d_10[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_10 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_10[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_10[0][0]']       
                                                                                                  
 batch_normalization_11 (Ba  (None, 32, 32, 512)          2048      ['conv2d_11[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_11 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_11[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 64, 64, 512)          0         ['activation_11[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_1 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_1[0][0]',     
 )                                                                   'activation_5[0][0]']        
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_1[0][0]']       
                                                                                                  
 batch_normalization_12 (Ba  (None, 64, 64, 256)          1024      ['conv2d_12[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_12 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_12[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_13 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_12[0][0]']       
                                                                                                  
 batch_normalization_13 (Ba  (None, 64, 64, 256)          1024      ['conv2d_13[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_13 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_13[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 128, 128, 256)        0         ['activation_13[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_2 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_2[0][0]',     
 )                                                                   'activation_3[0][0]']        
                                                                                                  
 conv2d_14 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_2[0][0]']       
                                                                                                  
 batch_normalization_14 (Ba  (None, 128, 128, 128)        512       ['conv2d_14[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_14 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_14[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_15 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_14[0][0]']       
                                                                                                  
 batch_normalization_15 (Ba  (None, 128, 128, 128)        512       ['conv2d_15[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_15 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_15[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 256, 256, 128)        0         ['activation_15[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_3 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_3[0][0]',     
 )                                                                   'activation_1[0][0]']        
                                                                                                  
 conv2d_16 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_3[0][0]']       
                                                                                                  
 batch_normalization_16 (Ba  (None, 256, 256, 64)         256       ['conv2d_16[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_16 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_16[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_16[0][0]']       
                                                                                                  
 batch_normalization_17 (Ba  (None, 256, 256, 64)         256       ['conv2d_17[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_17 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_17[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_18 (Conv2D)          (None, 256, 256, 1)          65        ['activation_17[0][0]']       
                                                                                                  
 batch_normalization_18 (Ba  (None, 256, 256, 1)          4         ['conv2d_18[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_18 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_18[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31401349 (119.79 MB)
Trainable params: 31389571 (119.74 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
None
âœ“ ConvNeXt-UNet: 34,590,913 parameters
âœ“ Model building successful
âœ“ Forward pass successful: (1, 64, 64, 1)
âœ“ ConvNeXt-UNet validation completed successfully
âœ“ ConvNeXt-UNet validation passed
=====================================

ðŸš€ STARTING CONVNEXT-UNET TRAINING
=============================================
Training ConvNeXt-UNet with enhanced dataset management

Training Configuration:
- Architecture: ConvNeXt-UNet (Modern CNN)
- Learning Rate: 1e-4 (Adam optimizer)
- Batch Size: 4 (memory optimized)
- Max Epochs: 100 (with early stopping)
- Loss: Binary Focal Loss (gamma=2)
- Special: No tf.data.Dataset caching

Expected timeline: 6-8 hours
Expected performance: 93-95% Jaccard
=============================================
Output directory: convnext_unet_training_20251001_235416

Starting ConvNeXt-UNet training execution...
======================================================================
CONVNEXT-UNET DEDICATED TRAINING FOR MITOCHONDRIA SEGMENTATION
======================================================================
Model: ConvNeXt-UNet (Modern CNN with improved efficiency)
Task: Mitochondria semantic segmentation
Framework: TensorFlow/Keras with enhanced dataset management

âœ“ GPU memory growth enabled for 1 GPUs
Output directory: convnext_unet_training_20251001_155440
=== LOADING DATASET FOR CONVNEXT-UNET ===
Using dataset: dataset_full_stack/images/ and dataset_full_stack/masks/
âœ“ Loaded 1980 images and 1980 masks
Training set: 1782 samples
Validation set: 198 samples

Training Configuration:
  Learning Rate: 0.0001
  Batch Size: 4
  Max Epochs: 100
  Input Shape: (256, 256, 3)

============================================================
TRAINING: ConvNeXt-UNet (Dedicated)
Learning Rate: 0.0001, Batch Size: 4, Max Epochs: 100
============================================================
ðŸ§¹ Performing aggressive cache clearing for ConvNeXt-UNet...
âœ“ Aggressive cache clearing completed: 4 items cleared
âœ“ Unique session ID: 3f62ce85
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 256, 256, 64)         640       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 256, 256, 64)         256       ['conv2d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 activation (Activation)     (None, 256, 256, 64)         0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['activation[0][0]']          
                                                                                                  
 batch_normalization_1 (Bat  (None, 256, 256, 64)         256       ['conv2d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_1 (Activation)   (None, 256, 256, 64)         0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['activation_1[0][0]']        
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       
                                                                                                  
 batch_normalization_2 (Bat  (None, 128, 128, 128)        512       ['conv2d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_2 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_3 (Conv2D)           (None, 128, 128, 128)        147584    ['activation_2[0][0]']        
                                                                                                  
 batch_normalization_3 (Bat  (None, 128, 128, 128)        512       ['conv2d_3[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_3 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_3[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_3[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 batch_normalization_4 (Bat  (None, 64, 64, 256)          1024      ['conv2d_4[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_4 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_4[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_5 (Conv2D)           (None, 64, 64, 256)          590080    ['activation_4[0][0]']        
                                                                                                  
 batch_normalization_5 (Bat  (None, 64, 64, 256)          1024      ['conv2d_5[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_5 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_5[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_5[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 512)          1180160   ['max_pooling2d_2[0][0]']     
                                                                                                  
 batch_normalization_6 (Bat  (None, 32, 32, 512)          2048      ['conv2d_6[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_6 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_6[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 32, 32, 512)          2359808   ['activation_6[0][0]']        
                                                                                                  
 batch_normalization_7 (Bat  (None, 32, 32, 512)          2048      ['conv2d_7[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_7 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_7[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_3 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_7[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 1024)         4719616   ['max_pooling2d_3[0][0]']     
                                                                                                  
 batch_normalization_8 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_8[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_8 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_8[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 1024)         9438208   ['activation_8[0][0]']        
                                                                                                  
 batch_normalization_9 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_9[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_9 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_9[0][0]'
                                                                    ]                             
                                                                                                  
 up_sampling2d (UpSampling2  (None, 32, 32, 1024)         0         ['activation_9[0][0]']        
 D)                                                                                               
                                                                                                  
 concatenate (Concatenate)   (None, 32, 32, 1536)         0         ['up_sampling2d[0][0]',       
                                                                     'activation_7[0][0]']        
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate[0][0]']         
                                                                                                  
 batch_normalization_10 (Ba  (None, 32, 32, 512)          2048      ['conv2d_10[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_10 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_10[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_10[0][0]']       
                                                                                                  
 batch_normalization_11 (Ba  (None, 32, 32, 512)          2048      ['conv2d_11[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_11 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_11[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 64, 64, 512)          0         ['activation_11[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_1 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_1[0][0]',     
 )                                                                   'activation_5[0][0]']        
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_1[0][0]']       
                                                                                                  
 batch_normalization_12 (Ba  (None, 64, 64, 256)          1024      ['conv2d_12[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_12 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_12[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_13 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_12[0][0]']       
                                                                                                  
 batch_normalization_13 (Ba  (None, 64, 64, 256)          1024      ['conv2d_13[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_13 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_13[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 128, 128, 256)        0         ['activation_13[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_2 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_2[0][0]',     
 )                                                                   'activation_3[0][0]']        
                                                                                                  
 conv2d_14 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_2[0][0]']       
                                                                                                  
 batch_normalization_14 (Ba  (None, 128, 128, 128)        512       ['conv2d_14[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_14 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_14[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_15 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_14[0][0]']       
                                                                                                  
 batch_normalization_15 (Ba  (None, 128, 128, 128)        512       ['conv2d_15[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_15 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_15[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 256, 256, 128)        0         ['activation_15[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_3 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_3[0][0]',     
 )                                                                   'activation_1[0][0]']        
                                                                                                  
 conv2d_16 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_3[0][0]']       
                                                                                                  
 batch_normalization_16 (Ba  (None, 256, 256, 64)         256       ['conv2d_16[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_16 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_16[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_16[0][0]']       
                                                                                                  
 batch_normalization_17 (Ba  (None, 256, 256, 64)         256       ['conv2d_17[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_17 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_17[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_18 (Conv2D)          (None, 256, 256, 1)          65        ['activation_17[0][0]']       
                                                                                                  
 batch_normalization_18 (Ba  (None, 256, 256, 1)          4         ['conv2d_18[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_18 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_18[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31401349 (119.79 MB)
Trainable params: 31389571 (119.74 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
None
Creating ConvNeXt-UNet model...
Model parameters: 34,590,913
Starting ConvNeXt-UNet training...
Applying ConvNeXt-specific optimizations...
Epoch 1/100
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1759334157.819066  286679 service.cc:145] XLA service 0x1462dde38c00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1759334157.819113  286679 service.cc:153]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6
I0000 00:00:1759334158.243049  286679 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
  1/446 [..............................] - ETA: 8:36:38 - loss: 0.2258 - accuracy: 0.4016 - jacard_coef: 0.0252  2/446 [..............................] - ETA: 2:20 - loss: 0.2090 - accuracy: 0.4438 - jacard_coef: 0.0295     3/446 [..............................] - ETA: 1:48 - loss: 0.1943 - accuracy: 0.4855 - jacard_coef: 0.0365  4/446 [..............................] - ETA: 1:35 - loss: 0.1822 - accuracy: 0.5286 - jacard_coef: 0.0441  5/446 [..............................] - ETA: 1:27 - loss: 0.1710 - accuracy: 0.5763 - jacard_coef: 0.0459  6/446 [..............................] - ETA: 1:21 - loss: 0.1584 - accuracy: 0.6363 - jacard_coef: 0.0394  7/446 [..............................] - ETA: 1:17 - loss: 0.1497 - accuracy: 0.6777 - jacard_coef: 0.0350  8/446 [..............................] - ETA: 1:15 - loss: 0.1408 - accuracy: 0.7126 - jacard_coef: 0.0307  9/446 [..............................] - ETA: 1:13 - loss: 0.1341 - accuracy: 0.7372 - jacard_coef: 0.0273 10/446 [..............................] - ETA: 1:11 - loss: 0.1285 - accuracy: 0.7563 - jacard_coef: 0.0246 11/446 [..............................] - ETA: 1:10 - loss: 0.1219 - accuracy: 0.7747 - jacard_coef: 0.0223 12/446 [..............................] - ETA: 1:09 - loss: 0.1192 - accuracy: 0.7859 - jacard_coef: 0.0205 13/446 [..............................] - ETA: 1:08 - loss: 0.1159 - accuracy: 0.7969 - jacard_coef: 0.0189 14/446 [..............................] - ETA: 1:07 - loss: 0.1108 - accuracy: 0.8090 - jacard_coef: 0.0176 15/446 [>.............................] - ETA: 1:07 - loss: 0.1109 - accuracy: 0.8144 - jacard_coef: 0.0164 16/446 [>.............................] - ETA: 1:06 - loss: 0.1106 - accuracy: 0.8196 - jacard_coef: 0.0154 17/446 [>.............................] - ETA: 1:05 - loss: 0.1092 - accuracy: 0.8254 - jacard_coef: 0.0145 18/446 [>.............................] - ETA: 1:05 - loss: 0.1051 - accuracy: 0.8337 - jacard_coef: 0.0137 19/446 [>.............................] - ETA: 1:04 - loss: 0.1022 - accuracy: 0.8403 - jacard_coef: 0.0129 20/446 [>.............................] - ETA: 1:04 - loss: 0.1015 - accuracy: 0.8438 - jacard_coef: 0.0123 21/446 [>.............................] - ETA: 1:03 - loss: 0.0988 - accuracy: 0.8497 - jacard_coef: 0.0117 22/446 [>.............................] - ETA: 1:03 - loss: 0.0964 - accuracy: 0.8551 - jacard_coef: 0.0112 23/446 [>.............................] - ETA: 1:03 - loss: 0.0955 - accuracy: 0.8580 - jacard_coef: 0.0107 24/446 [>.............................] - ETA: 1:02 - loss: 0.0946 - accuracy: 0.8610 - jacard_coef: 0.0102 25/446 [>.............................] - ETA: 1:02 - loss: 0.0945 - accuracy: 0.8626 - jacard_coef: 0.0098 26/446 [>.............................] - ETA: 1:02 - loss: 0.0922 - accuracy: 0.8671 - jacard_coef: 0.0095 27/446 [>.............................] - ETA: 1:02 - loss: 0.0905 - accuracy: 0.8708 - jacard_coef: 0.0091 28/446 [>.............................] - ETA: 1:01 - loss: 0.0892 - accuracy: 0.8738 - jacard_coef: 0.0088 29/446 [>.............................] - ETA: 1:01 - loss: 0.0890 - accuracy: 0.8752 - jacard_coef: 0.0085 30/446 [=>............................] - ETA: 1:01 - loss: 0.0885 - accuracy: 0.8768 - jacard_coef: 0.0082 31/446 [=>............................] - ETA: 1:01 - loss: 0.0883 - accuracy: 0.8780 - jacard_coef: 0.0079 32/446 [=>............................] - ETA: 1:00 - loss: 0.0874 - accuracy: 0.8801 - jacard_coef: 0.0077 33/446 [=>............................] - ETA: 1:00 - loss: 0.0862 - accuracy: 0.8827 - jacard_coef: 0.0074 34/446 [=>............................] - ETA: 1:00 - loss: 0.0859 - accuracy: 0.8838 - jacard_coef: 0.0072 35/446 [=>............................] - ETA: 1:00 - loss: 0.0845 - accuracy: 0.8866 - jacard_coef: 0.0070 36/446 [=>............................] - ETA: 59s - loss: 0.0837 - accuracy: 0.8884 - jacard_coef: 0.0068  37/446 [=>............................] - ETA: 59s - loss: 0.0834 - accuracy: 0.8894 - jacard_coef: 0.0066 38/446 [=>............................] - ETA: 59s - loss: 0.0823 - accuracy: 0.8915 - jacard_coef: 0.0065 39/446 [=>............................] - ETA: 59s - loss: 0.0821 - accuracy: 0.8924 - jacard_coef: 0.0063 40/446 [=>............................] - ETA: 59s - loss: 0.0818 - accuracy: 0.8934 - jacard_coef: 0.0061 41/446 [=>............................] - ETA: 58s - loss: 0.0808 - accuracy: 0.8952 - jacard_coef: 0.0060 42/446 [=>............................] - ETA: 58s - loss: 0.0805 - accuracy: 0.8962 - jacard_coef: 0.0059 43/446 [=>............................] - ETA: 58s - loss: 0.0794 - accuracy: 0.8982 - jacard_coef: 0.0057 44/446 [=>............................] - ETA: 58s - loss: 0.0790 - accuracy: 0.8993 - jacard_coef: 0.0056 45/446 [==>...........................] - ETA: 58s - loss: 0.0783 - accuracy: 0.9006 - jacard_coef: 0.0055 46/446 [==>...........................] - ETA: 57s - loss: 0.0779 - accuracy: 0.9016 - jacard_coef: 0.0053 47/446 [==>...........................] - ETA: 57s - loss: 0.0778 - accuracy: 0.9021 - jacard_coef: 0.0052 48/446 [==>...........................] - ETA: 57s - loss: 0.0773 - accuracy: 0.9032 - jacard_coef: 0.0051 49/446 [==>...........................] - ETA: 57s - loss: 0.0773 - accuracy: 0.9036 - jacard_coef: 0.0050 50/446 [==>...........................] - ETA: 57s - loss: 0.0765 - accuracy: 0.9051 - jacard_coef: 0.0049 51/446 [==>...........................] - ETA: 56s - loss: 0.0767 - accuracy: 0.9051 - jacard_coef: 0.0048 52/446 [==>...........................] - ETA: 56s - loss: 0.0761 - accuracy: 0.9063 - jacard_coef: 0.0047 53/446 [==>...........................] - ETA: 56s - loss: 0.0757 - accuracy: 0.9071 - jacard_coef: 0.0046 54/446 [==>...........................] - ETA: 56s - loss: 0.0750 - accuracy: 0.9083 - jacard_coef: 0.0046 55/446 [==>...........................] - ETA: 56s - loss: 0.0745 - accuracy: 0.9094 - jacard_coef: 0.0045 56/446 [==>...........................] - ETA: 56s - loss: 0.0740 - accuracy: 0.9102 - jacard_coef: 0.0044 57/446 [==>...........................] - ETA: 56s - loss: 0.0745 - accuracy: 0.9099 - jacard_coef: 0.0043 58/446 [==>...........................] - ETA: 55s - loss: 0.0743 - accuracy: 0.9105 - jacard_coef: 0.0042 59/446 [==>...........................] - ETA: 55s - loss: 0.0737 - accuracy: 0.9115 - jacard_coef: 0.0042 60/446 [===>..........................] - ETA: 55s - loss: 0.0739 - accuracy: 0.9115 - jacard_coef: 0.0041 61/446 [===>..........................] - ETA: 55s - loss: 0.0731 - accuracy: 0.9128 - jacard_coef: 0.0040 62/446 [===>..........................] - ETA: 55s - loss: 0.0725 - accuracy: 0.9138 - jacard_coef: 0.0040 63/446 [===>..........................] - ETA: 55s - loss: 0.0724 - accuracy: 0.9142 - jacard_coef: 0.0039 64/446 [===>..........................] - ETA: 54s - loss: 0.0719 - accuracy: 0.9150 - jacard_coef: 0.0038 65/446 [===>..........................] - ETA: 54s - loss: 0.0719 - accuracy: 0.9153 - jacard_coef: 0.0038 66/446 [===>..........................] - ETA: 54s - loss: 0.0718 - accuracy: 0.9157 - jacard_coef: 0.0037 67/446 [===>..........................] - ETA: 54s - loss: 0.0714 - accuracy: 0.9164 - jacard_coef: 0.0037 68/446 [===>..........................] - ETA: 54s - loss: 0.0715 - accuracy: 0.9164 - jacard_coef: 0.0036 69/446 [===>..........................] - ETA: 54s - loss: 0.0711 - accuracy: 0.9171 - jacard_coef: 0.0036 70/446 [===>..........................] - ETA: 53s - loss: 0.0711 - accuracy: 0.9173 - jacard_coef: 0.0035 71/446 [===>..........................] - ETA: 53s - loss: 0.0711 - accuracy: 0.9175 - jacard_coef: 0.0035 72/446 [===>..........................] - ETA: 53s - loss: 0.0708 - accuracy: 0.9181 - jacard_coef: 0.0034 73/446 [===>..........................] - ETA: 53s - loss: 0.0702 - accuracy: 0.9191 - jacard_coef: 0.0034 74/446 [===>..........................] - ETA: 53s - loss: 0.0701 - accuracy: 0.9194 - jacard_coef: 0.0033 75/446 [====>.........................] - ETA: 53s - loss: 0.0698 - accuracy: 0.9199 - jacard_coef: 0.0033 76/446 [====>.........................] - ETA: 52s - loss: 0.0695 - accuracy: 0.9206 - jacard_coef: 0.0032 77/446 [====>.........................] - ETA: 52s - loss: 0.0697 - accuracy: 0.9204 - jacard_coef: 0.0032 78/446 [====>.........................] - ETA: 52s - loss: 0.0694 - accuracy: 0.9209 - jacard_coef: 0.0032 79/446 [====>.........................] - ETA: 52s - loss: 0.0693 - accuracy: 0.9212 - jacard_coef: 0.0031 80/446 [====>.........................] - ETA: 52s - loss: 0.0692 - accuracy: 0.9215 - jacard_coef: 0.0031 81/446 [====>.........................] - ETA: 52s - loss: 0.0694 - accuracy: 0.9214 - jacard_coef: 0.0030 82/446 [====>.........................] - ETA: 51s - loss: 0.0690 - accuracy: 0.9220 - jacard_coef: 0.0030 83/446 [====>.........................] - ETA: 51s - loss: 0.0690 - accuracy: 0.9221 - jacard_coef: 0.0030 84/446 [====>.........................] - ETA: 51s - loss: 0.0685 - accuracy: 0.9229 - jacard_coef: 0.0029 85/446 [====>.........................] - ETA: 51s - loss: 0.0686 - accuracy: 0.9229 - jacard_coef: 0.0029 86/446 [====>.........................] - ETA: 51s - loss: 0.0686 - accuracy: 0.9230 - jacard_coef: 0.0029 87/446 [====>.........................] - ETA: 51s - loss: 0.0684 - accuracy: 0.9234 - jacard_coef: 0.0028 88/446 [====>.........................] - ETA: 51s - loss: 0.0681 - accuracy: 0.9240 - jacard_coef: 0.0028 89/446 [====>.........................] - ETA: 50s - loss: 0.0680 - accuracy: 0.9242 - jacard_coef: 0.0028 90/446 [=====>........................] - ETA: 50s - loss: 0.0678 - accuracy: 0.9245 - jacard_coef: 0.0027 91/446 [=====>........................] - ETA: 50s - loss: 0.0678 - accuracy: 0.9247 - jacard_coef: 0.0027 92/446 [=====>........................] - ETA: 50s - loss: 0.0679 - accuracy: 0.9246 - jacard_coef: 0.0027 93/446 [=====>........................] - ETA: 50s - loss: 0.0675 - accuracy: 0.9253 - jacard_coef: 0.0026 94/446 [=====>........................] - ETA: 50s - loss: 0.0676 - accuracy: 0.9253 - jacard_coef: 0.0026 95/446 [=====>........................] - ETA: 49s - loss: 0.0677 - accuracy: 0.9253 - jacard_coef: 0.0026 96/446 [=====>........................] - ETA: 49s - loss: 0.0678 - accuracy: 0.9252 - jacard_coef: 0.0026 97/446 [=====>........................] - ETA: 49s - loss: 0.0677 - accuracy: 0.9255 - jacard_coef: 0.0025 98/446 [=====>........................] - ETA: 49s - loss: 0.0676 - accuracy: 0.9256 - jacard_coef: 0.0025 99/446 [=====>........................] - ETA: 49s - loss: 0.0674 - accuracy: 0.9260 - jacard_coef: 0.0025100/446 [=====>........................] - ETA: 49s - loss: 0.0669 - accuracy: 0.9268 - jacard_coef: 0.0025101/446 [=====>........................] - ETA: 49s - loss: 0.0666 - accuracy: 0.9273 - jacard_coef: 0.0024102/446 [=====>........................] - ETA: 49s - loss: 0.0667 - accuracy: 0.9272 - jacard_coef: 0.0024103/446 [=====>........................] - ETA: 48s - loss: 0.0666 - accuracy: 0.9274 - jacard_coef: 0.0024104/446 [=====>........................] - ETA: 48s - loss: 0.0669 - accuracy: 0.9271 - jacard_coef: 0.0024105/446 [======>.......................] - ETA: 48s - loss: 0.0669 - accuracy: 0.9272 - jacard_coef: 0.0023106/446 [======>.......................] - ETA: 48s - loss: 0.0669 - accuracy: 0.9274 - jacard_coef: 0.0023107/446 [======>.......................] - ETA: 48s - loss: 0.0669 - accuracy: 0.9273 - jacard_coef: 0.0023108/446 [======>.......................] - ETA: 48s - loss: 0.0668 - accuracy: 0.9276 - jacard_coef: 0.0023109/446 [======>.......................] - ETA: 48s - loss: 0.0664 - accuracy: 0.9282 - jacard_coef: 0.0023110/446 [======>.......................] - ETA: 48s - loss: 0.0662 - accuracy: 0.9286 - jacard_coef: 0.0022111/446 [======>.......................] - ETA: 48s - loss: 0.0661 - accuracy: 0.9288 - jacard_coef: 0.0022112/446 [======>.......................] - ETA: 48s - loss: 0.0660 - accuracy: 0.9289 - jacard_coef: 0.0022113/446 [======>.......................] - ETA: 48s - loss: 0.0659 - accuracy: 0.9292 - jacard_coef: 0.0022114/446 [======>.......................] - ETA: 47s - loss: 0.0660 - accuracy: 0.9291 - jacard_coef: 0.0022115/446 [======>.......................] - ETA: 47s - loss: 0.0659 - accuracy: 0.9294 - jacard_coef: 0.0021116/446 [======>.......................] - ETA: 47s - loss: 0.0660 - accuracy: 0.9292 - jacard_coef: 0.0021117/446 [======>.......................] - ETA: 47s - loss: 0.0661 - accuracy: 0.9292 - jacard_coef: 0.0021118/446 [======>.......................] - ETA: 47s - loss: 0.0659 - accuracy: 0.9295 - jacard_coef: 0.0021119/446 [=======>......................] - ETA: 47s - loss: 0.0659 - accuracy: 0.9296 - jacard_coef: 0.0021120/446 [=======>......................] - ETA: 47s - loss: 0.0661 - accuracy: 0.9293 - jacard_coef: 0.0020121/446 [=======>......................] - ETA: 47s - loss: 0.0660 - accuracy: 0.9296 - jacard_coef: 0.0020122/446 [=======>......................] - ETA: 47s - loss: 0.0657 - accuracy: 0.9300 - jacard_coef: 0.0020123/446 [=======>......................] - ETA: 46s - loss: 0.0657 - accuracy: 0.9300 - jacard_coef: 0.0020124/446 [=======>......................] - ETA: 46s - loss: 0.0657 - accuracy: 0.9302 - jacard_coef: 0.0020125/446 [=======>......................] - ETA: 46s - loss: 0.0654 - accuracy: 0.9306 - jacard_coef: 0.0020126/446 [=======>......................] - ETA: 46s - loss: 0.0655 - accuracy: 0.9305 - jacard_coef: 0.0020127/446 [=======>......................] - ETA: 46s - loss: 0.0653 - accuracy: 0.9308 - jacard_coef: 0.0019128/446 [=======>......................] - ETA: 46s - loss: 0.0654 - accuracy: 0.9307 - jacard_coef: 0.0019129/446 [=======>......................] - ETA: 46s - loss: 0.0651 - accuracy: 0.9312 - jacard_coef: 0.0019130/446 [=======>......................] - ETA: 46s - loss: 0.0650 - accuracy: 0.9314 - jacard_coef: 0.0019131/446 [=======>......................] - ETA: 46s - loss: 0.0649 - accuracy: 0.9316 - jacard_coef: 0.0019132/446 [=======>......................] - ETA: 45s - loss: 0.0649 - accuracy: 0.9317 - jacard_coef: 0.0019133/446 [=======>......................] - ETA: 45s - loss: 0.0649 - accuracy: 0.9317 - jacard_coef: 0.0018134/446 [========>.....................] - ETA: 45s - loss: 0.0650 - accuracy: 0.9316 - jacard_coef: 0.0018135/446 [========>.....................] - ETA: 45s - loss: 0.0648 - accuracy: 0.9319 - jacard_coef: 0.0018136/446 [========>.....................] - ETA: 45s - loss: 0.0646 - accuracy: 0.9323 - jacard_coef: 0.0018137/446 [========>.....................] - ETA: 45s - loss: 0.0644 - accuracy: 0.9326 - jacard_coef: 0.0018138/446 [========>.....................] - ETA: 45s - loss: 0.0643 - accuracy: 0.9327 - jacard_coef: 0.0018139/446 [========>.....................] - ETA: 45s - loss: 0.0641 - accuracy: 0.9330 - jacard_coef: 0.0018140/446 [========>.....................] - ETA: 45s - loss: 0.0640 - accuracy: 0.9331 - jacard_coef: 0.0018141/446 [========>.....................] - ETA: 44s - loss: 0.0640 - accuracy: 0.9333 - jacard_coef: 0.0017142/446 [========>.....................] - ETA: 44s - loss: 0.0640 - accuracy: 0.9333 - jacard_coef: 0.0017143/446 [========>.....................] - ETA: 44s - loss: 0.0642 - accuracy: 0.9331 - jacard_coef: 0.0017144/446 [========>.....................] - ETA: 44s - loss: 0.0643 - accuracy: 0.9330 - jacard_coef: 0.0017145/446 [========>.....................] - ETA: 44s - loss: 0.0645 - accuracy: 0.9329 - jacard_coef: 0.0017146/446 [========>.....................] - ETA: 44s - loss: 0.0643 - accuracy: 0.9332 - jacard_coef: 0.0017147/446 [========>.....................] - ETA: 44s - loss: 0.0641 - accuracy: 0.9335 - jacard_coef: 0.0017148/446 [========>.....................] - ETA: 44s - loss: 0.0641 - accuracy: 0.9335 - jacard_coef: 0.0017149/446 [=========>....................] - ETA: 43s - loss: 0.0641 - accuracy: 0.9336 - jacard_coef: 0.0016150/446 [=========>....................] - ETA: 43s - loss: 0.0641 - accuracy: 0.9336 - jacard_coef: 0.0016151/446 [=========>....................] - ETA: 43s - loss: 0.0641 - accuracy: 0.9336 - jacard_coef: 0.0016152/446 [=========>....................] - ETA: 43s - loss: 0.0641 - accuracy: 0.9337 - jacard_coef: 0.0016153/446 [=========>....................] - ETA: 43s - loss: 0.0639 - accuracy: 0.9340 - jacard_coef: 0.0016154/446 [=========>....................] - ETA: 43s - loss: 0.0640 - accuracy: 0.9338 - jacard_coef: 0.0016155/446 [=========>....................] - ETA: 43s - loss: 0.0640 - accuracy: 0.9340 - jacard_coef: 0.0016156/446 [=========>....................] - ETA: 43s - loss: 0.0640 - accuracy: 0.9340 - jacard_coef: 0.0016157/446 [=========>....................] - ETA: 42s - loss: 0.0641 - accuracy: 0.9338 - jacard_coef: 0.0016158/446 [=========>....................] - ETA: 42s - loss: 0.0641 - accuracy: 0.9339 - jacard_coef: 0.0016159/446 [=========>....................] - ETA: 42s - loss: 0.0641 - accuracy: 0.9338 - jacard_coef: 0.0015160/446 [=========>....................] - ETA: 42s - loss: 0.0640 - accuracy: 0.9340 - jacard_coef: 0.0015161/446 [=========>....................] - ETA: 42s - loss: 0.0641 - accuracy: 0.9339 - jacard_coef: 0.0015162/446 [=========>....................] - ETA: 42s - loss: 0.0640 - accuracy: 0.9341 - jacard_coef: 0.0015163/446 [=========>....................] - ETA: 42s - loss: 0.0639 - accuracy: 0.9343 - jacard_coef: 0.0015164/446 [==========>...................] - ETA: 41s - loss: 0.0638 - accuracy: 0.9344 - jacard_coef: 0.0015165/446 [==========>...................] - ETA: 41s - loss: 0.0637 - accuracy: 0.9347 - jacard_coef: 0.0015166/446 [==========>...................] - ETA: 41s - loss: 0.0637 - accuracy: 0.9346 - jacard_coef: 0.0015167/446 [==========>...................] - ETA: 41s - loss: 0.0640 - accuracy: 0.9343 - jacard_coef: 0.0015168/446 [==========>...................] - ETA: 41s - loss: 0.0643 - accuracy: 0.9339 - jacard_coef: 0.0015169/446 [==========>...................] - ETA: 41s - loss: 0.0641 - accuracy: 0.9342 - jacard_coef: 0.0015170/446 [==========>...................] - ETA: 41s - loss: 0.0642 - accuracy: 0.9342 - jacard_coef: 0.0014171/446 [==========>...................] - ETA: 41s - loss: 0.0643 - accuracy: 0.9340 - jacard_coef: 0.0014172/446 [==========>...................] - ETA: 40s - loss: 0.0645 - accuracy: 0.9337 - jacard_coef: 0.0014173/446 [==========>...................] - ETA: 40s - loss: 0.0643 - accuracy: 0.9340 - jacard_coef: 0.0014174/446 [==========>...................] - ETA: 40s - loss: 0.0643 - accuracy: 0.9341 - jacard_coef: 0.0014175/446 [==========>...................] - ETA: 40s - loss: 0.0641 - accuracy: 0.9343 - jacard_coef: 0.0014176/446 [==========>...................] - ETA: 40s - loss: 0.0641 - accuracy: 0.9345 - jacard_coef: 0.0014177/446 [==========>...................] - ETA: 40s - loss: 0.0640 - accuracy: 0.9346 - jacard_coef: 0.0014178/446 [==========>...................] - ETA: 40s - loss: 0.0639 - accuracy: 0.9348 - jacard_coef: 0.0014179/446 [===========>..................] - ETA: 39s - loss: 0.0639 - accuracy: 0.9349 - jacard_coef: 0.0014180/446 [===========>..................] - ETA: 39s - loss: 0.0638 - accuracy: 0.9350 - jacard_coef: 0.0014181/446 [===========>..................] - ETA: 39s - loss: 0.0637 - accuracy: 0.9352 - jacard_coef: 0.0014182/446 [===========>..................] - ETA: 39s - loss: 0.0635 - accuracy: 0.9355 - jacard_coef: 0.0014183/446 [===========>..................] - ETA: 39s - loss: 0.0634 - accuracy: 0.9357 - jacard_coef: 0.0013184/446 [===========>..................] - ETA: 39s - loss: 0.0632 - accuracy: 0.9359 - jacard_coef: 0.0013185/446 [===========>..................] - ETA: 39s - loss: 0.0632 - accuracy: 0.9359 - jacard_coef: 0.0013186/446 [===========>..................] - ETA: 38s - loss: 0.0630 - accuracy: 0.9362 - jacard_coef: 0.0013187/446 [===========>..................] - ETA: 38s - loss: 0.0629 - accuracy: 0.9364 - jacard_coef: 0.0013188/446 [===========>..................] - ETA: 38s - loss: 0.0629 - accuracy: 0.9364 - jacard_coef: 0.0013189/446 [===========>..................] - ETA: 38s - loss: 0.0627 - accuracy: 0.9366 - jacard_coef: 0.0013190/446 [===========>..................] - ETA: 38s - loss: 0.0630 - accuracy: 0.9364 - jacard_coef: 0.0013191/446 [===========>..................] - ETA: 38s - loss: 0.0631 - accuracy: 0.9364 - jacard_coef: 0.0013192/446 [===========>..................] - ETA: 38s - loss: 0.0632 - accuracy: 0.9363 - jacard_coef: 0.0013193/446 [===========>..................] - ETA: 38s - loss: 0.0635 - accuracy: 0.9359 - jacard_coef: 0.0013194/446 [============>.................] - ETA: 37s - loss: 0.0636 - accuracy: 0.9359 - jacard_coef: 0.0013195/446 [============>.................] - ETA: 37s - loss: 0.0639 - accuracy: 0.9355 - jacard_coef: 0.0013196/446 [============>.................] - ETA: 37s - loss: 0.0638 - accuracy: 0.9357 - jacard_coef: 0.0013197/446 [============>.................] - ETA: 37s - loss: 0.0639 - accuracy: 0.9356 - jacard_coef: 0.0012198/446 [============>.................] - ETA: 37s - loss: 0.0640 - accuracy: 0.9353 - jacard_coef: 0.0012199/446 [============>.................] - ETA: 37s - loss: 0.0641 - accuracy: 0.9352 - jacard_coef: 0.0012200/446 [============>.................] - ETA: 37s - loss: 0.0641 - accuracy: 0.9354 - jacard_coef: 0.0012201/446 [============>.................] - ETA: 36s - loss: 0.0641 - accuracy: 0.9354 - jacard_coef: 0.0012202/446 [============>.................] - ETA: 36s - loss: 0.0641 - accuracy: 0.9355 - jacard_coef: 0.0012203/446 [============>.................] - ETA: 36s - loss: 0.0641 - accuracy: 0.9354 - jacard_coef: 0.0012204/446 [============>.................] - ETA: 36s - loss: 0.0643 - accuracy: 0.9352 - jacard_coef: 0.0012205/446 [============>.................] - ETA: 36s - loss: 0.0643 - accuracy: 0.9353 - jacard_coef: 0.0012206/446 [============>.................] - ETA: 36s - loss: 0.0643 - accuracy: 0.9352 - jacard_coef: 0.0012207/446 [============>.................] - ETA: 36s - loss: 0.0643 - accuracy: 0.9353 - jacard_coef: 0.0012208/446 [============>.................] - ETA: 35s - loss: 0.0643 - accuracy: 0.9354 - jacard_coef: 0.0012209/446 [=============>................] - ETA: 35s - loss: 0.0643 - accuracy: 0.9354 - jacard_coef: 0.0012210/446 [=============>................] - ETA: 35s - loss: 0.0642 - accuracy: 0.9355 - jacard_coef: 0.0012211/446 [=============>................] - ETA: 35s - loss: 0.0642 - accuracy: 0.9356 - jacard_coef: 0.0012212/446 [=============>................] - ETA: 35s - loss: 0.0642 - accuracy: 0.9357 - jacard_coef: 0.0012213/446 [=============>................] - ETA: 35s - loss: 0.0640 - accuracy: 0.9359 - jacard_coef: 0.0012214/446 [=============>................] - ETA: 35s - loss: 0.0641 - accuracy: 0.9359 - jacard_coef: 0.0011215/446 [=============>................] - ETA: 34s - loss: 0.0641 - accuracy: 0.9359 - jacard_coef: 0.0011216/446 [=============>................] - ETA: 34s - loss: 0.0643 - accuracy: 0.9357 - jacard_coef: 0.0011217/446 [=============>................] - ETA: 34s - loss: 0.0642 - accuracy: 0.9357 - jacard_coef: 0.0011218/446 [=============>................] - ETA: 34s - loss: 0.0642 - accuracy: 0.9357 - jacard_coef: 0.0011219/446 [=============>................] - ETA: 34s - loss: 0.0642 - accuracy: 0.9358 - jacard_coef: 0.0011220/446 [=============>................] - ETA: 34s - loss: 0.0641 - accuracy: 0.9360 - jacard_coef: 0.0011221/446 [=============>................] - ETA: 34s - loss: 0.0639 - accuracy: 0.9362 - jacard_coef: 0.0011222/446 [=============>................] - ETA: 33s - loss: 0.0639 - accuracy: 0.9362 - jacard_coef: 0.0011223/446 [==============>...............] - ETA: 33s - loss: 0.0639 - accuracy: 0.9363 - jacard_coef: 0.0011224/446 [==============>...............] - ETA: 33s - loss: 0.0639 - accuracy: 0.9362 - jacard_coef: 0.0011225/446 [==============>...............] - ETA: 33s - loss: 0.0639 - accuracy: 0.9363 - jacard_coef: 0.0011226/446 [==============>...............] - ETA: 33s - loss: 0.0638 - accuracy: 0.9364 - jacard_coef: 0.0011227/446 [==============>...............] - ETA: 33s - loss: 0.0641 - accuracy: 0.9361 - jacard_coef: 0.0011228/446 [==============>...............] - ETA: 33s - loss: 0.0641 - accuracy: 0.9361 - jacard_coef: 0.0011229/446 [==============>...............] - ETA: 32s - loss: 0.0641 - accuracy: 0.9360 - jacard_coef: 0.0011230/446 [==============>...............] - ETA: 32s - loss: 0.0642 - accuracy: 0.9360 - jacard_coef: 0.0011231/446 [==============>...............] - ETA: 32s - loss: 0.0643 - accuracy: 0.9358 - jacard_coef: 0.0011232/446 [==============>...............] - ETA: 32s - loss: 0.0643 - accuracy: 0.9359 - jacard_coef: 0.0011233/446 [==============>...............] - ETA: 32s - loss: 0.0643 - accuracy: 0.9359 - jacard_coef: 0.0011234/446 [==============>...............] - ETA: 32s - loss: 0.0643 - accuracy: 0.9359 - jacard_coef: 0.0011235/446 [==============>...............] - ETA: 32s - loss: 0.0643 - accuracy: 0.9359 - jacard_coef: 0.0010236/446 [==============>...............] - ETA: 31s - loss: 0.0643 - accuracy: 0.9360 - jacard_coef: 0.0010237/446 [==============>...............] - ETA: 31s - loss: 0.0642 - accuracy: 0.9361 - jacard_coef: 0.0010238/446 [===============>..............] - ETA: 31s - loss: 0.0642 - accuracy: 0.9361 - jacard_coef: 0.0010239/446 [===============>..............] - ETA: 31s - loss: 0.0642 - accuracy: 0.9361 - jacard_coef: 0.0010240/446 [===============>..............] - ETA: 31s - loss: 0.0643 - accuracy: 0.9360 - jacard_coef: 0.0010241/446 [===============>..............] - ETA: 31s - loss: 0.0641 - accuracy: 0.9362 - jacard_coef: 0.0010242/446 [===============>..............] - ETA: 31s - loss: 0.0641 - accuracy: 0.9362 - jacard_coef: 0.0010243/446 [===============>..............] - ETA: 30s - loss: 0.0640 - accuracy: 0.9365 - jacard_coef: 0.0010244/446 [===============>..............] - ETA: 30s - loss: 0.0641 - accuracy: 0.9364 - jacard_coef: 0.0010245/446 [===============>..............] - ETA: 30s - loss: 0.0639 - accuracy: 0.9365 - jacard_coef: 0.0010246/446 [===============>..............] - ETA: 30s - loss: 0.0640 - accuracy: 0.9365 - jacard_coef: 9.9885e-04247/446 [===============>..............] - ETA: 30s - loss: 0.0639 - accuracy: 0.9367 - jacard_coef: 9.9481e-04248/446 [===============>..............] - ETA: 30s - loss: 0.0640 - accuracy: 0.9365 - jacard_coef: 9.9080e-04249/446 [===============>..............] - ETA: 29s - loss: 0.0641 - accuracy: 0.9364 - jacard_coef: 9.8682e-04250/446 [===============>..............] - ETA: 29s - loss: 0.0640 - accuracy: 0.9365 - jacard_coef: 9.8287e-04251/446 [===============>..............] - ETA: 29s - loss: 0.0640 - accuracy: 0.9366 - jacard_coef: 9.7895e-04252/446 [===============>..............] - ETA: 29s - loss: 0.0640 - accuracy: 0.9366 - jacard_coef: 9.7507e-04253/446 [================>.............] - ETA: 29s - loss: 0.0640 - accuracy: 0.9366 - jacard_coef: 9.7122e-04254/446 [================>.............] - ETA: 29s - loss: 0.0641 - accuracy: 0.9365 - jacard_coef: 9.6739e-04255/446 [================>.............] - ETA: 29s - loss: 0.0639 - accuracy: 0.9367 - jacard_coef: 9.6360e-04256/446 [================>.............] - ETA: 28s - loss: 0.0639 - accuracy: 0.9367 - jacard_coef: 9.5983e-04257/446 [================>.............] - ETA: 28s - loss: 0.0639 - accuracy: 0.9367 - jacard_coef: 9.5610e-04258/446 [================>.............] - ETA: 28s - loss: 0.0640 - accuracy: 0.9366 - jacard_coef: 9.5239e-04259/446 [================>.............] - ETA: 28s - loss: 0.0640 - accuracy: 0.9366 - jacard_coef: 9.4872e-04260/446 [================>.............] - ETA: 28s - loss: 0.0640 - accuracy: 0.9366 - jacard_coef: 9.4507e-04261/446 [================>.............] - ETA: 28s - loss: 0.0639 - accuracy: 0.9367 - jacard_coef: 9.4145e-04262/446 [================>.............] - ETA: 28s - loss: 0.0639 - accuracy: 0.9367 - jacard_coef: 9.3785e-04263/446 [================>.............] - ETA: 27s - loss: 0.0639 - accuracy: 0.9368 - jacard_coef: 9.3429e-04264/446 [================>.............] - ETA: 27s - loss: 0.0638 - accuracy: 0.9369 - jacard_coef: 9.3075e-04265/446 [================>.............] - ETA: 27s - loss: 0.0639 - accuracy: 0.9368 - jacard_coef: 9.2724e-04266/446 [================>.............] - ETA: 27s - loss: 0.0640 - accuracy: 0.9367 - jacard_coef: 9.2375e-04267/446 [================>.............] - ETA: 27s - loss: 0.0639 - accuracy: 0.9368 - jacard_coef: 9.2029e-04268/446 [=================>............] - ETA: 27s - loss: 0.0638 - accuracy: 0.9369 - jacard_coef: 9.1686e-04269/446 [=================>............] - ETA: 27s - loss: 0.0639 - accuracy: 0.9369 - jacard_coef: 9.1345e-04270/446 [=================>............] - ETA: 26s - loss: 0.0638 - accuracy: 0.9370 - jacard_coef: 9.1006e-04271/446 [=================>............] - ETA: 26s - loss: 0.0639 - accuracy: 0.9369 - jacard_coef: 9.0671e-04272/446 [=================>............] - ETA: 26s - loss: 0.0639 - accuracy: 0.9369 - jacard_coef: 9.0337e-04273/446 [=================>............] - ETA: 26s - loss: 0.0639 - accuracy: 0.9368 - jacard_coef: 9.0006e-04274/446 [=================>............] - ETA: 26s - loss: 0.0639 - accuracy: 0.9368 - jacard_coef: 8.9678e-04275/446 [=================>............] - ETA: 26s - loss: 0.0641 - accuracy: 0.9366 - jacard_coef: 8.9352e-04276/446 [=================>............] - ETA: 25s - loss: 0.0640 - accuracy: 0.9368 - jacard_coef: 8.9028e-04277/446 [=================>............] - ETA: 25s - loss: 0.0639 - accuracy: 0.9369 - jacard_coef: 8.8707e-04278/446 [=================>............] - ETA: 25s - loss: 0.0641 - accuracy: 0.9366 - jacard_coef: 8.8388e-04279/446 [=================>............] - ETA: 25s - loss: 0.0641 - accuracy: 0.9366 - jacard_coef: 8.8071e-04280/446 [=================>............] - ETA: 25s - loss: 0.0641 - accuracy: 0.9366 - jacard_coef: 8.7756e-04281/446 [=================>............] - ETA: 25s - loss: 0.0642 - accuracy: 0.9365 - jacard_coef: 8.7444e-04282/446 [=================>............] - ETA: 25s - loss: 0.0642 - accuracy: 0.9365 - jacard_coef: 8.7134e-04283/446 [==================>...........] - ETA: 24s - loss: 0.0641 - accuracy: 0.9366 - jacard_coef: 8.6826e-04284/446 [==================>...........] - ETA: 24s - loss: 0.0641 - accuracy: 0.9366 - jacard_coef: 8.6520e-04285/446 [==================>...........] - ETA: 24s - loss: 0.0641 - accuracy: 0.9367 - jacard_coef: 8.6217e-04286/446 [==================>...........] - ETA: 24s - loss: 0.0641 - accuracy: 0.9367 - jacard_coef: 8.5915e-04287/446 [==================>...........] - ETA: 24s - loss: 0.0642 - accuracy: 0.9365 - jacard_coef: 8.5616e-04288/446 [==================>...........] - ETA: 24s - loss: 0.0643 - accuracy: 0.9364 - jacard_coef: 8.5319e-04289/446 [==================>...........] - ETA: 24s - loss: 0.0643 - accuracy: 0.9364 - jacard_coef: 8.5023e-04290/446 [==================>...........] - ETA: 23s - loss: 0.0644 - accuracy: 0.9363 - jacard_coef: 8.4730e-04291/446 [==================>...........] - ETA: 23s - loss: 0.0643 - accuracy: 0.9364 - jacard_coef: 8.4439e-04292/446 [==================>...........] - ETA: 23s - loss: 0.0643 - accuracy: 0.9364 - jacard_coef: 8.4150e-04293/446 [==================>...........] - ETA: 23s - loss: 0.0643 - accuracy: 0.9363 - jacard_coef: 8.3863e-04294/446 [==================>...........] - ETA: 23s - loss: 0.0643 - accuracy: 0.9364 - jacard_coef: 8.3577e-04295/446 [==================>...........] - ETA: 23s - loss: 0.0642 - accuracy: 0.9365 - jacard_coef: 8.3294e-04296/446 [==================>...........] - ETA: 22s - loss: 0.0641 - accuracy: 0.9367 - jacard_coef: 8.3013e-04297/446 [==================>...........] - ETA: 22s - loss: 0.0641 - accuracy: 0.9368 - jacard_coef: 8.2733e-04298/446 [===================>..........] - ETA: 22s - loss: 0.0640 - accuracy: 0.9369 - jacard_coef: 8.2456e-04299/446 [===================>..........] - ETA: 22s - loss: 0.0639 - accuracy: 0.9370 - jacard_coef: 8.2180e-04300/446 [===================>..........] - ETA: 22s - loss: 0.0639 - accuracy: 0.9370 - jacard_coef: 8.1906e-04301/446 [===================>..........] - ETA: 22s - loss: 0.0638 - accuracy: 0.9372 - jacard_coef: 8.1634e-04302/446 [===================>..........] - ETA: 22s - loss: 0.0638 - accuracy: 0.9371 - jacard_coef: 8.1363e-04303/446 [===================>..........] - ETA: 21s - loss: 0.0639 - accuracy: 0.9371 - jacard_coef: 8.1095e-04304/446 [===================>..........] - ETA: 21s - loss: 0.0640 - accuracy: 0.9369 - jacard_coef: 8.0828e-04305/446 [===================>..........] - ETA: 21s - loss: 0.0640 - accuracy: 0.9370 - jacard_coef: 8.0563e-04306/446 [===================>..........] - ETA: 21s - loss: 0.0639 - accuracy: 0.9371 - jacard_coef: 8.0300e-04307/446 [===================>..........] - ETA: 21s - loss: 0.0639 - accuracy: 0.9371 - jacard_coef: 8.0038e-04308/446 [===================>..........] - ETA: 21s - loss: 0.0640 - accuracy: 0.9371 - jacard_coef: 7.9778e-04309/446 [===================>..........] - ETA: 21s - loss: 0.0640 - accuracy: 0.9370 - jacard_coef: 7.9520e-04310/446 [===================>..........] - ETA: 20s - loss: 0.0639 - accuracy: 0.9372 - jacard_coef: 7.9264e-04311/446 [===================>..........] - ETA: 20s - loss: 0.0639 - accuracy: 0.9372 - jacard_coef: 7.9009e-04312/446 [===================>..........] - ETA: 20s - loss: 0.0639 - accuracy: 0.9372 - jacard_coef: 7.8756e-04313/446 [====================>.........] - ETA: 20s - loss: 0.0639 - accuracy: 0.9372 - jacard_coef: 7.8504e-04314/446 [====================>.........] - ETA: 20s - loss: 0.0638 - accuracy: 0.9374 - jacard_coef: 7.8254e-04315/446 [====================>.........] - ETA: 20s - loss: 0.0638 - accuracy: 0.9373 - jacard_coef: 7.8006e-04316/446 [====================>.........] - ETA: 19s - loss: 0.0638 - accuracy: 0.9373 - jacard_coef: 7.7759e-04317/446 [====================>.........] - ETA: 19s - loss: 0.0638 - accuracy: 0.9373 - jacard_coef: 7.7513e-04318/446 [====================>.........] - ETA: 19s - loss: 0.0638 - accuracy: 0.9374 - jacard_coef: 7.7270e-04319/446 [====================>.........] - ETA: 19s - loss: 0.0637 - accuracy: 0.9374 - jacard_coef: 7.7027e-04320/446 [====================>.........] - ETA: 19s - loss: 0.0637 - accuracy: 0.9375 - jacard_coef: 7.6787e-04321/446 [====================>.........] - ETA: 19s - loss: 0.0638 - accuracy: 0.9374 - jacard_coef: 7.6547e-04322/446 [====================>.........] - ETA: 19s - loss: 0.0637 - accuracy: 0.9375 - jacard_coef: 7.6310e-04323/446 [====================>.........] - ETA: 18s - loss: 0.0636 - accuracy: 0.9376 - jacard_coef: 7.6074e-04324/446 [====================>.........] - ETA: 18s - loss: 0.0636 - accuracy: 0.9376 - jacard_coef: 7.5839e-04325/446 [====================>.........] - ETA: 18s - loss: 0.0637 - accuracy: 0.9375 - jacard_coef: 7.5605e-04326/446 [====================>.........] - ETA: 18s - loss: 0.0637 - accuracy: 0.9375 - jacard_coef: 7.5373e-04327/446 [====================>.........] - ETA: 18s - loss: 0.0638 - accuracy: 0.9373 - jacard_coef: 7.5143e-04328/446 [=====================>........] - ETA: 18s - loss: 0.0638 - accuracy: 0.9374 - jacard_coef: 7.4914e-04329/446 [=====================>........] - ETA: 17s - loss: 0.0637 - accuracy: 0.9375 - jacard_coef: 7.4686e-04330/446 [=====================>........] - ETA: 17s - loss: 0.0637 - accuracy: 0.9375 - jacard_coef: 7.4460e-04331/446 [=====================>........] - ETA: 17s - loss: 0.0637 - accuracy: 0.9375 - jacard_coef: 7.4235e-04332/446 [=====================>........] - ETA: 17s - loss: 0.0637 - accuracy: 0.9375 - jacard_coef: 7.4011e-04333/446 [=====================>........] - ETA: 17s - loss: 0.0637 - accuracy: 0.9375 - jacard_coef: 7.3789e-04334/446 [=====================>........] - ETA: 17s - loss: 0.0637 - accuracy: 0.9375 - jacard_coef: 7.3568e-04335/446 [=====================>........] - ETA: 17s - loss: 0.0637 - accuracy: 0.9376 - jacard_coef: 7.3348e-04336/446 [=====================>........] - ETA: 16s - loss: 0.0638 - accuracy: 0.9374 - jacard_coef: 7.3130e-04337/446 [=====================>........] - ETA: 16s - loss: 0.0638 - accuracy: 0.9373 - jacard_coef: 7.2913e-04338/446 [=====================>........] - ETA: 16s - loss: 0.0637 - accuracy: 0.9375 - jacard_coef: 7.2697e-04339/446 [=====================>........] - ETA: 16s - loss: 0.0638 - accuracy: 0.9374 - jacard_coef: 7.2483e-04340/446 [=====================>........] - ETA: 16s - loss: 0.0638 - accuracy: 0.9374 - jacard_coef: 7.2270e-04341/446 [=====================>........] - ETA: 16s - loss: 0.0638 - accuracy: 0.9373 - jacard_coef: 7.2058e-04342/446 [======================>.......] - ETA: 16s - loss: 0.0638 - accuracy: 0.9374 - jacard_coef: 7.1847e-04343/446 [======================>.......] - ETA: 15s - loss: 0.0639 - accuracy: 0.9372 - jacard_coef: 7.1638e-04344/446 [======================>.......] - ETA: 15s - loss: 0.0640 - accuracy: 0.9372 - jacard_coef: 7.1429e-04345/446 [======================>.......] - ETA: 15s - loss: 0.0640 - accuracy: 0.9371 - jacard_coef: 7.1222e-04346/446 [======================>.......] - ETA: 15s - loss: 0.0639 - accuracy: 0.9372 - jacard_coef: 7.1017e-04347/446 [======================>.......] - ETA: 15s - loss: 0.0639 - accuracy: 0.9372 - jacard_coef: 7.0812e-04348/446 [======================>.......] - ETA: 15s - loss: 0.0641 - accuracy: 0.9370 - jacard_coef: 7.0608e-04349/446 [======================>.......] - ETA: 14s - loss: 0.0640 - accuracy: 0.9371 - jacard_coef: 7.0406e-04350/446 [======================>.......] - ETA: 14s - loss: 0.0641 - accuracy: 0.9369 - jacard_coef: 7.0205e-04351/446 [======================>.......] - ETA: 14s - loss: 0.0641 - accuracy: 0.9370 - jacard_coef: 7.0005e-04352/446 [======================>.......] - ETA: 14s - loss: 0.0641 - accuracy: 0.9370 - jacard_coef: 6.9806e-04353/446 [======================>.......] - ETA: 14s - loss: 0.0641 - accuracy: 0.9370 - jacard_coef: 6.9608e-04354/446 [======================>.......] - ETA: 14s - loss: 0.0640 - accuracy: 0.9372 - jacard_coef: 6.9412e-04355/446 [======================>.......] - ETA: 14s - loss: 0.0639 - accuracy: 0.9373 - jacard_coef: 6.9216e-04356/446 [======================>.......] - ETA: 13s - loss: 0.0638 - accuracy: 0.9374 - jacard_coef: 6.9022e-04357/446 [=======================>......] - ETA: 13s - loss: 0.0640 - accuracy: 0.9372 - jacard_coef: 6.8828e-04358/446 [=======================>......] - ETA: 13s - loss: 0.0639 - accuracy: 0.9373 - jacard_coef: 6.8636e-04359/446 [=======================>......] - ETA: 13s - loss: 0.0641 - accuracy: 0.9371 - jacard_coef: 6.8445e-04360/446 [=======================>......] - ETA: 13s - loss: 0.0641 - accuracy: 0.9371 - jacard_coef: 6.8255e-04361/446 [=======================>......] - ETA: 13s - loss: 0.0640 - accuracy: 0.9371 - jacard_coef: 6.8066e-04362/446 [=======================>......] - ETA: 12s - loss: 0.0640 - accuracy: 0.9371 - jacard_coef: 6.7878e-04363/446 [=======================>......] - ETA: 12s - loss: 0.0640 - accuracy: 0.9372 - jacard_coef: 6.7691e-04364/446 [=======================>......] - ETA: 12s - loss: 0.0639 - accuracy: 0.9373 - jacard_coef: 6.7505e-04365/446 [=======================>......] - ETA: 12s - loss: 0.0639 - accuracy: 0.9373 - jacard_coef: 6.7320e-04366/446 [=======================>......] - ETA: 12s - loss: 0.0640 - accuracy: 0.9372 - jacard_coef: 6.7136e-04367/446 [=======================>......] - ETA: 12s - loss: 0.0640 - accuracy: 0.9373 - jacard_coef: 6.6953e-04368/446 [=======================>......] - ETA: 12s - loss: 0.0639 - accuracy: 0.9374 - jacard_coef: 6.6771e-04369/446 [=======================>......] - ETA: 11s - loss: 0.0639 - accuracy: 0.9373 - jacard_coef: 6.6590e-04370/446 [=======================>......] - ETA: 11s - loss: 0.0640 - accuracy: 0.9372 - jacard_coef: 6.6410e-04371/446 [=======================>......] - ETA: 11s - loss: 0.0639 - accuracy: 0.9373 - jacard_coef: 6.6231e-04372/446 [========================>.....] - ETA: 11s - loss: 0.0640 - accuracy: 0.9372 - jacard_coef: 6.6053e-04373/446 [========================>.....] - ETA: 11s - loss: 0.0639 - accuracy: 0.9374 - jacard_coef: 6.5876e-04374/446 [========================>.....] - ETA: 11s - loss: 0.0639 - accuracy: 0.9374 - jacard_coef: 6.5700e-04375/446 [========================>.....] - ETA: 10s - loss: 0.0639 - accuracy: 0.9374 - jacard_coef: 6.5525e-04376/446 [========================>.....] - ETA: 10s - loss: 0.0639 - accuracy: 0.9374 - jacard_coef: 6.5350e-04377/446 [========================>.....] - ETA: 10s - loss: 0.0639 - accuracy: 0.9374 - jacard_coef: 6.5177e-04378/446 [========================>.....] - ETA: 10s - loss: 0.0639 - accuracy: 0.9373 - jacard_coef: 6.5005e-04379/446 [========================>.....] - ETA: 10s - loss: 0.0639 - accuracy: 0.9374 - jacard_coef: 6.4833e-04380/446 [========================>.....] - ETA: 10s - loss: 0.0639 - accuracy: 0.9374 - jacard_coef: 6.4662e-04381/446 [========================>.....] - ETA: 10s - loss: 0.0638 - accuracy: 0.9375 - jacard_coef: 6.4493e-04382/446 [========================>.....] - ETA: 9s - loss: 0.0638 - accuracy: 0.9375 - jacard_coef: 6.4324e-04 383/446 [========================>.....] - ETA: 9s - loss: 0.0638 - accuracy: 0.9375 - jacard_coef: 6.4156e-04384/446 [========================>.....] - ETA: 9s - loss: 0.0638 - accuracy: 0.9375 - jacard_coef: 6.3989e-04385/446 [========================>.....] - ETA: 9s - loss: 0.0637 - accuracy: 0.9376 - jacard_coef: 6.3823e-04386/446 [========================>.....] - ETA: 9s - loss: 0.0636 - accuracy: 0.9377 - jacard_coef: 6.3657e-04387/446 [=========================>....] - ETA: 9s - loss: 0.0636 - accuracy: 0.9378 - jacard_coef: 6.3493e-04388/446 [=========================>....] - ETA: 8s - loss: 0.0636 - accuracy: 0.9378 - jacard_coef: 6.3329e-04389/446 [=========================>....] - ETA: 8s - loss: 0.0637 - accuracy: 0.9377 - jacard_coef: 6.3166e-04390/446 [=========================>....] - ETA: 8s - loss: 0.0637 - accuracy: 0.9376 - jacard_coef: 6.3004e-04391/446 [=========================>....] - ETA: 8s - loss: 0.0638 - accuracy: 0.9376 - jacard_coef: 6.2843e-04392/446 [=========================>....] - ETA: 8s - loss: 0.0637 - accuracy: 0.9377 - jacard_coef: 6.2683e-04393/446 [=========================>....] - ETA: 8s - loss: 0.0637 - accuracy: 0.9377 - jacard_coef: 6.2524e-04394/446 [=========================>....] - ETA: 8s - loss: 0.0636 - accuracy: 0.9378 - jacard_coef: 6.2365e-04395/446 [=========================>....] - ETA: 7s - loss: 0.0636 - accuracy: 0.9378 - jacard_coef: 6.2207e-04396/446 [=========================>....] - ETA: 7s - loss: 0.0635 - accuracy: 0.9379 - jacard_coef: 6.2050e-04397/446 [=========================>....] - ETA: 7s - loss: 0.0635 - accuracy: 0.9380 - jacard_coef: 6.1894e-04398/446 [=========================>....] - ETA: 7s - loss: 0.0634 - accuracy: 0.9381 - jacard_coef: 6.1738e-04399/446 [=========================>....] - ETA: 7s - loss: 0.0634 - accuracy: 0.9380 - jacard_coef: 6.1583e-04400/446 [=========================>....] - ETA: 7s - loss: 0.0634 - accuracy: 0.9381 - jacard_coef: 6.1429e-04401/446 [=========================>....] - ETA: 6s - loss: 0.0634 - accuracy: 0.9381 - jacard_coef: 6.1276e-04402/446 [==========================>...] - ETA: 6s - loss: 0.0635 - accuracy: 0.9380 - jacard_coef: 6.1124e-04403/446 [==========================>...] - ETA: 6s - loss: 0.0635 - accuracy: 0.9379 - jacard_coef: 6.0972e-04404/446 [==========================>...] - ETA: 6s - loss: 0.0635 - accuracy: 0.9380 - jacard_coef: 6.0821e-04405/446 [==========================>...] - ETA: 6s - loss: 0.0635 - accuracy: 0.9379 - jacard_coef: 6.0671e-04406/446 [==========================>...] - ETA: 6s - loss: 0.0636 - accuracy: 0.9378 - jacard_coef: 6.0522e-04407/446 [==========================>...] - ETA: 6s - loss: 0.0636 - accuracy: 0.9379 - jacard_coef: 6.0373e-04408/446 [==========================>...] - ETA: 5s - loss: 0.0635 - accuracy: 0.9379 - jacard_coef: 6.0225e-04409/446 [==========================>...] - ETA: 5s - loss: 0.0635 - accuracy: 0.9379 - jacard_coef: 6.0078e-04410/446 [==========================>...] - ETA: 5s - loss: 0.0635 - accuracy: 0.9380 - jacard_coef: 5.9931e-04411/446 [==========================>...] - ETA: 5s - loss: 0.0634 - accuracy: 0.9381 - jacard_coef: 5.9785e-04412/446 [==========================>...] - ETA: 5s - loss: 0.0634 - accuracy: 0.9381 - jacard_coef: 5.9640e-04413/446 [==========================>...] - ETA: 5s - loss: 0.0634 - accuracy: 0.9381 - jacard_coef: 5.9496e-04414/446 [==========================>...] - ETA: 4s - loss: 0.0634 - accuracy: 0.9381 - jacard_coef: 5.9352e-04415/446 [==========================>...] - ETA: 4s - loss: 0.0634 - accuracy: 0.9381 - jacard_coef: 5.9209e-04416/446 [==========================>...] - ETA: 4s - loss: 0.0634 - accuracy: 0.9381 - jacard_coef: 5.9067e-04417/446 [===========================>..] - ETA: 4s - loss: 0.0634 - accuracy: 0.9382 - jacard_coef: 5.8925e-04418/446 [===========================>..] - ETA: 4s - loss: 0.0633 - accuracy: 0.9383 - jacard_coef: 5.8784e-04419/446 [===========================>..] - ETA: 4s - loss: 0.0633 - accuracy: 0.9383 - jacard_coef: 5.8644e-04420/446 [===========================>..] - ETA: 4s - loss: 0.0633 - accuracy: 0.9383 - jacard_coef: 5.8504e-04421/446 [===========================>..] - ETA: 3s - loss: 0.0633 - accuracy: 0.9383 - jacard_coef: 5.8365e-04422/446 [===========================>..] - ETA: 3s - loss: 0.0632 - accuracy: 0.9384 - jacard_coef: 5.8227e-04423/446 [===========================>..] - ETA: 3s - loss: 0.0632 - accuracy: 0.9384 - jacard_coef: 5.8089e-04424/446 [===========================>..] - ETA: 3s - loss: 0.0632 - accuracy: 0.9384 - jacard_coef: 5.7952e-04425/446 [===========================>..] - ETA: 3s - loss: 0.0631 - accuracy: 0.9385 - jacard_coef: 5.7816e-04426/446 [===========================>..] - ETA: 3s - loss: 0.0632 - accuracy: 0.9385 - jacard_coef: 5.7680e-04427/446 [===========================>..] - ETA: 2s - loss: 0.0631 - accuracy: 0.9386 - jacard_coef: 5.7545e-04428/446 [===========================>..] - ETA: 2s - loss: 0.0630 - accuracy: 0.9386 - jacard_coef: 5.7411e-04429/446 [===========================>..] - ETA: 2s - loss: 0.0631 - accuracy: 0.9386 - jacard_coef: 5.7277e-04430/446 [===========================>..] - ETA: 2s - loss: 0.0632 - accuracy: 0.9384 - jacard_coef: 5.7144e-04431/446 [===========================>..] - ETA: 2s - loss: 0.0632 - accuracy: 0.9385 - jacard_coef: 5.7011e-04432/446 [============================>.] - ETA: 2s - loss: 0.0631 - accuracy: 0.9385 - jacard_coef: 5.6879e-04433/446 [============================>.] - ETA: 2s - loss: 0.0631 - accuracy: 0.9385 - jacard_coef: 5.6748e-04434/446 [============================>.] - ETA: 1s - loss: 0.0630 - accuracy: 0.9387 - jacard_coef: 5.6617e-04435/446 [============================>.] - ETA: 1s - loss: 0.0630 - accuracy: 0.9387 - jacard_coef: 5.6487e-04436/446 [============================>.] - ETA: 1s - loss: 0.0630 - accuracy: 0.9387 - jacard_coef: 5.6357e-04437/446 [============================>.] - ETA: 1s - loss: 0.0630 - accuracy: 0.9387 - jacard_coef: 5.6228e-04438/446 [============================>.] - ETA: 1s - loss: 0.0630 - accuracy: 0.9387 - jacard_coef: 5.6100e-04439/446 [============================>.] - ETA: 1s - loss: 0.0630 - accuracy: 0.9387 - jacard_coef: 5.5972e-04440/446 [============================>.] - ETA: 0s - loss: 0.0630 - accuracy: 0.9387 - jacard_coef: 5.5845e-04441/446 [============================>.] - ETA: 0s - loss: 0.0629 - accuracy: 0.9388 - jacard_coef: 5.5718e-04442/446 [============================>.] - ETA: 0s - loss: 0.0629 - accuracy: 0.9389 - jacard_coef: 5.5592e-04443/446 [============================>.] - ETA: 0s - loss: 0.0629 - accuracy: 0.9389 - jacard_coef: 5.5467e-04444/446 [============================>.] - ETA: 0s - loss: 0.0629 - accuracy: 0.9389 - jacard_coef: 5.5342e-04445/446 [============================>.] - ETA: 0s - loss: 0.0629 - accuracy: 0.9389 - jacard_coef: 5.5217e-04446/446 [==============================] - ETA: 0s - loss: 0.0629 - accuracy: 0.9388 - jacard_coef: 5.5094e-04
Epoch 1: val_jacard_coef improved from -inf to 0.02000, saving model to convnext_unet_training_20251001_155440/ConvNeXt_UNet_lr0.0001_bs4_3f62ce85_model.hdf5
/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(
Traceback (most recent call last):
  File "/scratch/phyzxi/unet-HPC/convnext_unet_training.py", line 319, in train_convnext_unet
    history = model.fit(
  File "/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/usr/local/lib/python3.10/dist-packages/h5py/_hl/group.py", line 183, in create_dataset
    dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds)
  File "/usr/local/lib/python3.10/dist-packages/h5py/_hl/dataset.py", line 163, in make_new_dset
    dset_id = h5d.create(parent.id, name, tid, sid, dcpl=dcpl, dapl=dapl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5d.pyx", line 137, in h5py.h5d.create
ValueError: Unable to synchronously create dataset (name already exists)

âœ— ConvNeXt-UNet training failed: Unable to synchronously create dataset (name already exists)
ðŸ§¹ Performing aggressive cache clearing for ConvNeXt-UNet...
âœ“ Aggressive cache clearing completed: 4 items cleared
âœ“ Unique session ID: c0bb1ac8

âœ— ConvNeXt-UNet training failed!

======================================================================
CONVNEXT-UNET DEDICATED TRAINING COMPLETED
======================================================================

=======================================================================
CONVNEXT-UNET TRAINING COMPLETED
=======================================================================
Job finished on Wed Oct  1 11:57:40 PM +08 2025
Exit code: 0 âœ“ SUCCESS

âœ“ ConvNeXt-UNet training completed successfully!

Generated files:
ðŸ“ Training directory:
convnext_unet_training_20251001_153225/:
total 64
drwxr-x---  2 phyzxi svuusers    0 Oct  1 23:53 .
drwxr-xr-x 29 phyzxi svuusers 5619 Oct  1 23:54 ..

convnext_unet_training_20251001_155440/:
total 170872
drwxr-x---  2 phyzxi svuusers        64 Oct  1 23:57 .
drwxr-xr-x 29 phyzxi svuusers      5619 Oct  1 23:54 ..
-rw-r-----  1 phyzxi svuusers 139480840 Oct  1 23:57 ConvNeXt_UNet_lr0.0001_bs4_3f62ce85_model.hdf5

ðŸ“Š Model and results:
-rw-r----- 1 phyzxi svuusers 139480840 Oct  1 23:57 convnext_unet_training_20251001_155440/ConvNeXt_UNet_lr0.0001_bs4_3f62ce85_model.hdf5

ðŸŽ¯ CONVNEXT-UNET PERFORMANCE SUMMARY:
======================================
No ConvNeXt-UNet results found.

ðŸ“ CONSOLE LOG SAVED: convnext_unet_training_20251001_235416_console.log

ðŸ”— NEXT STEPS:
=============
1. Analyze ConvNeXt-UNet training results
2. Compare with Swin-UNet performance (93.57%)
3. Train CoAtNet-UNet separately if needed
4. Consider ensemble methods for best performance

=========================================
CONVNEXT-UNET TRAINING JOB COMPLETE
Model: ConvNeXt-UNet (Modern CNN)
Framework: TensorFlow/Keras + Enhanced Dataset Management
========================================
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
			Resource Usage on 2025-10-01 23:57:44.960132:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	JobId: 239495.stdct-mgmt-02
	Project: personal-phyzxi
	Exit Status: 0
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	NCPUs: Requested(36), Used(36)
	CPU Time Used: 00:05:27
	Memory: Requested(240gb), Used(14902312kb)
	Vmem Used: 43440684kb
	Walltime: Requested(12:00:00), Used(00:04:37)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	Execution Nodes Used: (GN-A40-097[0]:ncpus=36:ngpus=1:mem=251658240kb)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	No GPU-related information available for this job.
