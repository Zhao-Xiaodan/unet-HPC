âœ“ GPU memory growth enabled for 1 GPUs
Loading dataset...
Loaded 144 images and 144 masks
Training set: (129, 256, 256, 3), Validation set: (15, 256, 256, 3)

============================================================
TRAINING: Attention_UNet
Learning Rate: 0.0001, Batch Size: 16, Epochs: 30
============================================================
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 256, 256, 64)         640       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 256, 256, 64)         256       ['conv2d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 activation (Activation)     (None, 256, 256, 64)         0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['activation[0][0]']          
                                                                                                  
 batch_normalization_1 (Bat  (None, 256, 256, 64)         256       ['conv2d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_1 (Activation)   (None, 256, 256, 64)         0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['activation_1[0][0]']        
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       
                                                                                                  
 batch_normalization_2 (Bat  (None, 128, 128, 128)        512       ['conv2d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_2 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_3 (Conv2D)           (None, 128, 128, 128)        147584    ['activation_2[0][0]']        
                                                                                                  
 batch_normalization_3 (Bat  (None, 128, 128, 128)        512       ['conv2d_3[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_3 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_3[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_3[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 batch_normalization_4 (Bat  (None, 64, 64, 256)          1024      ['conv2d_4[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_4 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_4[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_5 (Conv2D)           (None, 64, 64, 256)          590080    ['activation_4[0][0]']        
                                                                                                  
 batch_normalization_5 (Bat  (None, 64, 64, 256)          1024      ['conv2d_5[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_5 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_5[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_5[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 512)          1180160   ['max_pooling2d_2[0][0]']     
                                                                                                  
 batch_normalization_6 (Bat  (None, 32, 32, 512)          2048      ['conv2d_6[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_6 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_6[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 32, 32, 512)          2359808   ['activation_6[0][0]']        
                                                                                                  
 batch_normalization_7 (Bat  (None, 32, 32, 512)          2048      ['conv2d_7[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_7 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_7[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_3 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_7[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 1024)         4719616   ['max_pooling2d_3[0][0]']     
                                                                                                  
 batch_normalization_8 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_8[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_8 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_8[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 1024)         9438208   ['activation_8[0][0]']        
                                                                                                  
 batch_normalization_9 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_9[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_9 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_9[0][0]'
                                                                    ]                             
                                                                                                  
 up_sampling2d (UpSampling2  (None, 32, 32, 1024)         0         ['activation_9[0][0]']        
 D)                                                                                               
                                                                                                  
 concatenate (Concatenate)   (None, 32, 32, 1536)         0         ['up_sampling2d[0][0]',       
                                                                     'activation_7[0][0]']        
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate[0][0]']         
                                                                                                  
 batch_normalization_10 (Ba  (None, 32, 32, 512)          2048      ['conv2d_10[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_10 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_10[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_10[0][0]']       
                                                                                                  
 batch_normalization_11 (Ba  (None, 32, 32, 512)          2048      ['conv2d_11[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_11 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_11[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 64, 64, 512)          0         ['activation_11[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_1 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_1[0][0]',     
 )                                                                   'activation_5[0][0]']        
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_1[0][0]']       
                                                                                                  
 batch_normalization_12 (Ba  (None, 64, 64, 256)          1024      ['conv2d_12[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_12 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_12[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_13 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_12[0][0]']       
                                                                                                  
 batch_normalization_13 (Ba  (None, 64, 64, 256)          1024      ['conv2d_13[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_13 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_13[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 128, 128, 256)        0         ['activation_13[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_2 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_2[0][0]',     
 )                                                                   'activation_3[0][0]']        
                                                                                                  
 conv2d_14 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_2[0][0]']       
                                                                                                  
 batch_normalization_14 (Ba  (None, 128, 128, 128)        512       ['conv2d_14[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_14 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_14[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_15 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_14[0][0]']       
                                                                                                  
 batch_normalization_15 (Ba  (None, 128, 128, 128)        512       ['conv2d_15[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_15 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_15[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 256, 256, 128)        0         ['activation_15[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_3 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_3[0][0]',     
 )                                                                   'activation_1[0][0]']        
                                                                                                  
 conv2d_16 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_3[0][0]']       
                                                                                                  
 batch_normalization_16 (Ba  (None, 256, 256, 64)         256       ['conv2d_16[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_16 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_16[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_16[0][0]']       
                                                                                                  
 batch_normalization_17 (Ba  (None, 256, 256, 64)         256       ['conv2d_17[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_17 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_17[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_18 (Conv2D)          (None, 256, 256, 1)          65        ['activation_17[0][0]']       
                                                                                                  
 batch_normalization_18 (Ba  (None, 256, 256, 1)          4         ['conv2d_18[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_18 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_18[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31401349 (119.79 MB)
Trainable params: 31389571 (119.74 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
WARNING:absl:`lr` is deprecated in TF-Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
None
âœ“ focal_loss imported successfully
Epoch 1/30
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1758863358.214600 3232297 service.cc:145] XLA service 0x1479a99ab130 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1758863358.214635 3232297 service.cc:153]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6
I0000 00:00:1758863358.670508 3232297 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
1/9 [==>...........................] - ETA: 7:55 - loss: 0.3434 - accuracy: 0.5138 - jacard_coef: 0.08582/9 [=====>........................] - ETA: 59s - loss: 0.3163 - accuracy: 0.5416 - jacard_coef: 0.0772 3/9 [=========>....................] - ETA: 26s - loss: 0.2913 - accuracy: 0.5084 - jacard_coef: 0.07944/9 [============>.................] - ETA: 15s - loss: 0.2737 - accuracy: 0.5005 - jacard_coef: 0.07745/9 [===============>..............] - ETA: 9s - loss: 0.2650 - accuracy: 0.5251 - jacard_coef: 0.0799 6/9 [===================>..........] - ETA: 5s - loss: 0.2567 - accuracy: 0.5471 - jacard_coef: 0.07817/9 [======================>.......] - ETA: 3s - loss: 0.2484 - accuracy: 0.5729 - jacard_coef: 0.07728/9 [=========================>....] - ETA: 1s - loss: 0.2411 - accuracy: 0.5877 - jacard_coef: 0.07689/9 [==============================] - ETA: 0s - loss: 0.2407 - accuracy: 0.5858 - jacard_coef: 0.06869/9 [==============================] - 79s 2s/step - loss: 0.2407 - accuracy: 0.5858 - jacard_coef: 0.0686 - val_loss: 1.2954 - val_accuracy: 0.9195 - val_jacard_coef: 0.0050 - lr: 0.0010
Epoch 2/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1864 - accuracy: 0.4436 - jacard_coef: 0.06642/9 [=====>........................] - ETA: 2s - loss: 0.1831 - accuracy: 0.4547 - jacard_coef: 0.07713/9 [=========>....................] - ETA: 2s - loss: 0.1796 - accuracy: 0.5358 - jacard_coef: 0.06974/9 [============>.................] - ETA: 1s - loss: 0.1781 - accuracy: 0.5970 - jacard_coef: 0.07415/9 [===============>..............] - ETA: 1s - loss: 0.1770 - accuracy: 0.6432 - jacard_coef: 0.07206/9 [===================>..........] - ETA: 1s - loss: 0.1761 - accuracy: 0.6693 - jacard_coef: 0.07377/9 [======================>.......] - ETA: 0s - loss: 0.1753 - accuracy: 0.6901 - jacard_coef: 0.07448/9 [=========================>....] - ETA: 0s - loss: 0.1748 - accuracy: 0.7072 - jacard_coef: 0.07559/9 [==============================] - 3s 337ms/step - loss: 0.1759 - accuracy: 0.7072 - jacard_coef: 0.0776 - val_loss: 1.7897 - val_accuracy: 0.8869 - val_jacard_coef: 0.0111 - lr: 0.0010
Epoch 3/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1700 - accuracy: 0.4508 - jacard_coef: 0.07742/9 [=====>........................] - ETA: 2s - loss: 0.1707 - accuracy: 0.4130 - jacard_coef: 0.07543/9 [=========>....................] - ETA: 2s - loss: 0.1707 - accuracy: 0.4169 - jacard_coef: 0.07244/9 [============>.................] - ETA: 1s - loss: 0.1711 - accuracy: 0.4172 - jacard_coef: 0.07335/9 [===============>..............] - ETA: 1s - loss: 0.1711 - accuracy: 0.4236 - jacard_coef: 0.07696/9 [===================>..........] - ETA: 1s - loss: 0.1709 - accuracy: 0.4460 - jacard_coef: 0.07267/9 [======================>.......] - ETA: 0s - loss: 0.1706 - accuracy: 0.4794 - jacard_coef: 0.07388/9 [=========================>....] - ETA: 0s - loss: 0.1705 - accuracy: 0.5186 - jacard_coef: 0.07559/9 [==============================] - 3s 339ms/step - loss: 0.1714 - accuracy: 0.5187 - jacard_coef: 0.0846 - val_loss: 14.0770 - val_accuracy: 0.0770 - val_jacard_coef: 0.0699 - lr: 0.0010
Epoch 4/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1684 - accuracy: 0.7680 - jacard_coef: 0.08112/9 [=====>........................] - ETA: 2s - loss: 0.1728 - accuracy: 0.7542 - jacard_coef: 0.07333/9 [=========>....................] - ETA: 2s - loss: 0.1736 - accuracy: 0.7402 - jacard_coef: 0.07614/9 [============>.................] - ETA: 1s - loss: 0.1735 - accuracy: 0.7343 - jacard_coef: 0.07485/9 [===============>..............] - ETA: 1s - loss: 0.1731 - accuracy: 0.7318 - jacard_coef: 0.07256/9 [===================>..........] - ETA: 1s - loss: 0.1725 - accuracy: 0.7288 - jacard_coef: 0.07517/9 [======================>.......] - ETA: 0s - loss: 0.1720 - accuracy: 0.7309 - jacard_coef: 0.07488/9 [=========================>....] - ETA: 0s - loss: 0.1716 - accuracy: 0.7303 - jacard_coef: 0.07559/9 [==============================] - 3s 331ms/step - loss: 0.1716 - accuracy: 0.7300 - jacard_coef: 0.0824 - val_loss: 0.7695 - val_accuracy: 0.9199 - val_jacard_coef: 0.0161 - lr: 0.0010
Epoch 5/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1679 - accuracy: 0.7243 - jacard_coef: 0.06242/9 [=====>........................] - ETA: 2s - loss: 0.1688 - accuracy: 0.7163 - jacard_coef: 0.06953/9 [=========>....................] - ETA: 2s - loss: 0.1689 - accuracy: 0.7109 - jacard_coef: 0.08054/9 [============>.................] - ETA: 1s - loss: 0.1688 - accuracy: 0.7152 - jacard_coef: 0.08075/9 [===============>..............] - ETA: 1s - loss: 0.1688 - accuracy: 0.7375 - jacard_coef: 0.08066/9 [===================>..........] - ETA: 1s - loss: 0.1686 - accuracy: 0.7605 - jacard_coef: 0.07887/9 [======================>.......] - ETA: 0s - loss: 0.1682 - accuracy: 0.7806 - jacard_coef: 0.07708/9 [=========================>....] - ETA: 0s - loss: 0.1677 - accuracy: 0.7961 - jacard_coef: 0.07639/9 [==============================] - 3s 331ms/step - loss: 0.1676 - accuracy: 0.7973 - jacard_coef: 0.0719 - val_loss: 14.8569 - val_accuracy: 0.0730 - val_jacard_coef: 0.0696 - lr: 0.0010
Epoch 6/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1636 - accuracy: 0.8672 - jacard_coef: 0.08862/9 [=====>........................] - ETA: 2s - loss: 0.1636 - accuracy: 0.8470 - jacard_coef: 0.08533/9 [=========>....................] - ETA: 2s - loss: 0.1633 - accuracy: 0.8454 - jacard_coef: 0.07684/9 [============>.................] - ETA: 1s - loss: 0.1632 - accuracy: 0.8431 - jacard_coef: 0.07355/9 [===============>..............] - ETA: 1s - loss: 0.1630 - accuracy: 0.8431 - jacard_coef: 0.07236/9 [===================>..........] - ETA: 1s - loss: 0.1630 - accuracy: 0.8399 - jacard_coef: 0.07447/9 [======================>.......] - ETA: 0s - loss: 0.1629 - accuracy: 0.8400 - jacard_coef: 0.07638/9 [=========================>....] - ETA: 0s - loss: 0.1626 - accuracy: 0.8494 - jacard_coef: 0.07479/9 [==============================] - 3s 338ms/step - loss: 0.1626 - accuracy: 0.8490 - jacard_coef: 0.0851 - val_loss: 13.6747 - val_accuracy: 0.0829 - val_jacard_coef: 0.0697 - lr: 0.0010
Epoch 7/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1610 - accuracy: 0.9015 - jacard_coef: 0.08862/9 [=====>........................] - ETA: 2s - loss: 0.1605 - accuracy: 0.9129 - jacard_coef: 0.07923/9 [=========>....................] - ETA: 2s - loss: 0.1605 - accuracy: 0.9126 - jacard_coef: 0.07964/9 [============>.................] - ETA: 1s - loss: 0.1607 - accuracy: 0.9092 - jacard_coef: 0.08245/9 [===============>..............] - ETA: 1s - loss: 0.1604 - accuracy: 0.9132 - jacard_coef: 0.07906/9 [===================>..........] - ETA: 1s - loss: 0.1603 - accuracy: 0.9135 - jacard_coef: 0.07887/9 [======================>.......] - ETA: 0s - loss: 0.1601 - accuracy: 0.9156 - jacard_coef: 0.07708/9 [=========================>....] - ETA: 0s - loss: 0.1599 - accuracy: 0.9178 - jacard_coef: 0.07529/9 [==============================] - 3s 338ms/step - loss: 0.1599 - accuracy: 0.9172 - jacard_coef: 0.0828 - val_loss: 0.4150 - val_accuracy: 0.2895 - val_jacard_coef: 0.0681 - lr: 0.0010
Epoch 8/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1584 - accuracy: 0.9200 - jacard_coef: 0.07372/9 [=====>........................] - ETA: 2s - loss: 0.1586 - accuracy: 0.9154 - jacard_coef: 0.07743/9 [=========>....................] - ETA: 2s - loss: 0.1585 - accuracy: 0.9145 - jacard_coef: 0.07794/9 [============>.................] - ETA: 1s - loss: 0.1584 - accuracy: 0.9122 - jacard_coef: 0.07725/9 [===============>..............] - ETA: 1s - loss: 0.1581 - accuracy: 0.9103 - jacard_coef: 0.07476/9 [===================>..........] - ETA: 1s - loss: 0.1581 - accuracy: 0.9055 - jacard_coef: 0.07687/9 [======================>.......] - ETA: 0s - loss: 0.1581 - accuracy: 0.9008 - jacard_coef: 0.07678/9 [=========================>....] - ETA: 0s - loss: 0.1579 - accuracy: 0.9016 - jacard_coef: 0.07509/9 [==============================] - 3s 338ms/step - loss: 0.1579 - accuracy: 0.9011 - jacard_coef: 0.0835 - val_loss: 0.6146 - val_accuracy: 0.2810 - val_jacard_coef: 0.0679 - lr: 0.0010
Epoch 9/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1578 - accuracy: 0.8652 - jacard_coef: 0.09712/9 [=====>........................] - ETA: 2s - loss: 0.1574 - accuracy: 0.8639 - jacard_coef: 0.08793/9 [=========>....................] - ETA: 2s - loss: 0.1568 - accuracy: 0.8747 - jacard_coef: 0.07814/9 [============>.................] - ETA: 1s - loss: 0.1567 - accuracy: 0.8751 - jacard_coef: 0.07705/9 [===============>..............] - ETA: 1s - loss: 0.1565 - accuracy: 0.8767 - jacard_coef: 0.07626/9 [===================>..........] - ETA: 1s - loss: 0.1565 - accuracy: 0.8751 - jacard_coef: 0.07557/9 [======================>.......] - ETA: 0s - loss: 0.1565 - accuracy: 0.8723 - jacard_coef: 0.07678/9 [=========================>....] - ETA: 0s - loss: 0.1564 - accuracy: 0.8725 - jacard_coef: 0.07599/9 [==============================] - 3s 338ms/step - loss: 0.1564 - accuracy: 0.8729 - jacard_coef: 0.0709 - val_loss: 0.1633 - val_accuracy: 0.8204 - val_jacard_coef: 0.0652 - lr: 5.0000e-04
Epoch 10/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1553 - accuracy: 0.8846 - jacard_coef: 0.07442/9 [=====>........................] - ETA: 2s - loss: 0.1554 - accuracy: 0.8889 - jacard_coef: 0.07133/9 [=========>....................] - ETA: 2s - loss: 0.1555 - accuracy: 0.8919 - jacard_coef: 0.07174/9 [============>.................] - ETA: 1s - loss: 0.1553 - accuracy: 0.8990 - jacard_coef: 0.06945/9 [===============>..............] - ETA: 1s - loss: 0.1554 - accuracy: 0.8989 - jacard_coef: 0.07266/9 [===================>..........] - ETA: 1s - loss: 0.1553 - accuracy: 0.9010 - jacard_coef: 0.07297/9 [======================>.......] - ETA: 0s - loss: 0.1553 - accuracy: 0.9014 - jacard_coef: 0.07428/9 [=========================>....] - ETA: 0s - loss: 0.1553 - accuracy: 0.9023 - jacard_coef: 0.07529/9 [==============================] - 3s 338ms/step - loss: 0.1553 - accuracy: 0.9018 - jacard_coef: 0.0817 - val_loss: 0.1511 - val_accuracy: 0.9304 - val_jacard_coef: 0.0650 - lr: 5.0000e-04
Epoch 11/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1545 - accuracy: 0.9191 - jacard_coef: 0.07442/9 [=====>........................] - ETA: 2s - loss: 0.1544 - accuracy: 0.9220 - jacard_coef: 0.07193/9 [=========>....................] - ETA: 2s - loss: 0.1546 - accuracy: 0.9171 - jacard_coef: 0.07614/9 [============>.................] - ETA: 1s - loss: 0.1544 - accuracy: 0.9212 - jacard_coef: 0.07265/9 [===============>..............] - ETA: 1s - loss: 0.1544 - accuracy: 0.9214 - jacard_coef: 0.07246/9 [===================>..........] - ETA: 1s - loss: 0.1543 - accuracy: 0.9229 - jacard_coef: 0.07117/9 [======================>.......] - ETA: 0s - loss: 0.1543 - accuracy: 0.9217 - jacard_coef: 0.07218/9 [=========================>....] - ETA: 0s - loss: 0.1545 - accuracy: 0.9170 - jacard_coef: 0.07609/9 [==============================] - 3s 339ms/step - loss: 0.1545 - accuracy: 0.9174 - jacard_coef: 0.0709 - val_loss: 0.1540 - val_accuracy: 0.9304 - val_jacard_coef: 0.0651 - lr: 5.0000e-04
Epoch 12/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1542 - accuracy: 0.9131 - jacard_coef: 0.07942/9 [=====>........................] - ETA: 2s - loss: 0.1530 - accuracy: 0.9332 - jacard_coef: 0.06183/9 [=========>....................] - ETA: 2s - loss: 0.1529 - accuracy: 0.9339 - jacard_coef: 0.06144/9 [============>.................] - ETA: 1s - loss: 0.1530 - accuracy: 0.9295 - jacard_coef: 0.06525/9 [===============>..............] - ETA: 1s - loss: 0.1531 - accuracy: 0.9273 - jacard_coef: 0.06716/9 [===================>..........] - ETA: 1s - loss: 0.1531 - accuracy: 0.9253 - jacard_coef: 0.06877/9 [======================>.......] - ETA: 0s - loss: 0.1533 - accuracy: 0.9206 - jacard_coef: 0.07248/9 [=========================>....] - ETA: 0s - loss: 0.1534 - accuracy: 0.9176 - jacard_coef: 0.07489/9 [==============================] - 3s 339ms/step - loss: 0.1534 - accuracy: 0.9169 - jacard_coef: 0.0831 - val_loss: 0.1526 - val_accuracy: 0.9304 - val_jacard_coef: 0.0648 - lr: 5.0000e-04
Epoch 13/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1524 - accuracy: 0.9223 - jacard_coef: 0.06852/9 [=====>........................] - ETA: 2s - loss: 0.1522 - accuracy: 0.9238 - jacard_coef: 0.06653/9 [=========>....................] - ETA: 2s - loss: 0.1521 - accuracy: 0.9214 - jacard_coef: 0.06634/9 [============>.................] - ETA: 1s - loss: 0.1524 - accuracy: 0.9147 - jacard_coef: 0.07105/9 [===============>..............] - ETA: 1s - loss: 0.1525 - accuracy: 0.9126 - jacard_coef: 0.07226/9 [===================>..........] - ETA: 1s - loss: 0.1527 - accuracy: 0.9090 - jacard_coef: 0.07597/9 [======================>.......] - ETA: 0s - loss: 0.1526 - accuracy: 0.9098 - jacard_coef: 0.07598/9 [=========================>....] - ETA: 0s - loss: 0.1524 - accuracy: 0.9115 - jacard_coef: 0.07489/9 [==============================] - 3s 339ms/step - loss: 0.1525 - accuracy: 0.9106 - jacard_coef: 0.0845 - val_loss: 0.1521 - val_accuracy: 0.9304 - val_jacard_coef: 0.0650 - lr: 5.0000e-04
/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(

âœ“ Training completed successfully!
  Best Val Jaccard: 0.0699 (epoch 3)
  Final Val Loss: 0.1521
  Training Time: 0:01:56.266436
  Stability (std): 5.5879

Results saved to: hyperparameter_optimization_20250926_123742/exp_14_Attention_UNet_lr1e-4_bs16/Attention_UNet_lr0.0001_bs16_results.json
