✓ GPU memory growth enabled for 1 GPUs
Loading dataset...
Loaded 144 images and 144 masks
Training set: (129, 256, 256, 3), Validation set: (15, 256, 256, 3)

============================================================
TRAINING: Attention_ResUNet
Learning Rate: 0.0001, Batch Size: 16, Epochs: 30
============================================================
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 256, 256, 64)         640       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 256, 256, 64)         256       ['conv2d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 activation (Activation)     (None, 256, 256, 64)         0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['activation[0][0]']          
                                                                                                  
 batch_normalization_1 (Bat  (None, 256, 256, 64)         256       ['conv2d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_1 (Activation)   (None, 256, 256, 64)         0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['activation_1[0][0]']        
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       
                                                                                                  
 batch_normalization_2 (Bat  (None, 128, 128, 128)        512       ['conv2d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_2 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_3 (Conv2D)           (None, 128, 128, 128)        147584    ['activation_2[0][0]']        
                                                                                                  
 batch_normalization_3 (Bat  (None, 128, 128, 128)        512       ['conv2d_3[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_3 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_3[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_3[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 batch_normalization_4 (Bat  (None, 64, 64, 256)          1024      ['conv2d_4[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_4 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_4[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_5 (Conv2D)           (None, 64, 64, 256)          590080    ['activation_4[0][0]']        
                                                                                                  
 batch_normalization_5 (Bat  (None, 64, 64, 256)          1024      ['conv2d_5[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_5 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_5[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_5[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 512)          1180160   ['max_pooling2d_2[0][0]']     
                                                                                                  
 batch_normalization_6 (Bat  (None, 32, 32, 512)          2048      ['conv2d_6[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_6 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_6[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 32, 32, 512)          2359808   ['activation_6[0][0]']        
                                                                                                  
 batch_normalization_7 (Bat  (None, 32, 32, 512)          2048      ['conv2d_7[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_7 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_7[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_3 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_7[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 1024)         4719616   ['max_pooling2d_3[0][0]']     
                                                                                                  
 batch_normalization_8 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_8[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_8 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_8[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 1024)         9438208   ['activation_8[0][0]']        
                                                                                                  
 batch_normalization_9 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_9[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_9 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_9[0][0]'
                                                                    ]                             
                                                                                                  
 up_sampling2d (UpSampling2  (None, 32, 32, 1024)         0         ['activation_9[0][0]']        
 D)                                                                                               
                                                                                                  
 concatenate (Concatenate)   (None, 32, 32, 1536)         0         ['up_sampling2d[0][0]',       
                                                                     'activation_7[0][0]']        
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate[0][0]']         
                                                                                                  
 batch_normalization_10 (Ba  (None, 32, 32, 512)          2048      ['conv2d_10[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_10 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_10[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_10[0][0]']       
                                                                                                  
 batch_normalization_11 (Ba  (None, 32, 32, 512)          2048      ['conv2d_11[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_11 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_11[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 64, 64, 512)          0         ['activation_11[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_1 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_1[0][0]',     
 )                                                                   'activation_5[0][0]']        
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_1[0][0]']       
                                                                                                  
 batch_normalization_12 (Ba  (None, 64, 64, 256)          1024      ['conv2d_12[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_12 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_12[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_13 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_12[0][0]']       
                                                                                                  
 batch_normalization_13 (Ba  (None, 64, 64, 256)          1024      ['conv2d_13[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_13 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_13[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 128, 128, 256)        0         ['activation_13[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_2 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_2[0][0]',     
 )                                                                   'activation_3[0][0]']        
                                                                                                  
 conv2d_14 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_2[0][0]']       
                                                                                                  
 batch_normalization_14 (Ba  (None, 128, 128, 128)        512       ['conv2d_14[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_14 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_14[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_15 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_14[0][0]']       
                                                                                                  
 batch_normalization_15 (Ba  (None, 128, 128, 128)        512       ['conv2d_15[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_15 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_15[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 256, 256, 128)        0         ['activation_15[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_3 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_3[0][0]',     
 )                                                                   'activation_1[0][0]']        
                                                                                                  
 conv2d_16 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_3[0][0]']       
                                                                                                  
 batch_normalization_16 (Ba  (None, 256, 256, 64)         256       ['conv2d_16[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_16 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_16[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_16[0][0]']       
                                                                                                  
 batch_normalization_17 (Ba  (None, 256, 256, 64)         256       ['conv2d_17[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_17 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_17[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_18 (Conv2D)          (None, 256, 256, 1)          65        ['activation_17[0][0]']       
                                                                                                  
 batch_normalization_18 (Ba  (None, 256, 256, 1)          4         ['conv2d_18[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_18 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_18[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31401349 (119.79 MB)
Trainable params: 31389571 (119.74 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
WARNING:absl:`lr` is deprecated in TF-Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
None
✓ focal_loss imported successfully
Epoch 1/30
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1758865323.634221 3310163 service.cc:145] XLA service 0x15133c904e40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1758865323.634279 3310163 service.cc:153]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6
I0000 00:00:1758865324.096056 3310163 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
1/9 [==>...........................] - ETA: 9:14 - loss: 0.3307 - accuracy: 0.4671 - jacard_coef: 0.07092/9 [=====>........................] - ETA: 58s - loss: 0.3022 - accuracy: 0.3847 - jacard_coef: 0.0847 3/9 [=========>....................] - ETA: 26s - loss: 0.2767 - accuracy: 0.3374 - jacard_coef: 0.08844/9 [============>.................] - ETA: 15s - loss: 0.2589 - accuracy: 0.3149 - jacard_coef: 0.08515/9 [===============>..............] - ETA: 9s - loss: 0.2471 - accuracy: 0.2834 - jacard_coef: 0.0816 6/9 [===================>..........] - ETA: 5s - loss: 0.2391 - accuracy: 0.2557 - jacard_coef: 0.07767/9 [======================>.......] - ETA: 3s - loss: 0.2330 - accuracy: 0.2383 - jacard_coef: 0.07738/9 [=========================>....] - ETA: 1s - loss: 0.2279 - accuracy: 0.2281 - jacard_coef: 0.07729/9 [==============================] - ETA: 0s - loss: 0.2275 - accuracy: 0.2277 - jacard_coef: 0.07469/9 [==============================] - 90s 3s/step - loss: 0.2275 - accuracy: 0.2277 - jacard_coef: 0.0746 - val_loss: 0.8667 - val_accuracy: 0.9304 - val_jacard_coef: 0.0048 - lr: 0.0010
Epoch 2/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1892 - accuracy: 0.1409 - jacard_coef: 0.07482/9 [=====>........................] - ETA: 2s - loss: 0.1901 - accuracy: 0.1430 - jacard_coef: 0.07173/9 [=========>....................] - ETA: 2s - loss: 0.1895 - accuracy: 0.1810 - jacard_coef: 0.08154/9 [============>.................] - ETA: 2s - loss: 0.1893 - accuracy: 0.2116 - jacard_coef: 0.07895/9 [===============>..............] - ETA: 1s - loss: 0.1871 - accuracy: 0.2695 - jacard_coef: 0.08296/9 [===================>..........] - ETA: 1s - loss: 0.1950 - accuracy: 0.2869 - jacard_coef: 0.08337/9 [======================>.......] - ETA: 0s - loss: 0.2001 - accuracy: 0.2818 - jacard_coef: 0.07998/9 [=========================>....] - ETA: 0s - loss: 0.2000 - accuracy: 0.2695 - jacard_coef: 0.07609/9 [==============================] - 4s 388ms/step - loss: 0.1999 - accuracy: 0.2694 - jacard_coef: 0.0828 - val_loss: 1.2094 - val_accuracy: 0.9157 - val_jacard_coef: 0.0050 - lr: 0.0010
Epoch 3/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1919 - accuracy: 0.1986 - jacard_coef: 0.07172/9 [=====>........................] - ETA: 2s - loss: 0.1912 - accuracy: 0.2217 - jacard_coef: 0.07623/9 [=========>....................] - ETA: 2s - loss: 0.1914 - accuracy: 0.2255 - jacard_coef: 0.06544/9 [============>.................] - ETA: 2s - loss: 0.1901 - accuracy: 0.2359 - jacard_coef: 0.07175/9 [===============>..............] - ETA: 1s - loss: 0.1893 - accuracy: 0.2402 - jacard_coef: 0.07806/9 [===================>..........] - ETA: 1s - loss: 0.1891 - accuracy: 0.2379 - jacard_coef: 0.07587/9 [======================>.......] - ETA: 0s - loss: 0.1884 - accuracy: 0.2383 - jacard_coef: 0.07808/9 [=========================>....] - ETA: 0s - loss: 0.1883 - accuracy: 0.2346 - jacard_coef: 0.07659/9 [==============================] - 4s 388ms/step - loss: 0.1883 - accuracy: 0.2343 - jacard_coef: 0.0710 - val_loss: 1.7396 - val_accuracy: 0.8517 - val_jacard_coef: 0.0143 - lr: 0.0010
Epoch 4/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1816 - accuracy: 0.2400 - jacard_coef: 0.07802/9 [=====>........................] - ETA: 2s - loss: 0.1830 - accuracy: 0.2745 - jacard_coef: 0.07983/9 [=========>....................] - ETA: 2s - loss: 0.1823 - accuracy: 0.3008 - jacard_coef: 0.07774/9 [============>.................] - ETA: 2s - loss: 0.1820 - accuracy: 0.3165 - jacard_coef: 0.07855/9 [===============>..............] - ETA: 1s - loss: 0.1817 - accuracy: 0.3277 - jacard_coef: 0.07506/9 [===================>..........] - ETA: 1s - loss: 0.1814 - accuracy: 0.3392 - jacard_coef: 0.07517/9 [======================>.......] - ETA: 0s - loss: 0.1807 - accuracy: 0.3448 - jacard_coef: 0.07508/9 [=========================>....] - ETA: 0s - loss: 0.1802 - accuracy: 0.3509 - jacard_coef: 0.07699/9 [==============================] - 3s 385ms/step - loss: 0.1802 - accuracy: 0.3506 - jacard_coef: 0.0689 - val_loss: 2.1866 - val_accuracy: 0.8236 - val_jacard_coef: 0.0258 - lr: 0.0010
Epoch 5/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1746 - accuracy: 0.4617 - jacard_coef: 0.08142/9 [=====>........................] - ETA: 2s - loss: 0.1738 - accuracy: 0.4729 - jacard_coef: 0.07133/9 [=========>....................] - ETA: 2s - loss: 0.1736 - accuracy: 0.5039 - jacard_coef: 0.07314/9 [============>.................] - ETA: 2s - loss: 0.1728 - accuracy: 0.5404 - jacard_coef: 0.07245/9 [===============>..............] - ETA: 1s - loss: 0.1724 - accuracy: 0.5609 - jacard_coef: 0.07516/9 [===================>..........] - ETA: 1s - loss: 0.1720 - accuracy: 0.5788 - jacard_coef: 0.07477/9 [======================>.......] - ETA: 0s - loss: 0.1716 - accuracy: 0.5920 - jacard_coef: 0.07518/9 [=========================>....] - ETA: 0s - loss: 0.1712 - accuracy: 0.6011 - jacard_coef: 0.07669/9 [==============================] - 3s 386ms/step - loss: 0.1712 - accuracy: 0.6014 - jacard_coef: 0.0706 - val_loss: 13.7736 - val_accuracy: 0.0797 - val_jacard_coef: 0.0700 - lr: 0.0010
Epoch 6/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1680 - accuracy: 0.5395 - jacard_coef: 0.07792/9 [=====>........................] - ETA: 2s - loss: 0.1673 - accuracy: 0.5985 - jacard_coef: 0.07063/9 [=========>....................] - ETA: 2s - loss: 0.1675 - accuracy: 0.6345 - jacard_coef: 0.07444/9 [============>.................] - ETA: 2s - loss: 0.1675 - accuracy: 0.6628 - jacard_coef: 0.07755/9 [===============>..............] - ETA: 1s - loss: 0.1673 - accuracy: 0.6860 - jacard_coef: 0.08026/9 [===================>..........] - ETA: 1s - loss: 0.1670 - accuracy: 0.7041 - jacard_coef: 0.07537/9 [======================>.......] - ETA: 0s - loss: 0.1667 - accuracy: 0.7138 - jacard_coef: 0.07698/9 [=========================>....] - ETA: 0s - loss: 0.1664 - accuracy: 0.7206 - jacard_coef: 0.07579/9 [==============================] - 3s 381ms/step - loss: 0.1666 - accuracy: 0.7192 - jacard_coef: 0.0819 - val_loss: 0.6968 - val_accuracy: 0.7014 - val_jacard_coef: 0.0533 - lr: 0.0010
Epoch 7/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1672 - accuracy: 0.6846 - jacard_coef: 0.08292/9 [=====>........................] - ETA: 2s - loss: 0.1679 - accuracy: 0.6371 - jacard_coef: 0.08603/9 [=========>....................] - ETA: 2s - loss: 0.1683 - accuracy: 0.6041 - jacard_coef: 0.08304/9 [============>.................] - ETA: 2s - loss: 0.1693 - accuracy: 0.5822 - jacard_coef: 0.08085/9 [===============>..............] - ETA: 1s - loss: 0.1691 - accuracy: 0.5771 - jacard_coef: 0.08276/9 [===================>..........] - ETA: 1s - loss: 0.1690 - accuracy: 0.5746 - jacard_coef: 0.08427/9 [======================>.......] - ETA: 0s - loss: 0.1689 - accuracy: 0.5799 - jacard_coef: 0.07878/9 [=========================>....] - ETA: 0s - loss: 0.1688 - accuracy: 0.5908 - jacard_coef: 0.07559/9 [==============================] - 3s 381ms/step - loss: 0.1688 - accuracy: 0.5914 - jacard_coef: 0.0825 - val_loss: 0.8358 - val_accuracy: 0.9109 - val_jacard_coef: 0.0352 - lr: 0.0010
Epoch 8/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1683 - accuracy: 0.7902 - jacard_coef: 0.07152/9 [=====>........................] - ETA: 2s - loss: 0.1684 - accuracy: 0.8015 - jacard_coef: 0.07663/9 [=========>....................] - ETA: 2s - loss: 0.1674 - accuracy: 0.8172 - jacard_coef: 0.07024/9 [============>.................] - ETA: 2s - loss: 0.1675 - accuracy: 0.8135 - jacard_coef: 0.07755/9 [===============>..............] - ETA: 1s - loss: 0.1674 - accuracy: 0.8155 - jacard_coef: 0.07676/9 [===================>..........] - ETA: 1s - loss: 0.1672 - accuracy: 0.8166 - jacard_coef: 0.07927/9 [======================>.......] - ETA: 0s - loss: 0.1670 - accuracy: 0.8179 - jacard_coef: 0.07778/9 [=========================>....] - ETA: 0s - loss: 0.1667 - accuracy: 0.8154 - jacard_coef: 0.07619/9 [==============================] - 3s 381ms/step - loss: 0.1668 - accuracy: 0.8145 - jacard_coef: 0.0729 - val_loss: 0.7263 - val_accuracy: 0.9172 - val_jacard_coef: 0.0382 - lr: 0.0010
Epoch 9/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1638 - accuracy: 0.8074 - jacard_coef: 0.04492/9 [=====>........................] - ETA: 2s - loss: 0.1636 - accuracy: 0.7995 - jacard_coef: 0.06913/9 [=========>....................] - ETA: 2s - loss: 0.1633 - accuracy: 0.7968 - jacard_coef: 0.07474/9 [============>.................] - ETA: 2s - loss: 0.1629 - accuracy: 0.8011 - jacard_coef: 0.07275/9 [===============>..............] - ETA: 1s - loss: 0.1629 - accuracy: 0.7967 - jacard_coef: 0.07806/9 [===================>..........] - ETA: 1s - loss: 0.1627 - accuracy: 0.7972 - jacard_coef: 0.07497/9 [======================>.......] - ETA: 0s - loss: 0.1627 - accuracy: 0.7954 - jacard_coef: 0.07568/9 [=========================>....] - ETA: 0s - loss: 0.1627 - accuracy: 0.7941 - jacard_coef: 0.07559/9 [==============================] - 3s 381ms/step - loss: 0.1627 - accuracy: 0.7935 - jacard_coef: 0.0823 - val_loss: 0.4048 - val_accuracy: 0.9051 - val_jacard_coef: 0.0509 - lr: 0.0010
Epoch 10/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1598 - accuracy: 0.8023 - jacard_coef: 0.08052/9 [=====>........................] - ETA: 2s - loss: 0.1603 - accuracy: 0.8087 - jacard_coef: 0.07053/9 [=========>....................] - ETA: 2s - loss: 0.1603 - accuracy: 0.8157 - jacard_coef: 0.07194/9 [============>.................] - ETA: 2s - loss: 0.1601 - accuracy: 0.8187 - jacard_coef: 0.07415/9 [===============>..............] - ETA: 1s - loss: 0.1596 - accuracy: 0.8243 - jacard_coef: 0.07356/9 [===================>..........] - ETA: 1s - loss: 0.1596 - accuracy: 0.8225 - jacard_coef: 0.07577/9 [======================>.......] - ETA: 0s - loss: 0.1596 - accuracy: 0.8229 - jacard_coef: 0.07678/9 [=========================>....] - ETA: 0s - loss: 0.1596 - accuracy: 0.8250 - jacard_coef: 0.07639/9 [==============================] - ETA: 0s - loss: 0.1596 - accuracy: 0.8246 - jacard_coef: 0.07329/9 [==============================] - 3s 386ms/step - loss: 0.1596 - accuracy: 0.8246 - jacard_coef: 0.0732 - val_loss: 0.1588 - val_accuracy: 0.8731 - val_jacard_coef: 0.0609 - lr: 0.0010
Epoch 11/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1581 - accuracy: 0.8453 - jacard_coef: 0.09872/9 [=====>........................] - ETA: 2s - loss: 0.1570 - accuracy: 0.8601 - jacard_coef: 0.08483/9 [=========>....................] - ETA: 2s - loss: 0.1570 - accuracy: 0.8550 - jacard_coef: 0.08084/9 [============>.................] - ETA: 2s - loss: 0.1570 - accuracy: 0.8590 - jacard_coef: 0.07755/9 [===============>..............] - ETA: 1s - loss: 0.1571 - accuracy: 0.8622 - jacard_coef: 0.07546/9 [===================>..........] - ETA: 1s - loss: 0.1569 - accuracy: 0.8559 - jacard_coef: 0.07367/9 [======================>.......] - ETA: 0s - loss: 0.1570 - accuracy: 0.8533 - jacard_coef: 0.07398/9 [=========================>....] - ETA: 0s - loss: 0.1570 - accuracy: 0.8506 - jacard_coef: 0.07649/9 [==============================] - ETA: 0s - loss: 0.1570 - accuracy: 0.8505 - jacard_coef: 0.07069/9 [==============================] - 4s 388ms/step - loss: 0.1570 - accuracy: 0.8505 - jacard_coef: 0.0706 - val_loss: 0.1402 - val_accuracy: 0.9086 - val_jacard_coef: 0.0637 - lr: 5.0000e-04
Epoch 12/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1559 - accuracy: 0.8568 - jacard_coef: 0.09012/9 [=====>........................] - ETA: 2s - loss: 0.1555 - accuracy: 0.8596 - jacard_coef: 0.08443/9 [=========>....................] - ETA: 2s - loss: 0.1552 - accuracy: 0.8563 - jacard_coef: 0.07914/9 [============>.................] - ETA: 2s - loss: 0.1548 - accuracy: 0.8693 - jacard_coef: 0.07475/9 [===============>..............] - ETA: 1s - loss: 0.1550 - accuracy: 0.8675 - jacard_coef: 0.07706/9 [===================>..........] - ETA: 1s - loss: 0.1550 - accuracy: 0.8737 - jacard_coef: 0.07577/9 [======================>.......] - ETA: 0s - loss: 0.1551 - accuracy: 0.8714 - jacard_coef: 0.07888/9 [=========================>....] - ETA: 0s - loss: 0.1549 - accuracy: 0.8655 - jacard_coef: 0.07639/9 [==============================] - ETA: 0s - loss: 0.1549 - accuracy: 0.8644 - jacard_coef: 0.07399/9 [==============================] - 4s 389ms/step - loss: 0.1549 - accuracy: 0.8644 - jacard_coef: 0.0739 - val_loss: 0.1227 - val_accuracy: 0.9147 - val_jacard_coef: 0.0632 - lr: 5.0000e-04
Epoch 13/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1540 - accuracy: 0.9095 - jacard_coef: 0.06792/9 [=====>........................] - ETA: 2s - loss: 0.1546 - accuracy: 0.8327 - jacard_coef: 0.06853/9 [=========>....................] - ETA: 2s - loss: 0.1545 - accuracy: 0.8506 - jacard_coef: 0.07224/9 [============>.................] - ETA: 2s - loss: 0.1547 - accuracy: 0.8629 - jacard_coef: 0.07425/9 [===============>..............] - ETA: 1s - loss: 0.1546 - accuracy: 0.8728 - jacard_coef: 0.07346/9 [===================>..........] - ETA: 1s - loss: 0.1548 - accuracy: 0.8767 - jacard_coef: 0.07557/9 [======================>.......] - ETA: 0s - loss: 0.1546 - accuracy: 0.8849 - jacard_coef: 0.07308/9 [=========================>....] - ETA: 0s - loss: 0.1547 - accuracy: 0.8859 - jacard_coef: 0.07559/9 [==============================] - ETA: 0s - loss: 0.1553 - accuracy: 0.8823 - jacard_coef: 0.08089/9 [==============================] - 4s 388ms/step - loss: 0.1553 - accuracy: 0.8823 - jacard_coef: 0.0808 - val_loss: 0.1514 - val_accuracy: 0.9267 - val_jacard_coef: 0.0644 - lr: 5.0000e-04
Epoch 14/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1544 - accuracy: 0.9352 - jacard_coef: 0.05292/9 [=====>........................] - ETA: 2s - loss: 0.1569 - accuracy: 0.8999 - jacard_coef: 0.07343/9 [=========>....................] - ETA: 2s - loss: 0.1586 - accuracy: 0.8717 - jacard_coef: 0.08224/9 [============>.................] - ETA: 2s - loss: 0.1593 - accuracy: 0.8688 - jacard_coef: 0.08145/9 [===============>..............] - ETA: 1s - loss: 0.1616 - accuracy: 0.8096 - jacard_coef: 0.08156/9 [===================>..........] - ETA: 1s - loss: 0.1611 - accuracy: 0.8111 - jacard_coef: 0.07907/9 [======================>.......] - ETA: 0s - loss: 0.1609 - accuracy: 0.8173 - jacard_coef: 0.07658/9 [=========================>....] - ETA: 0s - loss: 0.1605 - accuracy: 0.8245 - jacard_coef: 0.07539/9 [==============================] - ETA: 0s - loss: 0.1606 - accuracy: 0.8242 - jacard_coef: 0.08109/9 [==============================] - 4s 389ms/step - loss: 0.1606 - accuracy: 0.8242 - jacard_coef: 0.0810 - val_loss: 0.1547 - val_accuracy: 0.9304 - val_jacard_coef: 0.0647 - lr: 5.0000e-04
Epoch 15/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1591 - accuracy: 0.8260 - jacard_coef: 0.09942/9 [=====>........................] - ETA: 2s - loss: 0.1589 - accuracy: 0.8447 - jacard_coef: 0.08783/9 [=========>....................] - ETA: 2s - loss: 0.1584 - accuracy: 0.8495 - jacard_coef: 0.08224/9 [============>.................] - ETA: 2s - loss: 0.1585 - accuracy: 0.8527 - jacard_coef: 0.07775/9 [===============>..............] - ETA: 1s - loss: 0.1579 - accuracy: 0.8632 - jacard_coef: 0.07376/9 [===================>..........] - ETA: 1s - loss: 0.1580 - accuracy: 0.8614 - jacard_coef: 0.07957/9 [======================>.......] - ETA: 0s - loss: 0.1580 - accuracy: 0.8675 - jacard_coef: 0.07678/9 [=========================>....] - ETA: 0s - loss: 0.1577 - accuracy: 0.8719 - jacard_coef: 0.07609/9 [==============================] - ETA: 0s - loss: 0.1579 - accuracy: 0.8680 - jacard_coef: 0.06799/9 [==============================] - 4s 388ms/step - loss: 0.1579 - accuracy: 0.8680 - jacard_coef: 0.0679 - val_loss: 0.1652 - val_accuracy: 0.9304 - val_jacard_coef: 0.0650 - lr: 5.0000e-04
/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(

✓ Training completed successfully!
  Best Val Jaccard: 0.0700 (epoch 5)
  Final Val Loss: 0.1652
  Training Time: 0:02:19.879433
  Stability (std): 0.2729

Results saved to: hyperparameter_optimization_20250926_123742/exp_26_Attention_ResUNet_lr1e-4_bs16/Attention_ResUNet_lr0.0001_bs16_results.json
