✓ GPU memory growth enabled for 1 GPUs
Loading dataset...
Loaded 144 images and 144 masks
Training set: (129, 256, 256, 3), Validation set: (15, 256, 256, 3)

============================================================
TRAINING: UNet
Learning Rate: 0.0005, Batch Size: 8, Epochs: 30
============================================================
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 256, 256, 64)         640       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 256, 256, 64)         256       ['conv2d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 activation (Activation)     (None, 256, 256, 64)         0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['activation[0][0]']          
                                                                                                  
 batch_normalization_1 (Bat  (None, 256, 256, 64)         256       ['conv2d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_1 (Activation)   (None, 256, 256, 64)         0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['activation_1[0][0]']        
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       
                                                                                                  
 batch_normalization_2 (Bat  (None, 128, 128, 128)        512       ['conv2d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_2 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_3 (Conv2D)           (None, 128, 128, 128)        147584    ['activation_2[0][0]']        
                                                                                                  
 batch_normalization_3 (Bat  (None, 128, 128, 128)        512       ['conv2d_3[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_3 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_3[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_3[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 batch_normalization_4 (Bat  (None, 64, 64, 256)          1024      ['conv2d_4[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_4 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_4[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_5 (Conv2D)           (None, 64, 64, 256)          590080    ['activation_4[0][0]']        
                                                                                                  
 batch_normalization_5 (Bat  (None, 64, 64, 256)          1024      ['conv2d_5[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_5 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_5[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_5[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 512)          1180160   ['max_pooling2d_2[0][0]']     
                                                                                                  
 batch_normalization_6 (Bat  (None, 32, 32, 512)          2048      ['conv2d_6[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_6 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_6[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 32, 32, 512)          2359808   ['activation_6[0][0]']        
                                                                                                  
 batch_normalization_7 (Bat  (None, 32, 32, 512)          2048      ['conv2d_7[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_7 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_7[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_3 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_7[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 1024)         4719616   ['max_pooling2d_3[0][0]']     
                                                                                                  
 batch_normalization_8 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_8[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_8 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_8[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 1024)         9438208   ['activation_8[0][0]']        
                                                                                                  
 batch_normalization_9 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_9[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_9 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_9[0][0]'
                                                                    ]                             
                                                                                                  
 up_sampling2d (UpSampling2  (None, 32, 32, 1024)         0         ['activation_9[0][0]']        
 D)                                                                                               
                                                                                                  
 concatenate (Concatenate)   (None, 32, 32, 1536)         0         ['up_sampling2d[0][0]',       
                                                                     'activation_7[0][0]']        
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate[0][0]']         
                                                                                                  
 batch_normalization_10 (Ba  (None, 32, 32, 512)          2048      ['conv2d_10[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_10 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_10[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_10[0][0]']       
                                                                                                  
 batch_normalization_11 (Ba  (None, 32, 32, 512)          2048      ['conv2d_11[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_11 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_11[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 64, 64, 512)          0         ['activation_11[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_1 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_1[0][0]',     
 )                                                                   'activation_5[0][0]']        
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_1[0][0]']       
                                                                                                  
 batch_normalization_12 (Ba  (None, 64, 64, 256)          1024      ['conv2d_12[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_12 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_12[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_13 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_12[0][0]']       
                                                                                                  
 batch_normalization_13 (Ba  (None, 64, 64, 256)          1024      ['conv2d_13[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_13 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_13[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 128, 128, 256)        0         ['activation_13[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_2 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_2[0][0]',     
 )                                                                   'activation_3[0][0]']        
                                                                                                  
 conv2d_14 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_2[0][0]']       
                                                                                                  
 batch_normalization_14 (Ba  (None, 128, 128, 128)        512       ['conv2d_14[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_14 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_14[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_15 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_14[0][0]']       
                                                                                                  
 batch_normalization_15 (Ba  (None, 128, 128, 128)        512       ['conv2d_15[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_15 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_15[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 256, 256, 128)        0         ['activation_15[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_3 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_3[0][0]',     
 )                                                                   'activation_1[0][0]']        
                                                                                                  
 conv2d_16 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_3[0][0]']       
                                                                                                  
 batch_normalization_16 (Ba  (None, 256, 256, 64)         256       ['conv2d_16[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_16 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_16[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_16[0][0]']       
                                                                                                  
 batch_normalization_17 (Ba  (None, 256, 256, 64)         256       ['conv2d_17[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_17 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_17[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_18 (Conv2D)          (None, 256, 256, 1)          65        ['activation_17[0][0]']       
                                                                                                  
 batch_normalization_18 (Ba  (None, 256, 256, 1)          4         ['conv2d_18[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_18 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_18[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31401349 (119.79 MB)
Trainable params: 31389571 (119.74 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
None
✓ focal_loss imported successfully
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_2 (InputLayer)        [(None, 256, 256, 3)]        0         []                            
                                                                                                  
 conv2d_19 (Conv2D)          (None, 256, 256, 64)         1792      ['input_2[0][0]']             
                                                                                                  
 batch_normalization_19 (Ba  (None, 256, 256, 64)         256       ['conv2d_19[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_19 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_19[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_20 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_19[0][0]']       
                                                                                                  
 batch_normalization_20 (Ba  (None, 256, 256, 64)         256       ['conv2d_20[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_20 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_20[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_4 (MaxPoolin  (None, 128, 128, 64)         0         ['activation_20[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_21 (Conv2D)          (None, 128, 128, 128)        73856     ['max_pooling2d_4[0][0]']     
                                                                                                  
 batch_normalization_21 (Ba  (None, 128, 128, 128)        512       ['conv2d_21[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_21 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_21[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_22 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_21[0][0]']       
                                                                                                  
 batch_normalization_22 (Ba  (None, 128, 128, 128)        512       ['conv2d_22[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_22 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_22[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_5 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_22[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_23 (Conv2D)          (None, 64, 64, 256)          295168    ['max_pooling2d_5[0][0]']     
                                                                                                  
 batch_normalization_23 (Ba  (None, 64, 64, 256)          1024      ['conv2d_23[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_23 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_23[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_24 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_23[0][0]']       
                                                                                                  
 batch_normalization_24 (Ba  (None, 64, 64, 256)          1024      ['conv2d_24[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_24 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_24[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_6 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_24[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_25 (Conv2D)          (None, 32, 32, 512)          1180160   ['max_pooling2d_6[0][0]']     
                                                                                                  
 batch_normalization_25 (Ba  (None, 32, 32, 512)          2048      ['conv2d_25[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_25 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_25[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_26 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_25[0][0]']       
                                                                                                  
 batch_normalization_26 (Ba  (None, 32, 32, 512)          2048      ['conv2d_26[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_26 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_26[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_7 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_26[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_27 (Conv2D)          (None, 16, 16, 1024)         4719616   ['max_pooling2d_7[0][0]']     
                                                                                                  
 batch_normalization_27 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_27[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_27 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_27[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_28 (Conv2D)          (None, 16, 16, 1024)         9438208   ['activation_27[0][0]']       
                                                                                                  
 batch_normalization_28 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_28[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_28 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_28[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 1024)         0         ['activation_28[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_4 (Concatenate  (None, 32, 32, 1536)         0         ['up_sampling2d_4[0][0]',     
 )                                                                   'activation_26[0][0]']       
                                                                                                  
 conv2d_29 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate_4[0][0]']       
                                                                                                  
 batch_normalization_29 (Ba  (None, 32, 32, 512)          2048      ['conv2d_29[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_29 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_29[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_30 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_29[0][0]']       
                                                                                                  
 batch_normalization_30 (Ba  (None, 32, 32, 512)          2048      ['conv2d_30[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_30 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_30[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 512)          0         ['activation_30[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_5 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_5[0][0]',     
 )                                                                   'activation_24[0][0]']       
                                                                                                  
 conv2d_31 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_5[0][0]']       
                                                                                                  
 batch_normalization_31 (Ba  (None, 64, 64, 256)          1024      ['conv2d_31[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_31 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_31[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_32 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_31[0][0]']       
                                                                                                  
 batch_normalization_32 (Ba  (None, 64, 64, 256)          1024      ['conv2d_32[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_32 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_32[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_6 (UpSamplin  (None, 128, 128, 256)        0         ['activation_32[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_6 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_6[0][0]',     
 )                                                                   'activation_22[0][0]']       
                                                                                                  
 conv2d_33 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_6[0][0]']       
                                                                                                  
 batch_normalization_33 (Ba  (None, 128, 128, 128)        512       ['conv2d_33[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_33 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_33[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_34 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_33[0][0]']       
                                                                                                  
 batch_normalization_34 (Ba  (None, 128, 128, 128)        512       ['conv2d_34[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_34 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_34[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_7 (UpSamplin  (None, 256, 256, 128)        0         ['activation_34[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_7 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_7[0][0]',     
 )                                                                   'activation_20[0][0]']       
                                                                                                  
 conv2d_35 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_7[0][0]']       
                                                                                                  
 batch_normalization_35 (Ba  (None, 256, 256, 64)         256       ['conv2d_35[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_35 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_35[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_36 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_35[0][0]']       
                                                                                                  
 batch_normalization_36 (Ba  (None, 256, 256, 64)         256       ['conv2d_36[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_36 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_36[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_37 (Conv2D)          (None, 256, 256, 1)          65        ['activation_36[0][0]']       
                                                                                                  
 batch_normalization_37 (Ba  (None, 256, 256, 1)          4         ['conv2d_37[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_37 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_37[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31402501 (119.79 MB)
Trainable params: 31390723 (119.75 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
WARNING:absl:`lr` is deprecated in TF-Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
None
Epoch 1/30
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1758861954.287189 3188635 service.cc:145] XLA service 0x148ff1b6b6f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1758861954.287230 3188635 service.cc:153]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6
I0000 00:00:1758861954.675954 3188635 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
 1/17 [>.............................] - ETA: 10:52 - loss: 0.3503 - accuracy: 0.5178 - jacard_coef: 0.0648 2/17 [==>...........................] - ETA: 1:01 - loss: 0.3387 - accuracy: 0.4891 - jacard_coef: 0.0637  3/17 [====>.........................] - ETA: 37s - loss: 0.3083 - accuracy: 0.4283 - jacard_coef: 0.0754  4/17 [======>.......................] - ETA: 26s - loss: 0.2861 - accuracy: 0.3786 - jacard_coef: 0.0773 5/17 [=======>......................] - ETA: 18s - loss: 0.2732 - accuracy: 0.3376 - jacard_coef: 0.0734 6/17 [=========>....................] - ETA: 14s - loss: 0.2643 - accuracy: 0.3154 - jacard_coef: 0.0725 7/17 [===========>..................] - ETA: 11s - loss: 0.2570 - accuracy: 0.3018 - jacard_coef: 0.0744 8/17 [=============>................] - ETA: 8s - loss: 0.2493 - accuracy: 0.2991 - jacard_coef: 0.0722  9/17 [==============>...............] - ETA: 6s - loss: 0.2426 - accuracy: 0.2984 - jacard_coef: 0.072610/17 [================>.............] - ETA: 5s - loss: 0.2381 - accuracy: 0.3035 - jacard_coef: 0.071711/17 [==================>...........] - ETA: 4s - loss: 0.2331 - accuracy: 0.3147 - jacard_coef: 0.072412/17 [====================>.........] - ETA: 3s - loss: 0.2291 - accuracy: 0.3160 - jacard_coef: 0.072213/17 [=====================>........] - ETA: 2s - loss: 0.2256 - accuracy: 0.3171 - jacard_coef: 0.075414/17 [=======================>......] - ETA: 1s - loss: 0.2227 - accuracy: 0.3154 - jacard_coef: 0.074715/17 [=========================>....] - ETA: 1s - loss: 0.2200 - accuracy: 0.3192 - jacard_coef: 0.074416/17 [===========================>..] - ETA: 0s - loss: 0.2176 - accuracy: 0.3141 - jacard_coef: 0.076017/17 [==============================] - ETA: 0s - loss: 0.2174 - accuracy: 0.3134 - jacard_coef: 0.077917/17 [==============================] - 56s 944ms/step - loss: 0.2174 - accuracy: 0.3134 - jacard_coef: 0.0779 - val_loss: 1.1011 - val_accuracy: 0.9303 - val_jacard_coef: 4.9847e-04 - lr: 0.0010
Epoch 2/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1925 - accuracy: 0.2963 - jacard_coef: 0.0905 2/17 [==>...........................] - ETA: 1s - loss: 0.1859 - accuracy: 0.3210 - jacard_coef: 0.0860 3/17 [====>.........................] - ETA: 1s - loss: 0.1846 - accuracy: 0.3205 - jacard_coef: 0.0814 4/17 [======>.......................] - ETA: 1s - loss: 0.1831 - accuracy: 0.3250 - jacard_coef: 0.0764 5/17 [=======>......................] - ETA: 1s - loss: 0.1859 - accuracy: 0.3190 - jacard_coef: 0.0728 6/17 [=========>....................] - ETA: 1s - loss: 0.1862 - accuracy: 0.3080 - jacard_coef: 0.0717 7/17 [===========>..................] - ETA: 1s - loss: 0.1850 - accuracy: 0.3162 - jacard_coef: 0.0772 8/17 [=============>................] - ETA: 1s - loss: 0.1839 - accuracy: 0.3260 - jacard_coef: 0.0763 9/17 [==============>...............] - ETA: 1s - loss: 0.1833 - accuracy: 0.3296 - jacard_coef: 0.076010/17 [================>.............] - ETA: 0s - loss: 0.1828 - accuracy: 0.3378 - jacard_coef: 0.075111/17 [==================>...........] - ETA: 0s - loss: 0.1821 - accuracy: 0.3580 - jacard_coef: 0.074712/17 [====================>.........] - ETA: 0s - loss: 0.1815 - accuracy: 0.3688 - jacard_coef: 0.074413/17 [=====================>........] - ETA: 0s - loss: 0.1809 - accuracy: 0.3732 - jacard_coef: 0.074014/17 [=======================>......] - ETA: 0s - loss: 0.1806 - accuracy: 0.3773 - jacard_coef: 0.075015/17 [=========================>....] - ETA: 0s - loss: 0.1802 - accuracy: 0.3849 - jacard_coef: 0.074016/17 [===========================>..] - ETA: 0s - loss: 0.1798 - accuracy: 0.3975 - jacard_coef: 0.075317/17 [==============================] - ETA: 0s - loss: 0.1798 - accuracy: 0.3980 - jacard_coef: 0.080217/17 [==============================] - 2s 139ms/step - loss: 0.1798 - accuracy: 0.3980 - jacard_coef: 0.0802 - val_loss: 0.6407 - val_accuracy: 0.9301 - val_jacard_coef: 0.0103 - lr: 0.0010
Epoch 3/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1783 - accuracy: 0.6001 - jacard_coef: 0.0656 2/17 [==>...........................] - ETA: 1s - loss: 0.1746 - accuracy: 0.5608 - jacard_coef: 0.0605 3/17 [====>.........................] - ETA: 1s - loss: 0.1737 - accuracy: 0.5479 - jacard_coef: 0.0670 4/17 [======>.......................] - ETA: 1s - loss: 0.1735 - accuracy: 0.5638 - jacard_coef: 0.0798 5/17 [=======>......................] - ETA: 1s - loss: 0.1732 - accuracy: 0.5814 - jacard_coef: 0.0748 6/17 [=========>....................] - ETA: 1s - loss: 0.1733 - accuracy: 0.5695 - jacard_coef: 0.0745 7/17 [===========>..................] - ETA: 1s - loss: 0.1735 - accuracy: 0.5585 - jacard_coef: 0.0806 8/17 [=============>................] - ETA: 1s - loss: 0.1735 - accuracy: 0.5559 - jacard_coef: 0.0788 9/17 [==============>...............] - ETA: 1s - loss: 0.1741 - accuracy: 0.5600 - jacard_coef: 0.080410/17 [================>.............] - ETA: 0s - loss: 0.1738 - accuracy: 0.5546 - jacard_coef: 0.079711/17 [==================>...........] - ETA: 0s - loss: 0.1733 - accuracy: 0.5580 - jacard_coef: 0.076112/17 [====================>.........] - ETA: 0s - loss: 0.1727 - accuracy: 0.5623 - jacard_coef: 0.076113/17 [=====================>........] - ETA: 0s - loss: 0.1723 - accuracy: 0.5697 - jacard_coef: 0.075914/17 [=======================>......] - ETA: 0s - loss: 0.1720 - accuracy: 0.5740 - jacard_coef: 0.077515/17 [=========================>....] - ETA: 0s - loss: 0.1716 - accuracy: 0.5831 - jacard_coef: 0.076216/17 [===========================>..] - ETA: 0s - loss: 0.1713 - accuracy: 0.5942 - jacard_coef: 0.075917/17 [==============================] - 2s 136ms/step - loss: 0.1717 - accuracy: 0.5924 - jacard_coef: 0.0749 - val_loss: 0.3219 - val_accuracy: 0.9279 - val_jacard_coef: 0.0416 - lr: 0.0010
Epoch 4/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1702 - accuracy: 0.5506 - jacard_coef: 0.0754 2/17 [==>...........................] - ETA: 1s - loss: 0.1745 - accuracy: 0.5293 - jacard_coef: 0.0975 3/17 [====>.........................] - ETA: 1s - loss: 0.1818 - accuracy: 0.5128 - jacard_coef: 0.0939 4/17 [======>.......................] - ETA: 1s - loss: 0.1797 - accuracy: 0.5169 - jacard_coef: 0.0886 5/17 [=======>......................] - ETA: 1s - loss: 0.1789 - accuracy: 0.5260 - jacard_coef: 0.0833 6/17 [=========>....................] - ETA: 1s - loss: 0.1786 - accuracy: 0.5199 - jacard_coef: 0.0807 7/17 [===========>..................] - ETA: 1s - loss: 0.1775 - accuracy: 0.5325 - jacard_coef: 0.0748 8/17 [=============>................] - ETA: 1s - loss: 0.1764 - accuracy: 0.5462 - jacard_coef: 0.0766 9/17 [==============>...............] - ETA: 1s - loss: 0.1766 - accuracy: 0.5485 - jacard_coef: 0.077010/17 [================>.............] - ETA: 0s - loss: 0.1761 - accuracy: 0.5553 - jacard_coef: 0.074411/17 [==================>...........] - ETA: 0s - loss: 0.1754 - accuracy: 0.5659 - jacard_coef: 0.076912/17 [====================>.........] - ETA: 0s - loss: 0.1750 - accuracy: 0.5556 - jacard_coef: 0.078013/17 [=====================>........] - ETA: 0s - loss: 0.1744 - accuracy: 0.5717 - jacard_coef: 0.077514/17 [=======================>......] - ETA: 0s - loss: 0.1740 - accuracy: 0.5872 - jacard_coef: 0.077815/17 [=========================>....] - ETA: 0s - loss: 0.1735 - accuracy: 0.6028 - jacard_coef: 0.077516/17 [===========================>..] - ETA: 0s - loss: 0.1732 - accuracy: 0.6119 - jacard_coef: 0.076217/17 [==============================] - 2s 133ms/step - loss: 0.1732 - accuracy: 0.6099 - jacard_coef: 0.0749 - val_loss: 1.0927 - val_accuracy: 0.9294 - val_jacard_coef: 0.0018 - lr: 0.0010
Epoch 5/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1672 - accuracy: 0.6218 - jacard_coef: 0.0623 2/17 [==>...........................] - ETA: 1s - loss: 0.1684 - accuracy: 0.5833 - jacard_coef: 0.0601 3/17 [====>.........................] - ETA: 1s - loss: 0.1693 - accuracy: 0.5550 - jacard_coef: 0.0763 4/17 [======>.......................] - ETA: 1s - loss: 0.1686 - accuracy: 0.5860 - jacard_coef: 0.0784 5/17 [=======>......................] - ETA: 1s - loss: 0.1704 - accuracy: 0.6040 - jacard_coef: 0.0813 6/17 [=========>....................] - ETA: 1s - loss: 0.1696 - accuracy: 0.6183 - jacard_coef: 0.0766 7/17 [===========>..................] - ETA: 1s - loss: 0.1689 - accuracy: 0.6351 - jacard_coef: 0.0731 8/17 [=============>................] - ETA: 1s - loss: 0.1702 - accuracy: 0.6277 - jacard_coef: 0.0716 9/17 [==============>...............] - ETA: 1s - loss: 0.1699 - accuracy: 0.6404 - jacard_coef: 0.072410/17 [================>.............] - ETA: 0s - loss: 0.1698 - accuracy: 0.6549 - jacard_coef: 0.071711/17 [==================>...........] - ETA: 0s - loss: 0.1696 - accuracy: 0.6369 - jacard_coef: 0.071312/17 [====================>.........] - ETA: 0s - loss: 0.1698 - accuracy: 0.6427 - jacard_coef: 0.075313/17 [=====================>........] - ETA: 0s - loss: 0.1708 - accuracy: 0.6396 - jacard_coef: 0.076314/17 [=======================>......] - ETA: 0s - loss: 0.1709 - accuracy: 0.6376 - jacard_coef: 0.076615/17 [=========================>....] - ETA: 0s - loss: 0.1721 - accuracy: 0.6340 - jacard_coef: 0.076516/17 [===========================>..] - ETA: 0s - loss: 0.1720 - accuracy: 0.6329 - jacard_coef: 0.076017/17 [==============================] - 2s 134ms/step - loss: 0.1720 - accuracy: 0.6326 - jacard_coef: 0.0728 - val_loss: 1.1218 - val_accuracy: 0.9304 - val_jacard_coef: 3.4102e-05 - lr: 0.0010
Epoch 6/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1673 - accuracy: 0.4780 - jacard_coef: 0.0713 2/17 [==>...........................] - ETA: 1s - loss: 0.1684 - accuracy: 0.5481 - jacard_coef: 0.0757 3/17 [====>.........................] - ETA: 1s - loss: 0.1670 - accuracy: 0.5804 - jacard_coef: 0.0793 4/17 [======>.......................] - ETA: 1s - loss: 0.1677 - accuracy: 0.6197 - jacard_coef: 0.0778 5/17 [=======>......................] - ETA: 1s - loss: 0.1670 - accuracy: 0.6163 - jacard_coef: 0.0766 6/17 [=========>....................] - ETA: 1s - loss: 0.1659 - accuracy: 0.6503 - jacard_coef: 0.0780 7/17 [===========>..................] - ETA: 1s - loss: 0.1652 - accuracy: 0.6776 - jacard_coef: 0.0791 8/17 [=============>................] - ETA: 1s - loss: 0.1649 - accuracy: 0.6959 - jacard_coef: 0.0807 9/17 [==============>...............] - ETA: 1s - loss: 0.1648 - accuracy: 0.7104 - jacard_coef: 0.084010/17 [================>.............] - ETA: 0s - loss: 0.1649 - accuracy: 0.7153 - jacard_coef: 0.081211/17 [==================>...........] - ETA: 0s - loss: 0.1650 - accuracy: 0.7113 - jacard_coef: 0.078112/17 [====================>.........] - ETA: 0s - loss: 0.1648 - accuracy: 0.7193 - jacard_coef: 0.077413/17 [=====================>........] - ETA: 0s - loss: 0.1643 - accuracy: 0.7317 - jacard_coef: 0.076114/17 [=======================>......] - ETA: 0s - loss: 0.1640 - accuracy: 0.7380 - jacard_coef: 0.078315/17 [=========================>....] - ETA: 0s - loss: 0.1637 - accuracy: 0.7454 - jacard_coef: 0.077016/17 [===========================>..] - ETA: 0s - loss: 0.1634 - accuracy: 0.7512 - jacard_coef: 0.076217/17 [==============================] - 2s 136ms/step - loss: 0.1634 - accuracy: 0.7493 - jacard_coef: 0.0718 - val_loss: 2.2546 - val_accuracy: 0.8526 - val_jacard_coef: 0.0408 - lr: 0.0010
Epoch 7/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1597 - accuracy: 0.8504 - jacard_coef: 0.0559 2/17 [==>...........................] - ETA: 2s - loss: 0.1616 - accuracy: 0.8127 - jacard_coef: 0.0786 3/17 [====>.........................] - ETA: 1s - loss: 0.1618 - accuracy: 0.8118 - jacard_coef: 0.0724 4/17 [======>.......................] - ETA: 1s - loss: 0.1619 - accuracy: 0.8126 - jacard_coef: 0.0814 5/17 [=======>......................] - ETA: 1s - loss: 0.1615 - accuracy: 0.8242 - jacard_coef: 0.0818 6/17 [=========>....................] - ETA: 1s - loss: 0.1610 - accuracy: 0.8367 - jacard_coef: 0.0798 7/17 [===========>..................] - ETA: 1s - loss: 0.1622 - accuracy: 0.8437 - jacard_coef: 0.0804 8/17 [=============>................] - ETA: 1s - loss: 0.1614 - accuracy: 0.8541 - jacard_coef: 0.0759 9/17 [==============>...............] - ETA: 1s - loss: 0.1625 - accuracy: 0.8589 - jacard_coef: 0.076210/17 [================>.............] - ETA: 0s - loss: 0.1622 - accuracy: 0.8605 - jacard_coef: 0.076811/17 [==================>...........] - ETA: 0s - loss: 0.1621 - accuracy: 0.8631 - jacard_coef: 0.076612/17 [====================>.........] - ETA: 0s - loss: 0.1615 - accuracy: 0.8659 - jacard_coef: 0.073913/17 [=====================>........] - ETA: 0s - loss: 0.1611 - accuracy: 0.8710 - jacard_coef: 0.071514/17 [=======================>......] - ETA: 0s - loss: 0.1609 - accuracy: 0.8722 - jacard_coef: 0.072115/17 [=========================>....] - ETA: 0s - loss: 0.1609 - accuracy: 0.8727 - jacard_coef: 0.073616/17 [===========================>..] - ETA: 0s - loss: 0.1609 - accuracy: 0.8717 - jacard_coef: 0.075717/17 [==============================] - 2s 143ms/step - loss: 0.1608 - accuracy: 0.8723 - jacard_coef: 0.0714 - val_loss: 10.7675 - val_accuracy: 0.1597 - val_jacard_coef: 0.0665 - lr: 0.0010
Epoch 8/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1635 - accuracy: 0.9055 - jacard_coef: 0.0671 2/17 [==>...........................] - ETA: 2s - loss: 0.1581 - accuracy: 0.8990 - jacard_coef: 0.0641 3/17 [====>.........................] - ETA: 1s - loss: 0.1599 - accuracy: 0.7980 - jacard_coef: 0.0689 4/17 [======>.......................] - ETA: 1s - loss: 0.1575 - accuracy: 0.8380 - jacard_coef: 0.0612 5/17 [=======>......................] - ETA: 1s - loss: 0.1572 - accuracy: 0.8551 - jacard_coef: 0.0615 6/17 [=========>....................] - ETA: 1s - loss: 0.1573 - accuracy: 0.8571 - jacard_coef: 0.0643 7/17 [===========>..................] - ETA: 1s - loss: 0.1573 - accuracy: 0.8564 - jacard_coef: 0.0644 8/17 [=============>................] - ETA: 1s - loss: 0.1574 - accuracy: 0.8526 - jacard_coef: 0.0650 9/17 [==============>...............] - ETA: 1s - loss: 0.1576 - accuracy: 0.8491 - jacard_coef: 0.068710/17 [================>.............] - ETA: 0s - loss: 0.1590 - accuracy: 0.8490 - jacard_coef: 0.071311/17 [==================>...........] - ETA: 0s - loss: 0.1595 - accuracy: 0.8522 - jacard_coef: 0.073512/17 [====================>.........] - ETA: 0s - loss: 0.1590 - accuracy: 0.8595 - jacard_coef: 0.071813/17 [=====================>........] - ETA: 0s - loss: 0.1588 - accuracy: 0.8617 - jacard_coef: 0.073814/17 [=======================>......] - ETA: 0s - loss: 0.1586 - accuracy: 0.8656 - jacard_coef: 0.073615/17 [=========================>....] - ETA: 0s - loss: 0.1583 - accuracy: 0.8685 - jacard_coef: 0.073916/17 [===========================>..] - ETA: 0s - loss: 0.1581 - accuracy: 0.8683 - jacard_coef: 0.075817/17 [==============================] - 2s 143ms/step - loss: 0.1580 - accuracy: 0.8683 - jacard_coef: 0.0731 - val_loss: 12.8182 - val_accuracy: 0.1864 - val_jacard_coef: 0.0699 - lr: 0.0010
Epoch 9/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1535 - accuracy: 0.8315 - jacard_coef: 0.1070 2/17 [==>...........................] - ETA: 2s - loss: 0.1545 - accuracy: 0.8773 - jacard_coef: 0.0829 3/17 [====>.........................] - ETA: 1s - loss: 0.1574 - accuracy: 0.8715 - jacard_coef: 0.0911 4/17 [======>.......................] - ETA: 1s - loss: 0.1555 - accuracy: 0.8773 - jacard_coef: 0.0897 5/17 [=======>......................] - ETA: 1s - loss: 0.1541 - accuracy: 0.8842 - jacard_coef: 0.0846 6/17 [=========>....................] - ETA: 1s - loss: 0.1531 - accuracy: 0.8889 - jacard_coef: 0.0791 7/17 [===========>..................] - ETA: 1s - loss: 0.1539 - accuracy: 0.8808 - jacard_coef: 0.0797 8/17 [=============>................] - ETA: 1s - loss: 0.1533 - accuracy: 0.8821 - jacard_coef: 0.0811 9/17 [==============>...............] - ETA: 1s - loss: 0.1526 - accuracy: 0.8876 - jacard_coef: 0.078410/17 [================>.............] - ETA: 0s - loss: 0.1523 - accuracy: 0.8885 - jacard_coef: 0.079011/17 [==================>...........] - ETA: 0s - loss: 0.1519 - accuracy: 0.8902 - jacard_coef: 0.078912/17 [====================>.........] - ETA: 0s - loss: 0.1514 - accuracy: 0.8921 - jacard_coef: 0.078513/17 [=====================>........] - ETA: 0s - loss: 0.1510 - accuracy: 0.8937 - jacard_coef: 0.078214/17 [=======================>......] - ETA: 0s - loss: 0.1507 - accuracy: 0.8955 - jacard_coef: 0.077715/17 [=========================>....] - ETA: 0s - loss: 0.1507 - accuracy: 0.8992 - jacard_coef: 0.075516/17 [===========================>..] - ETA: 0s - loss: 0.1504 - accuracy: 0.9002 - jacard_coef: 0.075617/17 [==============================] - 2s 137ms/step - loss: 0.1504 - accuracy: 0.9009 - jacard_coef: 0.0716 - val_loss: 13.2116 - val_accuracy: 0.1006 - val_jacard_coef: 0.0694 - lr: 0.0010
Epoch 10/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1437 - accuracy: 0.9609 - jacard_coef: 0.0342 2/17 [==>...........................] - ETA: 2s - loss: 0.1447 - accuracy: 0.9474 - jacard_coef: 0.0441 3/17 [====>.........................] - ETA: 1s - loss: 0.1456 - accuracy: 0.9376 - jacard_coef: 0.0532 4/17 [======>.......................] - ETA: 1s - loss: 0.1455 - accuracy: 0.9349 - jacard_coef: 0.0558 5/17 [=======>......................] - ETA: 1s - loss: 0.1458 - accuracy: 0.9297 - jacard_coef: 0.0602 6/17 [=========>....................] - ETA: 1s - loss: 0.1460 - accuracy: 0.9288 - jacard_coef: 0.0613 7/17 [===========>..................] - ETA: 1s - loss: 0.1471 - accuracy: 0.9228 - jacard_coef: 0.0668 8/17 [=============>................] - ETA: 1s - loss: 0.1469 - accuracy: 0.9208 - jacard_coef: 0.0691 9/17 [==============>...............] - ETA: 1s - loss: 0.1466 - accuracy: 0.9197 - jacard_coef: 0.070410/17 [================>.............] - ETA: 0s - loss: 0.1463 - accuracy: 0.9190 - jacard_coef: 0.071311/17 [==================>...........] - ETA: 0s - loss: 0.1461 - accuracy: 0.9165 - jacard_coef: 0.073512/17 [====================>.........] - ETA: 0s - loss: 0.1459 - accuracy: 0.9178 - jacard_coef: 0.071413/17 [=====================>........] - ETA: 0s - loss: 0.1456 - accuracy: 0.9190 - jacard_coef: 0.070714/17 [=======================>......] - ETA: 0s - loss: 0.1454 - accuracy: 0.9187 - jacard_coef: 0.071215/17 [=========================>....] - ETA: 0s - loss: 0.1454 - accuracy: 0.9156 - jacard_coef: 0.073916/17 [===========================>..] - ETA: 0s - loss: 0.1458 - accuracy: 0.9150 - jacard_coef: 0.074617/17 [==============================] - 2s 137ms/step - loss: 0.1460 - accuracy: 0.9138 - jacard_coef: 0.0776 - val_loss: 12.8898 - val_accuracy: 0.1564 - val_jacard_coef: 0.0651 - lr: 0.0010
Epoch 11/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1461 - accuracy: 0.8985 - jacard_coef: 0.0813 2/17 [==>...........................] - ETA: 2s - loss: 0.1533 - accuracy: 0.9019 - jacard_coef: 0.0745 3/17 [====>.........................] - ETA: 1s - loss: 0.1527 - accuracy: 0.8956 - jacard_coef: 0.0780 4/17 [======>.......................] - ETA: 1s - loss: 0.1535 - accuracy: 0.8909 - jacard_coef: 0.0813 5/17 [=======>......................] - ETA: 1s - loss: 0.1527 - accuracy: 0.8925 - jacard_coef: 0.0745 6/17 [=========>....................] - ETA: 1s - loss: 0.1523 - accuracy: 0.8786 - jacard_coef: 0.0724 7/17 [===========>..................] - ETA: 1s - loss: 0.1521 - accuracy: 0.8712 - jacard_coef: 0.0758 8/17 [=============>................] - ETA: 1s - loss: 0.1519 - accuracy: 0.8612 - jacard_coef: 0.0784 9/17 [==============>...............] - ETA: 1s - loss: 0.1511 - accuracy: 0.8685 - jacard_coef: 0.075010/17 [================>.............] - ETA: 0s - loss: 0.1507 - accuracy: 0.8706 - jacard_coef: 0.075111/17 [==================>...........] - ETA: 0s - loss: 0.1503 - accuracy: 0.8718 - jacard_coef: 0.076112/17 [====================>.........] - ETA: 0s - loss: 0.1508 - accuracy: 0.8706 - jacard_coef: 0.078213/17 [=====================>........] - ETA: 0s - loss: 0.1501 - accuracy: 0.8733 - jacard_coef: 0.078014/17 [=======================>......] - ETA: 0s - loss: 0.1496 - accuracy: 0.8755 - jacard_coef: 0.077915/17 [=========================>....] - ETA: 0s - loss: 0.1490 - accuracy: 0.8796 - jacard_coef: 0.075816/17 [===========================>..] - ETA: 0s - loss: 0.1486 - accuracy: 0.8812 - jacard_coef: 0.075117/17 [==============================] - 2s 137ms/step - loss: 0.1489 - accuracy: 0.8790 - jacard_coef: 0.0737 - val_loss: 1.0298 - val_accuracy: 0.8898 - val_jacard_coef: 0.0334 - lr: 0.0010
Epoch 12/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1519 - accuracy: 0.8603 - jacard_coef: 0.1048 2/17 [==>...........................] - ETA: 2s - loss: 0.1550 - accuracy: 0.8577 - jacard_coef: 0.1069 3/17 [====>.........................] - ETA: 1s - loss: 0.1532 - accuracy: 0.8845 - jacard_coef: 0.0844 4/17 [======>.......................] - ETA: 1s - loss: 0.1531 - accuracy: 0.8898 - jacard_coef: 0.0806 5/17 [=======>......................] - ETA: 1s - loss: 0.1548 - accuracy: 0.8860 - jacard_coef: 0.0830 6/17 [=========>....................] - ETA: 1s - loss: 0.1556 - accuracy: 0.8857 - jacard_coef: 0.0825 7/17 [===========>..................] - ETA: 1s - loss: 0.1557 - accuracy: 0.8867 - jacard_coef: 0.0809 8/17 [=============>................] - ETA: 1s - loss: 0.1572 - accuracy: 0.8867 - jacard_coef: 0.0814 9/17 [==============>...............] - ETA: 1s - loss: 0.1581 - accuracy: 0.8932 - jacard_coef: 0.076510/17 [================>.............] - ETA: 0s - loss: 0.1573 - accuracy: 0.8915 - jacard_coef: 0.078111/17 [==================>...........] - ETA: 0s - loss: 0.1563 - accuracy: 0.8939 - jacard_coef: 0.076712/17 [====================>.........] - ETA: 0s - loss: 0.1553 - accuracy: 0.8961 - jacard_coef: 0.073613/17 [=====================>........] - ETA: 0s - loss: 0.1546 - accuracy: 0.8954 - jacard_coef: 0.072914/17 [=======================>......] - ETA: 0s - loss: 0.1538 - accuracy: 0.8972 - jacard_coef: 0.072015/17 [=========================>....] - ETA: 0s - loss: 0.1539 - accuracy: 0.8988 - jacard_coef: 0.071616/17 [===========================>..] - ETA: 0s - loss: 0.1540 - accuracy: 0.8969 - jacard_coef: 0.074317/17 [==============================] - 2s 137ms/step - loss: 0.1540 - accuracy: 0.8960 - jacard_coef: 0.0772 - val_loss: 0.1516 - val_accuracy: 0.9303 - val_jacard_coef: 0.0631 - lr: 0.0010
Epoch 13/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1531 - accuracy: 0.9051 - jacard_coef: 0.0841 2/17 [==>...........................] - ETA: 2s - loss: 0.1454 - accuracy: 0.9210 - jacard_coef: 0.0711 3/17 [====>.........................] - ETA: 1s - loss: 0.1476 - accuracy: 0.9047 - jacard_coef: 0.0840 4/17 [======>.......................] - ETA: 1s - loss: 0.1462 - accuracy: 0.8834 - jacard_coef: 0.0772 5/17 [=======>......................] - ETA: 1s - loss: 0.1453 - accuracy: 0.8839 - jacard_coef: 0.0810 6/17 [=========>....................] - ETA: 1s - loss: 0.1445 - accuracy: 0.8894 - jacard_coef: 0.0789 7/17 [===========>..................] - ETA: 1s - loss: 0.1439 - accuracy: 0.8919 - jacard_coef: 0.0789 8/17 [=============>................] - ETA: 1s - loss: 0.1434 - accuracy: 0.8971 - jacard_coef: 0.0758 9/17 [==============>...............] - ETA: 1s - loss: 0.1422 - accuracy: 0.9043 - jacard_coef: 0.070910/17 [================>.............] - ETA: 0s - loss: 0.1420 - accuracy: 0.9043 - jacard_coef: 0.071911/17 [==================>...........] - ETA: 0s - loss: 0.1416 - accuracy: 0.9040 - jacard_coef: 0.072712/17 [====================>.........] - ETA: 0s - loss: 0.1413 - accuracy: 0.9057 - jacard_coef: 0.071813/17 [=====================>........] - ETA: 0s - loss: 0.1408 - accuracy: 0.9064 - jacard_coef: 0.070814/17 [=======================>......] - ETA: 0s - loss: 0.1404 - accuracy: 0.9083 - jacard_coef: 0.069915/17 [=========================>....] - ETA: 0s - loss: 0.1404 - accuracy: 0.9054 - jacard_coef: 0.072716/17 [===========================>..] - ETA: 0s - loss: 0.1407 - accuracy: 0.9045 - jacard_coef: 0.074117/17 [==============================] - 2s 137ms/step - loss: 0.1408 - accuracy: 0.9041 - jacard_coef: 0.0771 - val_loss: 0.1708 - val_accuracy: 0.9304 - val_jacard_coef: 0.0606 - lr: 0.0010
Epoch 14/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1350 - accuracy: 0.9379 - jacard_coef: 0.0554 2/17 [==>...........................] - ETA: 2s - loss: 0.1369 - accuracy: 0.9243 - jacard_coef: 0.0667 3/17 [====>.........................] - ETA: 1s - loss: 0.1359 - accuracy: 0.9281 - jacard_coef: 0.0640 4/17 [======>.......................] - ETA: 1s - loss: 0.1355 - accuracy: 0.9242 - jacard_coef: 0.0676 5/17 [=======>......................] - ETA: 1s - loss: 0.1358 - accuracy: 0.9201 - jacard_coef: 0.0714 6/17 [=========>....................] - ETA: 1s - loss: 0.1371 - accuracy: 0.9165 - jacard_coef: 0.0743 7/17 [===========>..................] - ETA: 1s - loss: 0.1372 - accuracy: 0.9156 - jacard_coef: 0.0737 8/17 [=============>................] - ETA: 1s - loss: 0.1370 - accuracy: 0.9160 - jacard_coef: 0.0736 9/17 [==============>...............] - ETA: 1s - loss: 0.1365 - accuracy: 0.9183 - jacard_coef: 0.071810/17 [================>.............] - ETA: 0s - loss: 0.1367 - accuracy: 0.9156 - jacard_coef: 0.074111/17 [==================>...........] - ETA: 0s - loss: 0.1365 - accuracy: 0.9151 - jacard_coef: 0.074612/17 [====================>.........] - ETA: 0s - loss: 0.1362 - accuracy: 0.9162 - jacard_coef: 0.073713/17 [=====================>........] - ETA: 0s - loss: 0.1364 - accuracy: 0.9146 - jacard_coef: 0.075014/17 [=======================>......] - ETA: 0s - loss: 0.1360 - accuracy: 0.9185 - jacard_coef: 0.071615/17 [=========================>....] - ETA: 0s - loss: 0.1360 - accuracy: 0.9163 - jacard_coef: 0.073316/17 [===========================>..] - ETA: 0s - loss: 0.1360 - accuracy: 0.9151 - jacard_coef: 0.074217/17 [==============================] - 2s 137ms/step - loss: 0.1361 - accuracy: 0.9141 - jacard_coef: 0.0780 - val_loss: 0.1429 - val_accuracy: 0.9304 - val_jacard_coef: 0.0616 - lr: 5.0000e-04
Epoch 15/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1377 - accuracy: 0.9248 - jacard_coef: 0.0626 2/17 [==>...........................] - ETA: 2s - loss: 0.1411 - accuracy: 0.9009 - jacard_coef: 0.0823 3/17 [====>.........................] - ETA: 1s - loss: 0.1421 - accuracy: 0.8954 - jacard_coef: 0.0857 4/17 [======>.......................] - ETA: 1s - loss: 0.1428 - accuracy: 0.8965 - jacard_coef: 0.0857 5/17 [=======>......................] - ETA: 1s - loss: 0.1416 - accuracy: 0.9005 - jacard_coef: 0.0824 6/17 [=========>....................] - ETA: 1s - loss: 0.1408 - accuracy: 0.9046 - jacard_coef: 0.0792 7/17 [===========>..................] - ETA: 1s - loss: 0.1411 - accuracy: 0.8994 - jacard_coef: 0.0834 8/17 [=============>................] - ETA: 1s - loss: 0.1407 - accuracy: 0.9034 - jacard_coef: 0.0802 9/17 [==============>...............] - ETA: 1s - loss: 0.1403 - accuracy: 0.9042 - jacard_coef: 0.079710/17 [================>.............] - ETA: 0s - loss: 0.1396 - accuracy: 0.9073 - jacard_coef: 0.077511/17 [==================>...........] - ETA: 0s - loss: 0.1403 - accuracy: 0.9066 - jacard_coef: 0.078412/17 [====================>.........] - ETA: 0s - loss: 0.1399 - accuracy: 0.9081 - jacard_coef: 0.077513/17 [=====================>........] - ETA: 0s - loss: 0.1396 - accuracy: 0.9101 - jacard_coef: 0.076214/17 [=======================>......] - ETA: 0s - loss: 0.1394 - accuracy: 0.9138 - jacard_coef: 0.073215/17 [=========================>....] - ETA: 0s - loss: 0.1392 - accuracy: 0.9130 - jacard_coef: 0.074216/17 [===========================>..] - ETA: 0s - loss: 0.1391 - accuracy: 0.9125 - jacard_coef: 0.074817/17 [==============================] - 2s 137ms/step - loss: 0.1391 - accuracy: 0.9126 - jacard_coef: 0.0740 - val_loss: 0.1373 - val_accuracy: 0.9304 - val_jacard_coef: 0.0624 - lr: 5.0000e-04
Epoch 16/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1351 - accuracy: 0.9023 - jacard_coef: 0.0862 2/17 [==>...........................] - ETA: 2s - loss: 0.1387 - accuracy: 0.8940 - jacard_coef: 0.0928 3/17 [====>.........................] - ETA: 1s - loss: 0.1370 - accuracy: 0.9014 - jacard_coef: 0.0866 4/17 [======>.......................] - ETA: 1s - loss: 0.1358 - accuracy: 0.9080 - jacard_coef: 0.0812 5/17 [=======>......................] - ETA: 1s - loss: 0.1353 - accuracy: 0.9102 - jacard_coef: 0.0795 6/17 [=========>....................] - ETA: 1s - loss: 0.1352 - accuracy: 0.9100 - jacard_coef: 0.0798 7/17 [===========>..................] - ETA: 1s - loss: 0.1350 - accuracy: 0.9117 - jacard_coef: 0.0785 8/17 [=============>................] - ETA: 1s - loss: 0.1348 - accuracy: 0.9104 - jacard_coef: 0.0796 9/17 [==============>...............] - ETA: 1s - loss: 0.1347 - accuracy: 0.9103 - jacard_coef: 0.079810/17 [================>.............] - ETA: 0s - loss: 0.1356 - accuracy: 0.9122 - jacard_coef: 0.078211/17 [==================>...........] - ETA: 0s - loss: 0.1349 - accuracy: 0.9160 - jacard_coef: 0.075012/17 [====================>.........] - ETA: 0s - loss: 0.1349 - accuracy: 0.9139 - jacard_coef: 0.076713/17 [=====================>........] - ETA: 0s - loss: 0.1352 - accuracy: 0.9126 - jacard_coef: 0.077614/17 [=======================>......] - ETA: 0s - loss: 0.1345 - accuracy: 0.9163 - jacard_coef: 0.074415/17 [=========================>....] - ETA: 0s - loss: 0.1345 - accuracy: 0.9157 - jacard_coef: 0.075016/17 [===========================>..] - ETA: 0s - loss: 0.1343 - accuracy: 0.9158 - jacard_coef: 0.075017/17 [==============================] - 2s 138ms/step - loss: 0.1344 - accuracy: 0.9161 - jacard_coef: 0.0718 - val_loss: 0.1300 - val_accuracy: 0.9304 - val_jacard_coef: 0.0623 - lr: 5.0000e-04
Epoch 17/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1319 - accuracy: 0.9145 - jacard_coef: 0.0761 2/17 [==>...........................] - ETA: 2s - loss: 0.1305 - accuracy: 0.9291 - jacard_coef: 0.0638 3/17 [====>.........................] - ETA: 1s - loss: 0.1315 - accuracy: 0.9182 - jacard_coef: 0.0723 4/17 [======>.......................] - ETA: 1s - loss: 0.1324 - accuracy: 0.9125 - jacard_coef: 0.0773 5/17 [=======>......................] - ETA: 1s - loss: 0.1316 - accuracy: 0.9165 - jacard_coef: 0.0741 6/17 [=========>....................] - ETA: 1s - loss: 0.1327 - accuracy: 0.9068 - jacard_coef: 0.0817 7/17 [===========>..................] - ETA: 1s - loss: 0.1323 - accuracy: 0.9106 - jacard_coef: 0.0787 8/17 [=============>................] - ETA: 1s - loss: 0.1334 - accuracy: 0.9104 - jacard_coef: 0.0789 9/17 [==============>...............] - ETA: 1s - loss: 0.1329 - accuracy: 0.9148 - jacard_coef: 0.075210/17 [================>.............] - ETA: 0s - loss: 0.1322 - accuracy: 0.9188 - jacard_coef: 0.071811/17 [==================>...........] - ETA: 0s - loss: 0.1330 - accuracy: 0.9160 - jacard_coef: 0.074112/17 [====================>.........] - ETA: 0s - loss: 0.1331 - accuracy: 0.9144 - jacard_coef: 0.075513/17 [=====================>........] - ETA: 0s - loss: 0.1330 - accuracy: 0.9132 - jacard_coef: 0.076514/17 [=======================>......] - ETA: 0s - loss: 0.1327 - accuracy: 0.9155 - jacard_coef: 0.074615/17 [=========================>....] - ETA: 0s - loss: 0.1329 - accuracy: 0.9151 - jacard_coef: 0.075016/17 [===========================>..] - ETA: 0s - loss: 0.1326 - accuracy: 0.9166 - jacard_coef: 0.073817/17 [==============================] - 2s 137ms/step - loss: 0.1326 - accuracy: 0.9159 - jacard_coef: 0.0780 - val_loss: 0.1277 - val_accuracy: 0.9304 - val_jacard_coef: 0.0623 - lr: 5.0000e-04
Epoch 18/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1284 - accuracy: 0.9333 - jacard_coef: 0.0609 2/17 [==>...........................] - ETA: 2s - loss: 0.1311 - accuracy: 0.9176 - jacard_coef: 0.0741 3/17 [====>.........................] - ETA: 1s - loss: 0.1323 - accuracy: 0.9138 - jacard_coef: 0.0771 4/17 [======>.......................] - ETA: 1s - loss: 0.1334 - accuracy: 0.9021 - jacard_coef: 0.0865 5/17 [=======>......................] - ETA: 1s - loss: 0.1328 - accuracy: 0.9094 - jacard_coef: 0.0806 6/17 [=========>....................] - ETA: 1s - loss: 0.1321 - accuracy: 0.9115 - jacard_coef: 0.0787 7/17 [===========>..................] - ETA: 1s - loss: 0.1321 - accuracy: 0.9101 - jacard_coef: 0.0800 8/17 [=============>................] - ETA: 1s - loss: 0.1320 - accuracy: 0.9088 - jacard_coef: 0.0809 9/17 [==============>...............] - ETA: 1s - loss: 0.1315 - accuracy: 0.9110 - jacard_coef: 0.079210/17 [================>.............] - ETA: 0s - loss: 0.1312 - accuracy: 0.9132 - jacard_coef: 0.077311/17 [==================>...........] - ETA: 0s - loss: 0.1312 - accuracy: 0.9127 - jacard_coef: 0.077712/17 [====================>.........] - ETA: 0s - loss: 0.1310 - accuracy: 0.9135 - jacard_coef: 0.077113/17 [=====================>........] - ETA: 0s - loss: 0.1310 - accuracy: 0.9159 - jacard_coef: 0.075014/17 [=======================>......] - ETA: 0s - loss: 0.1312 - accuracy: 0.9133 - jacard_coef: 0.077015/17 [=========================>....] - ETA: 0s - loss: 0.1311 - accuracy: 0.9125 - jacard_coef: 0.077616/17 [===========================>..] - ETA: 0s - loss: 0.1306 - accuracy: 0.9157 - jacard_coef: 0.074817/17 [==============================] - 2s 137ms/step - loss: 0.1306 - accuracy: 0.9161 - jacard_coef: 0.0719 - val_loss: 0.1268 - val_accuracy: 0.9304 - val_jacard_coef: 0.0623 - lr: 5.0000e-04
/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(

✓ Training completed successfully!
  Best Val Jaccard: 0.0699 (epoch 8)
  Final Val Loss: 0.1268
  Training Time: 0:01:36.457689
  Stability (std): 5.1267

Results saved to: hyperparameter_optimization_20250926_123742/exp_4_UNet_lr5e-4_bs8/UNet_lr0.0005_bs8_results.json
