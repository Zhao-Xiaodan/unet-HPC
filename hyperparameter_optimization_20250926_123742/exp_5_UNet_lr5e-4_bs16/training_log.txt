âœ“ GPU memory growth enabled for 1 GPUs
Loading dataset...
Loaded 144 images and 144 masks
Training set: (129, 256, 256, 3), Validation set: (15, 256, 256, 3)

============================================================
TRAINING: UNet
Learning Rate: 0.0005, Batch Size: 16, Epochs: 30
============================================================
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 256, 256, 64)         640       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 256, 256, 64)         256       ['conv2d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 activation (Activation)     (None, 256, 256, 64)         0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['activation[0][0]']          
                                                                                                  
 batch_normalization_1 (Bat  (None, 256, 256, 64)         256       ['conv2d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_1 (Activation)   (None, 256, 256, 64)         0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['activation_1[0][0]']        
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       
                                                                                                  
 batch_normalization_2 (Bat  (None, 128, 128, 128)        512       ['conv2d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_2 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_3 (Conv2D)           (None, 128, 128, 128)        147584    ['activation_2[0][0]']        
                                                                                                  
 batch_normalization_3 (Bat  (None, 128, 128, 128)        512       ['conv2d_3[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_3 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_3[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_3[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 batch_normalization_4 (Bat  (None, 64, 64, 256)          1024      ['conv2d_4[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_4 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_4[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_5 (Conv2D)           (None, 64, 64, 256)          590080    ['activation_4[0][0]']        
                                                                                                  
 batch_normalization_5 (Bat  (None, 64, 64, 256)          1024      ['conv2d_5[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_5 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_5[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_5[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 512)          1180160   ['max_pooling2d_2[0][0]']     
                                                                                                  
 batch_normalization_6 (Bat  (None, 32, 32, 512)          2048      ['conv2d_6[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_6 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_6[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 32, 32, 512)          2359808   ['activation_6[0][0]']        
                                                                                                  
 batch_normalization_7 (Bat  (None, 32, 32, 512)          2048      ['conv2d_7[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_7 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_7[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_3 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_7[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 1024)         4719616   ['max_pooling2d_3[0][0]']     
                                                                                                  
 batch_normalization_8 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_8[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_8 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_8[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 1024)         9438208   ['activation_8[0][0]']        
                                                                                                  
 batch_normalization_9 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_9[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_9 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_9[0][0]'
                                                                    ]                             
                                                                                                  
 up_sampling2d (UpSampling2  (None, 32, 32, 1024)         0         ['activation_9[0][0]']        
 D)                                                                                               
                                                                                                  
 concatenate (Concatenate)   (None, 32, 32, 1536)         0         ['up_sampling2d[0][0]',       
                                                                     'activation_7[0][0]']        
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate[0][0]']         
                                                                                                  
 batch_normalization_10 (Ba  (None, 32, 32, 512)          2048      ['conv2d_10[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_10 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_10[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_10[0][0]']       
                                                                                                  
 batch_normalization_11 (Ba  (None, 32, 32, 512)          2048      ['conv2d_11[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_11 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_11[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 64, 64, 512)          0         ['activation_11[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_1 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_1[0][0]',     
 )                                                                   'activation_5[0][0]']        
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_1[0][0]']       
                                                                                                  
 batch_normalization_12 (Ba  (None, 64, 64, 256)          1024      ['conv2d_12[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_12 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_12[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_13 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_12[0][0]']       
                                                                                                  
 batch_normalization_13 (Ba  (None, 64, 64, 256)          1024      ['conv2d_13[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_13 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_13[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 128, 128, 256)        0         ['activation_13[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_2 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_2[0][0]',     
 )                                                                   'activation_3[0][0]']        
                                                                                                  
 conv2d_14 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_2[0][0]']       
                                                                                                  
 batch_normalization_14 (Ba  (None, 128, 128, 128)        512       ['conv2d_14[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_14 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_14[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_15 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_14[0][0]']       
                                                                                                  
 batch_normalization_15 (Ba  (None, 128, 128, 128)        512       ['conv2d_15[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_15 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_15[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 256, 256, 128)        0         ['activation_15[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_3 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_3[0][0]',     
 )                                                                   'activation_1[0][0]']        
                                                                                                  
 conv2d_16 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_3[0][0]']       
                                                                                                  
 batch_normalization_16 (Ba  (None, 256, 256, 64)         256       ['conv2d_16[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_16 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_16[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_16[0][0]']       
                                                                                                  
 batch_normalization_17 (Ba  (None, 256, 256, 64)         256       ['conv2d_17[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_17 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_17[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_18 (Conv2D)          (None, 256, 256, 1)          65        ['activation_17[0][0]']       
                                                                                                  
 batch_normalization_18 (Ba  (None, 256, 256, 1)          4         ['conv2d_18[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_18 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_18[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31401349 (119.79 MB)
Trainable params: 31389571 (119.74 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
None
âœ“ focal_loss imported successfully
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_2 (InputLayer)        [(None, 256, 256, 3)]        0         []                            
                                                                                                  
 conv2d_19 (Conv2D)          (None, 256, 256, 64)         1792      ['input_2[0][0]']             
                                                                                                  
 batch_normalization_19 (Ba  (None, 256, 256, 64)         256       ['conv2d_19[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_19 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_19[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_20 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_19[0][0]']       
                                                                                                  
 batch_normalization_20 (Ba  (None, 256, 256, 64)         256       ['conv2d_20[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_20 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_20[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_4 (MaxPoolin  (None, 128, 128, 64)         0         ['activation_20[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_21 (Conv2D)          (None, 128, 128, 128)        73856     ['max_pooling2d_4[0][0]']     
                                                                                                  
 batch_normalization_21 (Ba  (None, 128, 128, 128)        512       ['conv2d_21[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_21 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_21[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_22 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_21[0][0]']       
                                                                                                  
 batch_normalization_22 (Ba  (None, 128, 128, 128)        512       ['conv2d_22[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_22 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_22[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_5 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_22[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_23 (Conv2D)          (None, 64, 64, 256)          295168    ['max_pooling2d_5[0][0]']     
                                                                                                  
 batch_normalization_23 (Ba  (None, 64, 64, 256)          1024      ['conv2d_23[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_23 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_23[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_24 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_23[0][0]']       
                                                                                                  
 batch_normalization_24 (Ba  (None, 64, 64, 256)          1024      ['conv2d_24[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_24 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_24[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_6 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_24[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_25 (Conv2D)          (None, 32, 32, 512)          1180160   ['max_pooling2d_6[0][0]']     
                                                                                                  
 batch_normalization_25 (Ba  (None, 32, 32, 512)          2048      ['conv2d_25[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_25 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_25[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_26 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_25[0][0]']       
                                                                                                  
 batch_normalization_26 (Ba  (None, 32, 32, 512)          2048      ['conv2d_26[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_26 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_26[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_7 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_26[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_27 (Conv2D)          (None, 16, 16, 1024)         4719616   ['max_pooling2d_7[0][0]']     
                                                                                                  
 batch_normalization_27 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_27[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_27 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_27[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_28 (Conv2D)          (None, 16, 16, 1024)         9438208   ['activation_27[0][0]']       
                                                                                                  
 batch_normalization_28 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_28[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_28 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_28[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 1024)         0         ['activation_28[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_4 (Concatenate  (None, 32, 32, 1536)         0         ['up_sampling2d_4[0][0]',     
 )                                                                   'activation_26[0][0]']       
                                                                                                  
 conv2d_29 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate_4[0][0]']       
                                                                                                  
 batch_normalization_29 (Ba  (None, 32, 32, 512)          2048      ['conv2d_29[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_29 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_29[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_30 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_29[0][0]']       
                                                                                                  
 batch_normalization_30 (Ba  (None, 32, 32, 512)          2048      ['conv2d_30[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_30 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_30[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 512)          0         ['activation_30[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_5 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_5[0][0]',     
 )                                                                   'activation_24[0][0]']       
                                                                                                  
 conv2d_31 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_5[0][0]']       
                                                                                                  
 batch_normalization_31 (Ba  (None, 64, 64, 256)          1024      ['conv2d_31[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_31 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_31[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_32 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_31[0][0]']       
                                                                                                  
 batch_normalization_32 (Ba  (None, 64, 64, 256)          1024      ['conv2d_32[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_32 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_32[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_6 (UpSamplin  (None, 128, 128, 256)        0         ['activation_32[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_6 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_6[0][0]',     
 )                                                                   'activation_22[0][0]']       
                                                                                                  
 conv2d_33 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_6[0][0]']       
                                                                                                  
 batch_normalization_33 (Ba  (None, 128, 128, 128)        512       ['conv2d_33[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_33 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_33[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_34 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_33[0][0]']       
                                                                                                  
 batch_normalization_34 (Ba  (None, 128, 128, 128)        512       ['conv2d_34[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_34 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_34[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_7 (UpSamplin  (None, 256, 256, 128)        0         ['activation_34[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_7 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_7[0][0]',     
 )                                                                   'activation_20[0][0]']       
                                                                                                  
 conv2d_35 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_7[0][0]']       
                                                                                                  
 batch_normalization_35 (Ba  (None, 256, 256, 64)         256       ['conv2d_35[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_35 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_35[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_36 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_35[0][0]']       
                                                                                                  
 batch_normalization_36 (Ba  (None, 256, 256, 64)         256       ['conv2d_36[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_36 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_36[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_37 (Conv2D)          (None, 256, 256, 1)          65        ['activation_36[0][0]']       
                                                                                                  
 batch_normalization_37 (Ba  (None, 256, 256, 1)          4         ['conv2d_37[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_37 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_37[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31402501 (119.79 MB)
Trainable params: 31390723 (119.75 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
WARNING:absl:`lr` is deprecated in TF-Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
None
Epoch 1/30
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1758862085.867091 3192690 service.cc:145] XLA service 0x14bee5848c80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1758862085.867166 3192690 service.cc:153]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6
I0000 00:00:1758862086.327500 3192690 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
1/9 [==>...........................] - ETA: 6:00 - loss: 0.3481 - accuracy: 0.5051 - jacard_coef: 0.05862/9 [=====>........................] - ETA: 49s - loss: 0.3278 - accuracy: 0.4576 - jacard_coef: 0.0596 3/9 [=========>....................] - ETA: 29s - loss: 0.3005 - accuracy: 0.3845 - jacard_coef: 0.06264/9 [============>.................] - ETA: 20s - loss: 0.2797 - accuracy: 0.3599 - jacard_coef: 0.06825/9 [===============>..............] - ETA: 12s - loss: 0.2654 - accuracy: 0.3339 - jacard_coef: 0.06916/9 [===================>..........] - ETA: 7s - loss: 0.2545 - accuracy: 0.3177 - jacard_coef: 0.0761 7/9 [======================>.......] - ETA: 4s - loss: 0.2460 - accuracy: 0.3083 - jacard_coef: 0.07678/9 [=========================>....] - ETA: 1s - loss: 0.2387 - accuracy: 0.3111 - jacard_coef: 0.07579/9 [==============================] - ETA: 0s - loss: 0.2384 - accuracy: 0.3110 - jacard_coef: 0.08249/9 [==============================] - 65s 3s/step - loss: 0.2384 - accuracy: 0.3110 - jacard_coef: 0.0824 - val_loss: 1.1102 - val_accuracy: 0.9304 - val_jacard_coef: 3.4119e-04 - lr: 0.0010
Epoch 2/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1842 - accuracy: 0.4353 - jacard_coef: 0.07232/9 [=====>........................] - ETA: 1s - loss: 0.1845 - accuracy: 0.4021 - jacard_coef: 0.07033/9 [=========>....................] - ETA: 1s - loss: 0.1826 - accuracy: 0.4229 - jacard_coef: 0.07414/9 [============>.................] - ETA: 1s - loss: 0.1815 - accuracy: 0.4245 - jacard_coef: 0.07635/9 [===============>..............] - ETA: 0s - loss: 0.1807 - accuracy: 0.4242 - jacard_coef: 0.07736/9 [===================>..........] - ETA: 0s - loss: 0.1800 - accuracy: 0.4231 - jacard_coef: 0.07747/9 [======================>.......] - ETA: 0s - loss: 0.1793 - accuracy: 0.4289 - jacard_coef: 0.07818/9 [=========================>....] - ETA: 0s - loss: 0.1787 - accuracy: 0.4317 - jacard_coef: 0.07569/9 [==============================] - ETA: 0s - loss: 0.1788 - accuracy: 0.4318 - jacard_coef: 0.08219/9 [==============================] - 2s 244ms/step - loss: 0.1788 - accuracy: 0.4318 - jacard_coef: 0.0821 - val_loss: 1.1220 - val_accuracy: 0.9304 - val_jacard_coef: 1.4611e-05 - lr: 0.0010
Epoch 3/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1750 - accuracy: 0.5187 - jacard_coef: 0.07172/9 [=====>........................] - ETA: 1s - loss: 0.1746 - accuracy: 0.5649 - jacard_coef: 0.08183/9 [=========>....................] - ETA: 1s - loss: 0.1742 - accuracy: 0.5962 - jacard_coef: 0.07994/9 [============>.................] - ETA: 1s - loss: 0.1739 - accuracy: 0.6189 - jacard_coef: 0.07525/9 [===============>..............] - ETA: 0s - loss: 0.1736 - accuracy: 0.6214 - jacard_coef: 0.07426/9 [===================>..........] - ETA: 0s - loss: 0.1732 - accuracy: 0.6137 - jacard_coef: 0.07757/9 [======================>.......] - ETA: 0s - loss: 0.1731 - accuracy: 0.5980 - jacard_coef: 0.07778/9 [=========================>....] - ETA: 0s - loss: 0.1728 - accuracy: 0.5880 - jacard_coef: 0.07669/9 [==============================] - 2s 234ms/step - loss: 0.1732 - accuracy: 0.5852 - jacard_coef: 0.0687 - val_loss: 1.1209 - val_accuracy: 0.9304 - val_jacard_coef: 1.9471e-05 - lr: 0.0010
Epoch 4/30
1/9 [==>...........................] - ETA: 1s - loss: 0.2003 - accuracy: 0.1640 - jacard_coef: 0.09662/9 [=====>........................] - ETA: 1s - loss: 0.1923 - accuracy: 0.1868 - jacard_coef: 0.08533/9 [=========>....................] - ETA: 1s - loss: 0.1873 - accuracy: 0.2692 - jacard_coef: 0.08054/9 [============>.................] - ETA: 1s - loss: 0.1850 - accuracy: 0.3128 - jacard_coef: 0.07345/9 [===============>..............] - ETA: 0s - loss: 0.1827 - accuracy: 0.3465 - jacard_coef: 0.07526/9 [===================>..........] - ETA: 0s - loss: 0.1812 - accuracy: 0.3740 - jacard_coef: 0.07407/9 [======================>.......] - ETA: 0s - loss: 0.1799 - accuracy: 0.4076 - jacard_coef: 0.07498/9 [=========================>....] - ETA: 0s - loss: 0.1792 - accuracy: 0.4379 - jacard_coef: 0.07659/9 [==============================] - 2s 241ms/step - loss: 0.1795 - accuracy: 0.4387 - jacard_coef: 0.0683 - val_loss: 1.0319 - val_accuracy: 0.9180 - val_jacard_coef: 0.0124 - lr: 0.0010
Epoch 5/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1702 - accuracy: 0.7340 - jacard_coef: 0.09782/9 [=====>........................] - ETA: 1s - loss: 0.1706 - accuracy: 0.7134 - jacard_coef: 0.08293/9 [=========>....................] - ETA: 1s - loss: 0.1708 - accuracy: 0.6844 - jacard_coef: 0.07624/9 [============>.................] - ETA: 1s - loss: 0.1708 - accuracy: 0.6709 - jacard_coef: 0.07185/9 [===============>..............] - ETA: 0s - loss: 0.1704 - accuracy: 0.6635 - jacard_coef: 0.07106/9 [===================>..........] - ETA: 0s - loss: 0.1705 - accuracy: 0.6514 - jacard_coef: 0.07397/9 [======================>.......] - ETA: 0s - loss: 0.1708 - accuracy: 0.6258 - jacard_coef: 0.07728/9 [=========================>....] - ETA: 0s - loss: 0.1707 - accuracy: 0.6285 - jacard_coef: 0.07549/9 [==============================] - 2s 235ms/step - loss: 0.1707 - accuracy: 0.6277 - jacard_coef: 0.0813 - val_loss: 1.0435 - val_accuracy: 0.9214 - val_jacard_coef: 0.0113 - lr: 0.0010
Epoch 6/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1694 - accuracy: 0.6962 - jacard_coef: 0.07832/9 [=====>........................] - ETA: 1s - loss: 0.1688 - accuracy: 0.7122 - jacard_coef: 0.08533/9 [=========>....................] - ETA: 1s - loss: 0.1681 - accuracy: 0.7338 - jacard_coef: 0.07764/9 [============>.................] - ETA: 1s - loss: 0.1683 - accuracy: 0.7284 - jacard_coef: 0.07765/9 [===============>..............] - ETA: 0s - loss: 0.1679 - accuracy: 0.7504 - jacard_coef: 0.07816/9 [===================>..........] - ETA: 0s - loss: 0.1758 - accuracy: 0.6632 - jacard_coef: 0.07787/9 [======================>.......] - ETA: 0s - loss: 0.1744 - accuracy: 0.6893 - jacard_coef: 0.07908/9 [=========================>....] - ETA: 0s - loss: 0.1733 - accuracy: 0.7118 - jacard_coef: 0.07659/9 [==============================] - 2s 243ms/step - loss: 0.1733 - accuracy: 0.7106 - jacard_coef: 0.0687 - val_loss: 0.7515 - val_accuracy: 0.9209 - val_jacard_coef: 0.0235 - lr: 0.0010
Epoch 7/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1671 - accuracy: 0.8471 - jacard_coef: 0.07292/9 [=====>........................] - ETA: 1s - loss: 0.1676 - accuracy: 0.8411 - jacard_coef: 0.07753/9 [=========>....................] - ETA: 1s - loss: 0.1678 - accuracy: 0.8331 - jacard_coef: 0.08664/9 [============>.................] - ETA: 1s - loss: 0.1681 - accuracy: 0.8373 - jacard_coef: 0.08465/9 [===============>..............] - ETA: 0s - loss: 0.1676 - accuracy: 0.8446 - jacard_coef: 0.08316/9 [===================>..........] - ETA: 0s - loss: 0.1673 - accuracy: 0.8493 - jacard_coef: 0.08007/9 [======================>.......] - ETA: 0s - loss: 0.1672 - accuracy: 0.8509 - jacard_coef: 0.07648/9 [=========================>....] - ETA: 0s - loss: 0.1675 - accuracy: 0.8395 - jacard_coef: 0.07609/9 [==============================] - 2s 237ms/step - loss: 0.1675 - accuracy: 0.8396 - jacard_coef: 0.0723 - val_loss: 0.9511 - val_accuracy: 0.9261 - val_jacard_coef: 0.0091 - lr: 0.0010
Epoch 8/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1658 - accuracy: 0.8731 - jacard_coef: 0.07752/9 [=====>........................] - ETA: 1s - loss: 0.1652 - accuracy: 0.8783 - jacard_coef: 0.07843/9 [=========>....................] - ETA: 1s - loss: 0.1644 - accuracy: 0.8882 - jacard_coef: 0.07374/9 [============>.................] - ETA: 1s - loss: 0.1645 - accuracy: 0.8835 - jacard_coef: 0.08085/9 [===============>..............] - ETA: 0s - loss: 0.1646 - accuracy: 0.8816 - jacard_coef: 0.08466/9 [===================>..........] - ETA: 0s - loss: 0.1643 - accuracy: 0.8859 - jacard_coef: 0.08257/9 [======================>.......] - ETA: 0s - loss: 0.1641 - accuracy: 0.8906 - jacard_coef: 0.07978/9 [=========================>....] - ETA: 0s - loss: 0.1636 - accuracy: 0.8956 - jacard_coef: 0.07629/9 [==============================] - 2s 235ms/step - loss: 0.1636 - accuracy: 0.8958 - jacard_coef: 0.0680 - val_loss: 0.7256 - val_accuracy: 0.9227 - val_jacard_coef: 0.0143 - lr: 0.0010
Epoch 9/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1624 - accuracy: 0.9146 - jacard_coef: 0.07022/9 [=====>........................] - ETA: 1s - loss: 0.1617 - accuracy: 0.9095 - jacard_coef: 0.07493/9 [=========>....................] - ETA: 1s - loss: 0.1619 - accuracy: 0.8937 - jacard_coef: 0.08764/9 [============>.................] - ETA: 1s - loss: 0.1618 - accuracy: 0.9002 - jacard_coef: 0.07985/9 [===============>..............] - ETA: 0s - loss: 0.1613 - accuracy: 0.9022 - jacard_coef: 0.07866/9 [===================>..........] - ETA: 0s - loss: 0.1612 - accuracy: 0.9043 - jacard_coef: 0.07787/9 [======================>.......] - ETA: 0s - loss: 0.1610 - accuracy: 0.9074 - jacard_coef: 0.07608/9 [=========================>....] - ETA: 0s - loss: 0.1607 - accuracy: 0.9087 - jacard_coef: 0.07529/9 [==============================] - 2s 235ms/step - loss: 0.1607 - accuracy: 0.9082 - jacard_coef: 0.0807 - val_loss: 0.5379 - val_accuracy: 0.9267 - val_jacard_coef: 0.0174 - lr: 0.0010
Epoch 10/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1591 - accuracy: 0.9040 - jacard_coef: 0.07852/9 [=====>........................] - ETA: 1s - loss: 0.1597 - accuracy: 0.9007 - jacard_coef: 0.08393/9 [=========>....................] - ETA: 1s - loss: 0.1590 - accuracy: 0.9006 - jacard_coef: 0.08474/9 [============>.................] - ETA: 1s - loss: 0.1588 - accuracy: 0.9012 - jacard_coef: 0.08485/9 [===============>..............] - ETA: 0s - loss: 0.1584 - accuracy: 0.9068 - jacard_coef: 0.08036/9 [===================>..........] - ETA: 0s - loss: 0.1583 - accuracy: 0.9099 - jacard_coef: 0.07797/9 [======================>.......] - ETA: 0s - loss: 0.1582 - accuracy: 0.9100 - jacard_coef: 0.07818/9 [=========================>....] - ETA: 0s - loss: 0.1580 - accuracy: 0.9128 - jacard_coef: 0.07599/9 [==============================] - 2s 235ms/step - loss: 0.1580 - accuracy: 0.9130 - jacard_coef: 0.0734 - val_loss: 0.4860 - val_accuracy: 0.9269 - val_jacard_coef: 0.0182 - lr: 0.0010
Epoch 11/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1569 - accuracy: 0.9214 - jacard_coef: 0.07052/9 [=====>........................] - ETA: 1s - loss: 0.1563 - accuracy: 0.9165 - jacard_coef: 0.07533/9 [=========>....................] - ETA: 1s - loss: 0.1569 - accuracy: 0.9078 - jacard_coef: 0.08264/9 [============>.................] - ETA: 1s - loss: 0.1564 - accuracy: 0.9120 - jacard_coef: 0.07895/9 [===============>..............] - ETA: 0s - loss: 0.1559 - accuracy: 0.9151 - jacard_coef: 0.07646/9 [===================>..........] - ETA: 0s - loss: 0.1560 - accuracy: 0.9131 - jacard_coef: 0.07807/9 [======================>.......] - ETA: 0s - loss: 0.1558 - accuracy: 0.9134 - jacard_coef: 0.07798/9 [=========================>....] - ETA: 0s - loss: 0.1556 - accuracy: 0.9154 - jacard_coef: 0.07629/9 [==============================] - 2s 235ms/step - loss: 0.1560 - accuracy: 0.9108 - jacard_coef: 0.0683 - val_loss: 0.5114 - val_accuracy: 0.9271 - val_jacard_coef: 0.0188 - lr: 0.0010
Epoch 12/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1559 - accuracy: 0.9087 - jacard_coef: 0.07632/9 [=====>........................] - ETA: 1s - loss: 0.1553 - accuracy: 0.9127 - jacard_coef: 0.07473/9 [=========>....................] - ETA: 1s - loss: 0.1556 - accuracy: 0.8723 - jacard_coef: 0.07584/9 [============>.................] - ETA: 1s - loss: 0.1556 - accuracy: 0.8596 - jacard_coef: 0.07385/9 [===============>..............] - ETA: 0s - loss: 0.1554 - accuracy: 0.8615 - jacard_coef: 0.07316/9 [===================>..........] - ETA: 0s - loss: 0.1553 - accuracy: 0.8640 - jacard_coef: 0.07407/9 [======================>.......] - ETA: 0s - loss: 0.1555 - accuracy: 0.8535 - jacard_coef: 0.07378/9 [=========================>....] - ETA: 0s - loss: 0.1555 - accuracy: 0.8595 - jacard_coef: 0.07539/9 [==============================] - 2s 241ms/step - loss: 0.1556 - accuracy: 0.8578 - jacard_coef: 0.0847 - val_loss: 0.0921 - val_accuracy: 0.9041 - val_jacard_coef: 0.0634 - lr: 5.0000e-04
Epoch 13/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1559 - accuracy: 0.8992 - jacard_coef: 0.08442/9 [=====>........................] - ETA: 1s - loss: 0.1558 - accuracy: 0.8896 - jacard_coef: 0.08973/9 [=========>....................] - ETA: 1s - loss: 0.1552 - accuracy: 0.8939 - jacard_coef: 0.08594/9 [============>.................] - ETA: 1s - loss: 0.1549 - accuracy: 0.8970 - jacard_coef: 0.08215/9 [===============>..............] - ETA: 0s - loss: 0.1547 - accuracy: 0.8980 - jacard_coef: 0.08076/9 [===================>..........] - ETA: 0s - loss: 0.1546 - accuracy: 0.8991 - jacard_coef: 0.07937/9 [======================>.......] - ETA: 0s - loss: 0.1543 - accuracy: 0.9024 - jacard_coef: 0.07658/9 [=========================>....] - ETA: 0s - loss: 0.1540 - accuracy: 0.9038 - jacard_coef: 0.07589/9 [==============================] - 2s 240ms/step - loss: 0.1540 - accuracy: 0.9031 - jacard_coef: 0.0730 - val_loss: 0.1246 - val_accuracy: 0.9292 - val_jacard_coef: 0.0659 - lr: 5.0000e-04
Epoch 14/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1509 - accuracy: 0.9374 - jacard_coef: 0.05642/9 [=====>........................] - ETA: 1s - loss: 0.1520 - accuracy: 0.9203 - jacard_coef: 0.07153/9 [=========>....................] - ETA: 1s - loss: 0.1524 - accuracy: 0.9182 - jacard_coef: 0.07354/9 [============>.................] - ETA: 1s - loss: 0.1526 - accuracy: 0.9144 - jacard_coef: 0.07695/9 [===============>..............] - ETA: 0s - loss: 0.1525 - accuracy: 0.9163 - jacard_coef: 0.07536/9 [===================>..........] - ETA: 0s - loss: 0.1525 - accuracy: 0.9172 - jacard_coef: 0.07467/9 [======================>.......] - ETA: 0s - loss: 0.1528 - accuracy: 0.9156 - jacard_coef: 0.07618/9 [=========================>....] - ETA: 0s - loss: 0.1526 - accuracy: 0.9168 - jacard_coef: 0.07519/9 [==============================] - 2s 235ms/step - loss: 0.1528 - accuracy: 0.9162 - jacard_coef: 0.0817 - val_loss: 0.1405 - val_accuracy: 0.9301 - val_jacard_coef: 0.0652 - lr: 5.0000e-04
Epoch 15/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1508 - accuracy: 0.9334 - jacard_coef: 0.06152/9 [=====>........................] - ETA: 1s - loss: 0.1513 - accuracy: 0.9260 - jacard_coef: 0.06773/9 [=========>....................] - ETA: 1s - loss: 0.1512 - accuracy: 0.9296 - jacard_coef: 0.06424/9 [============>.................] - ETA: 1s - loss: 0.1517 - accuracy: 0.9195 - jacard_coef: 0.07235/9 [===============>..............] - ETA: 0s - loss: 0.1519 - accuracy: 0.9167 - jacard_coef: 0.07436/9 [===================>..........] - ETA: 0s - loss: 0.1522 - accuracy: 0.9127 - jacard_coef: 0.07727/9 [======================>.......] - ETA: 0s - loss: 0.1522 - accuracy: 0.9112 - jacard_coef: 0.07858/9 [=========================>....] - ETA: 0s - loss: 0.1517 - accuracy: 0.9152 - jacard_coef: 0.07519/9 [==============================] - 2s 235ms/step - loss: 0.1518 - accuracy: 0.9136 - jacard_coef: 0.0783 - val_loss: 0.1487 - val_accuracy: 0.9285 - val_jacard_coef: 0.0651 - lr: 5.0000e-04
Epoch 16/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1502 - accuracy: 0.9219 - jacard_coef: 0.07122/9 [=====>........................] - ETA: 1s - loss: 0.1507 - accuracy: 0.9255 - jacard_coef: 0.06763/9 [=========>....................] - ETA: 1s - loss: 0.1508 - accuracy: 0.9210 - jacard_coef: 0.07164/9 [============>.................] - ETA: 1s - loss: 0.1504 - accuracy: 0.9242 - jacard_coef: 0.06905/9 [===============>..............] - ETA: 0s - loss: 0.1508 - accuracy: 0.9187 - jacard_coef: 0.07366/9 [===================>..........] - ETA: 0s - loss: 0.1510 - accuracy: 0.9156 - jacard_coef: 0.07637/9 [======================>.......] - ETA: 0s - loss: 0.1508 - accuracy: 0.9183 - jacard_coef: 0.07418/9 [=========================>....] - ETA: 0s - loss: 0.1507 - accuracy: 0.9175 - jacard_coef: 0.07499/9 [==============================] - 2s 235ms/step - loss: 0.1509 - accuracy: 0.9154 - jacard_coef: 0.0832 - val_loss: 0.1466 - val_accuracy: 0.9297 - val_jacard_coef: 0.0651 - lr: 5.0000e-04
Epoch 17/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1516 - accuracy: 0.8981 - jacard_coef: 0.09132/9 [=====>........................] - ETA: 1s - loss: 0.1511 - accuracy: 0.9107 - jacard_coef: 0.08073/9 [=========>....................] - ETA: 1s - loss: 0.1498 - accuracy: 0.9258 - jacard_coef: 0.06754/9 [============>.................] - ETA: 1s - loss: 0.1503 - accuracy: 0.9177 - jacard_coef: 0.07425/9 [===============>..............] - ETA: 0s - loss: 0.1506 - accuracy: 0.9127 - jacard_coef: 0.07846/9 [===================>..........] - ETA: 0s - loss: 0.1500 - accuracy: 0.9192 - jacard_coef: 0.07277/9 [======================>.......] - ETA: 0s - loss: 0.1502 - accuracy: 0.9157 - jacard_coef: 0.07568/9 [=========================>....] - ETA: 0s - loss: 0.1500 - accuracy: 0.9158 - jacard_coef: 0.07569/9 [==============================] - 2s 235ms/step - loss: 0.1501 - accuracy: 0.9158 - jacard_coef: 0.0677 - val_loss: 0.1444 - val_accuracy: 0.9284 - val_jacard_coef: 0.0651 - lr: 5.0000e-04
Epoch 18/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1487 - accuracy: 0.9201 - jacard_coef: 0.07282/9 [=====>........................] - ETA: 1s - loss: 0.1485 - accuracy: 0.9278 - jacard_coef: 0.06573/9 [=========>....................] - ETA: 1s - loss: 0.1490 - accuracy: 0.9182 - jacard_coef: 0.07384/9 [============>.................] - ETA: 1s - loss: 0.1491 - accuracy: 0.9178 - jacard_coef: 0.07425/9 [===============>..............] - ETA: 0s - loss: 0.1491 - accuracy: 0.9171 - jacard_coef: 0.07486/9 [===================>..........] - ETA: 0s - loss: 0.1491 - accuracy: 0.9155 - jacard_coef: 0.07617/9 [======================>.......] - ETA: 0s - loss: 0.1490 - accuracy: 0.9163 - jacard_coef: 0.07558/9 [=========================>....] - ETA: 0s - loss: 0.1489 - accuracy: 0.9169 - jacard_coef: 0.07519/9 [==============================] - 2s 235ms/step - loss: 0.1491 - accuracy: 0.9164 - jacard_coef: 0.0801 - val_loss: 0.1419 - val_accuracy: 0.9290 - val_jacard_coef: 0.0651 - lr: 5.0000e-04
Epoch 19/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1487 - accuracy: 0.9277 - jacard_coef: 0.06552/9 [=====>........................] - ETA: 1s - loss: 0.1482 - accuracy: 0.9294 - jacard_coef: 0.06463/9 [=========>....................] - ETA: 1s - loss: 0.1485 - accuracy: 0.9192 - jacard_coef: 0.07324/9 [============>.................] - ETA: 1s - loss: 0.1486 - accuracy: 0.9177 - jacard_coef: 0.07455/9 [===============>..............] - ETA: 1s - loss: 0.1486 - accuracy: 0.9139 - jacard_coef: 0.07786/9 [===================>..........] - ETA: 0s - loss: 0.1495 - accuracy: 0.9103 - jacard_coef: 0.08027/9 [======================>.......] - ETA: 0s - loss: 0.1492 - accuracy: 0.9131 - jacard_coef: 0.07798/9 [=========================>....] - ETA: 0s - loss: 0.1488 - accuracy: 0.9168 - jacard_coef: 0.07489/9 [==============================] - 2s 238ms/step - loss: 0.1490 - accuracy: 0.9149 - jacard_coef: 0.0820 - val_loss: 0.1438 - val_accuracy: 0.9285 - val_jacard_coef: 0.0650 - lr: 2.5000e-04
Epoch 20/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1468 - accuracy: 0.9287 - jacard_coef: 0.06522/9 [=====>........................] - ETA: 1s - loss: 0.1496 - accuracy: 0.9265 - jacard_coef: 0.06523/9 [=========>....................] - ETA: 1s - loss: 0.1487 - accuracy: 0.9303 - jacard_coef: 0.06264/9 [============>.................] - ETA: 1s - loss: 0.1485 - accuracy: 0.9262 - jacard_coef: 0.06645/9 [===============>..............] - ETA: 0s - loss: 0.1486 - accuracy: 0.9207 - jacard_coef: 0.07116/9 [===================>..........] - ETA: 0s - loss: 0.1487 - accuracy: 0.9167 - jacard_coef: 0.07467/9 [======================>.......] - ETA: 0s - loss: 0.1486 - accuracy: 0.9161 - jacard_coef: 0.07528/9 [=========================>....] - ETA: 0s - loss: 0.1486 - accuracy: 0.9154 - jacard_coef: 0.07599/9 [==============================] - 2s 235ms/step - loss: 0.1486 - accuracy: 0.9159 - jacard_coef: 0.0678 - val_loss: 0.1465 - val_accuracy: 0.9272 - val_jacard_coef: 0.0649 - lr: 2.5000e-04
Epoch 21/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1466 - accuracy: 0.9221 - jacard_coef: 0.07082/9 [=====>........................] - ETA: 1s - loss: 0.1472 - accuracy: 0.9176 - jacard_coef: 0.07493/9 [=========>....................] - ETA: 1s - loss: 0.1475 - accuracy: 0.9160 - jacard_coef: 0.07634/9 [============>.................] - ETA: 1s - loss: 0.1474 - accuracy: 0.9173 - jacard_coef: 0.07505/9 [===============>..............] - ETA: 0s - loss: 0.1474 - accuracy: 0.9176 - jacard_coef: 0.07476/9 [===================>..........] - ETA: 0s - loss: 0.1474 - accuracy: 0.9178 - jacard_coef: 0.07447/9 [======================>.......] - ETA: 0s - loss: 0.1474 - accuracy: 0.9184 - jacard_coef: 0.07408/9 [=========================>....] - ETA: 0s - loss: 0.1475 - accuracy: 0.9162 - jacard_coef: 0.07599/9 [==============================] - 2s 235ms/step - loss: 0.1476 - accuracy: 0.9166 - jacard_coef: 0.0704 - val_loss: 0.1477 - val_accuracy: 0.9296 - val_jacard_coef: 0.0647 - lr: 2.5000e-04
Epoch 22/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1464 - accuracy: 0.9247 - jacard_coef: 0.06932/9 [=====>........................] - ETA: 1s - loss: 0.1457 - accuracy: 0.9289 - jacard_coef: 0.06573/9 [=========>....................] - ETA: 1s - loss: 0.1462 - accuracy: 0.9263 - jacard_coef: 0.06784/9 [============>.................] - ETA: 1s - loss: 0.1466 - accuracy: 0.9202 - jacard_coef: 0.07305/9 [===============>..............] - ETA: 0s - loss: 0.1466 - accuracy: 0.9187 - jacard_coef: 0.07436/9 [===================>..........] - ETA: 0s - loss: 0.1468 - accuracy: 0.9181 - jacard_coef: 0.07477/9 [======================>.......] - ETA: 0s - loss: 0.1467 - accuracy: 0.9183 - jacard_coef: 0.07468/9 [=========================>....] - ETA: 0s - loss: 0.1467 - accuracy: 0.9182 - jacard_coef: 0.07479/9 [==============================] - 2s 236ms/step - loss: 0.1468 - accuracy: 0.9172 - jacard_coef: 0.0850 - val_loss: 0.1471 - val_accuracy: 0.9300 - val_jacard_coef: 0.0646 - lr: 2.5000e-04
Epoch 23/30
1/9 [==>...........................] - ETA: 1s - loss: 0.1468 - accuracy: 0.9188 - jacard_coef: 0.07392/9 [=====>........................] - ETA: 1s - loss: 0.1474 - accuracy: 0.9068 - jacard_coef: 0.08413/9 [=========>....................] - ETA: 1s - loss: 0.1470 - accuracy: 0.9132 - jacard_coef: 0.07874/9 [============>.................] - ETA: 1s - loss: 0.1465 - accuracy: 0.9175 - jacard_coef: 0.07515/9 [===============>..............] - ETA: 0s - loss: 0.1465 - accuracy: 0.9189 - jacard_coef: 0.07406/9 [===================>..........] - ETA: 0s - loss: 0.1463 - accuracy: 0.9206 - jacard_coef: 0.07257/9 [======================>.......] - ETA: 0s - loss: 0.1464 - accuracy: 0.9170 - jacard_coef: 0.07558/9 [=========================>....] - ETA: 0s - loss: 0.1464 - accuracy: 0.9168 - jacard_coef: 0.07579/9 [==============================] - 2s 236ms/step - loss: 0.1464 - accuracy: 0.9172 - jacard_coef: 0.0704 - val_loss: 0.1463 - val_accuracy: 0.9302 - val_jacard_coef: 0.0646 - lr: 2.5000e-04
/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(

âœ“ Training completed successfully!
  Best Val Jaccard: 0.0659 (epoch 13)
  Final Val Loss: 0.1463
  Training Time: 0:01:53.434345
  Stability (std): 0.0025

Results saved to: hyperparameter_optimization_20250926_123742/exp_5_UNet_lr5e-4_bs16/UNet_lr0.0005_bs16_results.json
