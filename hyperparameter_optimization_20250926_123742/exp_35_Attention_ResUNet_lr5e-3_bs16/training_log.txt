✓ GPU memory growth enabled for 1 GPUs
Loading dataset...
Loaded 144 images and 144 masks
Training set: (129, 256, 256, 3), Validation set: (15, 256, 256, 3)

============================================================
TRAINING: Attention_ResUNet
Learning Rate: 0.005, Batch Size: 16, Epochs: 30
============================================================
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 256, 256, 64)         640       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 256, 256, 64)         256       ['conv2d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 activation (Activation)     (None, 256, 256, 64)         0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['activation[0][0]']          
                                                                                                  
 batch_normalization_1 (Bat  (None, 256, 256, 64)         256       ['conv2d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_1 (Activation)   (None, 256, 256, 64)         0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['activation_1[0][0]']        
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       
                                                                                                  
 batch_normalization_2 (Bat  (None, 128, 128, 128)        512       ['conv2d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_2 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_3 (Conv2D)           (None, 128, 128, 128)        147584    ['activation_2[0][0]']        
                                                                                                  
 batch_normalization_3 (Bat  (None, 128, 128, 128)        512       ['conv2d_3[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_3 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_3[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_3[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 batch_normalization_4 (Bat  (None, 64, 64, 256)          1024      ['conv2d_4[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_4 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_4[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_5 (Conv2D)           (None, 64, 64, 256)          590080    ['activation_4[0][0]']        
                                                                                                  
 batch_normalization_5 (Bat  (None, 64, 64, 256)          1024      ['conv2d_5[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_5 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_5[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_5[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 512)          1180160   ['max_pooling2d_2[0][0]']     
                                                                                                  
 batch_normalization_6 (Bat  (None, 32, 32, 512)          2048      ['conv2d_6[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_6 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_6[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 32, 32, 512)          2359808   ['activation_6[0][0]']        
                                                                                                  
 batch_normalization_7 (Bat  (None, 32, 32, 512)          2048      ['conv2d_7[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_7 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_7[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_3 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_7[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 1024)         4719616   ['max_pooling2d_3[0][0]']     
                                                                                                  
 batch_normalization_8 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_8[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_8 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_8[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 1024)         9438208   ['activation_8[0][0]']        
                                                                                                  
 batch_normalization_9 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_9[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_9 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_9[0][0]'
                                                                    ]                             
                                                                                                  
 up_sampling2d (UpSampling2  (None, 32, 32, 1024)         0         ['activation_9[0][0]']        
 D)                                                                                               
                                                                                                  
 concatenate (Concatenate)   (None, 32, 32, 1536)         0         ['up_sampling2d[0][0]',       
                                                                     'activation_7[0][0]']        
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate[0][0]']         
                                                                                                  
 batch_normalization_10 (Ba  (None, 32, 32, 512)          2048      ['conv2d_10[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_10 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_10[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_10[0][0]']       
                                                                                                  
 batch_normalization_11 (Ba  (None, 32, 32, 512)          2048      ['conv2d_11[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_11 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_11[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 64, 64, 512)          0         ['activation_11[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_1 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_1[0][0]',     
 )                                                                   'activation_5[0][0]']        
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_1[0][0]']       
                                                                                                  
 batch_normalization_12 (Ba  (None, 64, 64, 256)          1024      ['conv2d_12[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_12 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_12[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_13 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_12[0][0]']       
                                                                                                  
 batch_normalization_13 (Ba  (None, 64, 64, 256)          1024      ['conv2d_13[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_13 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_13[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 128, 128, 256)        0         ['activation_13[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_2 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_2[0][0]',     
 )                                                                   'activation_3[0][0]']        
                                                                                                  
 conv2d_14 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_2[0][0]']       
                                                                                                  
 batch_normalization_14 (Ba  (None, 128, 128, 128)        512       ['conv2d_14[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_14 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_14[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_15 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_14[0][0]']       
                                                                                                  
 batch_normalization_15 (Ba  (None, 128, 128, 128)        512       ['conv2d_15[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_15 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_15[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 256, 256, 128)        0         ['activation_15[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_3 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_3[0][0]',     
 )                                                                   'activation_1[0][0]']        
                                                                                                  
 conv2d_16 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_3[0][0]']       
                                                                                                  
 batch_normalization_16 (Ba  (None, 256, 256, 64)         256       ['conv2d_16[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_16 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_16[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_16[0][0]']       
                                                                                                  
 batch_normalization_17 (Ba  (None, 256, 256, 64)         256       ['conv2d_17[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_17 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_17[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_18 (Conv2D)          (None, 256, 256, 1)          65        ['activation_17[0][0]']       
                                                                                                  
 batch_normalization_18 (Ba  (None, 256, 256, 1)          4         ['conv2d_18[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_18 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_18[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31401349 (119.79 MB)
Trainable params: 31389571 (119.74 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
WARNING:absl:`lr` is deprecated in TF-Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
None
✓ focal_loss imported successfully
Epoch 1/30
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1758866959.889523 3380612 service.cc:145] XLA service 0x14cebdee8f10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1758866959.889564 3380612 service.cc:153]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6
I0000 00:00:1758866960.342263 3380612 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
1/9 [==>...........................] - ETA: 9:07 - loss: 0.3377 - accuracy: 0.4868 - jacard_coef: 0.07302/9 [=====>........................] - ETA: 59s - loss: 0.2915 - accuracy: 0.4271 - jacard_coef: 0.0745 3/9 [=========>....................] - ETA: 26s - loss: 0.2627 - accuracy: 0.3674 - jacard_coef: 0.07034/9 [============>.................] - ETA: 15s - loss: 0.2468 - accuracy: 0.3282 - jacard_coef: 0.07315/9 [===============>..............] - ETA: 9s - loss: 0.2370 - accuracy: 0.3084 - jacard_coef: 0.0747 6/9 [===================>..........] - ETA: 6s - loss: 0.2304 - accuracy: 0.2850 - jacard_coef: 0.07327/9 [======================>.......] - ETA: 3s - loss: 0.2255 - accuracy: 0.2643 - jacard_coef: 0.07408/9 [=========================>....] - ETA: 1s - loss: 0.2205 - accuracy: 0.2515 - jacard_coef: 0.07719/9 [==============================] - ETA: 0s - loss: 0.2202 - accuracy: 0.2509 - jacard_coef: 0.07449/9 [==============================] - 89s 3s/step - loss: 0.2202 - accuracy: 0.2509 - jacard_coef: 0.0744 - val_loss: 1.1188 - val_accuracy: 0.9244 - val_jacard_coef: 0.0031 - lr: 0.0010
Epoch 2/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1876 - accuracy: 0.1547 - jacard_coef: 0.08592/9 [=====>........................] - ETA: 2s - loss: 0.1888 - accuracy: 0.1468 - jacard_coef: 0.08223/9 [=========>....................] - ETA: 2s - loss: 0.1878 - accuracy: 0.1457 - jacard_coef: 0.08004/9 [============>.................] - ETA: 2s - loss: 0.1869 - accuracy: 0.1440 - jacard_coef: 0.07575/9 [===============>..............] - ETA: 1s - loss: 0.1860 - accuracy: 0.1568 - jacard_coef: 0.08226/9 [===================>..........] - ETA: 1s - loss: 0.1856 - accuracy: 0.1636 - jacard_coef: 0.08157/9 [======================>.......] - ETA: 0s - loss: 0.1850 - accuracy: 0.1721 - jacard_coef: 0.07838/9 [=========================>....] - ETA: 0s - loss: 0.1839 - accuracy: 0.1908 - jacard_coef: 0.07649/9 [==============================] - 4s 389ms/step - loss: 0.1840 - accuracy: 0.1917 - jacard_coef: 0.0787 - val_loss: 14.8358 - val_accuracy: 0.0770 - val_jacard_coef: 0.0698 - lr: 0.0010
Epoch 3/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1838 - accuracy: 0.3773 - jacard_coef: 0.07702/9 [=====>........................] - ETA: 2s - loss: 0.1807 - accuracy: 0.3940 - jacard_coef: 0.07813/9 [=========>....................] - ETA: 2s - loss: 0.1790 - accuracy: 0.3928 - jacard_coef: 0.07604/9 [============>.................] - ETA: 2s - loss: 0.1781 - accuracy: 0.4029 - jacard_coef: 0.07495/9 [===============>..............] - ETA: 1s - loss: 0.1802 - accuracy: 0.4043 - jacard_coef: 0.08306/9 [===================>..........] - ETA: 1s - loss: 0.1793 - accuracy: 0.4351 - jacard_coef: 0.07777/9 [======================>.......] - ETA: 0s - loss: 0.1787 - accuracy: 0.4573 - jacard_coef: 0.07718/9 [=========================>....] - ETA: 0s - loss: 0.1784 - accuracy: 0.4662 - jacard_coef: 0.07649/9 [==============================] - 4s 389ms/step - loss: 0.1784 - accuracy: 0.4663 - jacard_coef: 0.0756 - val_loss: 6.4550 - val_accuracy: 0.1578 - val_jacard_coef: 0.0713 - lr: 0.0010
Epoch 4/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1774 - accuracy: 0.3674 - jacard_coef: 0.09582/9 [=====>........................] - ETA: 2s - loss: 0.1761 - accuracy: 0.3275 - jacard_coef: 0.09213/9 [=========>....................] - ETA: 2s - loss: 0.1759 - accuracy: 0.3037 - jacard_coef: 0.08824/9 [============>.................] - ETA: 2s - loss: 0.1755 - accuracy: 0.3064 - jacard_coef: 0.07895/9 [===============>..............] - ETA: 1s - loss: 0.1753 - accuracy: 0.3266 - jacard_coef: 0.07756/9 [===================>..........] - ETA: 1s - loss: 0.1749 - accuracy: 0.3620 - jacard_coef: 0.07697/9 [======================>.......] - ETA: 0s - loss: 0.1746 - accuracy: 0.3970 - jacard_coef: 0.07638/9 [=========================>....] - ETA: 0s - loss: 0.1743 - accuracy: 0.4260 - jacard_coef: 0.07579/9 [==============================] - 3s 379ms/step - loss: 0.1744 - accuracy: 0.4267 - jacard_coef: 0.0834 - val_loss: 12.3765 - val_accuracy: 0.0771 - val_jacard_coef: 0.0698 - lr: 0.0010
Epoch 5/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1701 - accuracy: 0.6625 - jacard_coef: 0.09912/9 [=====>........................] - ETA: 2s - loss: 0.1696 - accuracy: 0.6547 - jacard_coef: 0.06533/9 [=========>....................] - ETA: 2s - loss: 0.1751 - accuracy: 0.6091 - jacard_coef: 0.07014/9 [============>.................] - ETA: 2s - loss: 0.1745 - accuracy: 0.5782 - jacard_coef: 0.07065/9 [===============>..............] - ETA: 1s - loss: 0.1738 - accuracy: 0.5476 - jacard_coef: 0.07526/9 [===================>..........] - ETA: 1s - loss: 0.1730 - accuracy: 0.5375 - jacard_coef: 0.07727/9 [======================>.......] - ETA: 0s - loss: 0.1723 - accuracy: 0.5354 - jacard_coef: 0.07368/9 [=========================>....] - ETA: 0s - loss: 0.1718 - accuracy: 0.5379 - jacard_coef: 0.07549/9 [==============================] - 3s 379ms/step - loss: 0.1718 - accuracy: 0.5385 - jacard_coef: 0.0836 - val_loss: 0.1367 - val_accuracy: 0.9263 - val_jacard_coef: 0.0502 - lr: 0.0010
Epoch 6/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1658 - accuracy: 0.6576 - jacard_coef: 0.07722/9 [=====>........................] - ETA: 2s - loss: 0.1658 - accuracy: 0.6208 - jacard_coef: 0.07503/9 [=========>....................] - ETA: 2s - loss: 0.1656 - accuracy: 0.6468 - jacard_coef: 0.07944/9 [============>.................] - ETA: 2s - loss: 0.1652 - accuracy: 0.6642 - jacard_coef: 0.08335/9 [===============>..............] - ETA: 1s - loss: 0.1650 - accuracy: 0.6981 - jacard_coef: 0.07896/9 [===================>..........] - ETA: 1s - loss: 0.1647 - accuracy: 0.7309 - jacard_coef: 0.07717/9 [======================>.......] - ETA: 0s - loss: 0.1644 - accuracy: 0.7531 - jacard_coef: 0.07678/9 [=========================>....] - ETA: 0s - loss: 0.1642 - accuracy: 0.7725 - jacard_coef: 0.07679/9 [==============================] - 3s 381ms/step - loss: 0.1647 - accuracy: 0.7697 - jacard_coef: 0.0684 - val_loss: 0.1052 - val_accuracy: 0.9177 - val_jacard_coef: 0.0520 - lr: 0.0010
Epoch 7/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1631 - accuracy: 0.8979 - jacard_coef: 0.08772/9 [=====>........................] - ETA: 2s - loss: 0.1635 - accuracy: 0.9051 - jacard_coef: 0.07743/9 [=========>....................] - ETA: 2s - loss: 0.1648 - accuracy: 0.8896 - jacard_coef: 0.08294/9 [============>.................] - ETA: 2s - loss: 0.1654 - accuracy: 0.8799 - jacard_coef: 0.08185/9 [===============>..............] - ETA: 1s - loss: 0.1651 - accuracy: 0.8826 - jacard_coef: 0.08006/9 [===================>..........] - ETA: 1s - loss: 0.1647 - accuracy: 0.8835 - jacard_coef: 0.08047/9 [======================>.......] - ETA: 0s - loss: 0.1645 - accuracy: 0.8850 - jacard_coef: 0.08018/9 [=========================>....] - ETA: 0s - loss: 0.1641 - accuracy: 0.8916 - jacard_coef: 0.07549/9 [==============================] - 3s 380ms/step - loss: 0.1641 - accuracy: 0.8908 - jacard_coef: 0.0831 - val_loss: 0.8079 - val_accuracy: 0.9252 - val_jacard_coef: 0.0107 - lr: 0.0010
Epoch 8/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1621 - accuracy: 0.8873 - jacard_coef: 0.06972/9 [=====>........................] - ETA: 2s - loss: 0.1625 - accuracy: 0.8875 - jacard_coef: 0.06603/9 [=========>....................] - ETA: 2s - loss: 0.1625 - accuracy: 0.8825 - jacard_coef: 0.06934/9 [============>.................] - ETA: 2s - loss: 0.1620 - accuracy: 0.8860 - jacard_coef: 0.06775/9 [===============>..............] - ETA: 1s - loss: 0.1619 - accuracy: 0.8803 - jacard_coef: 0.07396/9 [===================>..........] - ETA: 1s - loss: 0.1615 - accuracy: 0.8850 - jacard_coef: 0.07227/9 [======================>.......] - ETA: 0s - loss: 0.1614 - accuracy: 0.8851 - jacard_coef: 0.07498/9 [=========================>....] - ETA: 0s - loss: 0.1612 - accuracy: 0.8866 - jacard_coef: 0.07559/9 [==============================] - 3s 379ms/step - loss: 0.1612 - accuracy: 0.8865 - jacard_coef: 0.0781 - val_loss: 0.5502 - val_accuracy: 0.9232 - val_jacard_coef: 0.0114 - lr: 0.0010
Epoch 9/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1620 - accuracy: 0.7262 - jacard_coef: 0.07932/9 [=====>........................] - ETA: 2s - loss: 0.1606 - accuracy: 0.8140 - jacard_coef: 0.08203/9 [=========>....................] - ETA: 2s - loss: 0.1601 - accuracy: 0.8472 - jacard_coef: 0.07964/9 [============>.................] - ETA: 2s - loss: 0.1597 - accuracy: 0.8652 - jacard_coef: 0.07735/9 [===============>..............] - ETA: 1s - loss: 0.1597 - accuracy: 0.8722 - jacard_coef: 0.07916/9 [===================>..........] - ETA: 1s - loss: 0.1594 - accuracy: 0.8823 - jacard_coef: 0.07557/9 [======================>.......] - ETA: 0s - loss: 0.1596 - accuracy: 0.8840 - jacard_coef: 0.07768/9 [=========================>....] - ETA: 0s - loss: 0.1597 - accuracy: 0.8885 - jacard_coef: 0.07659/9 [==============================] - 3s 379ms/step - loss: 0.1597 - accuracy: 0.8892 - jacard_coef: 0.0682 - val_loss: 0.1475 - val_accuracy: 0.8564 - val_jacard_coef: 0.0651 - lr: 5.0000e-04
Epoch 10/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1607 - accuracy: 0.9101 - jacard_coef: 0.07812/9 [=====>........................] - ETA: 2s - loss: 0.1600 - accuracy: 0.9130 - jacard_coef: 0.07603/9 [=========>....................] - ETA: 2s - loss: 0.1596 - accuracy: 0.9147 - jacard_coef: 0.07494/9 [============>.................] - ETA: 2s - loss: 0.1592 - accuracy: 0.9147 - jacard_coef: 0.07535/9 [===============>..............] - ETA: 1s - loss: 0.1590 - accuracy: 0.9146 - jacard_coef: 0.07566/9 [===================>..........] - ETA: 1s - loss: 0.1587 - accuracy: 0.9180 - jacard_coef: 0.07287/9 [======================>.......] - ETA: 0s - loss: 0.1586 - accuracy: 0.9161 - jacard_coef: 0.07478/9 [=========================>....] - ETA: 0s - loss: 0.1585 - accuracy: 0.9155 - jacard_coef: 0.07539/9 [==============================] - 3s 379ms/step - loss: 0.1585 - accuracy: 0.9148 - jacard_coef: 0.0826 - val_loss: 0.1597 - val_accuracy: 0.9304 - val_jacard_coef: 0.0648 - lr: 5.0000e-04
Epoch 11/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1567 - accuracy: 0.9264 - jacard_coef: 0.06712/9 [=====>........................] - ETA: 2s - loss: 0.1573 - accuracy: 0.9089 - jacard_coef: 0.08203/9 [=========>....................] - ETA: 2s - loss: 0.1570 - accuracy: 0.9157 - jacard_coef: 0.07634/9 [============>.................] - ETA: 2s - loss: 0.1570 - accuracy: 0.9160 - jacard_coef: 0.07625/9 [===============>..............] - ETA: 1s - loss: 0.1571 - accuracy: 0.9119 - jacard_coef: 0.07966/9 [===================>..........] - ETA: 1s - loss: 0.1569 - accuracy: 0.9169 - jacard_coef: 0.07537/9 [======================>.......] - ETA: 0s - loss: 0.1568 - accuracy: 0.9159 - jacard_coef: 0.07638/9 [=========================>....] - ETA: 0s - loss: 0.1567 - accuracy: 0.9170 - jacard_coef: 0.07549/9 [==============================] - 3s 379ms/step - loss: 0.1567 - accuracy: 0.9166 - jacard_coef: 0.0807 - val_loss: 0.1576 - val_accuracy: 0.9304 - val_jacard_coef: 0.0648 - lr: 5.0000e-04
Epoch 12/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1560 - accuracy: 0.9231 - jacard_coef: 0.07072/9 [=====>........................] - ETA: 2s - loss: 0.1565 - accuracy: 0.9091 - jacard_coef: 0.08253/9 [=========>....................] - ETA: 2s - loss: 0.1564 - accuracy: 0.9088 - jacard_coef: 0.08274/9 [============>.................] - ETA: 2s - loss: 0.1561 - accuracy: 0.9146 - jacard_coef: 0.07795/9 [===============>..............] - ETA: 1s - loss: 0.1558 - accuracy: 0.9212 - jacard_coef: 0.07226/9 [===================>..........] - ETA: 1s - loss: 0.1560 - accuracy: 0.9154 - jacard_coef: 0.07707/9 [======================>.......] - ETA: 0s - loss: 0.1559 - accuracy: 0.9161 - jacard_coef: 0.07658/9 [=========================>....] - ETA: 0s - loss: 0.1558 - accuracy: 0.9169 - jacard_coef: 0.07599/9 [==============================] - 3s 379ms/step - loss: 0.1558 - accuracy: 0.9171 - jacard_coef: 0.0733 - val_loss: 0.1576 - val_accuracy: 0.9304 - val_jacard_coef: 0.0648 - lr: 5.0000e-04
Epoch 13/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1550 - accuracy: 0.9221 - jacard_coef: 0.07182/9 [=====>........................] - ETA: 2s - loss: 0.1548 - accuracy: 0.9260 - jacard_coef: 0.06853/9 [=========>....................] - ETA: 2s - loss: 0.1546 - accuracy: 0.9294 - jacard_coef: 0.06544/9 [============>.................] - ETA: 2s - loss: 0.1549 - accuracy: 0.9214 - jacard_coef: 0.07225/9 [===============>..............] - ETA: 1s - loss: 0.1547 - accuracy: 0.9241 - jacard_coef: 0.06996/9 [===================>..........] - ETA: 1s - loss: 0.1546 - accuracy: 0.9252 - jacard_coef: 0.06907/9 [======================>.......] - ETA: 0s - loss: 0.1548 - accuracy: 0.9202 - jacard_coef: 0.07328/9 [=========================>....] - ETA: 0s - loss: 0.1548 - accuracy: 0.9177 - jacard_coef: 0.07539/9 [==============================] - 3s 380ms/step - loss: 0.1548 - accuracy: 0.9172 - jacard_coef: 0.0804 - val_loss: 0.1585 - val_accuracy: 0.9304 - val_jacard_coef: 0.0648 - lr: 5.0000e-04
/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(

✓ Training completed successfully!
  Best Val Jaccard: 0.0713 (epoch 3)
  Final Val Loss: 0.1585
  Training Time: 0:02:11.451091
  Stability (std): 3.6402

Results saved to: hyperparameter_optimization_20250926_123742/exp_35_Attention_ResUNet_lr5e-3_bs16/Attention_ResUNet_lr0.005_bs16_results.json
