âœ“ GPU memory growth enabled for 1 GPUs
Loading dataset...
Loaded 144 images and 144 masks
Training set: (129, 256, 256, 3), Validation set: (15, 256, 256, 3)

============================================================
TRAINING: UNet
Learning Rate: 0.005, Batch Size: 8, Epochs: 30
============================================================
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 256, 256, 64)         640       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 256, 256, 64)         256       ['conv2d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 activation (Activation)     (None, 256, 256, 64)         0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['activation[0][0]']          
                                                                                                  
 batch_normalization_1 (Bat  (None, 256, 256, 64)         256       ['conv2d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_1 (Activation)   (None, 256, 256, 64)         0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['activation_1[0][0]']        
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       
                                                                                                  
 batch_normalization_2 (Bat  (None, 128, 128, 128)        512       ['conv2d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_2 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_3 (Conv2D)           (None, 128, 128, 128)        147584    ['activation_2[0][0]']        
                                                                                                  
 batch_normalization_3 (Bat  (None, 128, 128, 128)        512       ['conv2d_3[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_3 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_3[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_3[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 batch_normalization_4 (Bat  (None, 64, 64, 256)          1024      ['conv2d_4[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_4 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_4[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_5 (Conv2D)           (None, 64, 64, 256)          590080    ['activation_4[0][0]']        
                                                                                                  
 batch_normalization_5 (Bat  (None, 64, 64, 256)          1024      ['conv2d_5[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_5 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_5[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_5[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 512)          1180160   ['max_pooling2d_2[0][0]']     
                                                                                                  
 batch_normalization_6 (Bat  (None, 32, 32, 512)          2048      ['conv2d_6[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_6 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_6[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 32, 32, 512)          2359808   ['activation_6[0][0]']        
                                                                                                  
 batch_normalization_7 (Bat  (None, 32, 32, 512)          2048      ['conv2d_7[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_7 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_7[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_3 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_7[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 1024)         4719616   ['max_pooling2d_3[0][0]']     
                                                                                                  
 batch_normalization_8 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_8[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_8 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_8[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 1024)         9438208   ['activation_8[0][0]']        
                                                                                                  
 batch_normalization_9 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_9[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_9 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_9[0][0]'
                                                                    ]                             
                                                                                                  
 up_sampling2d (UpSampling2  (None, 32, 32, 1024)         0         ['activation_9[0][0]']        
 D)                                                                                               
                                                                                                  
 concatenate (Concatenate)   (None, 32, 32, 1536)         0         ['up_sampling2d[0][0]',       
                                                                     'activation_7[0][0]']        
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate[0][0]']         
                                                                                                  
 batch_normalization_10 (Ba  (None, 32, 32, 512)          2048      ['conv2d_10[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_10 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_10[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_10[0][0]']       
                                                                                                  
 batch_normalization_11 (Ba  (None, 32, 32, 512)          2048      ['conv2d_11[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_11 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_11[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 64, 64, 512)          0         ['activation_11[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_1 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_1[0][0]',     
 )                                                                   'activation_5[0][0]']        
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_1[0][0]']       
                                                                                                  
 batch_normalization_12 (Ba  (None, 64, 64, 256)          1024      ['conv2d_12[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_12 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_12[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_13 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_12[0][0]']       
                                                                                                  
 batch_normalization_13 (Ba  (None, 64, 64, 256)          1024      ['conv2d_13[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_13 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_13[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 128, 128, 256)        0         ['activation_13[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_2 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_2[0][0]',     
 )                                                                   'activation_3[0][0]']        
                                                                                                  
 conv2d_14 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_2[0][0]']       
                                                                                                  
 batch_normalization_14 (Ba  (None, 128, 128, 128)        512       ['conv2d_14[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_14 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_14[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_15 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_14[0][0]']       
                                                                                                  
 batch_normalization_15 (Ba  (None, 128, 128, 128)        512       ['conv2d_15[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_15 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_15[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 256, 256, 128)        0         ['activation_15[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_3 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_3[0][0]',     
 )                                                                   'activation_1[0][0]']        
                                                                                                  
 conv2d_16 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_3[0][0]']       
                                                                                                  
 batch_normalization_16 (Ba  (None, 256, 256, 64)         256       ['conv2d_16[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_16 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_16[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_16[0][0]']       
                                                                                                  
 batch_normalization_17 (Ba  (None, 256, 256, 64)         256       ['conv2d_17[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_17 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_17[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_18 (Conv2D)          (None, 256, 256, 1)          65        ['activation_17[0][0]']       
                                                                                                  
 batch_normalization_18 (Ba  (None, 256, 256, 1)          4         ['conv2d_18[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_18 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_18[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31401349 (119.79 MB)
Trainable params: 31389571 (119.74 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
None
âœ“ focal_loss imported successfully
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_2 (InputLayer)        [(None, 256, 256, 3)]        0         []                            
                                                                                                  
 conv2d_19 (Conv2D)          (None, 256, 256, 64)         1792      ['input_2[0][0]']             
                                                                                                  
 batch_normalization_19 (Ba  (None, 256, 256, 64)         256       ['conv2d_19[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_19 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_19[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_20 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_19[0][0]']       
                                                                                                  
 batch_normalization_20 (Ba  (None, 256, 256, 64)         256       ['conv2d_20[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_20 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_20[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_4 (MaxPoolin  (None, 128, 128, 64)         0         ['activation_20[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_21 (Conv2D)          (None, 128, 128, 128)        73856     ['max_pooling2d_4[0][0]']     
                                                                                                  
 batch_normalization_21 (Ba  (None, 128, 128, 128)        512       ['conv2d_21[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_21 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_21[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_22 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_21[0][0]']       
                                                                                                  
 batch_normalization_22 (Ba  (None, 128, 128, 128)        512       ['conv2d_22[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_22 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_22[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_5 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_22[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_23 (Conv2D)          (None, 64, 64, 256)          295168    ['max_pooling2d_5[0][0]']     
                                                                                                  
 batch_normalization_23 (Ba  (None, 64, 64, 256)          1024      ['conv2d_23[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_23 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_23[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_24 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_23[0][0]']       
                                                                                                  
 batch_normalization_24 (Ba  (None, 64, 64, 256)          1024      ['conv2d_24[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_24 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_24[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_6 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_24[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_25 (Conv2D)          (None, 32, 32, 512)          1180160   ['max_pooling2d_6[0][0]']     
                                                                                                  
 batch_normalization_25 (Ba  (None, 32, 32, 512)          2048      ['conv2d_25[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_25 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_25[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_26 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_25[0][0]']       
                                                                                                  
 batch_normalization_26 (Ba  (None, 32, 32, 512)          2048      ['conv2d_26[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_26 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_26[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_7 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_26[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_27 (Conv2D)          (None, 16, 16, 1024)         4719616   ['max_pooling2d_7[0][0]']     
                                                                                                  
 batch_normalization_27 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_27[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_27 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_27[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_28 (Conv2D)          (None, 16, 16, 1024)         9438208   ['activation_27[0][0]']       
                                                                                                  
 batch_normalization_28 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_28[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_28 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_28[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 1024)         0         ['activation_28[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_4 (Concatenate  (None, 32, 32, 1536)         0         ['up_sampling2d_4[0][0]',     
 )                                                                   'activation_26[0][0]']       
                                                                                                  
 conv2d_29 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate_4[0][0]']       
                                                                                                  
 batch_normalization_29 (Ba  (None, 32, 32, 512)          2048      ['conv2d_29[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_29 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_29[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_30 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_29[0][0]']       
                                                                                                  
 batch_normalization_30 (Ba  (None, 32, 32, 512)          2048      ['conv2d_30[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_30 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_30[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 512)          0         ['activation_30[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_5 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_5[0][0]',     
 )                                                                   'activation_24[0][0]']       
                                                                                                  
 conv2d_31 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_5[0][0]']       
                                                                                                  
 batch_normalization_31 (Ba  (None, 64, 64, 256)          1024      ['conv2d_31[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_31 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_31[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_32 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_31[0][0]']       
                                                                                                  
 batch_normalization_32 (Ba  (None, 64, 64, 256)          1024      ['conv2d_32[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_32 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_32[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_6 (UpSamplin  (None, 128, 128, 256)        0         ['activation_32[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_6 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_6[0][0]',     
 )                                                                   'activation_22[0][0]']       
                                                                                                  
 conv2d_33 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_6[0][0]']       
                                                                                                  
 batch_normalization_33 (Ba  (None, 128, 128, 128)        512       ['conv2d_33[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_33 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_33[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_34 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_33[0][0]']       
                                                                                                  
 batch_normalization_34 (Ba  (None, 128, 128, 128)        512       ['conv2d_34[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_34 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_34[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_7 (UpSamplin  (None, 256, 256, 128)        0         ['activation_34[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_7 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_7[0][0]',     
 )                                                                   'activation_20[0][0]']       
                                                                                                  
 conv2d_35 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_7[0][0]']       
                                                                                                  
 batch_normalization_35 (Ba  (None, 256, 256, 64)         256       ['conv2d_35[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_35 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_35[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_36 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_35[0][0]']       
                                                                                                  
 batch_normalization_36 (Ba  (None, 256, 256, 64)         256       ['conv2d_36[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_36 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_36[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_37 (Conv2D)          (None, 256, 256, 1)          65        ['activation_36[0][0]']       
                                                                                                  
 batch_normalization_37 (Ba  (None, 256, 256, 1)          4         ['conv2d_37[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_37 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_37[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31402501 (119.79 MB)
Trainable params: 31390723 (119.75 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
WARNING:absl:`lr` is deprecated in TF-Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
None
Epoch 1/30
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1758862773.691421 3213475 service.cc:145] XLA service 0x1544865f4290 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1758862773.691504 3213475 service.cc:153]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6
I0000 00:00:1758862774.153839 3213475 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
 1/17 [>.............................] - ETA: 10:46 - loss: 0.3452 - accuracy: 0.4878 - jacard_coef: 0.0818 2/17 [==>...........................] - ETA: 56s - loss: 0.3120 - accuracy: 0.4512 - jacard_coef: 0.0985   3/17 [====>.........................] - ETA: 34s - loss: 0.2866 - accuracy: 0.3638 - jacard_coef: 0.0846 4/17 [======>.......................] - ETA: 25s - loss: 0.2655 - accuracy: 0.3216 - jacard_coef: 0.0764 5/17 [=======>......................] - ETA: 18s - loss: 0.2517 - accuracy: 0.2950 - jacard_coef: 0.0766 6/17 [=========>....................] - ETA: 13s - loss: 0.2490 - accuracy: 0.2670 - jacard_coef: 0.0719 7/17 [===========>..................] - ETA: 10s - loss: 0.2433 - accuracy: 0.2480 - jacard_coef: 0.0721 8/17 [=============>................] - ETA: 8s - loss: 0.2396 - accuracy: 0.2288 - jacard_coef: 0.0674  9/17 [==============>...............] - ETA: 6s - loss: 0.2385 - accuracy: 0.2224 - jacard_coef: 0.066510/17 [================>.............] - ETA: 5s - loss: 0.2346 - accuracy: 0.2261 - jacard_coef: 0.068311/17 [==================>...........] - ETA: 4s - loss: 0.2306 - accuracy: 0.2288 - jacard_coef: 0.071312/17 [====================>.........] - ETA: 3s - loss: 0.2296 - accuracy: 0.2284 - jacard_coef: 0.072313/17 [=====================>........] - ETA: 2s - loss: 0.2277 - accuracy: 0.2285 - jacard_coef: 0.074114/17 [=======================>......] - ETA: 1s - loss: 0.2249 - accuracy: 0.2298 - jacard_coef: 0.074215/17 [=========================>....] - ETA: 1s - loss: 0.2251 - accuracy: 0.2300 - jacard_coef: 0.077316/17 [===========================>..] - ETA: 0s - loss: 0.2240 - accuracy: 0.2341 - jacard_coef: 0.076617/17 [==============================] - ETA: 0s - loss: 0.2239 - accuracy: 0.2339 - jacard_coef: 0.072417/17 [==============================] - 55s 927ms/step - loss: 0.2239 - accuracy: 0.2339 - jacard_coef: 0.0724 - val_loss: 1.1218 - val_accuracy: 0.9304 - val_jacard_coef: 3.4109e-05 - lr: 0.0010
Epoch 2/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1946 - accuracy: 0.2586 - jacard_coef: 0.0628 2/17 [==>...........................] - ETA: 1s - loss: 0.1936 - accuracy: 0.2345 - jacard_coef: 0.0704 3/17 [====>.........................] - ETA: 1s - loss: 0.2010 - accuracy: 0.2196 - jacard_coef: 0.0819 4/17 [======>.......................] - ETA: 1s - loss: 0.1998 - accuracy: 0.2025 - jacard_coef: 0.0709 5/17 [=======>......................] - ETA: 1s - loss: 0.1970 - accuracy: 0.2248 - jacard_coef: 0.0727 6/17 [=========>....................] - ETA: 1s - loss: 0.1977 - accuracy: 0.2346 - jacard_coef: 0.0798 7/17 [===========>..................] - ETA: 1s - loss: 0.1989 - accuracy: 0.2357 - jacard_coef: 0.0791 8/17 [=============>................] - ETA: 1s - loss: 0.2001 - accuracy: 0.2379 - jacard_coef: 0.0817 9/17 [==============>...............] - ETA: 1s - loss: 0.1986 - accuracy: 0.2402 - jacard_coef: 0.079610/17 [================>.............] - ETA: 0s - loss: 0.1969 - accuracy: 0.2507 - jacard_coef: 0.077611/17 [==================>...........] - ETA: 0s - loss: 0.1956 - accuracy: 0.2607 - jacard_coef: 0.077812/17 [====================>.........] - ETA: 0s - loss: 0.1944 - accuracy: 0.2692 - jacard_coef: 0.075213/17 [=====================>........] - ETA: 0s - loss: 0.1932 - accuracy: 0.2786 - jacard_coef: 0.076414/17 [=======================>......] - ETA: 0s - loss: 0.1928 - accuracy: 0.2887 - jacard_coef: 0.075815/17 [=========================>....] - ETA: 0s - loss: 0.1919 - accuracy: 0.2952 - jacard_coef: 0.077016/17 [===========================>..] - ETA: 0s - loss: 0.1910 - accuracy: 0.2949 - jacard_coef: 0.076517/17 [==============================] - ETA: 0s - loss: 0.1910 - accuracy: 0.2937 - jacard_coef: 0.072417/17 [==============================] - 2s 142ms/step - loss: 0.1910 - accuracy: 0.2937 - jacard_coef: 0.0724 - val_loss: 1.0260 - val_accuracy: 0.9293 - val_jacard_coef: 0.0130 - lr: 0.0010
Epoch 3/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1787 - accuracy: 0.3196 - jacard_coef: 0.0671 2/17 [==>...........................] - ETA: 1s - loss: 0.1796 - accuracy: 0.3202 - jacard_coef: 0.0747 3/17 [====>.........................] - ETA: 1s - loss: 0.1785 - accuracy: 0.3329 - jacard_coef: 0.0798 4/17 [======>.......................] - ETA: 1s - loss: 0.1772 - accuracy: 0.3481 - jacard_coef: 0.0821 5/17 [=======>......................] - ETA: 1s - loss: 0.1763 - accuracy: 0.3671 - jacard_coef: 0.0792 6/17 [=========>....................] - ETA: 1s - loss: 0.1756 - accuracy: 0.4048 - jacard_coef: 0.0796 7/17 [===========>..................] - ETA: 1s - loss: 0.1757 - accuracy: 0.4131 - jacard_coef: 0.0812 8/17 [=============>................] - ETA: 1s - loss: 0.1755 - accuracy: 0.4308 - jacard_coef: 0.0773 9/17 [==============>...............] - ETA: 1s - loss: 0.1753 - accuracy: 0.4486 - jacard_coef: 0.077110/17 [================>.............] - ETA: 0s - loss: 0.1751 - accuracy: 0.4604 - jacard_coef: 0.075711/17 [==================>...........] - ETA: 0s - loss: 0.1746 - accuracy: 0.4710 - jacard_coef: 0.075812/17 [====================>.........] - ETA: 0s - loss: 0.1747 - accuracy: 0.4646 - jacard_coef: 0.076513/17 [=====================>........] - ETA: 0s - loss: 0.1754 - accuracy: 0.4775 - jacard_coef: 0.078914/17 [=======================>......] - ETA: 0s - loss: 0.1752 - accuracy: 0.4877 - jacard_coef: 0.077415/17 [=========================>....] - ETA: 0s - loss: 0.1750 - accuracy: 0.4963 - jacard_coef: 0.075416/17 [===========================>..] - ETA: 0s - loss: 0.1748 - accuracy: 0.5000 - jacard_coef: 0.076517/17 [==============================] - 2s 137ms/step - loss: 0.1748 - accuracy: 0.4992 - jacard_coef: 0.0748 - val_loss: 1.0685 - val_accuracy: 0.9260 - val_jacard_coef: 0.0133 - lr: 0.0010
Epoch 4/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1709 - accuracy: 0.4732 - jacard_coef: 0.0456 2/17 [==>...........................] - ETA: 1s - loss: 0.1719 - accuracy: 0.4939 - jacard_coef: 0.0740 3/17 [====>.........................] - ETA: 1s - loss: 0.1756 - accuracy: 0.5086 - jacard_coef: 0.0776 4/17 [======>.......................] - ETA: 1s - loss: 0.1741 - accuracy: 0.5221 - jacard_coef: 0.0707 5/17 [=======>......................] - ETA: 1s - loss: 0.1732 - accuracy: 0.5296 - jacard_coef: 0.0698 6/17 [=========>....................] - ETA: 1s - loss: 0.1729 - accuracy: 0.5324 - jacard_coef: 0.0731 7/17 [===========>..................] - ETA: 1s - loss: 0.1723 - accuracy: 0.5405 - jacard_coef: 0.0736 8/17 [=============>................] - ETA: 1s - loss: 0.1718 - accuracy: 0.5515 - jacard_coef: 0.0725 9/17 [==============>...............] - ETA: 1s - loss: 0.1714 - accuracy: 0.5630 - jacard_coef: 0.072810/17 [================>.............] - ETA: 0s - loss: 0.1749 - accuracy: 0.5391 - jacard_coef: 0.071511/17 [==================>...........] - ETA: 0s - loss: 0.1743 - accuracy: 0.5595 - jacard_coef: 0.073212/17 [====================>.........] - ETA: 0s - loss: 0.1750 - accuracy: 0.5410 - jacard_coef: 0.073113/17 [=====================>........] - ETA: 0s - loss: 0.1788 - accuracy: 0.5237 - jacard_coef: 0.074514/17 [=======================>......] - ETA: 0s - loss: 0.1792 - accuracy: 0.4991 - jacard_coef: 0.073915/17 [=========================>....] - ETA: 0s - loss: 0.1817 - accuracy: 0.4820 - jacard_coef: 0.075616/17 [===========================>..] - ETA: 0s - loss: 0.1816 - accuracy: 0.4661 - jacard_coef: 0.075117/17 [==============================] - 2s 141ms/step - loss: 0.1816 - accuracy: 0.4652 - jacard_coef: 0.0786 - val_loss: 0.5482 - val_accuracy: 0.9187 - val_jacard_coef: 0.0443 - lr: 0.0010
Epoch 5/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1830 - accuracy: 0.2155 - jacard_coef: 0.0436 2/17 [==>...........................] - ETA: 2s - loss: 0.1854 - accuracy: 0.2224 - jacard_coef: 0.0621 3/17 [====>.........................] - ETA: 1s - loss: 0.1843 - accuracy: 0.2594 - jacard_coef: 0.0765 4/17 [======>.......................] - ETA: 1s - loss: 0.1819 - accuracy: 0.2754 - jacard_coef: 0.0775 5/17 [=======>......................] - ETA: 1s - loss: 0.1811 - accuracy: 0.2868 - jacard_coef: 0.0739 6/17 [=========>....................] - ETA: 1s - loss: 0.1790 - accuracy: 0.3356 - jacard_coef: 0.0758 7/17 [===========>..................] - ETA: 1s - loss: 0.1776 - accuracy: 0.3731 - jacard_coef: 0.0791 8/17 [=============>................] - ETA: 1s - loss: 0.1792 - accuracy: 0.3886 - jacard_coef: 0.0812 9/17 [==============>...............] - ETA: 1s - loss: 0.1790 - accuracy: 0.4287 - jacard_coef: 0.081910/17 [================>.............] - ETA: 0s - loss: 0.1796 - accuracy: 0.4655 - jacard_coef: 0.081211/17 [==================>...........] - ETA: 0s - loss: 0.1787 - accuracy: 0.4893 - jacard_coef: 0.080412/17 [====================>.........] - ETA: 0s - loss: 0.1777 - accuracy: 0.5110 - jacard_coef: 0.077913/17 [=====================>........] - ETA: 0s - loss: 0.1767 - accuracy: 0.5346 - jacard_coef: 0.078114/17 [=======================>......] - ETA: 0s - loss: 0.1760 - accuracy: 0.5529 - jacard_coef: 0.077815/17 [=========================>....] - ETA: 0s - loss: 0.1751 - accuracy: 0.5694 - jacard_coef: 0.075616/17 [===========================>..] - ETA: 0s - loss: 0.1745 - accuracy: 0.5793 - jacard_coef: 0.075617/17 [==============================] - 2s 137ms/step - loss: 0.1744 - accuracy: 0.5792 - jacard_coef: 0.0790 - val_loss: 1.0553 - val_accuracy: 0.9135 - val_jacard_coef: 0.0143 - lr: 0.0010
Epoch 6/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1636 - accuracy: 0.8271 - jacard_coef: 0.0353 2/17 [==>...........................] - ETA: 2s - loss: 0.1631 - accuracy: 0.8258 - jacard_coef: 0.0699 3/17 [====>.........................] - ETA: 1s - loss: 0.1635 - accuracy: 0.8331 - jacard_coef: 0.0629 4/17 [======>.......................] - ETA: 1s - loss: 0.1632 - accuracy: 0.8351 - jacard_coef: 0.0621 5/17 [=======>......................] - ETA: 1s - loss: 0.1632 - accuracy: 0.8322 - jacard_coef: 0.0619 6/17 [=========>....................] - ETA: 1s - loss: 0.1629 - accuracy: 0.8333 - jacard_coef: 0.0612 7/17 [===========>..................] - ETA: 1s - loss: 0.1632 - accuracy: 0.8212 - jacard_coef: 0.0670 8/17 [=============>................] - ETA: 1s - loss: 0.1630 - accuracy: 0.8316 - jacard_coef: 0.0663 9/17 [==============>...............] - ETA: 1s - loss: 0.1626 - accuracy: 0.8383 - jacard_coef: 0.067910/17 [================>.............] - ETA: 0s - loss: 0.1624 - accuracy: 0.8408 - jacard_coef: 0.070911/17 [==================>...........] - ETA: 0s - loss: 0.1622 - accuracy: 0.8446 - jacard_coef: 0.072412/17 [====================>.........] - ETA: 0s - loss: 0.1620 - accuracy: 0.8445 - jacard_coef: 0.075113/17 [=====================>........] - ETA: 0s - loss: 0.1617 - accuracy: 0.8412 - jacard_coef: 0.074314/17 [=======================>......] - ETA: 0s - loss: 0.1613 - accuracy: 0.8426 - jacard_coef: 0.074215/17 [=========================>....] - ETA: 0s - loss: 0.1610 - accuracy: 0.8434 - jacard_coef: 0.074416/17 [===========================>..] - ETA: 0s - loss: 0.1609 - accuracy: 0.8419 - jacard_coef: 0.075117/17 [==============================] - 2s 137ms/step - loss: 0.1610 - accuracy: 0.8392 - jacard_coef: 0.0791 - val_loss: 1.0130 - val_accuracy: 0.9143 - val_jacard_coef: 0.0226 - lr: 0.0010
Epoch 7/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1590 - accuracy: 0.9067 - jacard_coef: 0.0686 2/17 [==>...........................] - ETA: 2s - loss: 0.1599 - accuracy: 0.8558 - jacard_coef: 0.0676 3/17 [====>.........................] - ETA: 1s - loss: 0.1623 - accuracy: 0.7483 - jacard_coef: 0.0752 4/17 [======>.......................] - ETA: 1s - loss: 0.1616 - accuracy: 0.7509 - jacard_coef: 0.0712 5/17 [=======>......................] - ETA: 1s - loss: 0.1647 - accuracy: 0.6810 - jacard_coef: 0.0708 6/17 [=========>....................] - ETA: 1s - loss: 0.1639 - accuracy: 0.7154 - jacard_coef: 0.0689 7/17 [===========>..................] - ETA: 1s - loss: 0.1648 - accuracy: 0.7271 - jacard_coef: 0.0693 8/17 [=============>................] - ETA: 1s - loss: 0.1645 - accuracy: 0.7161 - jacard_coef: 0.0687 9/17 [==============>...............] - ETA: 1s - loss: 0.1640 - accuracy: 0.7170 - jacard_coef: 0.069810/17 [================>.............] - ETA: 0s - loss: 0.1635 - accuracy: 0.7122 - jacard_coef: 0.067611/17 [==================>...........] - ETA: 0s - loss: 0.1635 - accuracy: 0.7024 - jacard_coef: 0.068712/17 [====================>.........] - ETA: 0s - loss: 0.1635 - accuracy: 0.7014 - jacard_coef: 0.068513/17 [=====================>........] - ETA: 0s - loss: 0.1632 - accuracy: 0.7038 - jacard_coef: 0.069514/17 [=======================>......] - ETA: 0s - loss: 0.1630 - accuracy: 0.7043 - jacard_coef: 0.071815/17 [=========================>....] - ETA: 0s - loss: 0.1627 - accuracy: 0.7152 - jacard_coef: 0.074016/17 [===========================>..] - ETA: 0s - loss: 0.1623 - accuracy: 0.7248 - jacard_coef: 0.075017/17 [==============================] - 2s 137ms/step - loss: 0.1623 - accuracy: 0.7243 - jacard_coef: 0.0775 - val_loss: 0.5329 - val_accuracy: 0.9243 - val_jacard_coef: 0.0152 - lr: 0.0010
Epoch 8/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1543 - accuracy: 0.9112 - jacard_coef: 0.0728 2/17 [==>...........................] - ETA: 2s - loss: 0.1544 - accuracy: 0.9293 - jacard_coef: 0.0501 3/17 [====>.........................] - ETA: 1s - loss: 0.1544 - accuracy: 0.9153 - jacard_coef: 0.0635 4/17 [======>.......................] - ETA: 1s - loss: 0.1545 - accuracy: 0.9025 - jacard_coef: 0.0621 5/17 [=======>......................] - ETA: 1s - loss: 0.1560 - accuracy: 0.8806 - jacard_coef: 0.0678 6/17 [=========>....................] - ETA: 1s - loss: 0.1559 - accuracy: 0.8814 - jacard_coef: 0.0712 7/17 [===========>..................] - ETA: 1s - loss: 0.1560 - accuracy: 0.8783 - jacard_coef: 0.0782 8/17 [=============>................] - ETA: 1s - loss: 0.1556 - accuracy: 0.8817 - jacard_coef: 0.0788 9/17 [==============>...............] - ETA: 1s - loss: 0.1552 - accuracy: 0.8870 - jacard_coef: 0.077010/17 [================>.............] - ETA: 0s - loss: 0.1548 - accuracy: 0.8906 - jacard_coef: 0.076111/17 [==================>...........] - ETA: 0s - loss: 0.1546 - accuracy: 0.8929 - jacard_coef: 0.076112/17 [====================>.........] - ETA: 0s - loss: 0.1542 - accuracy: 0.8977 - jacard_coef: 0.073413/17 [=====================>........] - ETA: 0s - loss: 0.1541 - accuracy: 0.8954 - jacard_coef: 0.076214/17 [=======================>......] - ETA: 0s - loss: 0.1540 - accuracy: 0.8953 - jacard_coef: 0.072915/17 [=========================>....] - ETA: 0s - loss: 0.1539 - accuracy: 0.8911 - jacard_coef: 0.072516/17 [===========================>..] - ETA: 0s - loss: 0.1539 - accuracy: 0.8895 - jacard_coef: 0.074417/17 [==============================] - 2s 142ms/step - loss: 0.1540 - accuracy: 0.8871 - jacard_coef: 0.0783 - val_loss: 0.1602 - val_accuracy: 0.9176 - val_jacard_coef: 0.0631 - lr: 0.0010
Epoch 9/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1532 - accuracy: 0.8893 - jacard_coef: 0.0916 2/17 [==>...........................] - ETA: 2s - loss: 0.1522 - accuracy: 0.8975 - jacard_coef: 0.0878 3/17 [====>.........................] - ETA: 1s - loss: 0.1510 - accuracy: 0.9110 - jacard_coef: 0.0771 4/17 [======>.......................] - ETA: 1s - loss: 0.1518 - accuracy: 0.9073 - jacard_coef: 0.0798 5/17 [=======>......................] - ETA: 1s - loss: 0.1527 - accuracy: 0.9059 - jacard_coef: 0.0810 6/17 [=========>....................] - ETA: 1s - loss: 0.1520 - accuracy: 0.9119 - jacard_coef: 0.0765 7/17 [===========>..................] - ETA: 1s - loss: 0.1513 - accuracy: 0.9165 - jacard_coef: 0.0731 8/17 [=============>................] - ETA: 1s - loss: 0.1510 - accuracy: 0.9146 - jacard_coef: 0.0751 9/17 [==============>...............] - ETA: 1s - loss: 0.1514 - accuracy: 0.9166 - jacard_coef: 0.073610/17 [================>.............] - ETA: 0s - loss: 0.1511 - accuracy: 0.9154 - jacard_coef: 0.074911/17 [==================>...........] - ETA: 0s - loss: 0.1511 - accuracy: 0.9138 - jacard_coef: 0.076212/17 [====================>.........] - ETA: 0s - loss: 0.1508 - accuracy: 0.9136 - jacard_coef: 0.076213/17 [=====================>........] - ETA: 0s - loss: 0.1506 - accuracy: 0.9141 - jacard_coef: 0.075114/17 [=======================>......] - ETA: 0s - loss: 0.1506 - accuracy: 0.9117 - jacard_coef: 0.076615/17 [=========================>....] - ETA: 0s - loss: 0.1502 - accuracy: 0.9136 - jacard_coef: 0.075016/17 [===========================>..] - ETA: 0s - loss: 0.1501 - accuracy: 0.9112 - jacard_coef: 0.075917/17 [==============================] - 2s 143ms/step - loss: 0.1501 - accuracy: 0.9093 - jacard_coef: 0.0716 - val_loss: 0.4136 - val_accuracy: 0.6973 - val_jacard_coef: 0.0655 - lr: 0.0010
Epoch 10/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1514 - accuracy: 0.8790 - jacard_coef: 0.0973 2/17 [==>...........................] - ETA: 2s - loss: 0.1520 - accuracy: 0.8789 - jacard_coef: 0.0948 3/17 [====>.........................] - ETA: 1s - loss: 0.1522 - accuracy: 0.8837 - jacard_coef: 0.0878 4/17 [======>.......................] - ETA: 1s - loss: 0.1554 - accuracy: 0.8847 - jacard_coef: 0.0848 5/17 [=======>......................] - ETA: 1s - loss: 0.1552 - accuracy: 0.8785 - jacard_coef: 0.0871 6/17 [=========>....................] - ETA: 1s - loss: 0.1541 - accuracy: 0.8814 - jacard_coef: 0.0836 7/17 [===========>..................] - ETA: 1s - loss: 0.1553 - accuracy: 0.8783 - jacard_coef: 0.0833 8/17 [=============>................] - ETA: 1s - loss: 0.1562 - accuracy: 0.8764 - jacard_coef: 0.0815 9/17 [==============>...............] - ETA: 1s - loss: 0.1554 - accuracy: 0.8830 - jacard_coef: 0.076710/17 [================>.............] - ETA: 0s - loss: 0.1547 - accuracy: 0.8877 - jacard_coef: 0.075411/17 [==================>...........] - ETA: 0s - loss: 0.1553 - accuracy: 0.8899 - jacard_coef: 0.075712/17 [====================>.........] - ETA: 0s - loss: 0.1543 - accuracy: 0.8955 - jacard_coef: 0.072713/17 [=====================>........] - ETA: 0s - loss: 0.1551 - accuracy: 0.8938 - jacard_coef: 0.075314/17 [=======================>......] - ETA: 0s - loss: 0.1553 - accuracy: 0.8933 - jacard_coef: 0.076415/17 [=========================>....] - ETA: 0s - loss: 0.1550 - accuracy: 0.8930 - jacard_coef: 0.076616/17 [===========================>..] - ETA: 0s - loss: 0.1544 - accuracy: 0.8947 - jacard_coef: 0.075517/17 [==============================] - 2s 137ms/step - loss: 0.1545 - accuracy: 0.8926 - jacard_coef: 0.0713 - val_loss: 1.0308 - val_accuracy: 0.9113 - val_jacard_coef: 0.0267 - lr: 0.0010
Epoch 11/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1479 - accuracy: 0.9163 - jacard_coef: 0.0565 2/17 [==>...........................] - ETA: 2s - loss: 0.1502 - accuracy: 0.9147 - jacard_coef: 0.0617 3/17 [====>.........................] - ETA: 1s - loss: 0.1494 - accuracy: 0.9164 - jacard_coef: 0.0625 4/17 [======>.......................] - ETA: 1s - loss: 0.1499 - accuracy: 0.8935 - jacard_coef: 0.0679 5/17 [=======>......................] - ETA: 1s - loss: 0.1499 - accuracy: 0.8852 - jacard_coef: 0.0728 6/17 [=========>....................] - ETA: 1s - loss: 0.1499 - accuracy: 0.8783 - jacard_coef: 0.0744 7/17 [===========>..................] - ETA: 1s - loss: 0.1492 - accuracy: 0.8810 - jacard_coef: 0.0762 8/17 [=============>................] - ETA: 1s - loss: 0.1488 - accuracy: 0.8859 - jacard_coef: 0.0752 9/17 [==============>...............] - ETA: 1s - loss: 0.1483 - accuracy: 0.8889 - jacard_coef: 0.075310/17 [================>.............] - ETA: 0s - loss: 0.1478 - accuracy: 0.8937 - jacard_coef: 0.072311/17 [==================>...........] - ETA: 0s - loss: 0.1479 - accuracy: 0.8903 - jacard_coef: 0.076312/17 [====================>.........] - ETA: 0s - loss: 0.1477 - accuracy: 0.8896 - jacard_coef: 0.077613/17 [=====================>........] - ETA: 0s - loss: 0.1472 - accuracy: 0.8913 - jacard_coef: 0.076914/17 [=======================>......] - ETA: 0s - loss: 0.1469 - accuracy: 0.8938 - jacard_coef: 0.075515/17 [=========================>....] - ETA: 0s - loss: 0.1466 - accuracy: 0.8957 - jacard_coef: 0.075316/17 [===========================>..] - ETA: 0s - loss: 0.1463 - accuracy: 0.8974 - jacard_coef: 0.074717/17 [==============================] - 2s 137ms/step - loss: 0.1463 - accuracy: 0.8967 - jacard_coef: 0.0781 - val_loss: 0.1921 - val_accuracy: 0.2713 - val_jacard_coef: 0.0632 - lr: 0.0010
Epoch 12/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1446 - accuracy: 0.8945 - jacard_coef: 0.0758 2/17 [==>...........................] - ETA: 2s - loss: 0.1437 - accuracy: 0.8964 - jacard_coef: 0.0689 3/17 [====>.........................] - ETA: 1s - loss: 0.1443 - accuracy: 0.8926 - jacard_coef: 0.0730 4/17 [======>.......................] - ETA: 1s - loss: 0.1439 - accuracy: 0.8886 - jacard_coef: 0.0779 5/17 [=======>......................] - ETA: 1s - loss: 0.1432 - accuracy: 0.8955 - jacard_coef: 0.0747 6/17 [=========>....................] - ETA: 1s - loss: 0.1425 - accuracy: 0.9013 - jacard_coef: 0.0723 7/17 [===========>..................] - ETA: 1s - loss: 0.1423 - accuracy: 0.9037 - jacard_coef: 0.0725 8/17 [=============>................] - ETA: 1s - loss: 0.1418 - accuracy: 0.9085 - jacard_coef: 0.0701 9/17 [==============>...............] - ETA: 1s - loss: 0.1417 - accuracy: 0.9060 - jacard_coef: 0.073510/17 [================>.............] - ETA: 0s - loss: 0.1413 - accuracy: 0.9088 - jacard_coef: 0.072311/17 [==================>...........] - ETA: 0s - loss: 0.1411 - accuracy: 0.9093 - jacard_coef: 0.072812/17 [====================>.........] - ETA: 0s - loss: 0.1410 - accuracy: 0.9088 - jacard_coef: 0.074013/17 [=====================>........] - ETA: 0s - loss: 0.1412 - accuracy: 0.9061 - jacard_coef: 0.076714/17 [=======================>......] - ETA: 0s - loss: 0.1413 - accuracy: 0.9070 - jacard_coef: 0.076315/17 [=========================>....] - ETA: 0s - loss: 0.1410 - accuracy: 0.9089 - jacard_coef: 0.074916/17 [===========================>..] - ETA: 0s - loss: 0.1409 - accuracy: 0.9084 - jacard_coef: 0.075517/17 [==============================] - 2s 137ms/step - loss: 0.1409 - accuracy: 0.9091 - jacard_coef: 0.0712 - val_loss: 0.1574 - val_accuracy: 0.8593 - val_jacard_coef: 0.0632 - lr: 0.0010
Epoch 13/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1368 - accuracy: 0.9305 - jacard_coef: 0.0617 2/17 [==>...........................] - ETA: 2s - loss: 0.1380 - accuracy: 0.9170 - jacard_coef: 0.0734 3/17 [====>.........................] - ETA: 1s - loss: 0.1383 - accuracy: 0.9123 - jacard_coef: 0.0775 4/17 [======>.......................] - ETA: 1s - loss: 0.1391 - accuracy: 0.9093 - jacard_coef: 0.0787 5/17 [=======>......................] - ETA: 1s - loss: 0.1389 - accuracy: 0.9114 - jacard_coef: 0.0771 6/17 [=========>....................] - ETA: 1s - loss: 0.1387 - accuracy: 0.9108 - jacard_coef: 0.0782 7/17 [===========>..................] - ETA: 1s - loss: 0.1379 - accuracy: 0.9174 - jacard_coef: 0.0728 8/17 [=============>................] - ETA: 1s - loss: 0.1379 - accuracy: 0.9170 - jacard_coef: 0.0736 9/17 [==============>...............] - ETA: 1s - loss: 0.1378 - accuracy: 0.9159 - jacard_coef: 0.074710/17 [================>.............] - ETA: 0s - loss: 0.1377 - accuracy: 0.9177 - jacard_coef: 0.073311/17 [==================>...........] - ETA: 0s - loss: 0.1376 - accuracy: 0.9187 - jacard_coef: 0.072712/17 [====================>.........] - ETA: 0s - loss: 0.1376 - accuracy: 0.9172 - jacard_coef: 0.074013/17 [=====================>........] - ETA: 0s - loss: 0.1375 - accuracy: 0.9175 - jacard_coef: 0.073914/17 [=======================>......] - ETA: 0s - loss: 0.1374 - accuracy: 0.9170 - jacard_coef: 0.074415/17 [=========================>....] - ETA: 0s - loss: 0.1374 - accuracy: 0.9158 - jacard_coef: 0.075516/17 [===========================>..] - ETA: 0s - loss: 0.1372 - accuracy: 0.9159 - jacard_coef: 0.075417/17 [==============================] - 2s 137ms/step - loss: 0.1372 - accuracy: 0.9162 - jacard_coef: 0.0733 - val_loss: 0.1542 - val_accuracy: 0.8162 - val_jacard_coef: 0.0632 - lr: 0.0010
Epoch 14/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1341 - accuracy: 0.9421 - jacard_coef: 0.0520 2/17 [==>...........................] - ETA: 2s - loss: 0.1359 - accuracy: 0.9166 - jacard_coef: 0.0735 3/17 [====>.........................] - ETA: 1s - loss: 0.1363 - accuracy: 0.9094 - jacard_coef: 0.0786 4/17 [======>.......................] - ETA: 1s - loss: 0.1361 - accuracy: 0.9080 - jacard_coef: 0.0796 5/17 [=======>......................] - ETA: 1s - loss: 0.1356 - accuracy: 0.9128 - jacard_coef: 0.0760 6/17 [=========>....................] - ETA: 1s - loss: 0.1355 - accuracy: 0.9153 - jacard_coef: 0.0737 7/17 [===========>..................] - ETA: 1s - loss: 0.1359 - accuracy: 0.9131 - jacard_coef: 0.0755 8/17 [=============>................] - ETA: 1s - loss: 0.1356 - accuracy: 0.9140 - jacard_coef: 0.0750 9/17 [==============>...............] - ETA: 1s - loss: 0.1355 - accuracy: 0.9130 - jacard_coef: 0.075810/17 [================>.............] - ETA: 0s - loss: 0.1350 - accuracy: 0.9163 - jacard_coef: 0.073211/17 [==================>...........] - ETA: 0s - loss: 0.1347 - accuracy: 0.9176 - jacard_coef: 0.072212/17 [====================>.........] - ETA: 0s - loss: 0.1347 - accuracy: 0.9161 - jacard_coef: 0.073713/17 [=====================>........] - ETA: 0s - loss: 0.1348 - accuracy: 0.9145 - jacard_coef: 0.075214/17 [=======================>......] - ETA: 0s - loss: 0.1346 - accuracy: 0.9151 - jacard_coef: 0.074815/17 [=========================>....] - ETA: 0s - loss: 0.1343 - accuracy: 0.9169 - jacard_coef: 0.073516/17 [===========================>..] - ETA: 0s - loss: 0.1345 - accuracy: 0.9150 - jacard_coef: 0.075117/17 [==============================] - 2s 137ms/step - loss: 0.1348 - accuracy: 0.9115 - jacard_coef: 0.0729 - val_loss: 0.1371 - val_accuracy: 0.9304 - val_jacard_coef: 0.0626 - lr: 0.0010
Epoch 15/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1357 - accuracy: 0.8936 - jacard_coef: 0.0940 2/17 [==>...........................] - ETA: 2s - loss: 0.1363 - accuracy: 0.8923 - jacard_coef: 0.0944 3/17 [====>.........................] - ETA: 1s - loss: 0.1367 - accuracy: 0.8915 - jacard_coef: 0.0938 4/17 [======>.......................] - ETA: 1s - loss: 0.1356 - accuracy: 0.9002 - jacard_coef: 0.0865 5/17 [=======>......................] - ETA: 1s - loss: 0.1355 - accuracy: 0.9053 - jacard_coef: 0.0812 6/17 [=========>....................] - ETA: 1s - loss: 0.1359 - accuracy: 0.9003 - jacard_coef: 0.0850 7/17 [===========>..................] - ETA: 1s - loss: 0.1350 - accuracy: 0.9081 - jacard_coef: 0.0788 8/17 [=============>................] - ETA: 1s - loss: 0.1351 - accuracy: 0.9060 - jacard_coef: 0.0810 9/17 [==============>...............] - ETA: 1s - loss: 0.1343 - accuracy: 0.9119 - jacard_coef: 0.076310/17 [================>.............] - ETA: 0s - loss: 0.1341 - accuracy: 0.9144 - jacard_coef: 0.074511/17 [==================>...........] - ETA: 0s - loss: 0.1341 - accuracy: 0.9139 - jacard_coef: 0.075212/17 [====================>.........] - ETA: 0s - loss: 0.1345 - accuracy: 0.9148 - jacard_coef: 0.074613/17 [=====================>........] - ETA: 0s - loss: 0.1344 - accuracy: 0.9152 - jacard_coef: 0.074614/17 [=======================>......] - ETA: 0s - loss: 0.1340 - accuracy: 0.9173 - jacard_coef: 0.072915/17 [=========================>....] - ETA: 0s - loss: 0.1342 - accuracy: 0.9154 - jacard_coef: 0.074616/17 [===========================>..] - ETA: 0s - loss: 0.1341 - accuracy: 0.9161 - jacard_coef: 0.074117/17 [==============================] - 2s 137ms/step - loss: 0.1341 - accuracy: 0.9155 - jacard_coef: 0.0775 - val_loss: 0.1278 - val_accuracy: 0.9304 - val_jacard_coef: 0.0624 - lr: 5.0000e-04
Epoch 16/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1343 - accuracy: 0.9044 - jacard_coef: 0.0835 2/17 [==>...........................] - ETA: 2s - loss: 0.1299 - accuracy: 0.9368 - jacard_coef: 0.0559 3/17 [====>.........................] - ETA: 1s - loss: 0.1287 - accuracy: 0.9469 - jacard_coef: 0.0474 4/17 [======>.......................] - ETA: 1s - loss: 0.1302 - accuracy: 0.9344 - jacard_coef: 0.0581 5/17 [=======>......................] - ETA: 1s - loss: 0.1314 - accuracy: 0.9256 - jacard_coef: 0.0652 6/17 [=========>....................] - ETA: 1s - loss: 0.1314 - accuracy: 0.9261 - jacard_coef: 0.0645 7/17 [===========>..................] - ETA: 1s - loss: 0.1314 - accuracy: 0.9226 - jacard_coef: 0.0675 8/17 [=============>................] - ETA: 1s - loss: 0.1320 - accuracy: 0.9165 - jacard_coef: 0.0723 9/17 [==============>...............] - ETA: 1s - loss: 0.1320 - accuracy: 0.9168 - jacard_coef: 0.072110/17 [================>.............] - ETA: 0s - loss: 0.1328 - accuracy: 0.9144 - jacard_coef: 0.074111/17 [==================>...........] - ETA: 0s - loss: 0.1328 - accuracy: 0.9128 - jacard_coef: 0.075612/17 [====================>.........] - ETA: 0s - loss: 0.1326 - accuracy: 0.9130 - jacard_coef: 0.075713/17 [=====================>........] - ETA: 0s - loss: 0.1325 - accuracy: 0.9133 - jacard_coef: 0.075614/17 [=======================>......] - ETA: 0s - loss: 0.1329 - accuracy: 0.9099 - jacard_coef: 0.078315/17 [=========================>....] - ETA: 0s - loss: 0.1325 - accuracy: 0.9123 - jacard_coef: 0.076516/17 [===========================>..] - ETA: 0s - loss: 0.1321 - accuracy: 0.9154 - jacard_coef: 0.073917/17 [==============================] - 2s 138ms/step - loss: 0.1322 - accuracy: 0.9147 - jacard_coef: 0.0770 - val_loss: 0.1321 - val_accuracy: 0.9304 - val_jacard_coef: 0.0626 - lr: 5.0000e-04
Epoch 17/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1319 - accuracy: 0.9133 - jacard_coef: 0.0706 2/17 [==>...........................] - ETA: 2s - loss: 0.1336 - accuracy: 0.9122 - jacard_coef: 0.0718 3/17 [====>.........................] - ETA: 1s - loss: 0.1341 - accuracy: 0.9119 - jacard_coef: 0.0729 4/17 [======>.......................] - ETA: 1s - loss: 0.1349 - accuracy: 0.9079 - jacard_coef: 0.0771 5/17 [=======>......................] - ETA: 1s - loss: 0.1336 - accuracy: 0.9161 - jacard_coef: 0.0704 6/17 [=========>....................] - ETA: 1s - loss: 0.1342 - accuracy: 0.9101 - jacard_coef: 0.0754 7/17 [===========>..................] - ETA: 1s - loss: 0.1338 - accuracy: 0.9121 - jacard_coef: 0.0740 8/17 [=============>................] - ETA: 1s - loss: 0.1340 - accuracy: 0.9089 - jacard_coef: 0.0768 9/17 [==============>...............] - ETA: 1s - loss: 0.1341 - accuracy: 0.9080 - jacard_coef: 0.078110/17 [================>.............] - ETA: 0s - loss: 0.1336 - accuracy: 0.9109 - jacard_coef: 0.075911/17 [==================>...........] - ETA: 0s - loss: 0.1334 - accuracy: 0.9119 - jacard_coef: 0.075512/17 [====================>.........] - ETA: 0s - loss: 0.1332 - accuracy: 0.9119 - jacard_coef: 0.075813/17 [=====================>........] - ETA: 0s - loss: 0.1329 - accuracy: 0.9133 - jacard_coef: 0.074814/17 [=======================>......] - ETA: 0s - loss: 0.1327 - accuracy: 0.9144 - jacard_coef: 0.074115/17 [=========================>....] - ETA: 0s - loss: 0.1325 - accuracy: 0.9153 - jacard_coef: 0.073616/17 [===========================>..] - ETA: 0s - loss: 0.1326 - accuracy: 0.9150 - jacard_coef: 0.074117/17 [==============================] - 2s 137ms/step - loss: 0.1327 - accuracy: 0.9142 - jacard_coef: 0.0792 - val_loss: 0.1269 - val_accuracy: 0.9272 - val_jacard_coef: 0.0626 - lr: 5.0000e-04
Epoch 18/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1280 - accuracy: 0.9301 - jacard_coef: 0.0648 2/17 [==>...........................] - ETA: 2s - loss: 0.1303 - accuracy: 0.9137 - jacard_coef: 0.0781 3/17 [====>.........................] - ETA: 1s - loss: 0.1301 - accuracy: 0.9171 - jacard_coef: 0.0754 4/17 [======>.......................] - ETA: 1s - loss: 0.1292 - accuracy: 0.9221 - jacard_coef: 0.0713 5/17 [=======>......................] - ETA: 1s - loss: 0.1295 - accuracy: 0.9211 - jacard_coef: 0.0721 6/17 [=========>....................] - ETA: 1s - loss: 0.1296 - accuracy: 0.9210 - jacard_coef: 0.0722 7/17 [===========>..................] - ETA: 1s - loss: 0.1300 - accuracy: 0.9186 - jacard_coef: 0.0742 8/17 [=============>................] - ETA: 1s - loss: 0.1298 - accuracy: 0.9187 - jacard_coef: 0.0741 9/17 [==============>...............] - ETA: 1s - loss: 0.1298 - accuracy: 0.9186 - jacard_coef: 0.074210/17 [================>.............] - ETA: 0s - loss: 0.1296 - accuracy: 0.9183 - jacard_coef: 0.074511/17 [==================>...........] - ETA: 0s - loss: 0.1301 - accuracy: 0.9147 - jacard_coef: 0.077512/17 [====================>.........] - ETA: 0s - loss: 0.1295 - accuracy: 0.9182 - jacard_coef: 0.074513/17 [=====================>........] - ETA: 0s - loss: 0.1296 - accuracy: 0.9168 - jacard_coef: 0.075614/17 [=======================>......] - ETA: 0s - loss: 0.1295 - accuracy: 0.9167 - jacard_coef: 0.075715/17 [=========================>....] - ETA: 0s - loss: 0.1294 - accuracy: 0.9163 - jacard_coef: 0.076016/17 [===========================>..] - ETA: 0s - loss: 0.1292 - accuracy: 0.9170 - jacard_coef: 0.075217/17 [==============================] - 2s 137ms/step - loss: 0.1292 - accuracy: 0.9173 - jacard_coef: 0.0729 - val_loss: 0.1320 - val_accuracy: 0.9304 - val_jacard_coef: 0.0623 - lr: 5.0000e-04
Epoch 19/30
 1/17 [>.............................] - ETA: 2s - loss: 0.1277 - accuracy: 0.9114 - jacard_coef: 0.0780 2/17 [==>...........................] - ETA: 2s - loss: 0.1289 - accuracy: 0.9077 - jacard_coef: 0.0806 3/17 [====>.........................] - ETA: 1s - loss: 0.1287 - accuracy: 0.9077 - jacard_coef: 0.0805 4/17 [======>.......................] - ETA: 1s - loss: 0.1280 - accuracy: 0.9135 - jacard_coef: 0.0760 5/17 [=======>......................] - ETA: 1s - loss: 0.1280 - accuracy: 0.9128 - jacard_coef: 0.0765 6/17 [=========>....................] - ETA: 1s - loss: 0.1278 - accuracy: 0.9141 - jacard_coef: 0.0753 7/17 [===========>..................] - ETA: 1s - loss: 0.1276 - accuracy: 0.9152 - jacard_coef: 0.0744 8/17 [=============>................] - ETA: 1s - loss: 0.1274 - accuracy: 0.9157 - jacard_coef: 0.0741 9/17 [==============>...............] - ETA: 1s - loss: 0.1271 - accuracy: 0.9186 - jacard_coef: 0.071810/17 [================>.............] - ETA: 0s - loss: 0.1273 - accuracy: 0.9167 - jacard_coef: 0.073511/17 [==================>...........] - ETA: 0s - loss: 0.1272 - accuracy: 0.9174 - jacard_coef: 0.073112/17 [====================>.........] - ETA: 0s - loss: 0.1273 - accuracy: 0.9165 - jacard_coef: 0.073913/17 [=====================>........] - ETA: 0s - loss: 0.1279 - accuracy: 0.9158 - jacard_coef: 0.074614/17 [=======================>......] - ETA: 0s - loss: 0.1280 - accuracy: 0.9147 - jacard_coef: 0.075615/17 [=========================>....] - ETA: 0s - loss: 0.1280 - accuracy: 0.9142 - jacard_coef: 0.076116/17 [===========================>..] - ETA: 0s - loss: 0.1276 - accuracy: 0.9164 - jacard_coef: 0.074217/17 [==============================] - 2s 138ms/step - loss: 0.1277 - accuracy: 0.9158 - jacard_coef: 0.0776 - val_loss: 0.1281 - val_accuracy: 0.9304 - val_jacard_coef: 0.0624 - lr: 5.0000e-04
/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(

âœ“ Training completed successfully!
  Best Val Jaccard: 0.0655 (epoch 9)
  Final Val Loss: 0.1281
  Training Time: 0:01:38.518290
  Stability (std): 0.2670

Results saved to: hyperparameter_optimization_20250926_123742/exp_10_UNet_lr5e-3_bs8/UNet_lr0.005_bs8_results.json
