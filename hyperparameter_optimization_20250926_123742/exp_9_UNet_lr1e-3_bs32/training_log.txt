âœ“ GPU memory growth enabled for 1 GPUs
Loading dataset...
Loaded 144 images and 144 masks
Training set: (129, 256, 256, 3), Validation set: (15, 256, 256, 3)

============================================================
TRAINING: UNet
Learning Rate: 0.001, Batch Size: 32, Epochs: 30
============================================================
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 256, 256, 64)         640       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 256, 256, 64)         256       ['conv2d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 activation (Activation)     (None, 256, 256, 64)         0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['activation[0][0]']          
                                                                                                  
 batch_normalization_1 (Bat  (None, 256, 256, 64)         256       ['conv2d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_1 (Activation)   (None, 256, 256, 64)         0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['activation_1[0][0]']        
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       
                                                                                                  
 batch_normalization_2 (Bat  (None, 128, 128, 128)        512       ['conv2d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_2 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_3 (Conv2D)           (None, 128, 128, 128)        147584    ['activation_2[0][0]']        
                                                                                                  
 batch_normalization_3 (Bat  (None, 128, 128, 128)        512       ['conv2d_3[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_3 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_3[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_3[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 batch_normalization_4 (Bat  (None, 64, 64, 256)          1024      ['conv2d_4[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_4 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_4[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_5 (Conv2D)           (None, 64, 64, 256)          590080    ['activation_4[0][0]']        
                                                                                                  
 batch_normalization_5 (Bat  (None, 64, 64, 256)          1024      ['conv2d_5[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_5 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_5[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_5[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 512)          1180160   ['max_pooling2d_2[0][0]']     
                                                                                                  
 batch_normalization_6 (Bat  (None, 32, 32, 512)          2048      ['conv2d_6[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_6 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_6[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 32, 32, 512)          2359808   ['activation_6[0][0]']        
                                                                                                  
 batch_normalization_7 (Bat  (None, 32, 32, 512)          2048      ['conv2d_7[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_7 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_7[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_3 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_7[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 1024)         4719616   ['max_pooling2d_3[0][0]']     
                                                                                                  
 batch_normalization_8 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_8[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_8 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_8[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 1024)         9438208   ['activation_8[0][0]']        
                                                                                                  
 batch_normalization_9 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_9[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_9 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_9[0][0]'
                                                                    ]                             
                                                                                                  
 up_sampling2d (UpSampling2  (None, 32, 32, 1024)         0         ['activation_9[0][0]']        
 D)                                                                                               
                                                                                                  
 concatenate (Concatenate)   (None, 32, 32, 1536)         0         ['up_sampling2d[0][0]',       
                                                                     'activation_7[0][0]']        
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate[0][0]']         
                                                                                                  
 batch_normalization_10 (Ba  (None, 32, 32, 512)          2048      ['conv2d_10[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_10 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_10[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_10[0][0]']       
                                                                                                  
 batch_normalization_11 (Ba  (None, 32, 32, 512)          2048      ['conv2d_11[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_11 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_11[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 64, 64, 512)          0         ['activation_11[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_1 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_1[0][0]',     
 )                                                                   'activation_5[0][0]']        
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_1[0][0]']       
                                                                                                  
 batch_normalization_12 (Ba  (None, 64, 64, 256)          1024      ['conv2d_12[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_12 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_12[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_13 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_12[0][0]']       
                                                                                                  
 batch_normalization_13 (Ba  (None, 64, 64, 256)          1024      ['conv2d_13[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_13 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_13[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 128, 128, 256)        0         ['activation_13[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_2 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_2[0][0]',     
 )                                                                   'activation_3[0][0]']        
                                                                                                  
 conv2d_14 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_2[0][0]']       
                                                                                                  
 batch_normalization_14 (Ba  (None, 128, 128, 128)        512       ['conv2d_14[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_14 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_14[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_15 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_14[0][0]']       
                                                                                                  
 batch_normalization_15 (Ba  (None, 128, 128, 128)        512       ['conv2d_15[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_15 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_15[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 256, 256, 128)        0         ['activation_15[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_3 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_3[0][0]',     
 )                                                                   'activation_1[0][0]']        
                                                                                                  
 conv2d_16 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_3[0][0]']       
                                                                                                  
 batch_normalization_16 (Ba  (None, 256, 256, 64)         256       ['conv2d_16[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_16 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_16[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_16[0][0]']       
                                                                                                  
 batch_normalization_17 (Ba  (None, 256, 256, 64)         256       ['conv2d_17[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_17 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_17[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_18 (Conv2D)          (None, 256, 256, 1)          65        ['activation_17[0][0]']       
                                                                                                  
 batch_normalization_18 (Ba  (None, 256, 256, 1)          4         ['conv2d_18[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_18 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_18[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31401349 (119.79 MB)
Trainable params: 31389571 (119.74 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
None
âœ“ focal_loss imported successfully
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_2 (InputLayer)        [(None, 256, 256, 3)]        0         []                            
                                                                                                  
 conv2d_19 (Conv2D)          (None, 256, 256, 64)         1792      ['input_2[0][0]']             
                                                                                                  
 batch_normalization_19 (Ba  (None, 256, 256, 64)         256       ['conv2d_19[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_19 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_19[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_20 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_19[0][0]']       
                                                                                                  
 batch_normalization_20 (Ba  (None, 256, 256, 64)         256       ['conv2d_20[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_20 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_20[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_4 (MaxPoolin  (None, 128, 128, 64)         0         ['activation_20[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_21 (Conv2D)          (None, 128, 128, 128)        73856     ['max_pooling2d_4[0][0]']     
                                                                                                  
 batch_normalization_21 (Ba  (None, 128, 128, 128)        512       ['conv2d_21[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_21 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_21[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_22 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_21[0][0]']       
                                                                                                  
 batch_normalization_22 (Ba  (None, 128, 128, 128)        512       ['conv2d_22[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_22 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_22[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_5 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_22[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_23 (Conv2D)          (None, 64, 64, 256)          295168    ['max_pooling2d_5[0][0]']     
                                                                                                  
 batch_normalization_23 (Ba  (None, 64, 64, 256)          1024      ['conv2d_23[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_23 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_23[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_24 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_23[0][0]']       
                                                                                                  
 batch_normalization_24 (Ba  (None, 64, 64, 256)          1024      ['conv2d_24[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_24 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_24[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_6 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_24[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_25 (Conv2D)          (None, 32, 32, 512)          1180160   ['max_pooling2d_6[0][0]']     
                                                                                                  
 batch_normalization_25 (Ba  (None, 32, 32, 512)          2048      ['conv2d_25[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_25 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_25[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_26 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_25[0][0]']       
                                                                                                  
 batch_normalization_26 (Ba  (None, 32, 32, 512)          2048      ['conv2d_26[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_26 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_26[0][0]
                                                                    ']                            
                                                                                                  
 max_pooling2d_7 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_26[0][0]']       
 g2D)                                                                                             
                                                                                                  
 conv2d_27 (Conv2D)          (None, 16, 16, 1024)         4719616   ['max_pooling2d_7[0][0]']     
                                                                                                  
 batch_normalization_27 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_27[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_27 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_27[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_28 (Conv2D)          (None, 16, 16, 1024)         9438208   ['activation_27[0][0]']       
                                                                                                  
 batch_normalization_28 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_28[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_28 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_28[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 1024)         0         ['activation_28[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_4 (Concatenate  (None, 32, 32, 1536)         0         ['up_sampling2d_4[0][0]',     
 )                                                                   'activation_26[0][0]']       
                                                                                                  
 conv2d_29 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate_4[0][0]']       
                                                                                                  
 batch_normalization_29 (Ba  (None, 32, 32, 512)          2048      ['conv2d_29[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_29 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_29[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_30 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_29[0][0]']       
                                                                                                  
 batch_normalization_30 (Ba  (None, 32, 32, 512)          2048      ['conv2d_30[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_30 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_30[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 512)          0         ['activation_30[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_5 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_5[0][0]',     
 )                                                                   'activation_24[0][0]']       
                                                                                                  
 conv2d_31 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_5[0][0]']       
                                                                                                  
 batch_normalization_31 (Ba  (None, 64, 64, 256)          1024      ['conv2d_31[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_31 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_31[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_32 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_31[0][0]']       
                                                                                                  
 batch_normalization_32 (Ba  (None, 64, 64, 256)          1024      ['conv2d_32[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_32 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_32[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_6 (UpSamplin  (None, 128, 128, 256)        0         ['activation_32[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_6 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_6[0][0]',     
 )                                                                   'activation_22[0][0]']       
                                                                                                  
 conv2d_33 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_6[0][0]']       
                                                                                                  
 batch_normalization_33 (Ba  (None, 128, 128, 128)        512       ['conv2d_33[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_33 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_33[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_34 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_33[0][0]']       
                                                                                                  
 batch_normalization_34 (Ba  (None, 128, 128, 128)        512       ['conv2d_34[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_34 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_34[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_7 (UpSamplin  (None, 256, 256, 128)        0         ['activation_34[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_7 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_7[0][0]',     
 )                                                                   'activation_20[0][0]']       
                                                                                                  
 conv2d_35 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_7[0][0]']       
                                                                                                  
 batch_normalization_35 (Ba  (None, 256, 256, 64)         256       ['conv2d_35[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_35 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_35[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_36 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_35[0][0]']       
                                                                                                  
 batch_normalization_36 (Ba  (None, 256, 256, 64)         256       ['conv2d_36[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_36 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_36[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_37 (Conv2D)          (None, 256, 256, 1)          65        ['activation_36[0][0]']       
                                                                                                  
 batch_normalization_37 (Ba  (None, 256, 256, 1)          4         ['conv2d_37[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_37 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_37[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31402501 (119.79 MB)
Trainable params: 31390723 (119.75 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
WARNING:absl:`lr` is deprecated in TF-Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
None
Epoch 1/30
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1758862629.174457 3209327 service.cc:145] XLA service 0x151ee2560260 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1758862629.174496 3209327 service.cc:153]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6
I0000 00:00:1758862629.561641 3209327 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
1/5 [=====>........................] - ETA: 3:29 - loss: 0.3499 - accuracy: 0.5219 - jacard_coef: 0.06392/5 [===========>..................] - ETA: 37s - loss: 0.3380 - accuracy: 0.4884 - jacard_coef: 0.0685 3/5 [=================>............] - ETA: 15s - loss: 0.3058 - accuracy: 0.4450 - jacard_coef: 0.07284/5 [=======================>......] - ETA: 5s - loss: 0.2860 - accuracy: 0.4246 - jacard_coef: 0.0757 5/5 [==============================] - ETA: 0s - loss: 0.2858 - accuracy: 0.4224 - jacard_coef: 0.06425/5 [==============================] - 77s 6s/step - loss: 0.2858 - accuracy: 0.4224 - jacard_coef: 0.0642 - val_loss: 0.4826 - val_accuracy: 0.9304 - val_jacard_coef: 0.0227 - lr: 0.0010
Epoch 2/30
1/5 [=====>........................] - ETA: 1s - loss: 0.2142 - accuracy: 0.2111 - jacard_coef: 0.06992/5 [===========>..................] - ETA: 1s - loss: 0.2022 - accuracy: 0.2743 - jacard_coef: 0.07223/5 [=================>............] - ETA: 0s - loss: 0.2010 - accuracy: 0.2824 - jacard_coef: 0.07294/5 [=======================>......] - ETA: 0s - loss: 0.1981 - accuracy: 0.2953 - jacard_coef: 0.07675/5 [==============================] - ETA: 0s - loss: 0.1982 - accuracy: 0.2943 - jacard_coef: 0.06975/5 [==============================] - 2s 434ms/step - loss: 0.1982 - accuracy: 0.2943 - jacard_coef: 0.0697 - val_loss: 1.1217 - val_accuracy: 0.9304 - val_jacard_coef: 1.4652e-05 - lr: 0.0010
Epoch 3/30
1/5 [=====>........................] - ETA: 1s - loss: 0.2077 - accuracy: 0.3211 - jacard_coef: 0.07282/5 [===========>..................] - ETA: 1s - loss: 0.2023 - accuracy: 0.3238 - jacard_coef: 0.08083/5 [=================>............] - ETA: 0s - loss: 0.2007 - accuracy: 0.2855 - jacard_coef: 0.07404/5 [=======================>......] - ETA: 0s - loss: 0.1981 - accuracy: 0.2652 - jacard_coef: 0.07685/5 [==============================] - 2s 396ms/step - loss: 0.1981 - accuracy: 0.2641 - jacard_coef: 0.0737 - val_loss: 1.1218 - val_accuracy: 0.9304 - val_jacard_coef: 1.4615e-05 - lr: 0.0010
Epoch 4/30
1/5 [=====>........................] - ETA: 1s - loss: 0.1922 - accuracy: 0.2058 - jacard_coef: 0.06972/5 [===========>..................] - ETA: 1s - loss: 0.1899 - accuracy: 0.2484 - jacard_coef: 0.07623/5 [=================>............] - ETA: 0s - loss: 0.1923 - accuracy: 0.2505 - jacard_coef: 0.07494/5 [=======================>......] - ETA: 0s - loss: 0.1912 - accuracy: 0.2622 - jacard_coef: 0.07685/5 [==============================] - 2s 397ms/step - loss: 0.1912 - accuracy: 0.2613 - jacard_coef: 0.0724 - val_loss: 1.1218 - val_accuracy: 0.9304 - val_jacard_coef: 1.4615e-05 - lr: 0.0010
Epoch 5/30
1/5 [=====>........................] - ETA: 1s - loss: 0.1840 - accuracy: 0.3392 - jacard_coef: 0.09232/5 [===========>..................] - ETA: 1s - loss: 0.1833 - accuracy: 0.3336 - jacard_coef: 0.08313/5 [=================>............] - ETA: 0s - loss: 0.1853 - accuracy: 0.3358 - jacard_coef: 0.08014/5 [=======================>......] - ETA: 0s - loss: 0.1838 - accuracy: 0.3444 - jacard_coef: 0.07675/5 [==============================] - 2s 400ms/step - loss: 0.1841 - accuracy: 0.3443 - jacard_coef: 0.0666 - val_loss: 1.1111 - val_accuracy: 0.9304 - val_jacard_coef: 7.6163e-05 - lr: 0.0010
Epoch 6/30
1/5 [=====>........................] - ETA: 1s - loss: 0.1804 - accuracy: 0.3989 - jacard_coef: 0.07182/5 [===========>..................] - ETA: 1s - loss: 0.1853 - accuracy: 0.3952 - jacard_coef: 0.07643/5 [=================>............] - ETA: 0s - loss: 0.1845 - accuracy: 0.3863 - jacard_coef: 0.08074/5 [=======================>......] - ETA: 0s - loss: 0.1847 - accuracy: 0.3640 - jacard_coef: 0.07695/5 [==============================] - 2s 396ms/step - loss: 0.1848 - accuracy: 0.3618 - jacard_coef: 0.0634 - val_loss: 0.9801 - val_accuracy: 0.9304 - val_jacard_coef: 0.0038 - lr: 0.0010
Epoch 7/30
1/5 [=====>........................] - ETA: 1s - loss: 0.1832 - accuracy: 0.3048 - jacard_coef: 0.08082/5 [===========>..................] - ETA: 1s - loss: 0.1853 - accuracy: 0.3030 - jacard_coef: 0.07643/5 [=================>............] - ETA: 0s - loss: 0.1839 - accuracy: 0.3089 - jacard_coef: 0.08004/5 [=======================>......] - ETA: 0s - loss: 0.1854 - accuracy: 0.3060 - jacard_coef: 0.07675/5 [==============================] - 2s 396ms/step - loss: 0.1855 - accuracy: 0.3045 - jacard_coef: 0.0730 - val_loss: 0.3799 - val_accuracy: 0.9304 - val_jacard_coef: 0.0213 - lr: 5.0000e-04
Epoch 8/30
1/5 [=====>........................] - ETA: 1s - loss: 0.1813 - accuracy: 0.3136 - jacard_coef: 0.07312/5 [===========>..................] - ETA: 1s - loss: 0.1845 - accuracy: 0.3234 - jacard_coef: 0.07723/5 [=================>............] - ETA: 0s - loss: 0.1833 - accuracy: 0.3191 - jacard_coef: 0.07614/5 [=======================>......] - ETA: 0s - loss: 0.1827 - accuracy: 0.3221 - jacard_coef: 0.07675/5 [==============================] - 2s 415ms/step - loss: 0.1827 - accuracy: 0.3210 - jacard_coef: 0.0721 - val_loss: 0.2034 - val_accuracy: 0.9303 - val_jacard_coef: 0.0392 - lr: 5.0000e-04
Epoch 9/30
1/5 [=====>........................] - ETA: 1s - loss: 0.1787 - accuracy: 0.3316 - jacard_coef: 0.07072/5 [===========>..................] - ETA: 1s - loss: 0.1780 - accuracy: 0.3453 - jacard_coef: 0.07423/5 [=================>............] - ETA: 0s - loss: 0.1801 - accuracy: 0.3529 - jacard_coef: 0.07514/5 [=======================>......] - ETA: 0s - loss: 0.1794 - accuracy: 0.3546 - jacard_coef: 0.07605/5 [==============================] - 2s 413ms/step - loss: 0.1795 - accuracy: 0.3536 - jacard_coef: 0.0880 - val_loss: 0.1152 - val_accuracy: 0.9270 - val_jacard_coef: 0.0621 - lr: 5.0000e-04
Epoch 10/30
1/5 [=====>........................] - ETA: 1s - loss: 0.1759 - accuracy: 0.4201 - jacard_coef: 0.07772/5 [===========>..................] - ETA: 1s - loss: 0.1754 - accuracy: 0.4437 - jacard_coef: 0.07513/5 [=================>............] - ETA: 0s - loss: 0.1752 - accuracy: 0.4527 - jacard_coef: 0.07864/5 [=======================>......] - ETA: 0s - loss: 0.1766 - accuracy: 0.4487 - jacard_coef: 0.07675/5 [==============================] - 2s 409ms/step - loss: 0.1767 - accuracy: 0.4467 - jacard_coef: 0.0672 - val_loss: 0.1001 - val_accuracy: 0.8346 - val_jacard_coef: 0.0667 - lr: 5.0000e-04
Epoch 11/30
1/5 [=====>........................] - ETA: 1s - loss: 0.1754 - accuracy: 0.5100 - jacard_coef: 0.08312/5 [===========>..................] - ETA: 1s - loss: 0.1744 - accuracy: 0.5459 - jacard_coef: 0.07233/5 [=================>............] - ETA: 0s - loss: 0.1756 - accuracy: 0.5489 - jacard_coef: 0.07394/5 [=======================>......] - ETA: 0s - loss: 0.1748 - accuracy: 0.5362 - jacard_coef: 0.07675/5 [==============================] - 2s 396ms/step - loss: 0.1749 - accuracy: 0.5342 - jacard_coef: 0.0618 - val_loss: 0.1424 - val_accuracy: 0.6584 - val_jacard_coef: 0.0648 - lr: 5.0000e-04
Epoch 12/30
1/5 [=====>........................] - ETA: 1s - loss: 0.1717 - accuracy: 0.5419 - jacard_coef: 0.08822/5 [===========>..................] - ETA: 1s - loss: 0.1719 - accuracy: 0.5771 - jacard_coef: 0.08193/5 [=================>............] - ETA: 0s - loss: 0.1734 - accuracy: 0.5999 - jacard_coef: 0.07864/5 [=======================>......] - ETA: 0s - loss: 0.1726 - accuracy: 0.6163 - jacard_coef: 0.07665/5 [==============================] - 2s 398ms/step - loss: 0.1727 - accuracy: 0.6137 - jacard_coef: 0.0684 - val_loss: 0.1615 - val_accuracy: 0.6271 - val_jacard_coef: 0.0652 - lr: 5.0000e-04
Epoch 13/30
1/5 [=====>........................] - ETA: 1s - loss: 0.1698 - accuracy: 0.6506 - jacard_coef: 0.07782/5 [===========>..................] - ETA: 1s - loss: 0.1717 - accuracy: 0.6193 - jacard_coef: 0.07783/5 [=================>............] - ETA: 0s - loss: 0.1705 - accuracy: 0.6067 - jacard_coef: 0.07934/5 [=======================>......] - ETA: 0s - loss: 0.1701 - accuracy: 0.5965 - jacard_coef: 0.07555/5 [==============================] - 2s 397ms/step - loss: 0.1702 - accuracy: 0.5947 - jacard_coef: 0.0932 - val_loss: 0.1660 - val_accuracy: 0.6445 - val_jacard_coef: 0.0654 - lr: 5.0000e-04
Epoch 14/30
1/5 [=====>........................] - ETA: 1s - loss: 0.1706 - accuracy: 0.7205 - jacard_coef: 0.07192/5 [===========>..................] - ETA: 1s - loss: 0.1697 - accuracy: 0.6910 - jacard_coef: 0.07033/5 [=================>............] - ETA: 0s - loss: 0.1697 - accuracy: 0.6766 - jacard_coef: 0.07304/5 [=======================>......] - ETA: 0s - loss: 0.1696 - accuracy: 0.6659 - jacard_coef: 0.07665/5 [==============================] - 2s 399ms/step - loss: 0.1697 - accuracy: 0.6649 - jacard_coef: 0.0625 - val_loss: 0.1618 - val_accuracy: 0.7204 - val_jacard_coef: 0.0653 - lr: 5.0000e-04
Epoch 15/30
1/5 [=====>........................] - ETA: 1s - loss: 0.1673 - accuracy: 0.6303 - jacard_coef: 0.08572/5 [===========>..................] - ETA: 1s - loss: 0.1663 - accuracy: 0.6571 - jacard_coef: 0.07723/5 [=================>............] - ETA: 0s - loss: 0.1669 - accuracy: 0.6496 - jacard_coef: 0.07644/5 [=======================>......] - ETA: 0s - loss: 0.1677 - accuracy: 0.6469 - jacard_coef: 0.07555/5 [==============================] - 2s 396ms/step - loss: 0.1677 - accuracy: 0.6453 - jacard_coef: 0.0899 - val_loss: 0.1503 - val_accuracy: 0.8691 - val_jacard_coef: 0.0648 - lr: 5.0000e-04
Epoch 16/30
1/5 [=====>........................] - ETA: 1s - loss: 0.1681 - accuracy: 0.7098 - jacard_coef: 0.08022/5 [===========>..................] - ETA: 1s - loss: 0.1672 - accuracy: 0.7214 - jacard_coef: 0.07433/5 [=================>............] - ETA: 0s - loss: 0.1665 - accuracy: 0.7350 - jacard_coef: 0.07564/5 [=======================>......] - ETA: 0s - loss: 0.1661 - accuracy: 0.7426 - jacard_coef: 0.07575/5 [==============================] - 2s 397ms/step - loss: 0.1665 - accuracy: 0.7400 - jacard_coef: 0.0879 - val_loss: 0.1574 - val_accuracy: 0.8135 - val_jacard_coef: 0.0644 - lr: 2.5000e-04
Epoch 17/30
1/5 [=====>........................] - ETA: 1s - loss: 0.1650 - accuracy: 0.7498 - jacard_coef: 0.08322/5 [===========>..................] - ETA: 1s - loss: 0.1656 - accuracy: 0.7011 - jacard_coef: 0.07543/5 [=================>............] - ETA: 0s - loss: 0.1660 - accuracy: 0.6614 - jacard_coef: 0.07744/5 [=======================>......] - ETA: 0s - loss: 0.1667 - accuracy: 0.6426 - jacard_coef: 0.07625/5 [==============================] - 2s 400ms/step - loss: 0.1667 - accuracy: 0.6415 - jacard_coef: 0.0736 - val_loss: 0.0863 - val_accuracy: 0.9148 - val_jacard_coef: 0.0636 - lr: 2.5000e-04
Epoch 18/30
1/5 [=====>........................] - ETA: 1s - loss: 0.1702 - accuracy: 0.5818 - jacard_coef: 0.09482/5 [===========>..................] - ETA: 1s - loss: 0.1712 - accuracy: 0.5728 - jacard_coef: 0.08293/5 [=================>............] - ETA: 0s - loss: 0.1697 - accuracy: 0.5917 - jacard_coef: 0.07814/5 [=======================>......] - ETA: 0s - loss: 0.1691 - accuracy: 0.6048 - jacard_coef: 0.07665/5 [==============================] - 2s 397ms/step - loss: 0.1691 - accuracy: 0.6034 - jacard_coef: 0.0618 - val_loss: 0.0780 - val_accuracy: 0.9215 - val_jacard_coef: 0.0601 - lr: 2.5000e-04
Epoch 19/30
1/5 [=====>........................] - ETA: 1s - loss: 0.1668 - accuracy: 0.6856 - jacard_coef: 0.07682/5 [===========>..................] - ETA: 1s - loss: 0.1673 - accuracy: 0.7132 - jacard_coef: 0.06993/5 [=================>............] - ETA: 0s - loss: 0.1672 - accuracy: 0.7106 - jacard_coef: 0.07134/5 [=======================>......] - ETA: 0s - loss: 0.1676 - accuracy: 0.6952 - jacard_coef: 0.07665/5 [==============================] - 2s 399ms/step - loss: 0.1676 - accuracy: 0.6932 - jacard_coef: 0.0625 - val_loss: 0.0778 - val_accuracy: 0.9199 - val_jacard_coef: 0.0608 - lr: 2.5000e-04
Epoch 20/30
1/5 [=====>........................] - ETA: 1s - loss: 0.1672 - accuracy: 0.7960 - jacard_coef: 0.07122/5 [===========>..................] - ETA: 1s - loss: 0.1659 - accuracy: 0.8065 - jacard_coef: 0.07723/5 [=================>............] - ETA: 0s - loss: 0.1655 - accuracy: 0.8109 - jacard_coef: 0.07574/5 [=======================>......] - ETA: 0s - loss: 0.1654 - accuracy: 0.8081 - jacard_coef: 0.07645/5 [==============================] - 2s 399ms/step - loss: 0.1655 - accuracy: 0.8065 - jacard_coef: 0.0671 - val_loss: 0.0851 - val_accuracy: 0.9173 - val_jacard_coef: 0.0630 - lr: 2.5000e-04
/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(

âœ“ Training completed successfully!
  Best Val Jaccard: 0.0667 (epoch 10)
  Final Val Loss: 0.0851
  Training Time: 0:01:57.431445
  Stability (std): 0.0372

Results saved to: hyperparameter_optimization_20250926_123742/exp_9_UNet_lr1e-3_bs32/UNet_lr0.001_bs32_results.json
