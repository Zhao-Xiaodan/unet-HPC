✓ GPU memory growth enabled for 1 GPUs
Loading dataset...
Loaded 144 images and 144 masks
Training set: (129, 256, 256, 3), Validation set: (15, 256, 256, 3)

============================================================
TRAINING: Attention_ResUNet
Learning Rate: 0.0005, Batch Size: 16, Epochs: 30
============================================================
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 256, 256, 64)         640       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 256, 256, 64)         256       ['conv2d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 activation (Activation)     (None, 256, 256, 64)         0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['activation[0][0]']          
                                                                                                  
 batch_normalization_1 (Bat  (None, 256, 256, 64)         256       ['conv2d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_1 (Activation)   (None, 256, 256, 64)         0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['activation_1[0][0]']        
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       
                                                                                                  
 batch_normalization_2 (Bat  (None, 128, 128, 128)        512       ['conv2d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_2 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_3 (Conv2D)           (None, 128, 128, 128)        147584    ['activation_2[0][0]']        
                                                                                                  
 batch_normalization_3 (Bat  (None, 128, 128, 128)        512       ['conv2d_3[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_3 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_3[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_3[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 batch_normalization_4 (Bat  (None, 64, 64, 256)          1024      ['conv2d_4[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_4 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_4[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_5 (Conv2D)           (None, 64, 64, 256)          590080    ['activation_4[0][0]']        
                                                                                                  
 batch_normalization_5 (Bat  (None, 64, 64, 256)          1024      ['conv2d_5[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_5 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_5[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_5[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 512)          1180160   ['max_pooling2d_2[0][0]']     
                                                                                                  
 batch_normalization_6 (Bat  (None, 32, 32, 512)          2048      ['conv2d_6[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_6 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_6[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 32, 32, 512)          2359808   ['activation_6[0][0]']        
                                                                                                  
 batch_normalization_7 (Bat  (None, 32, 32, 512)          2048      ['conv2d_7[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_7 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_7[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_3 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_7[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 1024)         4719616   ['max_pooling2d_3[0][0]']     
                                                                                                  
 batch_normalization_8 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_8[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_8 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_8[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 1024)         9438208   ['activation_8[0][0]']        
                                                                                                  
 batch_normalization_9 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_9[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_9 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_9[0][0]'
                                                                    ]                             
                                                                                                  
 up_sampling2d (UpSampling2  (None, 32, 32, 1024)         0         ['activation_9[0][0]']        
 D)                                                                                               
                                                                                                  
 concatenate (Concatenate)   (None, 32, 32, 1536)         0         ['up_sampling2d[0][0]',       
                                                                     'activation_7[0][0]']        
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate[0][0]']         
                                                                                                  
 batch_normalization_10 (Ba  (None, 32, 32, 512)          2048      ['conv2d_10[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_10 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_10[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_10[0][0]']       
                                                                                                  
 batch_normalization_11 (Ba  (None, 32, 32, 512)          2048      ['conv2d_11[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_11 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_11[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 64, 64, 512)          0         ['activation_11[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_1 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_1[0][0]',     
 )                                                                   'activation_5[0][0]']        
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_1[0][0]']       
                                                                                                  
 batch_normalization_12 (Ba  (None, 64, 64, 256)          1024      ['conv2d_12[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_12 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_12[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_13 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_12[0][0]']       
                                                                                                  
 batch_normalization_13 (Ba  (None, 64, 64, 256)          1024      ['conv2d_13[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_13 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_13[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 128, 128, 256)        0         ['activation_13[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_2 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_2[0][0]',     
 )                                                                   'activation_3[0][0]']        
                                                                                                  
 conv2d_14 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_2[0][0]']       
                                                                                                  
 batch_normalization_14 (Ba  (None, 128, 128, 128)        512       ['conv2d_14[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_14 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_14[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_15 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_14[0][0]']       
                                                                                                  
 batch_normalization_15 (Ba  (None, 128, 128, 128)        512       ['conv2d_15[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_15 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_15[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 256, 256, 128)        0         ['activation_15[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_3 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_3[0][0]',     
 )                                                                   'activation_1[0][0]']        
                                                                                                  
 conv2d_16 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_3[0][0]']       
                                                                                                  
 batch_normalization_16 (Ba  (None, 256, 256, 64)         256       ['conv2d_16[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_16 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_16[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_16[0][0]']       
                                                                                                  
 batch_normalization_17 (Ba  (None, 256, 256, 64)         256       ['conv2d_17[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_17 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_17[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_18 (Conv2D)          (None, 256, 256, 1)          65        ['activation_17[0][0]']       
                                                                                                  
 batch_normalization_18 (Ba  (None, 256, 256, 1)          4         ['conv2d_18[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_18 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_18[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31401349 (119.79 MB)
Trainable params: 31389571 (119.74 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
WARNING:absl:`lr` is deprecated in TF-Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
None
✓ focal_loss imported successfully
Epoch 1/30
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1758865869.377522 3333943 service.cc:145] XLA service 0x154025e0be50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1758865869.377576 3333943 service.cc:153]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6
I0000 00:00:1758865869.834734 3333943 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
1/9 [==>...........................] - ETA: 9:11 - loss: 0.3435 - accuracy: 0.5120 - jacard_coef: 0.08882/9 [=====>........................] - ETA: 58s - loss: 0.3186 - accuracy: 0.4760 - jacard_coef: 0.0773 3/9 [=========>....................] - ETA: 26s - loss: 0.2922 - accuracy: 0.5121 - jacard_coef: 0.07654/9 [============>.................] - ETA: 15s - loss: 0.2733 - accuracy: 0.5416 - jacard_coef: 0.07585/9 [===============>..............] - ETA: 9s - loss: 0.2582 - accuracy: 0.5551 - jacard_coef: 0.0792 6/9 [===================>..........] - ETA: 5s - loss: 0.2556 - accuracy: 0.5611 - jacard_coef: 0.07857/9 [======================>.......] - ETA: 3s - loss: 0.2476 - accuracy: 0.5880 - jacard_coef: 0.07398/9 [=========================>....] - ETA: 1s - loss: 0.2407 - accuracy: 0.6070 - jacard_coef: 0.07569/9 [==============================] - ETA: 0s - loss: 0.2404 - accuracy: 0.6076 - jacard_coef: 0.08209/9 [==============================] - 89s 3s/step - loss: 0.2404 - accuracy: 0.6076 - jacard_coef: 0.0820 - val_loss: 14.3699 - val_accuracy: 0.0981 - val_jacard_coef: 0.0693 - lr: 0.0010
Epoch 2/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1844 - accuracy: 0.5873 - jacard_coef: 0.09052/9 [=====>........................] - ETA: 2s - loss: 0.1815 - accuracy: 0.5636 - jacard_coef: 0.08493/9 [=========>....................] - ETA: 2s - loss: 0.1839 - accuracy: 0.5508 - jacard_coef: 0.07154/9 [============>.................] - ETA: 2s - loss: 0.1829 - accuracy: 0.5886 - jacard_coef: 0.06965/9 [===============>..............] - ETA: 1s - loss: 0.1824 - accuracy: 0.6196 - jacard_coef: 0.07076/9 [===================>..........] - ETA: 1s - loss: 0.1827 - accuracy: 0.6423 - jacard_coef: 0.07157/9 [======================>.......] - ETA: 0s - loss: 0.1831 - accuracy: 0.6603 - jacard_coef: 0.07428/9 [=========================>....] - ETA: 0s - loss: 0.1832 - accuracy: 0.6763 - jacard_coef: 0.07669/9 [==============================] - 4s 391ms/step - loss: 0.1831 - accuracy: 0.6773 - jacard_coef: 0.0688 - val_loss: 14.7803 - val_accuracy: 0.0829 - val_jacard_coef: 0.0695 - lr: 0.0010
Epoch 3/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1790 - accuracy: 0.8264 - jacard_coef: 0.05512/9 [=====>........................] - ETA: 2s - loss: 0.1785 - accuracy: 0.8286 - jacard_coef: 0.06933/9 [=========>....................] - ETA: 2s - loss: 0.1777 - accuracy: 0.8212 - jacard_coef: 0.07904/9 [============>.................] - ETA: 2s - loss: 0.1766 - accuracy: 0.8069 - jacard_coef: 0.07945/9 [===============>..............] - ETA: 1s - loss: 0.1759 - accuracy: 0.7928 - jacard_coef: 0.08076/9 [===================>..........] - ETA: 1s - loss: 0.1748 - accuracy: 0.7775 - jacard_coef: 0.07937/9 [======================>.......] - ETA: 0s - loss: 0.1742 - accuracy: 0.7688 - jacard_coef: 0.07598/9 [=========================>....] - ETA: 0s - loss: 0.1736 - accuracy: 0.7611 - jacard_coef: 0.07559/9 [==============================] - 4s 390ms/step - loss: 0.1736 - accuracy: 0.7611 - jacard_coef: 0.0809 - val_loss: 14.7684 - val_accuracy: 0.0831 - val_jacard_coef: 0.0695 - lr: 0.0010
Epoch 4/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1686 - accuracy: 0.6531 - jacard_coef: 0.09552/9 [=====>........................] - ETA: 2s - loss: 0.1679 - accuracy: 0.6555 - jacard_coef: 0.07373/9 [=========>....................] - ETA: 2s - loss: 0.1677 - accuracy: 0.6797 - jacard_coef: 0.06644/9 [============>.................] - ETA: 2s - loss: 0.1675 - accuracy: 0.6797 - jacard_coef: 0.07765/9 [===============>..............] - ETA: 1s - loss: 0.1673 - accuracy: 0.6935 - jacard_coef: 0.07536/9 [===================>..........] - ETA: 1s - loss: 0.1671 - accuracy: 0.7073 - jacard_coef: 0.07417/9 [======================>.......] - ETA: 0s - loss: 0.1669 - accuracy: 0.7163 - jacard_coef: 0.07578/9 [=========================>....] - ETA: 0s - loss: 0.1667 - accuracy: 0.7300 - jacard_coef: 0.07629/9 [==============================] - 3s 380ms/step - loss: 0.1667 - accuracy: 0.7309 - jacard_coef: 0.0722 - val_loss: 4.6661 - val_accuracy: 0.2743 - val_jacard_coef: 0.0656 - lr: 0.0010
Epoch 5/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1672 - accuracy: 0.7072 - jacard_coef: 0.10972/9 [=====>........................] - ETA: 2s - loss: 0.1661 - accuracy: 0.7146 - jacard_coef: 0.09013/9 [=========>....................] - ETA: 2s - loss: 0.1653 - accuracy: 0.7217 - jacard_coef: 0.08244/9 [============>.................] - ETA: 2s - loss: 0.1651 - accuracy: 0.7316 - jacard_coef: 0.08165/9 [===============>..............] - ETA: 1s - loss: 0.1647 - accuracy: 0.7330 - jacard_coef: 0.07806/9 [===================>..........] - ETA: 1s - loss: 0.1645 - accuracy: 0.7450 - jacard_coef: 0.07817/9 [======================>.......] - ETA: 0s - loss: 0.1643 - accuracy: 0.7496 - jacard_coef: 0.07928/9 [=========================>....] - ETA: 0s - loss: 0.1641 - accuracy: 0.7592 - jacard_coef: 0.07669/9 [==============================] - ETA: 0s - loss: 0.1641 - accuracy: 0.7606 - jacard_coef: 0.06849/9 [==============================] - 3s 384ms/step - loss: 0.1641 - accuracy: 0.7606 - jacard_coef: 0.0684 - val_loss: 0.5318 - val_accuracy: 0.4438 - val_jacard_coef: 0.0665 - lr: 0.0010
Epoch 6/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1626 - accuracy: 0.8537 - jacard_coef: 0.07862/9 [=====>........................] - ETA: 2s - loss: 0.1620 - accuracy: 0.8574 - jacard_coef: 0.07463/9 [=========>....................] - ETA: 2s - loss: 0.1618 - accuracy: 0.8503 - jacard_coef: 0.07554/9 [============>.................] - ETA: 2s - loss: 0.1618 - accuracy: 0.8516 - jacard_coef: 0.07995/9 [===============>..............] - ETA: 1s - loss: 0.1619 - accuracy: 0.8458 - jacard_coef: 0.08226/9 [===================>..........] - ETA: 1s - loss: 0.1615 - accuracy: 0.8464 - jacard_coef: 0.07707/9 [======================>.......] - ETA: 0s - loss: 0.1614 - accuracy: 0.8420 - jacard_coef: 0.07808/9 [=========================>....] - ETA: 0s - loss: 0.1612 - accuracy: 0.8448 - jacard_coef: 0.07559/9 [==============================] - ETA: 0s - loss: 0.1612 - accuracy: 0.8438 - jacard_coef: 0.08339/9 [==============================] - 4s 387ms/step - loss: 0.1612 - accuracy: 0.8438 - jacard_coef: 0.0833 - val_loss: 0.1178 - val_accuracy: 0.8873 - val_jacard_coef: 0.0635 - lr: 0.0010
Epoch 7/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1594 - accuracy: 0.8192 - jacard_coef: 0.08212/9 [=====>........................] - ETA: 2s - loss: 0.1603 - accuracy: 0.7964 - jacard_coef: 0.08323/9 [=========>....................] - ETA: 2s - loss: 0.1604 - accuracy: 0.7890 - jacard_coef: 0.08054/9 [============>.................] - ETA: 2s - loss: 0.1602 - accuracy: 0.7870 - jacard_coef: 0.07865/9 [===============>..............] - ETA: 1s - loss: 0.1602 - accuracy: 0.7826 - jacard_coef: 0.07666/9 [===================>..........] - ETA: 1s - loss: 0.1602 - accuracy: 0.7912 - jacard_coef: 0.07827/9 [======================>.......] - ETA: 0s - loss: 0.1602 - accuracy: 0.8033 - jacard_coef: 0.07808/9 [=========================>....] - ETA: 0s - loss: 0.1601 - accuracy: 0.8159 - jacard_coef: 0.07679/9 [==============================] - ETA: 0s - loss: 0.1607 - accuracy: 0.8148 - jacard_coef: 0.06859/9 [==============================] - 4s 388ms/step - loss: 0.1607 - accuracy: 0.8148 - jacard_coef: 0.0685 - val_loss: 0.1127 - val_accuracy: 0.9153 - val_jacard_coef: 0.0627 - lr: 0.0010
Epoch 8/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1603 - accuracy: 0.9460 - jacard_coef: 0.04212/9 [=====>........................] - ETA: 2s - loss: 0.1624 - accuracy: 0.9251 - jacard_coef: 0.05903/9 [=========>....................] - ETA: 2s - loss: 0.1632 - accuracy: 0.9129 - jacard_coef: 0.06574/9 [============>.................] - ETA: 2s - loss: 0.1648 - accuracy: 0.8958 - jacard_coef: 0.07465/9 [===============>..............] - ETA: 1s - loss: 0.1646 - accuracy: 0.8906 - jacard_coef: 0.07246/9 [===================>..........] - ETA: 1s - loss: 0.1648 - accuracy: 0.8843 - jacard_coef: 0.07207/9 [======================>.......] - ETA: 0s - loss: 0.1651 - accuracy: 0.8725 - jacard_coef: 0.07618/9 [=========================>....] - ETA: 0s - loss: 0.1651 - accuracy: 0.8687 - jacard_coef: 0.07619/9 [==============================] - ETA: 0s - loss: 0.1651 - accuracy: 0.8688 - jacard_coef: 0.06829/9 [==============================] - 4s 387ms/step - loss: 0.1651 - accuracy: 0.8688 - jacard_coef: 0.0682 - val_loss: 0.1874 - val_accuracy: 0.4148 - val_jacard_coef: 0.0649 - lr: 5.0000e-04
Epoch 9/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1652 - accuracy: 0.8480 - jacard_coef: 0.08392/9 [=====>........................] - ETA: 2s - loss: 0.1642 - accuracy: 0.8571 - jacard_coef: 0.08253/9 [=========>....................] - ETA: 2s - loss: 0.1635 - accuracy: 0.8669 - jacard_coef: 0.07974/9 [============>.................] - ETA: 2s - loss: 0.1627 - accuracy: 0.8721 - jacard_coef: 0.07735/9 [===============>..............] - ETA: 1s - loss: 0.1626 - accuracy: 0.8731 - jacard_coef: 0.08066/9 [===================>..........] - ETA: 1s - loss: 0.1624 - accuracy: 0.8796 - jacard_coef: 0.07827/9 [======================>.......] - ETA: 0s - loss: 0.1619 - accuracy: 0.8833 - jacard_coef: 0.07768/9 [=========================>....] - ETA: 0s - loss: 0.1617 - accuracy: 0.8875 - jacard_coef: 0.07629/9 [==============================] - ETA: 0s - loss: 0.1621 - accuracy: 0.8879 - jacard_coef: 0.06849/9 [==============================] - 4s 388ms/step - loss: 0.1621 - accuracy: 0.8879 - jacard_coef: 0.0684 - val_loss: 0.1457 - val_accuracy: 0.9120 - val_jacard_coef: 0.0640 - lr: 5.0000e-04
Epoch 10/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1588 - accuracy: 0.8972 - jacard_coef: 0.07792/9 [=====>........................] - ETA: 2s - loss: 0.1603 - accuracy: 0.8885 - jacard_coef: 0.08783/9 [=========>....................] - ETA: 2s - loss: 0.1605 - accuracy: 0.8942 - jacard_coef: 0.08194/9 [============>.................] - ETA: 2s - loss: 0.1605 - accuracy: 0.9037 - jacard_coef: 0.07475/9 [===============>..............] - ETA: 1s - loss: 0.1602 - accuracy: 0.9051 - jacard_coef: 0.07406/9 [===================>..........] - ETA: 1s - loss: 0.1603 - accuracy: 0.9043 - jacard_coef: 0.07537/9 [======================>.......] - ETA: 0s - loss: 0.1602 - accuracy: 0.9045 - jacard_coef: 0.07598/9 [=========================>....] - ETA: 0s - loss: 0.1599 - accuracy: 0.9048 - jacard_coef: 0.07599/9 [==============================] - ETA: 0s - loss: 0.1599 - accuracy: 0.9049 - jacard_coef: 0.07409/9 [==============================] - 4s 387ms/step - loss: 0.1599 - accuracy: 0.9049 - jacard_coef: 0.0740 - val_loss: 0.1423 - val_accuracy: 0.9232 - val_jacard_coef: 0.0641 - lr: 5.0000e-04
Epoch 11/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1598 - accuracy: 0.8712 - jacard_coef: 0.10332/9 [=====>........................] - ETA: 2s - loss: 0.1588 - accuracy: 0.8930 - jacard_coef: 0.08793/9 [=========>....................] - ETA: 2s - loss: 0.1580 - accuracy: 0.9065 - jacard_coef: 0.07734/9 [============>.................] - ETA: 2s - loss: 0.1579 - accuracy: 0.9053 - jacard_coef: 0.07915/9 [===============>..............] - ETA: 1s - loss: 0.1573 - accuracy: 0.9086 - jacard_coef: 0.07676/9 [===================>..........] - ETA: 1s - loss: 0.1567 - accuracy: 0.9141 - jacard_coef: 0.07197/9 [======================>.......] - ETA: 0s - loss: 0.1571 - accuracy: 0.9122 - jacard_coef: 0.07308/9 [=========================>....] - ETA: 0s - loss: 0.1571 - accuracy: 0.9110 - jacard_coef: 0.07469/9 [==============================] - ETA: 0s - loss: 0.1572 - accuracy: 0.9100 - jacard_coef: 0.08509/9 [==============================] - 4s 387ms/step - loss: 0.1572 - accuracy: 0.9100 - jacard_coef: 0.0850 - val_loss: 0.1558 - val_accuracy: 0.9247 - val_jacard_coef: 0.0641 - lr: 5.0000e-04
Epoch 12/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1575 - accuracy: 0.9143 - jacard_coef: 0.07712/9 [=====>........................] - ETA: 2s - loss: 0.1575 - accuracy: 0.9010 - jacard_coef: 0.08823/9 [=========>....................] - ETA: 2s - loss: 0.1569 - accuracy: 0.9070 - jacard_coef: 0.08344/9 [============>.................] - ETA: 2s - loss: 0.1565 - accuracy: 0.9118 - jacard_coef: 0.07945/9 [===============>..............] - ETA: 1s - loss: 0.1566 - accuracy: 0.9081 - jacard_coef: 0.08266/9 [===================>..........] - ETA: 1s - loss: 0.1563 - accuracy: 0.9105 - jacard_coef: 0.08057/9 [======================>.......] - ETA: 0s - loss: 0.1560 - accuracy: 0.9134 - jacard_coef: 0.07818/9 [=========================>....] - ETA: 0s - loss: 0.1557 - accuracy: 0.9157 - jacard_coef: 0.07619/9 [==============================] - ETA: 0s - loss: 0.1557 - accuracy: 0.9160 - jacard_coef: 0.07019/9 [==============================] - 4s 389ms/step - loss: 0.1557 - accuracy: 0.9160 - jacard_coef: 0.0701 - val_loss: 0.1572 - val_accuracy: 0.9220 - val_jacard_coef: 0.0643 - lr: 5.0000e-04
Epoch 13/30
1/9 [==>...........................] - ETA: 3s - loss: 0.1538 - accuracy: 0.9220 - jacard_coef: 0.06922/9 [=====>........................] - ETA: 2s - loss: 0.1547 - accuracy: 0.9058 - jacard_coef: 0.08233/9 [=========>....................] - ETA: 2s - loss: 0.1545 - accuracy: 0.9089 - jacard_coef: 0.07984/9 [============>.................] - ETA: 2s - loss: 0.1545 - accuracy: 0.9106 - jacard_coef: 0.07885/9 [===============>..............] - ETA: 1s - loss: 0.1543 - accuracy: 0.9134 - jacard_coef: 0.07676/9 [===================>..........] - ETA: 1s - loss: 0.1542 - accuracy: 0.9131 - jacard_coef: 0.07737/9 [======================>.......] - ETA: 0s - loss: 0.1541 - accuracy: 0.9132 - jacard_coef: 0.07738/9 [=========================>....] - ETA: 0s - loss: 0.1540 - accuracy: 0.9149 - jacard_coef: 0.07619/9 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 0.9153 - jacard_coef: 0.07179/9 [==============================] - 4s 388ms/step - loss: 0.1540 - accuracy: 0.9153 - jacard_coef: 0.0717 - val_loss: 0.1552 - val_accuracy: 0.9257 - val_jacard_coef: 0.0645 - lr: 2.5000e-04
/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(

✓ Training completed successfully!
  Best Val Jaccard: 0.0695 (epoch 3)
  Final Val Loss: 0.1552
  Training Time: 0:02:12.561912
  Stability (std): 1.3480

Results saved to: hyperparameter_optimization_20250926_123742/exp_29_Attention_ResUNet_lr5e-4_bs16/Attention_ResUNet_lr0.0005_bs16_results.json
