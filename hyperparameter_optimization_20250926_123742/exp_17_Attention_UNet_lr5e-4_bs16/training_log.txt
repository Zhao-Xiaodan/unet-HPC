âœ“ GPU memory growth enabled for 1 GPUs
Loading dataset...
Loaded 144 images and 144 masks
Training set: (129, 256, 256, 3), Validation set: (15, 256, 256, 3)

============================================================
TRAINING: Attention_UNet
Learning Rate: 0.0005, Batch Size: 16, Epochs: 30
============================================================
Model: "UNet"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 256, 256, 64)         640       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 256, 256, 64)         256       ['conv2d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 activation (Activation)     (None, 256, 256, 64)         0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['activation[0][0]']          
                                                                                                  
 batch_normalization_1 (Bat  (None, 256, 256, 64)         256       ['conv2d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_1 (Activation)   (None, 256, 256, 64)         0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['activation_1[0][0]']        
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       
                                                                                                  
 batch_normalization_2 (Bat  (None, 128, 128, 128)        512       ['conv2d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_2 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_3 (Conv2D)           (None, 128, 128, 128)        147584    ['activation_2[0][0]']        
                                                                                                  
 batch_normalization_3 (Bat  (None, 128, 128, 128)        512       ['conv2d_3[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_3 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_3[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_3[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 batch_normalization_4 (Bat  (None, 64, 64, 256)          1024      ['conv2d_4[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_4 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_4[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_5 (Conv2D)           (None, 64, 64, 256)          590080    ['activation_4[0][0]']        
                                                                                                  
 batch_normalization_5 (Bat  (None, 64, 64, 256)          1024      ['conv2d_5[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_5 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_5[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_5[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 512)          1180160   ['max_pooling2d_2[0][0]']     
                                                                                                  
 batch_normalization_6 (Bat  (None, 32, 32, 512)          2048      ['conv2d_6[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_6 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_6[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 32, 32, 512)          2359808   ['activation_6[0][0]']        
                                                                                                  
 batch_normalization_7 (Bat  (None, 32, 32, 512)          2048      ['conv2d_7[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_7 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_7[0][0]'
                                                                    ]                             
                                                                                                  
 max_pooling2d_3 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_7[0][0]']        
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 1024)         4719616   ['max_pooling2d_3[0][0]']     
                                                                                                  
 batch_normalization_8 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_8[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_8 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_8[0][0]'
                                                                    ]                             
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 1024)         9438208   ['activation_8[0][0]']        
                                                                                                  
 batch_normalization_9 (Bat  (None, 16, 16, 1024)         4096      ['conv2d_9[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 activation_9 (Activation)   (None, 16, 16, 1024)         0         ['batch_normalization_9[0][0]'
                                                                    ]                             
                                                                                                  
 up_sampling2d (UpSampling2  (None, 32, 32, 1024)         0         ['activation_9[0][0]']        
 D)                                                                                               
                                                                                                  
 concatenate (Concatenate)   (None, 32, 32, 1536)         0         ['up_sampling2d[0][0]',       
                                                                     'activation_7[0][0]']        
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 512)          7078400   ['concatenate[0][0]']         
                                                                                                  
 batch_normalization_10 (Ba  (None, 32, 32, 512)          2048      ['conv2d_10[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_10 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_10[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_10[0][0]']       
                                                                                                  
 batch_normalization_11 (Ba  (None, 32, 32, 512)          2048      ['conv2d_11[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_11 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_11[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 64, 64, 512)          0         ['activation_11[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_1 (Concatenate  (None, 64, 64, 768)          0         ['up_sampling2d_1[0][0]',     
 )                                                                   'activation_5[0][0]']        
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate_1[0][0]']       
                                                                                                  
 batch_normalization_12 (Ba  (None, 64, 64, 256)          1024      ['conv2d_12[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_12 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_12[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_13 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_12[0][0]']       
                                                                                                  
 batch_normalization_13 (Ba  (None, 64, 64, 256)          1024      ['conv2d_13[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_13 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_13[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 128, 128, 256)        0         ['activation_13[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_2 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_2[0][0]',     
 )                                                                   'activation_3[0][0]']        
                                                                                                  
 conv2d_14 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_2[0][0]']       
                                                                                                  
 batch_normalization_14 (Ba  (None, 128, 128, 128)        512       ['conv2d_14[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_14 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_14[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_15 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_14[0][0]']       
                                                                                                  
 batch_normalization_15 (Ba  (None, 128, 128, 128)        512       ['conv2d_15[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_15 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_15[0][0]
                                                                    ']                            
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 256, 256, 128)        0         ['activation_15[0][0]']       
 g2D)                                                                                             
                                                                                                  
 concatenate_3 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_3[0][0]',     
 )                                                                   'activation_1[0][0]']        
                                                                                                  
 conv2d_16 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_3[0][0]']       
                                                                                                  
 batch_normalization_16 (Ba  (None, 256, 256, 64)         256       ['conv2d_16[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_16 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_16[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_16[0][0]']       
                                                                                                  
 batch_normalization_17 (Ba  (None, 256, 256, 64)         256       ['conv2d_17[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_17 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_17[0][0]
                                                                    ']                            
                                                                                                  
 conv2d_18 (Conv2D)          (None, 256, 256, 1)          65        ['activation_17[0][0]']       
                                                                                                  
 batch_normalization_18 (Ba  (None, 256, 256, 1)          4         ['conv2d_18[0][0]']           
 tchNormalization)                                                                                
                                                                                                  
 activation_18 (Activation)  (None, 256, 256, 1)          0         ['batch_normalization_18[0][0]
                                                                    ']                            
                                                                                                  
==================================================================================================
Total params: 31401349 (119.79 MB)
Trainable params: 31389571 (119.74 MB)
Non-trainable params: 11778 (46.01 KB)
__________________________________________________________________________________________________
WARNING:absl:`lr` is deprecated in TF-Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
None
âœ“ focal_loss imported successfully
Epoch 1/30
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1758863839.695421 3251268 service.cc:145] XLA service 0x152d21d8f870 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1758863839.695458 3251268 service.cc:153]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6
I0000 00:00:1758863840.157135 3251268 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
1/9 [==>...........................] - ETA: 8:00 - loss: 0.3436 - accuracy: 0.5018 - jacard_coef: 0.09912/9 [=====>........................] - ETA: 59s - loss: 0.3104 - accuracy: 0.4313 - jacard_coef: 0.0943 3/9 [=========>....................] - ETA: 26s - loss: 0.2871 - accuracy: 0.3474 - jacard_coef: 0.08214/9 [============>.................] - ETA: 15s - loss: 0.2707 - accuracy: 0.3204 - jacard_coef: 0.08135/9 [===============>..............] - ETA: 9s - loss: 0.2593 - accuracy: 0.3039 - jacard_coef: 0.0797 6/9 [===================>..........] - ETA: 5s - loss: 0.2494 - accuracy: 0.2992 - jacard_coef: 0.07917/9 [======================>.......] - ETA: 3s - loss: 0.2404 - accuracy: 0.3029 - jacard_coef: 0.07948/9 [=========================>....] - ETA: 1s - loss: 0.2325 - accuracy: 0.3153 - jacard_coef: 0.07659/9 [==============================] - ETA: 0s - loss: 0.2321 - accuracy: 0.3148 - jacard_coef: 0.07429/9 [==============================] - 79s 2s/step - loss: 0.2321 - accuracy: 0.3148 - jacard_coef: 0.0742 - val_loss: 0.2286 - val_accuracy: 0.9304 - val_jacard_coef: 0.0536 - lr: 0.0010
Epoch 2/30
1/9 [==>...........................] - ETA: 2s - loss: 0.2584 - accuracy: 0.2974 - jacard_coef: 0.05882/9 [=====>........................] - ETA: 2s - loss: 0.2421 - accuracy: 0.2299 - jacard_coef: 0.05743/9 [=========>....................] - ETA: 2s - loss: 0.2275 - accuracy: 0.1941 - jacard_coef: 0.06524/9 [============>.................] - ETA: 1s - loss: 0.2221 - accuracy: 0.1768 - jacard_coef: 0.07315/9 [===============>..............] - ETA: 1s - loss: 0.2157 - accuracy: 0.1640 - jacard_coef: 0.07426/9 [===================>..........] - ETA: 1s - loss: 0.2109 - accuracy: 0.1570 - jacard_coef: 0.07437/9 [======================>.......] - ETA: 0s - loss: 0.2073 - accuracy: 0.1514 - jacard_coef: 0.07408/9 [=========================>....] - ETA: 0s - loss: 0.2042 - accuracy: 0.1535 - jacard_coef: 0.07659/9 [==============================] - 3s 334ms/step - loss: 0.2040 - accuracy: 0.1536 - jacard_coef: 0.0809 - val_loss: 1.1218 - val_accuracy: 0.9304 - val_jacard_coef: 1.4615e-05 - lr: 0.0010
Epoch 3/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1791 - accuracy: 0.4192 - jacard_coef: 0.08332/9 [=====>........................] - ETA: 2s - loss: 0.1793 - accuracy: 0.4142 - jacard_coef: 0.07973/9 [=========>....................] - ETA: 2s - loss: 0.1783 - accuracy: 0.4384 - jacard_coef: 0.07924/9 [============>.................] - ETA: 1s - loss: 0.1775 - accuracy: 0.4537 - jacard_coef: 0.08035/9 [===============>..............] - ETA: 1s - loss: 0.1772 - accuracy: 0.4525 - jacard_coef: 0.07576/9 [===================>..........] - ETA: 1s - loss: 0.1768 - accuracy: 0.4678 - jacard_coef: 0.07927/9 [======================>.......] - ETA: 0s - loss: 0.1767 - accuracy: 0.4890 - jacard_coef: 0.07908/9 [=========================>....] - ETA: 0s - loss: 0.1763 - accuracy: 0.4978 - jacard_coef: 0.07569/9 [==============================] - 3s 332ms/step - loss: 0.1775 - accuracy: 0.4961 - jacard_coef: 0.0806 - val_loss: 1.1706 - val_accuracy: 0.9270 - val_jacard_coef: 0.0035 - lr: 0.0010
Epoch 4/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1789 - accuracy: 0.3660 - jacard_coef: 0.07362/9 [=====>........................] - ETA: 2s - loss: 0.1775 - accuracy: 0.3836 - jacard_coef: 0.07573/9 [=========>....................] - ETA: 2s - loss: 0.1774 - accuracy: 0.3912 - jacard_coef: 0.06734/9 [============>.................] - ETA: 1s - loss: 0.1772 - accuracy: 0.3883 - jacard_coef: 0.05965/9 [===============>..............] - ETA: 1s - loss: 0.1769 - accuracy: 0.3751 - jacard_coef: 0.06836/9 [===================>..........] - ETA: 1s - loss: 0.1768 - accuracy: 0.3777 - jacard_coef: 0.06777/9 [======================>.......] - ETA: 0s - loss: 0.1765 - accuracy: 0.3907 - jacard_coef: 0.07318/9 [=========================>....] - ETA: 0s - loss: 0.1761 - accuracy: 0.4146 - jacard_coef: 0.07599/9 [==============================] - 3s 332ms/step - loss: 0.1761 - accuracy: 0.4150 - jacard_coef: 0.0737 - val_loss: 1.1755 - val_accuracy: 0.9270 - val_jacard_coef: 0.0035 - lr: 0.0010
Epoch 5/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1746 - accuracy: 0.5404 - jacard_coef: 0.05202/9 [=====>........................] - ETA: 2s - loss: 0.1743 - accuracy: 0.5643 - jacard_coef: 0.06193/9 [=========>....................] - ETA: 2s - loss: 0.1738 - accuracy: 0.5657 - jacard_coef: 0.05844/9 [============>.................] - ETA: 1s - loss: 0.1733 - accuracy: 0.6089 - jacard_coef: 0.06965/9 [===============>..............] - ETA: 1s - loss: 0.1726 - accuracy: 0.6424 - jacard_coef: 0.07246/9 [===================>..........] - ETA: 1s - loss: 0.1723 - accuracy: 0.6714 - jacard_coef: 0.07287/9 [======================>.......] - ETA: 0s - loss: 0.1719 - accuracy: 0.6874 - jacard_coef: 0.07728/9 [=========================>....] - ETA: 0s - loss: 0.1716 - accuracy: 0.6936 - jacard_coef: 0.07619/9 [==============================] - 3s 332ms/step - loss: 0.1720 - accuracy: 0.6900 - jacard_coef: 0.0715 - val_loss: 1.1762 - val_accuracy: 0.9270 - val_jacard_coef: 0.0035 - lr: 0.0010
Epoch 6/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1707 - accuracy: 0.8000 - jacard_coef: 0.07112/9 [=====>........................] - ETA: 2s - loss: 0.1787 - accuracy: 0.4668 - jacard_coef: 0.07883/9 [=========>....................] - ETA: 2s - loss: 0.1776 - accuracy: 0.5177 - jacard_coef: 0.07354/9 [============>.................] - ETA: 1s - loss: 0.1759 - accuracy: 0.5821 - jacard_coef: 0.07215/9 [===============>..............] - ETA: 1s - loss: 0.1749 - accuracy: 0.6240 - jacard_coef: 0.07186/9 [===================>..........] - ETA: 1s - loss: 0.1741 - accuracy: 0.6573 - jacard_coef: 0.07117/9 [======================>.......] - ETA: 0s - loss: 0.1737 - accuracy: 0.6755 - jacard_coef: 0.07288/9 [=========================>....] - ETA: 0s - loss: 0.1733 - accuracy: 0.6899 - jacard_coef: 0.07529/9 [==============================] - 3s 332ms/step - loss: 0.1734 - accuracy: 0.6866 - jacard_coef: 0.0863 - val_loss: 1.1188 - val_accuracy: 0.9268 - val_jacard_coef: 0.0043 - lr: 0.0010
Epoch 7/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1686 - accuracy: 0.7913 - jacard_coef: 0.08992/9 [=====>........................] - ETA: 2s - loss: 0.1693 - accuracy: 0.8058 - jacard_coef: 0.08723/9 [=========>....................] - ETA: 2s - loss: 0.1691 - accuracy: 0.8010 - jacard_coef: 0.08684/9 [============>.................] - ETA: 1s - loss: 0.1688 - accuracy: 0.8123 - jacard_coef: 0.08755/9 [===============>..............] - ETA: 1s - loss: 0.1684 - accuracy: 0.8217 - jacard_coef: 0.08546/9 [===================>..........] - ETA: 1s - loss: 0.1685 - accuracy: 0.8237 - jacard_coef: 0.08427/9 [======================>.......] - ETA: 0s - loss: 0.1685 - accuracy: 0.8305 - jacard_coef: 0.07818/9 [=========================>....] - ETA: 0s - loss: 0.1682 - accuracy: 0.8370 - jacard_coef: 0.07649/9 [==============================] - 3s 332ms/step - loss: 0.1682 - accuracy: 0.8366 - jacard_coef: 0.0682 - val_loss: 0.3791 - val_accuracy: 0.8967 - val_jacard_coef: 0.0445 - lr: 5.0000e-04
Epoch 8/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1654 - accuracy: 0.8646 - jacard_coef: 0.09162/9 [=====>........................] - ETA: 2s - loss: 0.1660 - accuracy: 0.8656 - jacard_coef: 0.08073/9 [=========>....................] - ETA: 2s - loss: 0.1660 - accuracy: 0.8644 - jacard_coef: 0.08144/9 [============>.................] - ETA: 1s - loss: 0.1662 - accuracy: 0.8720 - jacard_coef: 0.07605/9 [===============>..............] - ETA: 1s - loss: 0.1660 - accuracy: 0.8764 - jacard_coef: 0.07396/9 [===================>..........] - ETA: 1s - loss: 0.1661 - accuracy: 0.8738 - jacard_coef: 0.07817/9 [======================>.......] - ETA: 0s - loss: 0.1659 - accuracy: 0.8764 - jacard_coef: 0.07718/9 [=========================>....] - ETA: 0s - loss: 0.1658 - accuracy: 0.8781 - jacard_coef: 0.07649/9 [==============================] - 3s 341ms/step - loss: 0.1658 - accuracy: 0.8779 - jacard_coef: 0.0682 - val_loss: 0.1273 - val_accuracy: 0.8404 - val_jacard_coef: 0.0674 - lr: 5.0000e-04
Epoch 9/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1653 - accuracy: 0.8977 - jacard_coef: 0.08442/9 [=====>........................] - ETA: 2s - loss: 0.1648 - accuracy: 0.8979 - jacard_coef: 0.07693/9 [=========>....................] - ETA: 2s - loss: 0.1647 - accuracy: 0.8994 - jacard_coef: 0.07824/9 [============>.................] - ETA: 1s - loss: 0.1646 - accuracy: 0.9066 - jacard_coef: 0.07395/9 [===============>..............] - ETA: 1s - loss: 0.1645 - accuracy: 0.9037 - jacard_coef: 0.07586/9 [===================>..........] - ETA: 1s - loss: 0.1646 - accuracy: 0.9020 - jacard_coef: 0.07657/9 [======================>.......] - ETA: 0s - loss: 0.1643 - accuracy: 0.8995 - jacard_coef: 0.07938/9 [=========================>....] - ETA: 0s - loss: 0.1641 - accuracy: 0.9044 - jacard_coef: 0.07519/9 [==============================] - 3s 334ms/step - loss: 0.1642 - accuracy: 0.9008 - jacard_coef: 0.0859 - val_loss: 0.1678 - val_accuracy: 0.8897 - val_jacard_coef: 0.0653 - lr: 5.0000e-04
Epoch 10/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1622 - accuracy: 0.9455 - jacard_coef: 0.04062/9 [=====>........................] - ETA: 2s - loss: 0.1614 - accuracy: 0.9367 - jacard_coef: 0.04803/9 [=========>....................] - ETA: 2s - loss: 0.1617 - accuracy: 0.9233 - jacard_coef: 0.05714/9 [============>.................] - ETA: 1s - loss: 0.1624 - accuracy: 0.9081 - jacard_coef: 0.06495/9 [===============>..............] - ETA: 1s - loss: 0.1626 - accuracy: 0.8973 - jacard_coef: 0.06966/9 [===================>..........] - ETA: 1s - loss: 0.1625 - accuracy: 0.8894 - jacard_coef: 0.07127/9 [======================>.......] - ETA: 0s - loss: 0.1624 - accuracy: 0.8831 - jacard_coef: 0.07548/9 [=========================>....] - ETA: 0s - loss: 0.1624 - accuracy: 0.8797 - jacard_coef: 0.07529/9 [==============================] - 3s 334ms/step - loss: 0.1626 - accuracy: 0.8759 - jacard_coef: 0.0817 - val_loss: 0.1685 - val_accuracy: 0.7275 - val_jacard_coef: 0.0647 - lr: 5.0000e-04
Epoch 11/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1612 - accuracy: 0.8905 - jacard_coef: 0.08692/9 [=====>........................] - ETA: 2s - loss: 0.1626 - accuracy: 0.8928 - jacard_coef: 0.08653/9 [=========>....................] - ETA: 2s - loss: 0.1622 - accuracy: 0.8932 - jacard_coef: 0.08514/9 [============>.................] - ETA: 1s - loss: 0.1620 - accuracy: 0.8986 - jacard_coef: 0.08035/9 [===============>..............] - ETA: 1s - loss: 0.1621 - accuracy: 0.8869 - jacard_coef: 0.08046/9 [===================>..........] - ETA: 1s - loss: 0.1620 - accuracy: 0.8931 - jacard_coef: 0.07547/9 [======================>.......] - ETA: 0s - loss: 0.1617 - accuracy: 0.8942 - jacard_coef: 0.07708/9 [=========================>....] - ETA: 0s - loss: 0.1615 - accuracy: 0.8976 - jacard_coef: 0.07619/9 [==============================] - 3s 337ms/step - loss: 0.1617 - accuracy: 0.8947 - jacard_coef: 0.0718 - val_loss: 0.1579 - val_accuracy: 0.9173 - val_jacard_coef: 0.0646 - lr: 5.0000e-04
Epoch 12/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1608 - accuracy: 0.8767 - jacard_coef: 0.09482/9 [=====>........................] - ETA: 2s - loss: 0.1610 - accuracy: 0.8803 - jacard_coef: 0.09143/9 [=========>....................] - ETA: 2s - loss: 0.1610 - accuracy: 0.8817 - jacard_coef: 0.09194/9 [============>.................] - ETA: 1s - loss: 0.1607 - accuracy: 0.8920 - jacard_coef: 0.08425/9 [===============>..............] - ETA: 1s - loss: 0.1606 - accuracy: 0.9010 - jacard_coef: 0.07356/9 [===================>..........] - ETA: 1s - loss: 0.1604 - accuracy: 0.9015 - jacard_coef: 0.07497/9 [======================>.......] - ETA: 0s - loss: 0.1603 - accuracy: 0.9025 - jacard_coef: 0.07538/9 [=========================>....] - ETA: 0s - loss: 0.1603 - accuracy: 0.9031 - jacard_coef: 0.07569/9 [==============================] - 3s 340ms/step - loss: 0.1603 - accuracy: 0.9032 - jacard_coef: 0.0733 - val_loss: 0.1594 - val_accuracy: 0.9228 - val_jacard_coef: 0.0647 - lr: 5.0000e-04
Epoch 13/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1590 - accuracy: 0.9057 - jacard_coef: 0.07832/9 [=====>........................] - ETA: 2s - loss: 0.1591 - accuracy: 0.9075 - jacard_coef: 0.07683/9 [=========>....................] - ETA: 2s - loss: 0.1593 - accuracy: 0.8928 - jacard_coef: 0.07344/9 [============>.................] - ETA: 1s - loss: 0.1596 - accuracy: 0.8892 - jacard_coef: 0.07825/9 [===============>..............] - ETA: 1s - loss: 0.1596 - accuracy: 0.8894 - jacard_coef: 0.07606/9 [===================>..........] - ETA: 1s - loss: 0.1600 - accuracy: 0.8871 - jacard_coef: 0.07667/9 [======================>.......] - ETA: 0s - loss: 0.1599 - accuracy: 0.8882 - jacard_coef: 0.07578/9 [=========================>....] - ETA: 0s - loss: 0.1598 - accuracy: 0.8900 - jacard_coef: 0.07619/9 [==============================] - 3s 340ms/step - loss: 0.1598 - accuracy: 0.8908 - jacard_coef: 0.0680 - val_loss: 0.1578 - val_accuracy: 0.9211 - val_jacard_coef: 0.0647 - lr: 5.0000e-04
Epoch 14/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1595 - accuracy: 0.9306 - jacard_coef: 0.06302/9 [=====>........................] - ETA: 2s - loss: 0.1588 - accuracy: 0.9249 - jacard_coef: 0.06793/9 [=========>....................] - ETA: 2s - loss: 0.1589 - accuracy: 0.9204 - jacard_coef: 0.07204/9 [============>.................] - ETA: 1s - loss: 0.1587 - accuracy: 0.9160 - jacard_coef: 0.07545/9 [===============>..............] - ETA: 1s - loss: 0.1587 - accuracy: 0.9165 - jacard_coef: 0.07526/9 [===================>..........] - ETA: 1s - loss: 0.1584 - accuracy: 0.9211 - jacard_coef: 0.07147/9 [======================>.......] - ETA: 0s - loss: 0.1584 - accuracy: 0.9162 - jacard_coef: 0.07528/9 [=========================>....] - ETA: 0s - loss: 0.1582 - accuracy: 0.9159 - jacard_coef: 0.07549/9 [==============================] - 3s 340ms/step - loss: 0.1589 - accuracy: 0.9129 - jacard_coef: 0.0829 - val_loss: 0.1613 - val_accuracy: 0.9091 - val_jacard_coef: 0.0648 - lr: 2.5000e-04
Epoch 15/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1581 - accuracy: 0.9099 - jacard_coef: 0.07202/9 [=====>........................] - ETA: 2s - loss: 0.1592 - accuracy: 0.9045 - jacard_coef: 0.07093/9 [=========>....................] - ETA: 2s - loss: 0.1594 - accuracy: 0.9034 - jacard_coef: 0.07104/9 [============>.................] - ETA: 1s - loss: 0.1593 - accuracy: 0.8987 - jacard_coef: 0.07315/9 [===============>..............] - ETA: 1s - loss: 0.1597 - accuracy: 0.8945 - jacard_coef: 0.07496/9 [===================>..........] - ETA: 1s - loss: 0.1594 - accuracy: 0.8965 - jacard_coef: 0.07447/9 [======================>.......] - ETA: 0s - loss: 0.1593 - accuracy: 0.8986 - jacard_coef: 0.07318/9 [=========================>....] - ETA: 0s - loss: 0.1598 - accuracy: 0.8942 - jacard_coef: 0.07599/9 [==============================] - 3s 340ms/step - loss: 0.1600 - accuracy: 0.8895 - jacard_coef: 0.0735 - val_loss: 0.1590 - val_accuracy: 0.9242 - val_jacard_coef: 0.0651 - lr: 2.5000e-04
Epoch 16/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1595 - accuracy: 0.8904 - jacard_coef: 0.08002/9 [=====>........................] - ETA: 2s - loss: 0.1591 - accuracy: 0.8956 - jacard_coef: 0.07373/9 [=========>....................] - ETA: 2s - loss: 0.1591 - accuracy: 0.8928 - jacard_coef: 0.07304/9 [============>.................] - ETA: 1s - loss: 0.1594 - accuracy: 0.8900 - jacard_coef: 0.07305/9 [===============>..............] - ETA: 1s - loss: 0.1594 - accuracy: 0.8921 - jacard_coef: 0.07226/9 [===================>..........] - ETA: 1s - loss: 0.1595 - accuracy: 0.8909 - jacard_coef: 0.07227/9 [======================>.......] - ETA: 0s - loss: 0.1596 - accuracy: 0.8886 - jacard_coef: 0.07328/9 [=========================>....] - ETA: 0s - loss: 0.1594 - accuracy: 0.8885 - jacard_coef: 0.07529/9 [==============================] - 3s 340ms/step - loss: 0.1595 - accuracy: 0.8880 - jacard_coef: 0.0817 - val_loss: 0.1568 - val_accuracy: 0.9232 - val_jacard_coef: 0.0648 - lr: 2.5000e-04
Epoch 17/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1600 - accuracy: 0.8887 - jacard_coef: 0.08482/9 [=====>........................] - ETA: 2s - loss: 0.1590 - accuracy: 0.8960 - jacard_coef: 0.08013/9 [=========>....................] - ETA: 2s - loss: 0.1588 - accuracy: 0.9070 - jacard_coef: 0.07244/9 [============>.................] - ETA: 1s - loss: 0.1586 - accuracy: 0.9076 - jacard_coef: 0.07345/9 [===============>..............] - ETA: 1s - loss: 0.1586 - accuracy: 0.9077 - jacard_coef: 0.07436/9 [===================>..........] - ETA: 1s - loss: 0.1584 - accuracy: 0.9079 - jacard_coef: 0.07497/9 [======================>.......] - ETA: 0s - loss: 0.1585 - accuracy: 0.9085 - jacard_coef: 0.07498/9 [=========================>....] - ETA: 0s - loss: 0.1585 - accuracy: 0.9077 - jacard_coef: 0.07619/9 [==============================] - 3s 339ms/step - loss: 0.1585 - accuracy: 0.9079 - jacard_coef: 0.0730 - val_loss: 0.1561 - val_accuracy: 0.9233 - val_jacard_coef: 0.0648 - lr: 2.5000e-04
Epoch 18/30
1/9 [==>...........................] - ETA: 2s - loss: 0.1585 - accuracy: 0.8862 - jacard_coef: 0.09492/9 [=====>........................] - ETA: 2s - loss: 0.1576 - accuracy: 0.8919 - jacard_coef: 0.08663/9 [=========>....................] - ETA: 2s - loss: 0.1581 - accuracy: 0.8959 - jacard_coef: 0.08214/9 [============>.................] - ETA: 1s - loss: 0.1578 - accuracy: 0.8935 - jacard_coef: 0.08105/9 [===============>..............] - ETA: 1s - loss: 0.1576 - accuracy: 0.8957 - jacard_coef: 0.07796/9 [===================>..........] - ETA: 1s - loss: 0.1575 - accuracy: 0.8963 - jacard_coef: 0.07767/9 [======================>.......] - ETA: 0s - loss: 0.1573 - accuracy: 0.8949 - jacard_coef: 0.07858/9 [=========================>....] - ETA: 0s - loss: 0.1570 - accuracy: 0.8979 - jacard_coef: 0.07629/9 [==============================] - 3s 340ms/step - loss: 0.1571 - accuracy: 0.8952 - jacard_coef: 0.0686 - val_loss: 0.1555 - val_accuracy: 0.9237 - val_jacard_coef: 0.0648 - lr: 2.5000e-04
/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(

âœ“ Training completed successfully!
  Best Val Jaccard: 0.0674 (epoch 8)
  Final Val Loss: 0.1555
  Training Time: 0:02:12.121523
  Stability (std): 0.0044

Results saved to: hyperparameter_optimization_20250926_123742/exp_17_Attention_UNet_lr5e-4_bs16/Attention_UNet_lr0.0005_bs16_results.json
